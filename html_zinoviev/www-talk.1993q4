From marca@ncsa.uiuc.edu  Thu Sep 30 18:34:11 1993 -0500
Message-Id: <9309302334.AA24315@wintermute.ncsa.uiuc.edu>
Date: Thu, 30 Sep 93 18:34:11 -0500
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: www clients and dns

It seems to be the experience of quite a few Mosaic 2.0pre4 users (now
that the status line tells you exactly what's happening at each stage
of a connection and data transfer) that DNS hostname lookups often
take a very long time in relation to the actual time needed for the
connection and data transfer.

This brings up an interesting question: should we therefore maintain a
cache of hostnames and IP addresses on the client side to try to paper
this (non-Mosaic) problem over, or should we leave it up to DNS to be
fast or slow as it wishes at each installation and put the burden on
the DNS and network admins to make sure it gets faster if users are
unhappy?

Marc




From montulli@stat1.cc.ukans.edu  Thu Sep 30 19:30:00 1993 CDT
Message-Id: <9310010030.AA13183@stat1.cc.ukans.edu>
Date: Thu, 30 Sep 93 19:30:00 CDT
From: montulli@stat1.cc.ukans.edu (Lou Montulli)
Subject: Mailto: URL's and other things

For those of you who currently support mailto: URL's and those
of you adding it, I have a suggestion. 

I (Lynx) has been including the URL of the document that the message was
sent from within the subject, but I realized that there is a much better 
way.  We should agree upon an "x-" header and always include the
URL as part of the message header.  Something like "x-within-URL:"

The reason that this is important is that many times a mailto: URL
will be used within <link rev=made> tags which specify the owner
of the document.  A user can then send a comment directly to
the document owner from within the Web browser.  The only problem
is that a lot messages look like this:

    You misspelled the word "unique" on line 5 of this file.

If the URL is not included by the browser, the recipient of the 
message has little chance of finding the document in question if
they maintain a large number.

Another useful thing that could be done when knowing the URL is
to use mailto: links as a primitive query mechanisim.  A file
might say: click here and send us your home address for a 
free copy by mail.  Since the URL is included a program can uniquely
identify the product to be mailed.  A commonly known x- resource
header is needed for a program to scan the correct header for the URL.

I would like to hear other suggestions on how this should be done if
there is a better way.  I would also like to hear some people come up with
a better x header, since I came up with "x-within-URL" with
about 2 seconds of continuous thought.

:lou
-- 
  **************************************************************************
  *           T H E   U N I V E R S I T Y   O F   K A N S A S              *
  *         Lou  MONTULLI @ Ukanaix.cc.ukans.edu                           *
  *                         Kuhub.cc.ukans.edu      ACS Computing Services *
  *     913/864-0436        Ukanvax.bitnet             Lawrence, KS 66044  *
  *             UNIX! Cool! I know that!  Jurassic Park - The Movie        *
  **************************************************************************



From masinter@parc.xerox.com  Fri Oct  1 00:45:52 1993 PDT
Message-Id: <93Oct1.004554pdt.2794@golden.parc.xerox.com>
Date: Fri, 1 Oct 1993 00:45:52 PDT
From: masinter@parc.xerox.com (Larry Masinter)
Subject: are there any www tools that can browse ftp.cu.nih.gov?

I was going to put a link to this, but I can't get anything (lynx, www
linemode, telnet to info.cern.ch, or even gopher/ftp gateways) to 
be able to browse 'ftp.cu.nih.gov'.

Even linking directly to one of the files is a bit problematic.
My copy of the linemode browser seems to retrieve it in binary
(EBCDIC?) although info.cern.ch gets the first part OK in ascii.



The Center for Electronic Records of the U.S. National Archives has
updated the FTP-able file containing the Center's "Title List: A
Preliminary and Partial Listing of the Data Files in the National
Archives and Records Administration" (TITLE.LIST.SEP2893).  The FTP
directory can be accessed by FTPing to FTP.CU.NIH.GOV
(128.231.64.7).  Log on as an anonymous user; press enter (or enter
your user name or 'guest') at password prompt.  The directory in
which this information is stored is NARA_ELECTRONIC (CD
NARA_ELECTRONIC); it contains six files.  Use the FTP GET command to
retrieve copies of the files, as in GET TITLE.LIST.SEP2893.



From dsr@hplb.hpl.hp.com  Fri Oct  1 10:49:17 1993 BST
Message-Id: <9310010949.AA00974@manuel.hpl.hp.com>
Date: Fri, 1 Oct 93 10:49:17 BST
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: The new draft of HTML+

Redrafting HTML+
================

Marc writes as a reason for wanting HTML+ to be backwards compatible
with HTML:

> It makes it easy to evolve the browsers over time rather than
> try to do a complete implementation of HTML+ at one time (which,
> as discussed at WWWWW, isn't likely in the near future).

OK, I am currently trying to support that, e.g. making character emphasis
match the HTML model rather than overloading <EM> and putting REV and
REL in place of ROLE for <A> and <LINK>. People can treat <P> as a
separator or as a container. <BR> is in but is deprecated in favor of
<LIT> which is a proportional font version of <PRE> and suitable for
stuff like poetry with significant leading spaces. Some elements in HTML
have been dropped in favor of cleaner constructs, but in the transition
period browsers can support both. The new draft is full of examples and
will be available very soon - I have been furiously typing all week.

The new version of HTML+ is simpler and cleaner!

Dave Raggett



From dsr@hplb.hpl.hp.com  Fri Oct  1 10:49:17 1993 BST
Message-Id: <9310010949.AA00974@manuel.hpl.hp.com>
Date: Fri, 1 Oct 93 10:49:17 BST
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: The new draft of HTML+

Redrafting HTML+
================

Marc writes as a reason for wanting HTML+ to be backwards compatible
with HTML:

> It makes it easy to evolve the browsers over time rather than
> try to do a complete implementation of HTML+ at one time (which,
> as discussed at WWWWW, isn't likely in the near future).

OK, I am currently trying to support that, e.g. making character emphasis
match the HTML model rather than overloading <EM> and putting REV and
REL in place of ROLE for <A> and <LINK>. People can treat <P> as a
separator or as a container. <BR> is in but is deprecated in favor of
<LIT> which is a proportional font version of <PRE> and suitable for
stuff like poetry with significant leading spaces. Some elements in HTML
have been dropped in favor of cleaner constructs, but in the transition
period browsers can support both. The new draft is full of examples and
will be available very soon - I have been furiously typing all week.

The new version of HTML+ is simpler and cleaner!

Dave Raggett



From marca@ncsa.uiuc.edu  Fri Oct  1 00:51:25 1993 -0500
Message-Id: <9310010551.AA25473@wintermute.ncsa.uiuc.edu>
Date: Fri, 1 Oct 93 00:51:25 -0500
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: problem: type/* content-types and HTTP/1.0

The latest CERN server seems to not recognize that when a client says
it accepts "image/*" or the like that "image/gif" and "image/jpeg"
etc. are indeed accepted.

This doesn't seem to be explicitly spelled out one way or the other in
the HTTP/1.0 spec, but the mailcap spec makes it pretty explicit --
"If the subtype is specified as "*", it is intended to match all
subtypes of the named content-type."

I'd strongly encourage adoption of this methodology by HTTP/1.0 and
the servers, as it makes the user's life much easier and it makes it
possible for browsers to conform to RFC 1343.

Marc




From henrich@crh.cl.msu.edu  Fri Oct  1 10:16:56 1993 -0400 (EDT)
Message-Id: <9310011416.AA18180@crh.cl.msu.edu>
Date: Fri, 1 Oct 1993 10:16:56 -0400 (EDT)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: New tag (or old?)

I dont remember, is there a <sep>erator tag in html+?  If there isnt, Id like
to propose it, as many people these days are doing <img src="/groove.gif">
which doesnt translate very well to non graphical browsers (and not always
graphical if the sizes are wrong).  How about a format like:

<sep style> where style is groove, bump, wide etc...  Can be ignored for
            non graphical browsers, who could at least stuff in a dashed line..

-Crh



From appel@cih.hcuge.ch  Fri Oct  1 15:50:05 1993 +0100
Message-Id: <1082*/S=appel/OU=cih/O=hcuge/PRMD=switch/ADMD=arcom/C=ch/@MHS>
Date: Fri, 1 Oct 1993 15:50:05 +0100
From: appel@cih.hcuge.ch (Ron D. Appel)
Subject: log analysis tools

Doeas anybody have some programs to analyse the logs for the NCSA httpd,
like how many accesses per day, what host access how many times, etc?

Thanks.

-------------------------------------------------------------------------
| Ron D. Appel                             | Tel.:   (+41 22) 372 6264  |
| Hopital Cantonal Universitaire de Geneve | Fax.:   (+41 22) 372 6198  |
| Centre d'Informatique Hospitaliere       | e-mail: appel@cih.hcuge.ch |
| 24, rue Micheli-du-Crest                 |   (S=appel;OU=cih;O=hcuge; |
| CH-1211 Geneve 14                        |    P=switch;A=arcom;C=ch)  |
| Switzerland                              |                            |
-------------------------------------------------------------------------



From dcmartin@library.ucsf.edu  Fri Oct  1 09:21:51 1993 PDT
Message-Id: <199310011625.AA18022@library.ucsf.edu>
Date: Fri, 01 Oct 1993 09:21:51 PDT
From: dcmartin@library.ucsf.edu (David C. Martin)
Subject: Re: www clients and dns 

I agree, but you may want to invalidate the members of the cache after a
certain period of time to avoid DNS mismatch.  This may also be
something that could be folded into the authorization layer.

dcm
--------
Marc Andreessen writes:

It seems to be the experience of quite a few Mosaic 2.0pre4 users (now
that the status line tells you exactly what's happening at each stage
of a connection and data transfer) that DNS hostname lookups often
take a very long time in relation to the actual time needed for the
connection and data transfer.

This brings up an interesting question: should we therefore maintain a
cache of hostnames and IP addresses on the client side to try to paper
this (non-Mosaic) problem over, or should we leave it up to DNS to be
fast or slow as it wishes at each installation and put the burden on
the DNS and network admins to make sure it gets faster if users are
unhappy?

Marc





From dsr@hplb.hpl.hp.com  Fri Oct  1 17:29:32 1993 BST
Message-Id: <9310011629.AA06082@manuel.hpl.hp.com>
Date: Fri, 1 Oct 93 17:29:32 BST
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: New tag (or old?)

> I dont remember, is there a <sep>erator tag in html+?  If there isnt, Id like
> to propose it, as many people these days are doing <img src="/groove.gif">
> which doesnt translate very well to non graphical browsers (and not always
> graphical if the sizes are wrong).  How about a format like:

> <sep style> where style is groove, bump, wide etc...  Can be ignored for
>        non graphical browsers, who could at least stuff in a dashed line..

I haven't seen this myself, but do you mean a horizontal line that separates
two sections of text? If so the anwser is yes: <HR> for horizontal rule,
which leaves the precise appearence up to the browser.

Dave



From hgs@research.att.com  Fri Oct  1 12:59:17 1993 EDT
Message-Id: <9310011700.AA05479@dxmint.cern.ch>
Date: Fri, 1 Oct 93 12:59:17 EDT
From: hgs@research.att.com (Henning G. Schulzrinne)
Subject: Re: www clients and dns

DNS already caches replies. Having two caches with roughly the same
functionality except that one is only populated for a small fraction
of the name queries (www), but with different time-outs and weird
consistency issues, unless the www cache times out well before the
shortest DNS time out.

---
Henning Schulzrinne (hgs@research.att.com)
AT&T Bell Laboratories  (MH 2A-244)
600 Mountain Ave; Murray Hill, NJ 07974
phone: +1 908 582-2262; fax: +1 908 582-5809




From phillips@cs.ubc.ca  Mon Oct  1 11:09:00 1993 -0700
Message-Id: <6437*phillips@cs.ubc.ca>
Date: 1 Oct 93 11:09 -0700
From: phillips@cs.ubc.ca (George Phillips)
Subject: New tag (or old?)

Charles Henrich said:
>I dont remember, is there a <sep>erator tag in html+?  If there isnt, Id like
>to propose it, as many people these days are doing <img src="/groove.gif">
>which doesnt translate very well to non graphical browsers (and not always
>graphical if the sizes are wrong).

I saw Dave's answer that <HR> does the trick for HTML+.  For ordinary
HTML, something like <IMG SRC=groove.gif ALT=_____________________________>
should work reasonably well.



From henrich@crh.cl.msu.edu  Fri Oct  1 14:21:53 1993 -0400 (EDT)
Message-Id: <9310011821.AA18831@crh.cl.msu.edu>
Date: Fri, 1 Oct 1993 14:21:53 -0400 (EDT)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: New tag (or old?)

>I haven't seen this myself, but do you mean a horizontal line that separates
>two sections of text? If so the anwser is yes: <HR> for horizontal rule,
>which leaves the precise appearence up to the browser.

Ah.  May we add a style to the <hr> tag?  Im trying to keep folks who all like
different line styles from using GIF's as the break.

-Crh



From hoesel@chem.rug.nl  Fri Oct  1 22:01:26 1993 +0100 (DST)
Message-Id: <9310012001.AA03182@Xtreme>
Date: Fri, 1 Oct 1993 22:01:26 +0100 (DST)
From: hoesel@chem.rug.nl (frans van hoesel)
Subject: Re: www clients and dns

> 
> DNS already caches replies. Having two caches with roughly the same
> functionality except that one is only populated for a small fraction
> of the name queries (www), but with different time-outs and weird
> consistency issues, unless the www cache times out well before the
> shortest DNS time out.
> 
I'm not much of an expert, but my host is on a slip line to the university
and what happens here is that it tries to do a local search (which
always fails), before doing the bind request over the slipline to the
name server, this request is slow.

- frans





From vinay@eit.com  Fri Oct  1 15:16:01 1993 PDT
Message-Id: <9310012216.AA10933@eit.COM>
Date: Fri, 1 Oct 93 15:16:01 PDT
From: vinay@eit.com (Vinay Kumar)
Subject: slideshow-1.2 now available

"ss" or slideshow Ver1.2 is now available by anonymous ftp from:

	eitech.eit.com	(192.100.58.2)
under
	/pub/share/ss-1.2.tar.Z

Usage:
	ss [filename]

where, [filename] is an ascii text file containing all the URL's (Details 
included in the distribution).

The following new options have been added:

 h (H, ?)               to display this message.
 d (D)                  to show all the slides on STDOUT.
 n (N, <Return>)        to view next slide in XMosaic.
 p (P)                  to view previous slide.
 l (L)                  to view the last slide.
 f (F)                  to view the first slide.
 q (Q)                  to quit this slideshow session.
 #			to jump to a specific slide number # (e.g. 0,1,5,2..).

Thanks to Kevin Altis@Intel for suggestions and helping me out in testing 
some of this stuff.

--
  Vinay Kumar
vinay@collage.eit.com






From andym@inrird.com  Fri Oct  1 16:36:44 1993 -0700 (PDT)
Message-Id: <m0oiu1l-00000uC@inrird.com>
Date: Fri, 1 Oct 1993 16:36:44 -0700 (PDT)
From: andym@inrird.com (Andy Micone)
Subject: DNS and Mosaic

Marc Wrote:
"DNS hostname lookups often take a very long time in relation to the
actual time needed for the
connection and data transfer. should we therefore maintain a cache of
hostnames and IP addresses on the client side to try to paper this
(non-Mosaic) problem over?"

Well my first reaction is don't do it, because any Administrator who
doesn't run DNS so it caches  addresses is just asking for performance
problems. We, for example, connect to the internet through a 14.4K
modem, it's pretty slow. Hostname lookups, however, aren't one of our
problems since one machine on the local LAN caches address lookups.
It's the Administrator's job to resolve log-jams like this, at least
that's my philosophy.

It is, however, off-putting for a user to have to wait to for anything
to come up on a computer. In the real world you can just turn to the
footnote in the back of the book, or stare down at the bottom of the
page. A computer lookup of a link should take no less time. The
acceptance of a technology is often based on how easy it is to access,
and a user does not care, nor is knowledgable about how things happen,
they just should happen as quickly as possible.  The web is an
important technology, and I think people working with it should make
every effort to speed its acceptance. Further, some users may be using
a slow link to the Internet through SLIP on non-UNIX machines, so
local DNS isn't an option for them. 

I conclude, therefore, for non-Unix versions, definitely cache,
because its more than likely there will be no caching options locally.
For Unix versions it's a toss-up, my guess is that fewer people would
gain by its inclusion than would benefit by having DNS setup correctly
for their local cluster.

-- Andy



From jallard@microsoft.com  Fri Oct  1 17:45:20 1993
Message-Id: <9310020129.AA01830@netmail.microsoft.com>
Date: Fri, 01 Oct 93 17:45:20 
From: jallard@microsoft.com (jallard@microsoft.com)
Subject: Re: DNS and Mosaic


Andy> Well my first reaction is don't do it, because any Administrator 
Andy> who doesn't run DNS so it caches  addresses is just asking for 
Andy> performance problems. We, for example, connect to the internet 
Andy> through a 14.4K modem, it's pretty slow. Hostname lookups, 
Andy> however, aren't one of our problems since one machine on the local 
Andy> LAN caches address lookups. It's the Administrator's job to 
Andy> resolve log-jams like this, at least that's my philosophy. 

you're making a couple of assumptions that might not be valid for all 
environments: 

a) the dns services available to a user are administered by their 
organization

b) the local dns services implement their own caching scheme.

in tommorow's world of dialup/isdn/cable from-the-home internet 
connectivity assertion (a) fails. as for (b), many smaller organizations 
run pc-based dns servers which generally do not cache, frequently 
referring rather than recursing queries.

that said, i would think that it wouldn't be the end of the world if a 
client could choose to postpend www hostname resolution results in their 
/etc/hosts (or equivalent hosttable store) if said option was enabled. 
in fact, some people might think it was nice.

a good place to ask this question might be comp.protocols.tcp-ip.ibmpc, 
where some of the less powerful hostname resolution schemes are better 
understood.

_______________________________________________________________
J. Allard                                 jallard@microsoft.com
Program Manager of TCP/IP Technologies    work: (206)882-8080
Microsoft Corporation                     home: (206)860-8862







From winograd@interval.com  Sat Oct  2 10:35:45 1993 -0800
Message-Id: <9310021735.AA29337@interval.interval.com>
Date: Sat, 2 Oct 1993 10:35:45 -0800
From: winograd@interval.com (Terry Winograd)
Subject: Re: URN single or multiple variants (was: four-part harmony?)

At 12:46 AM 9/23/93 -0700, John A. Kunze wrote:
>
>Foundation premises.  See if you can sing these verses, or maybe hum along:
>

There's starting to be a nice melody there...

>(1) Documents, images, and other objects may be closely related enough that
>    many people would agree they have the "same intellectual content".  An
>    absolute or universal concept of "sameness", however, does not concern
>    us since it's a Very Hard Problem and a Very Big Meeting Time Sink.

Definitely!

>(2) Instead we're interested in "Who says What is the same or different".
>    That way users benefit from different points of view, but they know
>    whose point of view it is.  Users will need more than one point of
>    view because Entity A may have an opinion about objects X and Y, but
>    not about Z, which Entity B may have an opinion about.

Point of view is not the same as an entity. A single person takes different
points of view for different purposes.   From one of my own poinst of view
two versions of the same document have the "same intellectual content"
while from another point of view they don't.
>
>(3) An entity that has an opinion on this subject (I'll call it an
>    IdAuthority for now -- I can't find the URN paper) can be anybody
>    in principle; familiar examples will be publishers and libraries.

Even more familiar examples are people (like a department administrator or
working group secretary) who make materials available on the net by
sticking them in an FTP directory, Gopher server, etc.  That is, I think we
shouldn't focus on the heavyweight institutional players and lose sight of
the fact that their current roles are going to be chopped up and
distributed around the net.

>(4) Two entities may have different opinions about any set of objects.

One entity may have different opinions from different points of view, as well.

>(5) The creator or owner (whatever that means) of an object may be one of
>    several IdAuthorities for that object, or it may not be an IdAuthority.

Yes.  There will be a spectrum of IdAuthorities, with the low end being "I
am my own ID authority for what I put on the net" and the high end being
"The Official International Government Poobah Everything Registration
Authority".  People will choose (and at times pay for) a level of authority
that fits their needs.  Homebrew is fine for sharing documents in a group
(but still needs to follow the semantics of identifiers, locators, etc. in
a consistent way).  Higher levels bring more guarantees that the URNs will
be translatable to URLs via standard services, that the URLs won't point
into empty space, that the items will still be accessible a few centuries
from now, etc. (this means that the same authority organizations will
likely be providing services for access, storage, archiving, etc.)

 I think it is useful to make some distinctions between the ORIGINATOR of
an information object, a PROVIDER of the object, the AUTHORITY of a URN and
the DECLARER of that URN:

    ORIGINATOR: actually produces the object. May or may not have further
        rights.  (this is close to what we think of as "author"

    PROVIDER: makes an object accessible electronically (this could be
        generalized to handle other modes, but let's stop at that for now).
       Any one object may be provided by any number of providers.  The
      provider may be the originator, the originator's institution,
       a library, publisher, archive, etc.  A URLs specifies an object with
        respect to a particular provider.

    AUTHORITY: assigns URNs, as in JAK's message.  An authority may
        do so without ever seeing the document, providing it, knowing what
       is in it, etc.  Typically the use of a particular authority will go
along with
        the presence of lookup catalogs and the like.

    DECLARER: an entity which requests an object (under a particular
        point of view) be given a name by an authority.
        the declarer is the arbiter of what constitutes
        "same content" for that object.

In simple cases these collapse into one.  If I put a file on a server, send
you a locator, and a unique name that I made up, I am doing all of the
above.  In a fully disaggregated case, I write something (ORIGINATOR), my
boss (DECLARER) decides to make my version available to the world by
sending off for an official identifier from some trade-association
(AUTHORITY), and by shipping the bits to FindItHere.com (PROVIDER), which
sends back a URL and a monthly invoice for making the bits available on the
net.

>(6) An IdAuthority assigns a unique string (call it an IdDesignator for now)
>    to each object that is "intellectually different" in its view.  The
>    IdAuthority name plus the IdDesignator make up a URN.

When it is an "authority for hire" the view will be that of the declarer,
not the authority. The authority is just there to serve.

>(7) The IdDesignator string is "officially" opaque, in the sense that it
>    has no shared semantics across all URNs, *even* if it is widely known
>    how to crack some of them (e.g., a Library of Congress catalog number).

It isn't clear whether "unofficial nonopacity" should be encouraged.  It
allows for neat shortcuts in the short run, but leaves lots of problems
later, when it is desirable to unify different designator schemes, and
previous software built on the "unofficial" stuff stops working.

>Now for the baby step premises (building on the foundation premises).
>
>(8) One URN may designate a set of "intellectually equivalent" objects
>    (to the IdAuthority) or may designate just one object.

Yes, but.  This assumes that "one object" is well defined.  I think it is
better to always think in terms of equivalence classes.  I'm not even sure
whether you intended the equivalence class for "one object" to mean bitwise
equivalence, or would allow for encodings, different file system
conventions, and the like.  If we give up the idea that there is an
inherent notion of "real" sameness, things get easier.

>(9) If a URN designates a set of objects, individual objects in the set are
>    called "variants" with respect to that URN.

Reword:  When distinct subsets can be identified within the class
designated by a URN, the equivalence classes associated with those subsets
are "variants" of the one designated by the URN.
>
>(10)Variants may be derived from all sorts of transformations of one object
>    into another, either by machine or by hand, but we don't deal with that
>    Very Hard Problem.

Yes.

>(11)Instead we only need to know how to tell one variant from another in
>    the set of variants (intellectually equivalent objects).  A string
>    (which I'll call a "variant specifier") is used to identify a variant.

This is a syntactic device, which can be used in various ways. I interpret
it as "The base URN will uniquely determine the equivalence class, and the
string is anything that can be read by any program which will allow it to
determine a subclass."  The good news is that you can do anything with it.
The bad news, is that everyone will want to do something different.

>(12)A variant specifer is *not* carried below the URN level.  So a variant
>    specifier never meets a URL.  Instead a lookup of the <URN plus variant
>    specifier> produces a URL for that particular variant.  This Very
>    Common Mistake wastes vast quantities of discussion time.

Yes, although I would also allow URN + specifier to produce a new URN (for
the relevant subset), as either Tim or John said in the following (It gets
hard to keep track of the nesting level):

>> **NO**. This is more like contraphrasing me.  I don't believe in
>> variant specifiers, so I wouln't have said that.  I can imagine
>> saying "Give me a URN for a postscript version of document <urn>".
>> I can imagine saying "Give my a URN for a 600x300 pixel 5-colour GIF
>> of document <urn>".  I can imagine there being an infinite
>> number of possible variants on a document, so I wouldn't ask for a list.
>> But what I would get would be another, more specific, URN.
>>

Note that in cases like this, you will start with a fairly "heavyweight"
URN (e.g., the one registerd with the Library of Congress for the document"
and get in turn a lightweight one (the authority is the same server that
will be the provider, and the URN will be "virtual" in the sense that it is
generated from the description acoording to some convention used by that
authority, and not saved.

>(13)To paraphrase Tim, given a URN you should be able to ask some server
>    to return you one or more variant specifiers, one for each variant.
>    You select the variant you want, and pass it off together with the
>    URN when you need to lookup the corresponding URL.

Sounds right, with the providso that "one for each variant" means "one for
each of the variants in the set you ask for" rather than "one for each
possible variant".  I might ask for all the different formats of a
document, but what it would send back is a variant URN for each of the ones
it is willing to provide, not each of the ones that might in principle be
generated.

>(14)For various reasons (e.g., optimization), you may get a variant
>    specifier at the same time as the URN and packaged together with it.

Yes, or you may get a URN for the subclass designated by the variant, or
both.  That is, an embedded reference may include any number of URNs for
different variants (properly identified), so that the client that runs
across it can simply go get the right one.  Or it may have a single URN for
the larger class, and the client needs to do dynamic lookup of the kind
described in the previous section to find out what variants (e.g., formats)
are available.  The language for embedding pointers should be flexible
enough to allow this.

>(15)If you like the variant specifier, you may use it without needing
>    to looking up other variants.
>
>(16)If you don't like the variant specifier, you may want to go ahead
>    and look up the other variants to see what else is available.
>
>(17)The variant specifier is thus a thing that optionally accompanies
>    a URN, at the same level in our UR* scheme of things.
>
>(18)We need a new member of the UR* family for variants.  How about URV?

This is movement towards making the "string" have more semantics.  This is
the hard part that deals with all of the different ways in which things
vary.  The URV has the function of "Given a URN plus the description
contained in the URV, produce either a new URN or a URL that points to an
object meeting the description."  This requires a full-fledged descriptive
language to do it right.  A small vocabulary of "variant types" or "link
types" may be a useful taxonomy for starting, but isn't the real thing.  It
is more like "attributes," which can be used as a general representation
for relationships.

--t





From hotsand!ellson  Sat Oct  2 13:42:14 1993 EDT
Message-Id: <9310021742.AA20293@hotsand.dacsand>
Date: Sat, 2 Oct 93 13:42:14 EDT
From: hotsand!ellson (John Ellson)
Subject: env vars for server side includes?

This question is primarily for the ncsa-httpd developers, but also
for Tony Sanders if he would consider implementing server side
includes into plexus.

I'd like to put the last-modified date of the html file into the display.
Is there a way to obtain the full pathname of the current html file to pass 
to a program?

I'm thinking perhaps an environment variable set by the server 
daemon so that I can do something like:

  Last modified: <inc srv "|ls -l $HTML_PATHNAME |awk '{print $5,$6,$7}'>

Some other possibly useful environment variables that come to mind are the
identity and version of the server daemon.

John.Ellson@att.com



From henrich@crh.cl.msu.edu  Sat Oct  2 14:50:56 1993 -0400 (EDT)
Message-Id: <9310021850.AA21537@crh.cl.msu.edu>
Date: Sat, 2 Oct 1993 14:50:56 -0400 (EDT)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: HTML+ Addition

Got another crazy idea.  As I was watching my web logs, and the Mosaic p4
status display, it occured to me that when there are lots of small <4k inlined
images, it typically takes longer to establish the connection than transfer the
file.  Hence a new tag

<imgpkg src="URL">

which could be something like a tar file with all the inlined images in it.
references on the page would be stay the same (i.e. <img src="URL.gif">)

However the browser could (if the tag is recognized) go retrieve the package,
and grab all the inlined images in it in one shot, should improve performance
dramatically on pages with lots of inlined images.

-Crh



From ses@tipper.oit.unc.edu  Sat Oct  2 18:06:36 1993 -0400
Message-Id: <9310022206.AA29200@tipper.oit.unc.edu>
Date: Sat, 02 Oct 93 18:06:36 -0400
From: ses@tipper.oit.unc.edu (Simon E Spero)
Subject: Re: URN single or multiple variants (was: four-part harmony?) 

[The Terry Winograd?]

The thing that has become apparent during the course of the entire URI 
discussion is that there are certain parts of the problem for which there
is an obvious solution, and others which seem to be "open research problems"
- i.e. flame-bait. 

 URLs were pretty straightforward, since there was already a large body of 
code in-place proving their viability. 

URNs were slightly more troublesome, since people tended to overload different
meanings that were completely different to everyone elses. The current 
definition is extremely minimalist; adding anything will break the rough 
(way rough) consensus. 

The definitions of sameness from allocation domain to allocation domain; 
each allocation domain is only allowed one viewpoint. If an allocating 
body wishes to use a different comparator, then a different allocating 
domain should be used. 

One idea might be to define an IAFA-style template to describe allocating
domains and bodies; we could have an equality-definition field, and 
some standard definitions for use with that field. We could also have templates
for defining the definitions (this is getting recursive!)

Simon



From Nathan.Torkington@vuw.ac.nz  Sun Oct  3 16:50:07 1993 +1300
Message-Id: <199310030350.AA24130@kauri.vuw.ac.nz>
Date: Sun, 3 Oct 1993 16:50:07 +1300
From: Nathan.Torkington@vuw.ac.nz (Nathan Torkington)
Subject: curseperl

Has anyone set about using the curseperl stuff that comes with the
perl distribution to write a perl www browser?

Nat



From decoux@moulon.inra.fr  Sun Oct  3 12:45:59 1993 +0100
Message-Id: <9310031145.AA23644@moulon.moulon.inra.fr>
Date: Sun, 3 Oct 93 12:45:59 +0100
From: decoux@moulon.inra.fr (ts)
Subject: Worm WWW



New features for gateway WWW-ACEDB (WWWW)


 * Genetic, chromosomic, physical, features maps (ASCII or PostScript
graphic).  

    - If you want to retrieve a PostScript graphic, you MUST have a client
      1.0 which accept "application/postscript".  

    - server send PostScript colour graphic if "COLOUR" is defined in
      "${DATABASE}/wspec/psfonts.wrm".  

    - features maps only if sequence length < 5000, because with a length of
      1 000 000 sequences "moulon.inra.fr" take approximately 30 seconds
      to calculate the map, 3 minutes to write a PostScript file (whole map
      = 15 pages) and size of result file is greater than 20 Mbyte for a
      whole map 


 * more "dumper" : keySet, DNA ("ace" dump), longText 

   At compile time, definitions for dump and display (map) functions are
read from "${ACEDB_SRC}/wspec/quovadis.wrm".  If you have modified this
file, you must adapt your functions for WWW (examples are given in
wwwgmapdisp.c, wwwpmapdisp.c, ...).

 * table maker file (command "table table_maker_def arg") : name of table
   maker definitions file are read from "${DATABASE}/wspec/table.menu.wrm".

 * server detect automatically if a map, bibliography or table maker file
is associated with the document.

 * For security reasons : 

    + All pathnames of table maker definitions files are relative to directory
      ${DATABASE}.  You can't put ".." in the pathname.  Example for : 

                Gene
                Map_Data : wquery/map_data.1.def

      Pathname is "${DATABASE}/wquery/map_data.1.def".  

    + you can't prefix a command with $ (subshell) or @.  

    + isWriteAccess return always FALSE.  


 If all is well, source (only ANSI C) available Friday.

Guy Decoux



From hoesel@chem.rug.nl  Sun Oct  3 13:33:00 1993 +0100 (MET)
Message-Id: <9310031233.AA00878@Xtreme>
Date: Sun, 3 Oct 1993 13:33:00 +0100 (MET)
From: hoesel@chem.rug.nl (frans van hoesel)
Subject: Re: HTML+ Addition

> 
> Got another crazy idea.  As I was watching my web logs, and the Mosaic p4
> status display, it occured to me that when there are lots of small <4k inlined
> images, it typically takes longer to establish the connection than transfer the
> file.  Hence a new tag
> 
> <imgpkg src="URL">
> 
> which could be something like a tar file with all the inlined images in it.
> references on the page would be stay the same (i.e. <img src="URL.gif">)
> 
> However the browser could (if the tag is recognized) go retrieve the package,
> and grab all the inlined images in it in one shot, should improve performance
> dramatically on pages with lots of inlined images.
> 
> -Crh

would it be simpler to allow the inlined data actually be send just in place

so the html file would contain the text, and the image data in one piece
something like
<image href=included>....</image> with the ... replaced by the actual
image data.
or 
<image href="url"> for the old style

there must however be a better syntax than I suggested above.

- frans





From sanders@bsdi.com  Sun Oct  3 11:32:32 1993 -0500
Message-Id: <9310031632.AA07567@austin.BSDI.COM>
Date: Sun, 03 Oct 1993 11:32:32 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: curseperl 

> Has anyone set about using the curseperl stuff that comes with the
> perl distribution to write a perl www browser?

There already is a perl browser:
http://info.cern.ch/hypertext/WWW/FineWWW/Status.html



From montulli@stat1.cc.ukans.edu  Sun Oct  3 12:25:57 1993 CDT
Message-Id: <9310031725.AA31101@stat1.cc.ukans.edu>
Date: Sun, 3 Oct 93 12:25:57 CDT
From: montulli@stat1.cc.ukans.edu (Lou Montulli)
Subject: Re: HTML+ Addition

> 
> Got another crazy idea.  As I was watching my web logs, and the Mosaic p4
> status display, it occured to me that when there are lots of small <4k inlined
> images, it typically takes longer to establish the connection than transfer the
> file.  Hence a new tag
> 
> <imgpkg src="URL">
> 
> which could be something like a tar file with all the inlined images in it.
> references on the page would be stay the same (i.e. <img src="URL.gif">)
> 
> However the browser could (if the tag is recognized) go retrieve the package,
> and grab all the inlined images in it in one shot, should improve performance
> dramatically on pages with lots of inlined images.
> 
> -Crh
> 
I think the best way to solve this problem is not to package all of
the images into one file so that a single get can receive all the
images.  A good solution would be to extend HTTP so that multiple
gets can be done with a single connection.  That would give the
same effect as imgpkg but wouln't entail all of the extra overhead
of packing and unpacking.
(This was Marc's idea first, I'm just copying him :)

:lou
-- 
  **************************************************************************
  *           T H E   U N I V E R S I T Y   O F   K A N S A S              *
  *         Lou  MONTULLI @ Ukanaix.cc.ukans.edu                           *
  *                         Kuhub.cc.ukans.edu      ACS Computing Services *
  *     913/864-0436        Ukanvax.bitnet             Lawrence, KS 66044  *
  *             UNIX! Cool! I know that!  Jurassic Park - The Movie        *
  **************************************************************************



From hgs@research.att.com  Sun Oct  3 13:54:16 1993 EDT
Message-Id: <9310031754.AA20584@dxmint.cern.ch>
Date: Sun, 3 Oct 93 13:54:16 EDT
From: hgs@research.att.com (Henning G. Schulzrinne)
Subject: Re: HTML+ Addition

> From: montulli@stat1.cc.ukans.edu (Lou Montulli)
> I think the best way to solve this problem is not to package all of
> the images into one file so that a single get can receive all the
> images.  A good solution would be to extend HTTP so that multiple
> gets can be done with a single connection.  That would give the
> same effect as imgpkg but wouln't entail all of the extra overhead
> of packing and unpacking.
> (This was Marc's idea first, I'm just copying him :)
> 
Another idea is prefetching (probably requires about the same support):
Have the server return more than was asked of it, since the server
'knows' that the next request is going to be another small inlined image.
The client would cache the 'extra' data. This can clearly lead to
some problems; maybe the client should indicate something like "don't
send me more than 20 kB of prefetch stuff". This would make clients
very responsive after a slightly longer startup phase. 

Henning
---
Henning Schulzrinne (hgs@research.att.com)
AT&T Bell Laboratories  (MH 2A-244)
600 Mountain Ave; Murray Hill, NJ 07974
phone: +1 908 582-2262; fax: +1 908 582-5809



From roeber@vxcrna.cern.ch  Sun Oct  3 19:11:54 1993 +0100
Message-Id: <9310031811.AA21931@dxmint.cern.ch>
Date: Sun, 3 Oct 1993 19:11:54 +0100
From: roeber@vxcrna.cern.ch (Frederick G.M. Roeber)
Subject: Re: HTML+ Addition

>Another idea is prefetching (probably requires about the same support):
>Have the server return more than was asked of it, since the server
>'knows' that the next request is going to be another small inlined image.
>The client would cache the 'extra' data. This can clearly lead to
>some problems; maybe the client should indicate something like "don't
>send me more than 20 kB of prefetch stuff". This would make clients
>very responsive after a slightly longer startup phase.

How about making the document a "multipart/hyper" (well, ../x-hyper for now)
type, where the first part (of type "text/html") is the initial text, and
contains links to the later parts (e.g., of type "image/gif" suitably encoded)?

Then there'll just be the one document fetch; it will automatically work for 
news:, it'll be easier to do servers which generate inlined images on-the-fly,
and more.
--
<a href="http://info.cern.ch/roeber/fgmr.html">Frederick.</a>



From totic@milton.cs.uiuc.edu  Sun Oct  3 13:26:55 1993 CDT
Message-Id: <199310031826.AA11494@milton.cs.uiuc.edu>
Date: Sun, 3 Oct 93 13:26:55 CDT
From: totic@milton.cs.uiuc.edu (Aleksandar Totic)
Subject: Re: HTML+ Addition

> I think the best way to solve this problem is not to package all of
> the images into one file so that a single get can receive all the
> images.  A good solution would be to extend HTTP so that multiple
> gets can be done with a single connection.  That would give the
> same effect as imgpkg but wouln't entail all of the extra overhead
> of packing and unpacking.
> (This was Marc's idea first, I'm just copying him :)

Sounds like a job for multipart mime messages.

Aleks
-- 
Aleksandar Totic                                           atotic@ncsa.uiuc.edu
Software Development Group      National Center for Supercomputing Applications



From kevin@scic.intel.com  Sun Oct  3 12:13:56 1993 -0800
Message-Id: <9310031917.AA17252@rs042.scic.intel.com>
Date: Sun, 3 Oct 1993 12:13:56 -0800
From: kevin@scic.intel.com (Kevin Altis)
Subject: proposed MIME type, Microsoft Help

Microsoft Help files are the standard HyperText of Windows and are used on
the Macintosh platform as well. The Gopher community has started using them
over the net as a rich document type. I think WWW should support Windows
Help files by having a MIME type and standard extension to look for. This
can get added to the MIME/extension list already in progress:
1. MIME application/x-mshelp or application/hlp or application/microsoft-help
2. under Windows, the extension is .hlp, I don't have a Windows machine
here with me to tell you the program name that actually displays the files.
3. on the Mac, the Type is "HELP", the Creator varies, the Application that
actually displays the files is called "Microsoft Help" with a Creator type
of "MSHE".

Another thing that comes to mind is that a conversion tool from Microsoft
Help to HTML might be worthwhile. I need to get a hold of the tools for
creating help files and file format documentation. Anybody out there know
anything about Microsoft Help files?

ka





From WIGGINS@msu.edu  Sun Oct  3 20:30:12 1993 EDT
Message-Id: <9310040038.AA04007@dxmint.cern.ch>
Date: Sun, 03 Oct 93 20:30:12 EDT
From: WIGGINS@msu.edu (Rich Wiggins)
Subject: Re: Crawling info displays and slide shows

I want to be able to deliver a pageful of text to the user, and after a
timeout send the subsequent page.  If I follow this, you want to
relocate the functionality to the client side from the server.
Your scheme forces me to invent a new mechanism, whereas it seems
natural to me to want to deliver followon text after a timeout.  The
context isn't just slide shows per se; there might be all sorts
of situations where you'd want the client to go fetch a followon
URL -- for instance you might have an instructional "video" that
fetches one thing if the user selects an answer from a multiple-
choice menu; if the timeout period elapses, a "hint" page is
delivered instead.

I don't understand how this "clutters" the language.  Can't the
HTML document metaphor embrace temporal aspects?

/rich

>Define a new Content-type: (e.g., www/slideshow), then define the protocol,
>and then get browsers to support it.  Please Please Please don't clutter
>up the language with stuff that is more easily and better done externally.
>
>Something along these lines would be a start.  This steals a bit from
>/bin/sh syntax.  You could *almost* do this today with xmosaic :-)
>
>    .mailcap:   www/slideshow; /usr/local/bin/mosaic-slideshow %s
>or maybe
>    .mailcap:   www/slideshow; mosaic-internal-reference
>
>Content-type: www/slideshow
>
># www/slideshow example
>get http://www.bsdi.com/slideshow/audio/welcome.au &
>get http://www.bsdi.com/slideshow/welcome.html
>wait
>get http://www.bsdi.com/slideshow/audio/intro.au &
>get http://www.bsdi.com/slideshow/intro.html
>waitio		# waits until the user selects something from intro.html
>...
>
>--sanders



From sanders@bsdi.com  Sun Oct  3 20:11:39 1993 -0500
Message-Id: <9310040111.AA00271@austin.BSDI.COM>
Date: Sun, 03 Oct 1993 20:11:39 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: Crawling info displays and slide shows 

> I want to be able to deliver a pageful of text to the user, and after a
> timeout send the subsequent page.  If I follow this, you want to
> relocate the functionality to the client side from the server.
Yep, because that's where it belongs.  It certainly doesn't belong in the
transport system.

> I don't understand how this "clutters" the language.  Can't the
> HTML document metaphor embrace temporal aspects?
#1 Controlling temporal aspects of anything is very complex (thus the
   dearth of useful multimedia protocols and formats).  Ever try to
   play an MPEG back at normal speed?
#2 It's much easier for the client to drive a simple system than it is
   to invent ever more complex protocols.  I already showed you how you
   could this on the client end today using NCSA Mosaic.  There is even
   software (the "slideshow" stuff that was just posted) that does it.

--sanders



From leddo@minnie.cs.su.oz.au  Mon Oct  4 11:25:37 1993 +1000 (EST)
Message-Id: <9310040125.AA07585@dxmint.cern.ch>
Date: Mon, 4 Oct 1993 11:25:37 +1000 (EST)
From: leddo@minnie.cs.su.oz.au (Michael Francis Ledwidge)
Subject: Citations, quotes, and other thingys


	The recent discussion on the hypertext newgroups (alt.hypertext,
comp.infosys.www) concerning citing Web material attracted my interest since
I am in the process of writing an Honours thesis on authoring facilities
for the Web.
	I have been lurking on this mailing list all year and the
discussions that have taken place here have been a considerable source of
material. I am not entirely clear whether or not quoting from mail messages is
considered an invasion of `privacy'. I would guess that forwarding of mail to
other unrelated groups or lists, without prior knowledge, is not appreciated.
If I do decide to quote anyone who from this list I will be mailing them
individually. Please let me know if I am violating some ancient protocol by
this.
	On a similar note, the majority of my material is Web-based so I
have an obvious dilema with citing. Jerry Whelan's proposal, NAMEing the start
of paragraphs, may be adopted in time but I have to submit a bibliography in
a month's time! I was thinking of a site+author reference since many of the
Web sites I have accessed have consisted of material authored by a small number
of people.  

	I have been working on my own Web editing tool, WHype which is based on
the UNIX-ported libraries of the plan9 *from Bell Labs* OS. I hope to have
something stable available soon. The editor has an interface similar
to Rob Pike's sam text editor (used extensively in this department but I
don't know where else!).
	I only was only able to get a look at Joe Wang's tkWWW browser/editor 
very recently (thanx to Rob McCool of NCSA) but we have taken quite
different approaches to the task. WHype is more of an editor/browser - you
can browse and look at graphics, but it is a dedicated editing application
designed to support existing Web browsers rather than provide navigation help.
 With a less technical background (Arts),
I was more interested in making a tool that offered less facilities but
was simpler, and hopefully quicker, to use. I was also trying to encourage
people to contribute original hypertext without having to even be aware of
HTML. 
	The main problem with WHype (now that its namesake bug has been fixed :)
is that I do not support all of HTML. I adopted the approach that the
most used features of HTML be supported and the rest ignored. Unfortunately,
this means that documents containing certain markup will lose it when WHyped.
	Obviously this problem can be eradicated by `simply' supporting
all of HTML but my question is - should every Web client be so detailed?
	I know that the purpose of this list is to discuss the extensions 
and expansion of this powerful new communication medium but, nevertheless,
I sometimes wonder if, as the complexity grows, the Web will lose its
appeal to those, like myself, who simply want to use its scope without having
to think about it.
	Anyway I would be interested to hear what aspects of HTML people
consider are vital. Personally, I believe that the anchor tag and in-line image
tags are the only ones that are. (Let the mud-slinging commence!). WHype 
supports these tags at present:
	Headers 1&2, Bulleted Lists, 
	Anchors(NAME and HREF, although only HREF is modifiable in the program)

	I am working on these:
	In-line images, all style markup (headers, bold etc...) 

	In any case, I have to finalise the prototype for submission quite
soon so any glaring omissions pointed out would be appreciated. I am
aware that the glossary tag (<DT><DD>) is fairly widely used (at least at
CERN) but time is marching on.
	I hope this all isn't too vague, I'd love some feedback!.

	
Thanx
Michael Ledwidge
leddo@minnie.cs.su.oz.au
<A HREF=http://minnie.cs.su.oz.au/hype/MFL.html>.M.</A>




From henrich@crh.cl.msu.edu  Mon Oct  4 00:10:24 1993 -0400 (EDT)
Message-Id: <9310040410.AA26144@crh.cl.msu.edu>
Date: Mon, 4 Oct 1993 00:10:24 -0400 (EDT)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: Multiple gets per connection

After thinking about it abit more, it would be fairly easy to implment
something like:

Client issues: GET <item1> <item2> <item3> HTTP/1.0

Server responds with 3 MIME headers, where each *must* include Content-length
(I think thats the bytecount header entry).  The client can then proceed to
ingest all the items, reading by the returned bytecounts.

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                      http://rs560.msu.edu/~henrich



From kevin@scic.intel.com  Sun Oct  3 21:17:13 1993 -0800
Message-Id: <9310040420.AA18358@rs042.scic.intel.com>
Date: Sun, 3 Oct 1993 21:17:13 -0800
From: kevin@scic.intel.com (Kevin Altis)
Subject: Re: Crawling info displays and slide shows

>> I want to be able to deliver a pageful of text to the user, and after a
>> timeout send the subsequent page.  If I follow this, you want to
>> relocate the functionality to the client side from the server.
>Yep, because that's where it belongs.  It certainly doesn't belong in the
>transport system.
>
>> I don't understand how this "clutters" the language.  Can't the
>> HTML document metaphor embrace temporal aspects?
>#1 Controlling temporal aspects of anything is very complex (thus the
>   dearth of useful multimedia protocols and formats).  Ever try to
>   play an MPEG back at normal speed?
>#2 It's much easier for the client to drive a simple system than it is
>   to invent ever more complex protocols.  I already showed you how you
>   could this on the client end today using NCSA Mosaic.  There is even
>   software (the "slideshow" stuff that was just posted) that does it.

Please don't add anything to the HTML language or HTTP protocol to
specifically support "temporal" aspects. A simple modification of the
existing slideshow script allows you to handle most time based events with
XMosaic and the same kind of control will be possible with Mac and Windows
clients in the near future (though how near is up to the developers ;-)

The client display software will never be able to do everything, so as long
as the client supports some simple control mechanisms we can write
elaborate software to do the actual controlling.

ka





From marca@ncsa.uiuc.edu  Mon Oct  4 01:36:07 1993 -0500
Message-Id: <9310040636.AA06764@wintermute.ncsa.uiuc.edu>
Date: Mon, 4 Oct 93 01:36:07 -0500
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: feature bonanza

I notice a certain enthusiasm on this list for lots and lots and lots
and lots of little features :-).  Unfortunately, clients like Mosaic
are already approaching the dreaded state of kitchen sinkhood.  So
with that in mind...

How much would a feature like image prefetching or packaging or ...
really add, relative to the overhead and complexity involved in
supporting it?  One would get a marginal performance increase on
low-latency, high-bandwidth networks (which are rare -- in life, it
seems to be either high/high or low/low, excluding certain very rare
special cases) but not much else.  Probably wouldn't even be
noticeable...

So I might suggest that design discussions take into account
practicality and usefulness in a system as complex as (e.g.) Mosaic
2.0 plus Plexus 3.0, and try to triage below a certain level, in
general.

Between HTTP/1.0, fill-out forms, and the other recent/coming
advancements on both client and server ends, we're nearing a really
powerful general-purpose information environment with considerable
extensibility; at this point we may want to focus on applications and
advanced functionality rather than "under the hood" types of things
like image packaging.

Just a thought,
Marc




From P.Lister@cranfield.ac.uk  Mon Oct  4 09:18:12 1993 BST
Message-Id: <9310040818.AA03257@xdm039.ccc.cranfield.ac.uk>
Date: Mon, 04 Oct 93 09:18:12 BST
From: P.Lister@cranfield.ac.uk (Peter Lister, Cranfield Computer Centre)
Subject: Re: proposed MIME type, Microsoft Help

I know that local documents written for Microsoft help have been
authored in Word, and can be exported as RTF. 

Also (I make this plea AGAIN) does anyone know how to translate DEC
bookreader format into HTML? DEC refuse to even discuss the file format with me.

Peter Lister                             Email: p.lister@cranfield.ac.uk
Computer Centre, Cranfield University    Voice: +44 234 754200 ext 2828
Cranfield, Bedfordshire MK43 0AL UK        Fax: +44 234 750875
--- Almost (but not quite) entirely unlike tea ---



From anthony@aaii.oz.au  Mon Oct  4 19:08:34 1993 +1000
Message-Id: <199310040911.AA00362@eden-valley.aaii.oz.AU>
Date: Mon, 04 Oct 1993 19:08:34 +1000
From: anthony@aaii.oz.au (Anthony Baxter)
Subject: Re: proposed MIME type, Microsoft Help 

You write:
> Also (I make this plea AGAIN) does anyone know how to translate DEC
> bookreader format into HTML? DEC refuse to even discuss the file
> format with me.

From memory, there _was_ a program posted that spat text out from
bookreader documents - it got squished, DEC claimed the format was
proprietry, or something. This was maybe a year or two ago. I think
DECwrite can read and write bookreader files, but thats a $$$ option.
Who knows, DEC just put all their info on gatekeeper onto the Web, maybe
they will write something like this and release it? (Yeah, right...)

Anthony
--
 anthony baxter                 australian artificial intelligence institute
email : anthony@aaii.oz.au         1 grattan st, carlton, australia 3053
    /\/\||                                  phone : +613 663 7922



From dsr@hplb.hpl.hp.com  Mon Oct  4 11:31:07 1993 BST
Message-Id: <9310041031.AA18925@manuel.hpl.hp.com>
Date: Mon, 4 Oct 93 11:31:07 BST
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: HTML+ Addition

Charles Heinrich writes:

> Got another crazy idea.  As I was watching my web logs, and the Mosaic p4
> status display, it occured to me that when there are lots of small <4k inlined
> images, it typically takes longer to establish the connection than transfer the
> file.  Hence a new tag

> <imgpkg src="URL">

> which could be something like a tar file with all the inlined images in it.
> references on the page would be stay the same (i.e. <img src="URL.gif">)

A better solution for HTTP servers, is to adapt servers and browsers to
support the MIME multi-part message format, and supply the images along with
the document. Each part should supply its URL in the part header. This way
the browser will put each message part it receives into its cache, so that 
when it comes to render the document, it looks up the URL of the image in its
cache and hey presto - the images are already there! I guess, that you may
want to include a header in the HTTP request so that the server knows the
client can cope with multi-part messages.

For other servers, we could embed small images in the document directly
provided that the majority of browsers can cope with the format (no format
negotiation possible this way). e.g.

        <IMAGE>
            <EMBED TYPE=GIF>
              ....  
            </EMBED>
            A photo of the author.
        </IMAGE>

A suitable character encoding is needed for the image data, either based on
MIME or perhaps the more compact ASCII base-85 encoding used in Adobe's PDF?

Comments please.

Dave Raggett



From appel@cih.hcuge.ch  Mon Oct  4 12:17:16 1993 +0100
Message-Id: <1088*/S=appel/OU=cih/O=hcuge/PRMD=switch/ADMD=arcom/C=ch/@MHS>
Date: Mon, 4 Oct 1993 12:17:16 +0100
From: appel@cih.hcuge.ch (Ron D. Appel)
Subject: xmosaic 2, prerelease 4

With xmosaic 2, prerelease 4, I cannot get the following document:

gopher://pdb.pdb.bnl.gov:70/l9/PDB/Entries/.1le2/1le2.gif

It seems not to recognize that it's an image and displays the following:

GIF87adw

Can anyone tell me why?

Thanks

-------------------------------------------------------------------------
| Ron D. Appel                             | Tel.:   (+41 22) 372 6264  |
| Hopital Cantonal Universitaire de Geneve | Fax.:   (+41 22) 372 6198  |
| Centre d'Informatique Hospitaliere       | e-mail: appel@cih.hcuge.ch |
| 24, rue Micheli-du-Crest                 |   (S=appel;OU=cih;O=hcuge; |
| CH-1211 Geneve 14                        |    P=switch;A=arcom;C=ch)  |
| Switzerland                              |                            |
-------------------------------------------------------------------------



From appel@cih.hcuge.ch  Mon Oct  4 12:18:52 1993 +0100
Message-Id: <1089*/S=appel/OU=cih/O=hcuge/PRMD=switch/ADMD=arcom/C=ch/@MHS>
Date: Mon, 4 Oct 1993 12:18:52 +0100
From: appel@cih.hcuge.ch (Ron D. Appel)
Subject: WebReport

Does anybody know where I can get the WebReport code to analyse the performance
of the NCSA server?

Thanks

-------------------------------------------------------------------------
| Ron D. Appel                             | Tel.:   (+41 22) 372 6264  |
| Hopital Cantonal Universitaire de Geneve | Fax.:   (+41 22) 372 6198  |
| Centre d'Informatique Hospitaliere       | e-mail: appel@cih.hcuge.ch |
| 24, rue Micheli-du-Crest                 |   (S=appel;OU=cih;O=hcuge; |
| CH-1211 Geneve 14                        |    P=switch;A=arcom;C=ch)  |
| Switzerland                              |                            |
-------------------------------------------------------------------------



From marca@ncsa.uiuc.edu  Mon Oct  4 06:29:33 1993 -0500
Message-Id: <9310041129.AA07087@wintermute.ncsa.uiuc.edu>
Date: Mon, 4 Oct 93 06:29:33 -0500
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: xmosaic 2, prerelease 4

"Ron D. Appel" writes:
> With xmosaic 2, prerelease 4, I cannot get the following document:
> 
> gopher://pdb.pdb.bnl.gov:70/l9/PDB/Entries/.1le2/1le2.gif
> 
> It seems not to recognize that it's an image and displays the following:
> 
> GIF87adw
> 
> Can anyone tell me why?

Because the CERN library still doesn't do this by default and I hadn't
done the patches needed to make it happen for pre4.  It will be in
pre5 (added it yesterday)...

Marc




From marca@ncsa.uiuc.edu  Mon Oct  4 06:30:30 1993 -0500
Message-Id: <9310041130.AA07091@wintermute.ncsa.uiuc.edu>
Date: Mon, 4 Oct 93 06:30:30 -0500
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: WebReport

"Ron D. Appel" writes:
> Does anybody know where I can get the WebReport code to analyse the
> performance of the NCSA server?

Mail ekatz@ncsa.uiuc.edu.  To tell you the truth, I really don't know
why it's not available either through the Web server or on our ftp
server, but it's not...

Marc




From P.Lister@cranfield.ac.uk  Mon Oct  4 14:07:41 1993 BST
Message-Id: <9310041307.AA05679@xdm039.ccc.cranfield.ac.uk>
Date: Mon, 04 Oct 93 14:07:41 BST
From: P.Lister@cranfield.ac.uk (Peter Lister, Cranfield Computer Centre)
Subject: Re: proposed MIME type, Microsoft Help

> From memory, there _was_ a program posted that spat text out from
> bookreader documents - it got squished, DEC claimed the format was
> proprietry, or something. This was maybe a year or two ago. I think
> DECwrite can read and write bookreader files, but thats a $$$ option.

We have DECwrite (for our sins), and it will output to bookreader, but
not input. The output is pathetic, as it takes all the paper specific
settings - typeface, page breaks, and along with the document structure
- it's more trouble than it's worth. Even if DECwrite did input
bookreader, it would do something dumb with it....

> Who knows, DEC just put all their info on gatekeeper onto the Web, maybe
> they will write something like this and release it? (Yeah, right...)

Oooh, look at that pig flying past my window!

Thanx anyway.

Peter Lister                             Email: p.lister@cranfield.ac.uk
Computer Centre, Cranfield University    Voice: +44 234 754200 ext 2828
Cranfield, Bedfordshire MK43 0AL UK        Fax: +44 234 750875
--- Almost (but not quite) entirely unlike tea ---



From henrich@rs560.cl.msu.edu  Mon Oct  4 09:30:40 1993 -0400 (EDT)
Message-Id: <9310041331.AA20797@rs560.cl.msu.edu>
Date: Mon, 4 Oct 1993 09:30:40 -0400 (EDT)
From: henrich@rs560.cl.msu.edu (Charles Henrich)
Subject: Re: feature bonanza

> How much would a feature like image prefetching or packaging or ...
> really add, relative to the overhead and complexity involved in
> supporting it?  One would get a marginal performance increase on
> low-latency, high-bandwidth networks (which are rare -- in life, it
> seems to be either high/high or low/low, excluding certain very rare
> special cases) but not much else.  Probably wouldn't even be
> noticeable...

Actually on our local network between my workstation and the server it is
noticeable.  Because for every connection the server must fork off a new
process, which then must do all its initialization, authorization checking and
the like, then pass the document down.

But I agree, the creepingfeature beasties have certainly popped up lately, of
which I am certainly guilty.  No retrieving multiple images simultaneously is
not at all necessary (although would be nice).  The problem here is that as the
Web becomes more and more used, everyone wants their little thing in it :)
Course id be happy to code the multipart get's into the NCSA Server and Mosaic
:)

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                      http://rs560.msu.edu/~henrich




From sanders@bsdi.com  Mon Oct  4 09:52:59 1993 -0500
Message-Id: <9310041453.AA01241@austin.BSDI.COM>
Date: Mon, 04 Oct 1993 09:52:59 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: HTML+ Addition 

> How about making the document a "multipart/hyper" (well, ../x-hyper for now)
> type, where the first part (of type "text/html") is the initial text, and
> contains links to the later parts (e.g., of type "image/gif" suitably encoded)?
This blows any caching scheme you might have out of the water (not an
issue if you are talking news distribution but it is a *BIG* issue when
you are talking interactive performance), but if you are going to bundle
then I do agree we should use a MIME type (though I think multipart/mixed
is probably suitable and it's already well defined).  You can also use
multipart/alternative for sending different representations of the same data.

> Then there'll just be the one document fetch; it will automatically work for 
> news:
Dan Connolly wrote a bunch of stuff about this back in June 1992.  Check
out the www-talk archives (get the 1992 stuff):
    http://info.cern.ch/hypertext/WWW/Administration/Mailing/Overview.html

> it'll be easier to do servers which generate inlined images on-the-fly,
> and more.
I think you have this backwards.  It's a hell of a lot more work on the
server end.  How do you decide which images to include?  Are you going
to parse the HTML on the server end?  What happens with:
    <IMG SRC="http:otherserver...">
There are lots of other issues to be considered here.

--sanders



From luotonen@ptsun00.cern.ch  Mon Oct  4 16:36:40 1993 +0100
Message-Id: <9310041536.AA27445@ptsun00.cern.ch>
Date: Mon, 4 Oct 93 16:36:40 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: Access Authorization About to be Ready


Access Authorization is in, and the new library version will be out
this week.

So this is how it turned out...  Protocol is as it was decided in this
mailing list.  This is all CERN server specific.


RULE FILE:

	Two new rules, NO other changes:

		defprot <template> <setupfile> [<uid>][.<gid>]
		protect <template> [<setupfile> [<uid>][.<gid>]]

	Neither of these passes, only sets protection, and
	translation continues from the next rule.

	"protect" protects absolutely -- if ACL doesn't
	exist access is forbidden.

	"defprot" rule sets the default protection, i.e.
	if not explisitely protected by "protect" rule but
	ACL exists this protection setting is used.
	This is also used if "protect" rule doesn't provide
	all the necessary protection information.

	("fork" rule went salut!)


SETUP FILE:

	Mask-Group	user, @128.141.*.*, group@(131.*.*.*, *.cern.ch)
	Authenticate	Basic, Pubkey, KerberosV4, ...
	Server-Id	<password server name for Basic-scheme>
	Passwd		<password file for for Basic-scheme>
	Group		<group file for for Basic-scheme>

	If "Mask-Group" doesn't exist all the connection are accepted.
	Otherwise only people belonging to that group are allowed.
	Access control list is consulted only after this succeeds.
	Syntax of "Mask-Group" is as that of group definitions in
	the group file.
	
	"Authenticate" specifies valid authentication schemes.

	If there is no "Authenticate", and "Mask-Group" contains
	only internet addresses, e.g.

	Mask-Group	@128.141.*.*, @131.*.*.*, @*.cern.ch

	only connections from those addresses are allowed, but
	there is no other access authorization.
	This is the only case where access is still allowed with
	protect rule, but without access control list file.


GROUP FILE:

	groupname: user, group, @address,
		   user@address, group@address,
        	   (user, group, user, ...)@address,
		   user@(address, address, address, ...),
		   (user, group, user, ...)@(address, address, ...)

	address may be either an IP number template (e.g. 128.141.*.*)
	or IP name template (e.g. *.cern.ch).

	IP address is checked first. Iff successful users group
	membership is checked (recursively). During recursion
	IP address must always match, e.g.

	    hackers: marca@*.uiuc.edu, ari@ptsun*.cern.ch, timbl@info.cern.ch
	    cern-hackers: hackers@*.cern.ch

	marca can never get access into anything requiring cern-hacker
	access because *.cern.ch and *.uiuc.edu are exclusive.

	Only restriction is that addresses cannot be group names.
	If someone wants this (strange) feature, I'll implement it.

	IP address template matching is only implemented for IP
	numbers -- I'm not sure if they even should be implemented
	for domain names (I refer to the recent discussion about
	DNS lookup deficiency).
	


ACCESS CONTROL LIST FILE:

	<template> : get,put,... : user, group, (user,...)@(address,...)

	Last field has equal syntax and semantics as group definition,
	and it is translated in the context of group file.



PASSWORD FILE:

	<username> : <crypt()'ed password> : <Whatever>

	So understands directly unix /etc/passwd if someone
	wants that.


FORKING:

	If a stand-alone CERN server (-p or -a option) is
	running as root or is started up with -fork option
	it forks itself to serve all requests.


SET-UID AND SET-GID:

	If a stand-alone server is running as root the child
	always does setuid() and setgid() (as specified in
	rule file by "defprot" and "protect" rules).

	If server is lauched by inetd and is running as root
	it doesn't fork but does setuid() and setgid() itself.

	If uid or gid is not specified default is 65534 (nobody
	and nogroup).

	Server refuses to serve a request as root.



-- Salut, Ari --


                     \\\\Ari Luotonen//////
                      \\\\WWW Person//////
                       \\\\\\/\\\\\//////
                        \\\\//\\\\//////
                         \\////\\//////
                          \/\/\/\/\/\/




From dcmartin@library.ucsf.edu  Mon Oct  4 09:24:19 1993 PDT
Message-Id: <199310041628.AA08608@library.ucsf.edu>
Date: Mon, 04 Oct 1993 09:24:19 PDT
From: dcmartin@library.ucsf.edu (David C. Martin)
Subject: Re: HTML+ Addition 

Perhaps the solution is to read then entire page and then group the
accesses to a particular host.

dcm
--------
Charles Henrich writes:

Got another crazy idea.  As I was watching my web logs, and the Mosaic p4
status display, it occured to me that when there are lots of small <4k inlined
images, it typically takes longer to establish the connection than transfer the
file.  Hence a new tag

<imgpkg src="URL">

which could be something like a tar file with all the inlined images in it.
references on the page would be stay the same (i.e. <img src="URL.gif">)

However the browser could (if the tag is recognized) go retrieve the package,
and grab all the inlined images in it in one shot, should improve performance
dramatically on pages with lots of inlined images.

-Crh




From timbl@www3.cern.ch  Mon Oct  4 17:36:42 1993 +0100
Message-Id: <9310041636.AA02839@www3.cern.ch>
Date: Mon, 4 Oct 93 17:36:42 +0100
From: timbl@www3.cern.ch (Tim Berners-Lee)
Subject: Re: POST questions



Tony:

I agree that the URL should be returned as a header, and in fact  
there may be other bit sof metadata whioch would be server-generated
and would be returned at the same time.  I have changed the spec to
read

"Return object headers

The method shall return a set (possibly empty) of object headers for  
the newly posted object.  If a URL has been assigned by the server,  
then that may be included.  Similarly, if a URN has been assigned,  
then that shall be returned. Other things which may be returned  
include for example the expiry-date if any.   The server may return  
the entire metadata for the object (as in the HEAD command), or a  
subset of it.

The object body shall not be returned, so the transaction shall end  
with the blank line terminating the headers."

I would expect one could use the same code for implementing HEAD
to a large extent.  On getting the returned header, the client would  
sync up its internal data on the object, which is incomplete until  
the post has happened.

2. At the same time I feel like changing the Live-URL: fields
to a

URI: blah  vary=version, language, content-type

field.  I didn't get any feedback on that.  Seemed sensible though,
cleaner.  Any objections? **** Speak now...


3. The message-boundary.

> Secondly, how should "message boundary" work?  I've seen
>    Content-type: text/html, boundary="string"
> and
>    Message-Boundary: string

It is a pain that MIME defines it in the first form, and only for
Content-type multipart.  I guess we would do best to go
the same way.  Where have you seen the second method?
(I would prefer it on the encoding rather than the type field)

Tim



Tim





From kevin@scic.intel.com  Mon Oct  4 09:51:16 1993 -0800
Message-Id: <9310041654.AA17224@rs042.scic.intel.com>
Date: Mon, 4 Oct 1993 09:51:16 -0800
From: kevin@scic.intel.com (Kevin Altis)
Subject: Re: ISMAP coordinate tool

At  4:34 PM 9/30/93 -0400, Jim Davis wrote:
>Has anyone yet built a tool to facilitate creating the sets of
>rectangle definitions needed for an ISMAP image?  I have one
>about 1/3 finished, but suddenly was struck by the thought that
>someone ELSE may already have one working.  In an unusual attack
>of conscience I decided to ask the net instead of just hacking
>away anyway.  Sooooo  has anyone written such a thing yet?
>
>And if not, what would be a reasonable output format?  I've
>seen the format in HTTP://pulua/hcc.hawaii.edu/files/mapd.html
>
>Is everyone using their format for ISMAP, or are other formats
>also in use?  (e.g. in the floorplan demo at
>insti.physics.sunysb.edu/floorplan.html or the active room
>at http://utis179.cs.utwente.nl:8001/esperanto/hyperkursus/oficej.html
>
>(I can't find the "fish picture" anymore.  What does it use?)

I've started writing some tools in MetaCard that support XMosaic
specifically and other aspects of the Web in general. One of the tools I've
started allows you to import a picture then you draw buttons on the picture
to represent hot spots, then you export the hot spots and associated URLs
to a text file. This way you don't have to spend lots of time clicking
around in xv and you can save your hot spots for later updating and if a
server uses 0-1 mapping rather than the current XMosaic pixel mapping, then
the stack can do the calculations for you. MetaCard runs on the same
platforms supported by XMosaic.

I need to finish my GUI slideshow controller today, but after that's done
I'll work some more on the ISMAP stuff.

ka





From sanders@bsdi.com  Mon Oct  4 12:02:54 1993 -0500
Message-Id: <9310041702.AA02184@austin.BSDI.COM>
Date: Mon, 04 Oct 1993 12:02:54 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: POST questions 

> "Return object headers
> 
> The method shall return a set (possibly empty) of object headers for  
> the newly posted object.  If a URL has been assigned by the server,  
...

> 2. At the same time I feel like changing the Live-URL: fields
> to a
>     URI: blah  vary=version, language, content-type
> field.  I didn't get any feedback on that.  Seemed sensible though,
> cleaner.  Any objections? **** Speak now...
Sounds reasonable to me.  So this replaces Live-URI and Version-URI
right?  Where Version-URI: is URI: without any vary fields.

So POST might return something like:
    HTTP/1.0 201 URI follows
    URI: http://www.bsdi.com/test-cases/HTTP/200.www
BTW: I think 201 should allow a content-type so that browers that don't
grok it could just pop up the document which might be something as
simple as:
    HTTP/1.0 201 URI follows
    URI: http://www.bsdi.com/test-cases/HTTP/200.www
    MIME-Version: 1.0
    Content-type: text/html

    <A HREF="http://www.bsdi.com/test-cases/HTTP/200.www">Posted</A>
If the client groks the 201 reply then it can it just ignore the
message body.  That way clients can be "dumb" and just accept all
2?? replies as ok and still work reasonably.

> >    Message-Boundary: string
> the same way.  Where have you seen the second method?
We talked about it at WWWWW I guess.

> (I would prefer it on the encoding rather than the type field)
interesting

--sanders



From kevin@scic.intel.com  Mon Oct  4 09:51:16 1993 -0800
Message-Id: <9310041654.AA17224@rs042.scic.intel.com>
Date: Mon, 4 Oct 1993 09:51:16 -0800
From: kevin@scic.intel.com (Kevin Altis)
Subject: Re: ISMAP coordinate tool

At  4:34 PM 9/30/93 -0400, Jim Davis wrote:
>Has anyone yet built a tool to facilitate creating the sets of
>rectangle definitions needed for an ISMAP image?  I have one
>about 1/3 finished, but suddenly was struck by the thought that
>someone ELSE may already have one working.  In an unusual attack
>of conscience I decided to ask the net instead of just hacking
>away anyway.  Sooooo  has anyone written such a thing yet?
>
>And if not, what would be a reasonable output format?  I've
>seen the format in HTTP://pulua/hcc.hawaii.edu/files/mapd.html
>
>Is everyone using their format for ISMAP, or are other formats
>also in use?  (e.g. in the floorplan demo at
>insti.physics.sunysb.edu/floorplan.html or the active room
>at http://utis179.cs.utwente.nl:8001/esperanto/hyperkursus/oficej.html
>
>(I can't find the "fish picture" anymore.  What does it use?)

I've started writing some tools in MetaCard that support XMosaic
specifically and other aspects of the Web in general. One of the tools I've
started allows you to import a picture then you draw buttons on the picture
to represent hot spots, then you export the hot spots and associated URLs
to a text file. This way you don't have to spend lots of time clicking
around in xv and you can save your hot spots for later updating and if a
server uses 0-1 mapping rather than the current XMosaic pixel mapping, then
the stack can do the calculations for you. MetaCard runs on the same
platforms supported by XMosaic.

I need to finish my GUI slideshow controller today, but after that's done
I'll work some more on the ISMAP stuff.

ka





From sanders@bsdi.com  Mon Oct  4 13:25:26 1993 -0500
Message-Id: <9310041825.AA02521@austin.BSDI.COM>
Date: Mon, 04 Oct 1993 13:25:26 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: ISMAP coordinate tool 

Enclosed is a proposal for how this might all work.  As this evolves
I will keep this URL updated with the latest info:
    http://www.bsdi.com/home/sanders/www-notes/ismap-proposal.txt

> >Has anyone yet built a tool to facilitate creating the sets of
> >rectangle definitions needed for an ISMAP image?  I have one
If we going to do this it would be nice to standardize the format
of this file so all the servers interoperate.  I think we understand
the problem well enough to solve it.

#1  We should assume HTTP/1.0 with support for 302 (forward)
    and content-type encoding.  Otherwise there are lots of restrictions
    and problems to worry about.  By the time you get the tools done
    I expect most browsers will support these (NCSA Mosaic 2.0pre4 does
    so that means others will probably follow).

#2  We need to consider the various forms of object encoding.  Rectangles
    are probably the most straight forward.  Also bitmasks (XBM and XBMRAW),
    pixmasks (XPM), triangles, circles, and general polygons.  You probably
    want to tell the tool which modes your server supports.  If you guys
    write a tool that outputs triangles, rects and XPM files then that is
    what servers will support.

#3  The reference should look something like this:
       <A HREF="http://server/path/thingy.map"><IMG SRC="img"></A>

#4  thingy.map is what we mostly need to standardize.  How about this:

    default URL
	Either the client doesn't understad ISMAP or none of the
	object matched.  Probably returns a menu or an error message.
	If undefined then a menu will be generated using the
	menu_description fields (I'm flexible on this part, I would
	be happy to just return an error if people don't think this is
	useful).
    title menu_title
        This is simple the title of a menu that is generated if
        the client doesn't support ISMAP and no-spacejump isn't defined.
        This basically lets you embded the default behavoir in the config
        or define an external URL to access.  For example: if you are
        serving weather reports from a weather map you might use
	    no-spacejump http://rs560.cl.msu.edu/weather/getmegif.html
        to rediect them to a fillout form version.
    default URL [menu "menu_description"]
        This URL is returned if nothing else matches.  If not present then
        it generates
    xbmobject URL OBJECTFILE [menu "menu_description"]
        textual xbm files (just like you get out of bitmap)
    xbmraw URL OBJECTFILE width height [menu "menu_description"]
        xbm files converted to raw data (what plexus supports)
    xpmobject URL OBJECTFILE [menu "menu_description"]
        xpm files (lets you defined multiple object masks in a single file)
    rect URL x y width height [menu "menu_description"]
        rectangles (upper-left at x,y extents width,height)
    circle TBS [menu "menu_description"]
    triangle TBS [menu "menu_description"]
    poly URL x,y x,y x,y [x,y ...] [menu "menu_description"]

    When the server gets a request for *.map file it grabs the query part
    and passes it onto the decoder which then figures out which object
    matched and returns the corisponding URL in a 302 "forward" reply.

    This is how 302 replies work.  http://www.bsdi.com/test-cases/HTTP/302.www
    replies:
	HTTP/1.0 302 Temporary Relocation URI follows
	Last-modified: Sunday, 03-Oct-93 19:32:54 GMT
	Date: Sunday, 03-Oct-93 19:37:52 GMT
	Server: plexus/3.0i
	Location: http://www.bsdi.com/test-cases/HTTP/302.html
	MIME-version: 1.0
	Content-type: text/html

	<TITLE>Return Code: 302 Temporary Relocation URI follows</TITLE>
	If you see this message then it didn't work.
	<A HREF="/test-cases/HTTP/302.html">This</A> is what you should have seen.
    It expects the browser to automatically retrieve the URL pointed to
    by the Location: header.

--sanders



From robm@ncsa.uiuc.edu  Mon Oct  4 15:17:16 1993 -0500
Message-Id: <9310042017.AA19457@void.ncsa.uiuc.edu>
Date: Mon, 4 Oct 1993 15:17:16 -0500
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: ISMAP coordinate tool

/*
 * ISMAP coordinate tool  by Jim Davis (davis@dri.cornell.edu)
 *    written on Sep 30,  4:34pm.
 *
 * Has anyone yet built a tool to facilitate creating the sets of
 * rectangle definitions needed for an ISMAP image?  I have one
 * about 1/3 finished, but suddenly was struck by the thought that
 * someone ELSE may already have one working.  In an unusual attack
 * of conscience I decided to ask the net instead of just hacking
 * away anyway.  Sooooo  has anyone written such a thing yet?
 * 
 * And if not, what would be a reasonable output format?  I've
 * seen the format in HTTP://pulua/hcc.hawaii.edu/files/mapd.html
 * 
 * Is everyone using their format for ISMAP, or are other formats
 * also in use?  (e.g. in the floorplan demo at
 * insti.physics.sunysb.edu/floorplan.html or the active room
 * at http://utis179.cs.utwente.nl:8001/esperanto/hyperkursus/oficej.html
 * 
 * (I can't find the "fish picture" anymore.  What does it use?)
 */

The fish picture might be referring to the demo I put together for NCSA
  httpd, and can be found at URL http://hoohoo.ncsa.uiuc.edu/docs/Demo.html

I used xv to put together the coordinates, and the imagerect.conf
  format described in the server's docs as an output format.

--Rob




From emv@garnet.msen.com  Mon Oct  4 20:55:13 1993 -0400
Message-Id: <m0ok0gO-000EetC@garnet.msen.com>
Date: Mon, 04 Oct 1993 20:55:13 -0400
From: emv@garnet.msen.com (Edward Vielmetti)
Subject: maps of USA, World with country outlines available?

This might be hoping too much, but does anyone have US or world maps
ready for use with Mosaic's ISMAP?  I'd like to put database queries
on a geographically coded database behind a nice map.

thanks much for any leads.  (I suspect the MSU "weather map" would be
a model for this.)

--Ed



From eostrom@gac.edu  Mon Oct  4 20:53:14 1993 (CDT)
Message-Id: <9310050153.AA06247@gac.edu>
Date: Mon, 4 Oct 1993 20:53:14 (CDT)
From: eostrom@gac.edu (Erik Ostrom)
Subject: Re: Crawling info displays and slide shows

--sanders:
> >Define a new Content-type: (e.g., www/slideshow), then define the protocol,
> >and then get browsers to support it.  Please Please Please don't clutter
> >up the language with stuff that is more easily and better done externally.

/rich:
> I want to be able to deliver a pageful of text to the user, and after a
> timeout send the subsequent page.  If I follow this, you want to
> relocate the functionality to the client side from the server.
> Your scheme forces me to invent a new mechanism, whereas it seems
> natural to me to want to deliver followon text after a timeout.

I think I must have missed your proposal for a timed-display system
that doesn't require a new mechanism.  Tony's idea requires a new
content-type (www/slideshow) for MIME; another idea I've seen requires
adding a new tag or tag attribute (requiring in-client timing) to
HTML.

It seems to me that we're inherently talking about new functionality;
we're just discussing where to put it.

> I don't understand how this "clutters" the language.  Can't the
> HTML document metaphor embrace temporal aspects?

It could; it doesn't seem compelling that it should.  Putting this
functionality in HTML and not in HTTP (or MIME) means that we don't
get timed display of any document type except HTML.  Of course,
putting it in MIME and not in HTML means that we don't get timed
display for documents fetched by protocols other than HTTP (unless we
define another file extension to guess at).  But to me, doing slide
shows that include GIFs seems much more useful than doing slide shows
that are all HTTP but fetched via FTP.

Tell me if I'm way off-base here.

--Erik



From sanders@bsdi.com  Tue Oct  5 00:17:47 1993 -0500
Message-Id: <9310050517.AA04774@austin.BSDI.COM>
Date: Tue, 05 Oct 1993 00:17:47 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: Crawling info displays and slide shows 

> functionality in HTML and not in HTTP (or MIME) means that we don't
> get timed display of any document type except HTML.  Of course,

My suggestion was not to make it a part of HTML or HTTP or MIME.
I suggested inventing a NEW protocol that does multimedia presentations
by driving a WWW client (or whatever you want to do).

--sanders



From marca@ncsa.uiuc.edu  Tue Oct  5 00:46:46 1993 -0500
Message-Id: <9310050546.AA09839@wintermute.ncsa.uiuc.edu>
Date: Tue, 5 Oct 93 00:46:46 -0500
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: a crazy idea

How about shipping around commonly used images in all these extra
messages being spit out by the Magical Broken CERN Mail Robot?

But seriously, how about finally killing this list and moving to
Usenet -- hard to believe this mailing list still doesn't work right a
year after I joined it.

Cheers,
Marc
[and Marc and Marc and Marc and Marc and Marc...]




From gehmeyr@forwiss.uni-passau.de  Tue Oct  5 10:21:12 1993 +0100 (MET)
Message-Id: <199310050921.AA26540@turgon.forwiss.uni-passau.de>
Date: Tue, 5 Oct 1993 10:21:12 +0100 (MET)
From: gehmeyr@forwiss.uni-passau.de (Andreas Gehmeyr)
Subject: Re: a crazy idea

Wie Marc Andreessen schrieb:
:::  
:::  How about shipping around commonly used images in all these extra
:::  messages being spit out by the Magical Broken CERN Mail Robot?
Now that many browsers have got those bookmark-images (home, forward,
backward, right hand and so on) and similar often-used images: 
How about defining a standard directory to place those standard-images 
(with standard names) on each server?
Then the client could get them on the local host (which will be faster!),
and anyone can define his/her own set of preferred images.
Servus, 
Andi
-- 
<I>
<A HREF="http://httpserver.forwiss.uni-passau.de/worterklaerungen/xmosaic.html">The name of the browser is called XMosaic.</A>
</I>
<P>
<ADDRESS>
Andreas Gehmeyr, FORWISS Passau <P>
gehmeyr@forwiss.uni-passau.de<P>
http://httpserver.forwiss.uni-passau.de/forwiss/mitarbeiter/hiwis/gehmeyr.html
</ADDRESS>



From timbl@www3.cern.ch  Tue Oct  5 10:35:17 1993 +0100
Message-Id: <9310050935.AA03789@www3.cern.ch>
Date: Tue, 5 Oct 93 10:35:17 +0100
From: timbl@www3.cern.ch (Tim Berners-Lee)
Subject: Re: Crawling info displays and slide shows

I wonder if this gets anyone programming...

> I don't understand how this "clutters" the language.  Can't the
> HTML document metaphor embrace temporal aspects?


What we're heading for is a full 4D montage language,
which will need its own editors to make life easier.
There are of course people working in this area...

Look at Microsoft's AVS (seemed boring) and
HyTime (this is EXACTLY what HyTime was _designed_
to do  (but don't let that influence you ;-)).

Or reinvent it if you can do a much more powerful
job.  Even if you implement a very simple subset
now, it is wise to remember where you're headed.
I think we'll need something for descibing
3D things such as rooms in a MUDD:

room4 = {
	align (23,400,12), {687, 400, 13), centers,
		{ eostrom, marca, wiggins, timbl };
	let t = at  (30,40,67)  table(400, north) ;
	ontopof  t, flowers(100);

    }
where marc = http://wintermute.../wefgwwgikjvh;
where flowers = http://elvinrude.../comon/clipart/flowers3;
[...]

slide4 = timeslice{ 4, rotate(0,1,0) {room4 } }

slideshow = consecutive {
	slide1,
	{ontopof {slide2, slide3}},
	zoom { (23,56,0.005), 0.672, slide5 },
	timestretch{2, slide5 };
}
	
and so on.  The functions are just the normal
operators, 4d versions of the menus in 2d drawing
packages (like Transform, Group, Align...), but regarded
as operators
describing a compoisite object, rather than procedures
as the menus are.  Checkout "renderman" .rib files
for one 3d version. There must be tens of them now.

I can see us adding 3d rendering
requests to http, so that a basically 2d viewer
can ask an object for a rendering as from a particular
point under particular lighting:-


	RENDER  /comon/clipart/flowers3  HTTP/1.0
	Lighting: 30@(-3,-6,+78); 100@(-56,-6, 7)
	View: from (100,23,23) to (0,0,0)
	Accept: image/x-tiff

This would allow a 2-d display with transparency to
make a good job of displaying a 3d montage.

Of course an alternative would be to return 3d object
descriptions, which would be quicker if one were to
rotate in the client, but on the other hand, the idea
of having objects on servers which would render themselves
is kinda neat because for one thing, different objects
can make different approximations when rendering themselves,
and some objects know that they have symmetery, and others
(like faces around a conference table) could just always
cheat and render themselves in 2d, so the faces would
always face the viewer!  Of course, the question of
whether the server should return a 3d version if it has one
is just done in the format negotiation, no sweat.

So how about making a slideshow program a subset of
a function descripion of a 4D montage designed for lazy
distributed evaluation?

I think it should be independent of HTML!

The objects should also be accesible with any WWW protocol,
(any URL) including
new pointers to any realtime isochronous protocols, for
putting a *live* erik at the table in the room.

Just thought I'd throw it into the ring...  :-)

Tim BL


 



From timbl@www3.cern.ch  Tue Oct  5 12:01:58 1993 +0100
Message-Id: <9310051101.AA04209@www3.cern.ch>
Date: Tue, 5 Oct 93 12:01:58 +0100
From: timbl@www3.cern.ch (Tim Berners-Lee)
Subject: Test -- Ignore this UNLESS YOU GET TWO 


Mail duplication

This seems to be a bug in sendmail, on one of two machines.

This message was exploded by www3 using a more recnet sendmail than  
the one on info (nxoc01).

If you get a duplicate, then please forward
www-bug@info.cern.ch a copy of all the headers 

from each copy, mentioning this message.

If this works we'll leave this list like this.
Thanks, and sorry for the duplicates.
Thanks, and sorry for the duplicates.

Tim BL





From dimou@dxmint.cern.ch  Tue Oct  5 15:30:55 1993 +0100
Message-Id: <9310051430.AA24036@dxmint.cern.ch>
Date: Tue, 5 Oct 1993 15:30:55 +0100
From: dimou@dxmint.cern.ch (M.  Dimou-Zacharova)
Subject: test, please, ignore

We are just testing a new list set-up which should be transparent to you.
Please ignore except if you receive duplicates of this message.
 - postmaster



From dietrich@afsw01.cern.ch  Wed Oct  6 11:16:12 1993 +0100
Message-Id: <9310061016.AA00358@afsw01.cern.ch>
Date: Wed, 6 Oct 1993 11:16:12 +0100
From: dietrich@afsw01.cern.ch (Dietrich Wiegandt)
Subject: Testing, please ignore.

No body.



From dietrich@afsw01.cern.ch  Wed Oct  6 12:05:01 1993 +0100
Message-Id: <9310061105.AA00418@afsw01.cern.ch>
Date: Wed, 6 Oct 1993 12:05:01 +0100
From: dietrich@afsw01.cern.ch (Dietrich Wiegandt)
Subject: Test, please ignore

Delivery to files using /usr/local/bin/deliver



From dsr@hplb.hpl.hp.com  Wed Oct  6 12:03:40 1993 BST
Message-Id: <9310061103.AA29262@manuel.hpl.hp.com>
Date: Wed, 6 Oct 93 12:03:40 BST
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: Generalising inlined images

Nathan wants to be able to inline arbitary kinds of things into
an HTML+ document:

>  ...and regardless of whether the HREF was to an image, a sound file or
> more hypertext, it would be included in the current document.

> How will/should this be done?

Does the inlined object behaves like a character or a paragraph?

Do you play sound immediately or when the user clicks the link?

Do you retrieve an "inlined" Postscript file automatically or
wait until the user clicks the link?

HTML+ does provide some support for inlined linked HTML or plain text,
but we need to clarify what we want.

Dave



From nikos@cbl.leeds.ac.uk  Wed Oct  6 12:36:31 1993 BST
Message-Id: <29351.9310061136@cbl.leeds.ac.uk>
Date: Wed, 6 Oct 93 12:36:31 BST
From: nikos@cbl.leeds.ac.uk (N F Drakos)
Subject: Re: Math markups.


Emanuel Knill writes:
>
>Hi everyone,
>
>You probably have seen the recent discussion on markups for
>math on comp.infosystems.www. Unfortunately I could not
>so far determine who is actually working on implementing
>mathematical expressions. There are at least five
>mathematicians here who would take immediate advantage
>of such features if they were available. Yes,
>I have seen latex2html, and tried converting some of my
>papers. Though I think it is great to
>have build this tool, the results were not satisfactory for
>what I tried. The most
>obvious problem was symbol alignment.

What is the symbol alignment problem?
If you are referring to equation images not being aligned
correctly within a piece of text that flows around them 
then this can be fixed with the new version of mosaic
(XMosaic 2.0 prerelease 4) and the next release of latex2html
(or the patch to v0.3.1 in
http://cbl.leeds.ac.uk/nikos/tex2html/previous-versions/patch0.3.1-to-0.3.3.txt)

If you want to align several equations then why not use latex 
multiline formulas (eqnarray). Alternatively you can enclose 
whatever equation+text arrangement whose exact presentation style
you want to preserve in an environment that would force the 
generation of an inlined image for it. 

What other problems are there?

>I did notice that html+ will include embedded elements,
>and in fact one of the examples referres to embedded TeX.
>My understanding is that we could have an external program
>which can convert such embedded formulas to an image
>and provide this to the browser for inclusion. Is this correct?
>If so, is anyone working on providing such programs?
>As I see it, the only disadvantage of such an approach
>is that one cannot take advantage of the macro definition
>capabilities of TeX.  Finally, 
>it seems that concepts such as "theorems",
>"lemmas", "examples" etc. should be added to the paragraph
>roles?

Apart from the macro capabilities of TeX, and the 
inclusion of style files there other problems
resulting from the fact that in many cases single equations 
cannot be treated in isolation. For example automatic 
equation numbering, cross references using symbolic 
equation labels, automatic generation
of theorem/subtheorem/axiom/lemma numbers cannot be 
addressed by embedding TeX in HTML unless parts of the 
TeX engine are replicated, or 
as Marc points out, unless TeX becomes more modular
so that it can be used with other packages. 
For the time being these issues can only be addressed if
the equations and the text around them are processed
together and preferably off-line because of potential overheads.

Nikos Drakos 
Computer Based Learning Unit    
University of Leeds

email: nikos@cbl.leeds.ac.uk
WWW  : http://cbl.leeds.ac.uk/nikos/personal.html



From dduchier@csi.uottawa.ca  Wed Oct  6 10:51:12 1993 -0400
Message-Id: <9310061451.AA04810@csi.UOttawa.CA>
Date: Wed, 6 Oct 93 10:51:12 -0400
From: dduchier@csi.uottawa.ca (Denys Duchier)
Subject: Re: Math markups

I think you are giving up to easily.  Look at it this way: one
advantage to having math markup is that, in the advent that the
browser does not implement native support for the display of math
formulae, it can relatively easily convert them to another format (say
e.g. TeX) and render them with the help of an external tool.

--Denys



From knill@c3serve.c3.lanl.gov  Wed Oct  6 08:50:43 1993 -0600
Message-Id: <9310061450.AA01782@c3serve.c3.lanl.gov>
Date: Wed, 06 Oct 1993 08:50:43 -0600
From: knill@c3serve.c3.lanl.gov (Emanuel Knill)
Subject: Re: Math markups. 

In-reply-to: Your message of "Wed, 06 Oct 1993 12:36:31 -0000."

--------

>
>Emanuel Knill writes:
>>
>>I have seen latex2html, and tried converting some of my
>>papers. Though I think it is great to
>>have build this tool, the results were not satisfactory for
>>what I tried. The most
>>obvious problem was symbol alignment.
>

Nikos Drakos writes:

>What is the symbol alignment problem?
>If you are referring to equation images not being aligned
>correctly within a piece of text that flows around them 
>then this can be fixed with the new version of mosaic
>(XMosaic 2.0 prerelease 4) and the next release of latex2html
>(or the patch to v0.3.1 in
>http://cbl.leeds.ac.uk/nikos/tex2html/previous-versions/patch0.3.1-to-0.3.3.tx
>t)
>

The problem I was thinking of occurs with inline
greek and other math symbols. Their vertical alignment is
inconsistent. They hop all over the place (I assume because
the bottom of the image is alligned instead of the baseline
of the characters). I will try the patches.


Nikos Drakos continues:
>
>Apart from the macro capabilities of TeX, and the 
>inclusion of style files there other problems
>resulting from the fact that in many cases single equations 
>cannot be treated in isolation. For example automatic 
>equation numbering, cross references using symbolic 
>equation labels, automatic generation
>of theorem/subtheorem/axiom/lemma numbers cannot be 
>addressed by embedding TeX in HTML unless parts of the 
>TeX engine are replicated, or 
>as Marc points out, unless TeX becomes more modular
>so that it can be used with other packages. 
>For the time being these issues can only be addressed if
>the equations and the text around them are processed
>together and preferably off-line because of potential overheads.
>

Standard numbering in a math document designed primarily as
hypertext may not be what I would want... And you are right,
automatic generation of references across multiple documents
could be quite tricky, unless the original document is a
(La)TeX paper, in which case a conversion program like
latex2html makes sense.

Manny






From secret@hpwww.cern.ch  Wed Oct  6 16:17:39 1993 MET
Message-Id: <9310061517.AA22263@dxmint.cern.ch>
Date: Wed, 6 Oct 93 16:17:39 MET
From: secret@hpwww.cern.ch (Arthur Secret)
Subject: BBEdit HTML extensions (fwd)

Forwarded message:

:> Dear netters,
:> 
:> I've written a set of BBEdit extensions which can assist HTML
:> (HyperText Markup Language) documents edition. Our Web Gang'
:> (we have an experimental World Wide Web server: 'http://www.uji.es')
:> has used it, and it has proved to be useful for us.
:> 
:> Drag files to 'BBEdit extensions' folder in order to install
:> the extensions. Once installed, the  usage is very simple:
:> select the text you want to be, say, a link to another document,
:> and then select the 'HTML link' in the 'Extensions' menu.
:> 
:> Included extensions are:
:> 
:> - Title
:> - Heading
:> - Paragraph
:> - Comment
:> - Anchor
:> - Link
:> - Format (numbered, unnumbered and descriptive lists,
:>   extended quotes, preformatted text, listings, menus and
:>   directories)
:> - Style (bold, italics, underline, emphasis,
:>   strong emphasis, citation and address)
:> - Typewriter font
:> - Image
:> - Specials translation (translation of special
:>   mac characters into HTML sequences)
:> 
:> I hope this can be useful to other people over the net.
:> 
:> Please, send me any comments, suggestions or bug reports.
:> 
:> (The package may be included in the CD-ROM of the archives.)
:> 
:> Carles Bellver <bellverc@si.uji.es>
:> Web Gang - Universitat Jaume I SPAIN
:> 
:> (This file must be converted with BinHex 4.0)
:> 

:'N*#4@4TG#e)9%e-,@9iG'9ZFfP[ER-ZFf9K!%&38%a&@&45)3!!!#d!!!!cf8,
9!3%(+!!!+Q+!4QTBDQGS8)PTF)QJD(#TUN"jF+"JLTGfJ)!!!!#3!(Q(GfU)UBP
jL&L+ChP`J*!!LTGRPjKPLJ#!ChL)K`#TN!!!Q@HU!!"j!*QBHJ#J#3!!N!!!!*!
!#JL(!+Q3!!#!J!!!F*!!!+!!!+!*!!!!LT!!!!!*!!!!S*!!!!#!HS#+F(#!J(#
!LA83!!)N0%4R8(F&!!F(#!!!#!`64@B%Ce9A!!"@!'#%+3#F,r%)5!*#HHVLkN+
[&ielacDdE8*,Y6[dTkYc"(,*M$ih$jZIcqG(-[kI9e1a6$'hEk@IFiqReD8+0Iq
NN!!"(5@(hG[h0X#+P5@jJcE&lc*'NL@,DK,2@VrmRTh2NcYHpjA6PF-[2RE&Im*
kJ3EpZ[0VDX)kN!#4L+l8cDFpI1ejjH,Blr'Rh[HTqhJZB*YDE3SmpU@cIK@P[d8
3UhUQV4G&C5@E[%5Z)B$5fCjU2(0ejZ[GK6rb'QpDb)9XV)K9jYqMH!6b!*[lAcB
i&3iNhZadHRfj["0S3KDPYp`,1)&NXfh4rZcSfT33UlAEXk*8G$rm+ckUqPUVCIP
8S99JUl"9DX+i@C80V64GdAZJ&9B&Rll1MERY5l9hNIVp2,Ka%@2P@-@BPR4MRbf
B83p(3rebi2jJZL1$F0%CSH6bDX,XR)bB8#N2iZ8JVVK@)KeK`!*jMf"YI-`YPC&
(!FD+,I1maXbbSeDriA[1,qD3!'A`i@-qcD8mZ(Blh'RmV,U*l$Y3`P(V%p6[9lf
r'UKM9SZB-1a2+QPTpl[dVfqXe!'+kc(N*M1f'0NK`K&09%(+bQ4fGHV+L6rh428
iYLpiY@#(Ve512*M6mLhpFQ0(,5$4UL$H&N'!c$FScp[0NaVF4UbJcTQq0*Aq,&d
6TlJh"C@lLl&SrP2$CrJFdGhY@qjPC--%Em*Bp@%dfcMk)f0N8HIZpNKJFNj[`d[
d6EIjFSN,@6$#K)#f&YI%@PUc#i)4ZEApTEm+9'j29!LR4ZA[aDq[QFIPab3f[kJ
0[phXSX[3Kp5piES#H*G#9*YN*[)3K#,,9TYN3Vradj`EPU#bh*Qf8*H$l+0h(bk
0fe#e"TiY2KKRJ*QM+RKkAEFF!YN!Ypr5lEAKQ8!'C43J$c1@6Dc19##"N!!h$bF
b-fCcqCkq,LmSGcIRkF2c!2`XQPBKdD9b5Rd2D82Kpi(bb92hD9r6kR@*1Y#Y$%K
p'ak(-[pVUGL2`DQYf)qhFjhVCj1rU"h)TG'[KFchrjGU1Ie2jpVV$JRT3X`X`q1
PV`T8Km#1$B(ILSDAUIh`rY!Vp-2FK69c#%-6PqcRmi#2fF[RG$f!)j)p%K%q+k@
0rf'!Hd3Np@'PMGCBcj4"YQ9kqdqi!!!!J%CR@'G@H'#)H'Q!PhHAN!#3!&P`Q(#
!H3H@J)N)L3#3!*PTH@J*#(#!Q8"jD(Q!H3#CPhLBQ'D*Q*GfH)LA!!#3!!Q3!'G
`J!P`!)!)K`N*F!!!!*!!N!#!#3Q!Q*Q3!*!!J)!!!)!!J)!!!!N!N!#!!)!!N!!
*#3Q3!!!!N!#3!!#!N!#!J*!!Q(#*F("T"JN!!L-d3'"J4Q!(%MC`"`8!")3R!*H
FD%*i#3p,TpIKrpKF'GVe[ai@[#&cMrGHmqmKd1c@ci3r[Yr$#&,*br@p@EN@Xr2
j1Km@hRKR@VCQAAaZ4bTd,ZRU52b%028Tp6X9+)%8,ck-$0PiFr@jeIJF'6Ajhdr
AqADKGSH*qHkPXHekRISH9eGY[1Ar1*4K$q,&$+l8*erR!RHpRQj8qe*`2QbTrrd
rYNTHMZ0jbk0fMiYM$`m1RqYVUIT*5Klfij-N2Em'aHEAMHchYEIHEdrNmkhAaX$
"eUh9mMpjd2"AbG[LI2Hr,i2Jfh)(e&I1h#kD&XjEdpUlhimb2-cS6[2QY3Na,8*
CTErpV&b1Nm)F6"XA1,UZ,D--k6L6V0+RJpE#Xq(hCrX@kpY6e1T#LKl"Xd1YIf0
QD96'MGVfkH$CT&pZm+cr[AR@0PKU!-Al$'`6(&e@YPMK%6da(KDbcU!8Ab58UZV
(I"bT#3QV-YHh0N%a6`V0$Gi0M[D-&2@+%f22MCheEljmCXKBDD83hGE$!C6Hicb
mQI'Y0(5dETZUpXBEDMTFFrhT-60MT4iehBMf,[qBQV8T!4hGlkq6SAEJ#E)#E%f
K#P0bS8)p+YpP6c,YaK$&MdXI0Zh#5)3"'UVk25bIMKp3#DiMZKQG'T!!BDhlk%a
NK0N%L%)4d*PJ*%3Q5k%"EJJY[mcSpcm,ZcMj#1VP5$S$HjXIFQcFVSalR2cq2lq
K#&1V#V#V$d2*amH#KY28PG`%-@Vr@jlB&H2$IXp0#&m293Q2kh&UlYH#i5m%!!!
!J%CiD&GhCfPjHA"kJ'L3!*UAB)U+F'#+Q'@!J+#CS*!!DBGjH(L*H(PTD)PiH)T
`N!#DZ(GhKhHAZSKRLAGSQSU!J*!!DBH3!*!!J*!!QBL+!*!!#U#3!*!!N!#!S*!
!#AJ+UT!!S)UJ!)"`LJ#3!!#JN!#DS+#JLUU3!*!!QS#J#U#JJ!UUN!#JQ`Y`J("
`GhKP(!!"-d9@CQGhGiJ*#BJ!!!!!#3!!!!!!!!!!!*!!&a-e49D)"i!)F!F!#!J
!#!!!!!J!G`L!K#8",Eb)3Q!5'C!!K,kGRMmVPCf64bE))iR!aF6cI,`DFU(VG'A
I#V"a21Tcq$RCr,akb),qraF6$h@6k5S-C!Vi5ZG,pA2d`4&EHqK2`"XNNcmfYk6
lNPG!X[US'PDX)4!Qfkhh,hpr`E[pZS$0YjAr#jHYdCeZX(Y-I3d)3YI%aJHNjJM
q,bpH6kURTe26aS4H62cS5paR3Y*pTFIebpQTcA*$#RCHcaHNmPZC$'Pi8V-Qh-l
XEI-eFLbieI$VX2A-F,96dl-Ll&aPkdqdBBjNQ(AZCfC04pGEI-e2ebX[@D03$&`
dBlb'1,dQfc)F3Lb@NDVE,'L&%aBPD-GCIe"b1%Y$@CDBGHII)BZG[Q4A8l,rlc)
-2CF8rGfXl-hPrqLeR6ljN!"TpS3ErEF'"PblTRfX'eRAmqTcHC)Nk`kj4YHTcDR
(Ne)k-*Pl4KDB0@68!RH!QYerEhB+KEe2r*r)p(U91h8im)4cEri4CELbE8dj2NS
FL1D%,6Vp5Kb%8F2rk%ar&A[1&A9Ie90&8`9Ck+ZC#i&Pl$Vj,&h%HD!YX&R"SFL
rc)j[AaYjGrA[S@l&MeE'eRKd142a*Y#%N!$`Z2mH""qX'U4BqP+4K$c-6NN[H8S
5&3qmlU#j`ZSM-,!%edf"erEE,AY'5`QY&,G0cVE(PTfVh()6IK1,DmU`Y)lE"jd
0S6MkP&5`9h9&E8&Ga483+lDLV-&I)SSdeBl5LV8&GK45Al5MYNS9h5K+"hZhKGP
kUlc*F9,C6U41V*rhb0G@1M*XS%!L%TL%S*c)jphqh4VK6HX+"$iqhm8QYZlk6@S
eii2$+i3))[IG-N)G0`bq)NMTSjV@$rUlhL9cFeB6D)fI9N6N%Qb$0a8kY#l8GV-
(H0GpVec`4m`8PK+M8kZkZipV(YA9FQ4Q-Gq*a@!GXkcG@[*H,e-E#(fdEIGR4be
CE2cGb[Lp4kKPR'F#fG0a$%(IREKQ,e-24l@M9l'k+mp1+-,T!JZp9eN#%+Vmb#R
rHEV2rNAM2'4EUldrBc)5YX&)QDNSAFFZ1@pj&XGehN@amlLXHb$[PqL[H4'93Kd
ATiZ*E'Nla,BpeYjKk1RSi[8cX0cZ"mRMM'YMN[10E')jJerq0c!024U`Nk&"0b2
F+R)%(AKZS8K#Brfj03iCNEMT4RDECp#KjkEHdUerm0l5KARQpTrT3U91VZq3!-q
,0,3MTB2"jGB2@3Ue9i3a09UGA#"e@,bZK$D5DTh+e8C%@Yr4kL*)k%-0Hl(iYj4
Ne2ZhdfqKCj'&[pHbhRE[[jrr`K8rNaeMH1#*B)SJMDJLm"%3)m8%@B)f`)Y!4EJ
Le"#6+C*UcDX*8QTQ6!4C5DQA#6e8S(Ad8pNY,3BHbi5V)RfUe2S3qMIkmVV0d$"
jmVTJ6e`*cfI2'ck"i!Z$Vlp)8aJ*a`*6D1EjSjlJ8h3%6J`Bf2D$%h'k'$ci@!*
hQLhU+@b`Pmi%q9SYM+@iJ5q)#I!"2b0'[m,([(#9F#HS"18"-KUHGd2A@01#@#"
0m"2YY10*($pj0RRZ8iqN+@"`X2I3T8q&[S3T4U0K5`+DKX43f!`d%kARF#TaN!"
c5jJm(FA%i96c!9'i&`TF6$i#%P$`TAp2KlrcI2ih$a&(4Zap,M,,QSSJfP`hC*!
!EBrpXHaBr,Bl0Mq0MZf,%RLGrZGrr2IqR[kRIel&PBQ@,NqfV2AKDJIDr,$V3rY
$Z5l,KqD`Ik!2pbA&[mHVNjA+3RG3hX,b(jS[!UFhPj'9RjA*RmV0d+bITp!0H6$
Y4H$aUY9l1F31C%2f4@r!jeE+UmN0HRcFkYP*%H5'r`3rT&iA%cmV,AcM@$pE+jb
ZHF([CKALXkC#XfVQ)8pS+Hr$hSTIRC9AQT!!1N%DN!$XaA'"PD'6Rj[-VC[UC6F
lf[@$[B&eVJCZIPC0E1cr`Tq&I@Ka)9jAN5Z9#8RQLdV[VqMarXlc`Ii!Va$"E*I
1d)H(JF,%TJLm`+I$m`%Edp&3RT%FIFd)9j*$e02KMlQkB-QH,$(qap%eerQrZ!!
!!)"&H@GTD(PTL(G`LCPiJ*HSB)S!J'QU"fCiN!#3!*J!QRKhH@L*LQQ*KdL+H(U
!F)#CPhL)KQCi!)"SDAKiS)#!N!#TD*S!S(!!#CL+!!!!S!#3!!UJ!!!)GJ!*N!!
+J)!!UB!!N!#JLT!!S(S!F!"`#B#(UTS!!!#J!!#3!*!!S*U3!(#+N!"`J(TP$3!
"0$9ACQ"eF(#!#!F0%c4A8'!!"hF!!'9JB)3N!NhfB3[3*$3!RS6H0dV24VD2H[!
EaSmA,b[AiR,`)3ld1cm-bI9c-VN8+YERG(T@E(Q)LU9-h-brbG$3NK+)(`J0-(8
qICqS%6C[mNJAQ)&p#pUp6UkA95!CRXCZCTDAAdT%-Ci&[IS39IEk%0fJk6P3KI3
rKrlhF$8lhqXS*HI`[c3[!41iA$,lfIKRlTN5h'9cZKdV-)60E2h+dD&Y*YkrNPq
k2[4pl2K*ke$U3QErU3R8*errQ[YakcSKam+[Ym[6HbeU'I-imPLIJiAGhPMm1IH
ITYjGY6f$6KZ'(X+a0lYrAfU%j6&UA,Yi1&BRSqhHmXE2HNVl64U!B[fM(M3abp0
YXX1)4H-T(i0XXqD+,jN5R+kVrF(+F*L'V%l,Yd-P$'$[,%hGi9IrPU#RUmfKL60
@aLe2PQDY$*@$8*a"[XEJ`-`AP-r,9QDY5K(V@T8R@AE+0j)pER*[kC[mk2@Mc,[
JMhjI[hqR6RJMl+2k+YQADe0+Th-M'KES@B6k'K#-HhLCdZh6T5lHTeDH09Up(4$
ei+[&9XhI!dQXalI("eQE`rIK*,iV@,VdTGM$bEZaKK#liNI$DB-[&([bGe#&AV`
QC'0m%YcpD35R4KPKl`h2h6l)bm0LF#,bliDrqh(Rm8)A2f!EDe1UUb[#6cjp**3
#TS+i0hBV3KYJVeEZaci3fD[BN[bjIiMhrrq(PGV$XhGLAkb)Di%eJ*UYB00-X#e
hkDG*!M"$CbqMfdJ5`DlmfEfUF'MATUD#hlmhYDrcAGE%bEZY6K6Jiql%2fJ6ha4
DFIGL'H&ZDlI8VZZq3#e#rTAGLENbkr$bCI%rE+dBp[2QKL5jUdFk2Zd-lPGU1[M
8kZ2jX&$0$+[imH%)mbACTdSAf45K1)4XJ6aTd*Fq,%"80bN!pXJ%HC!!K6Re1i,
0b,%kZrY4cUFm)6VRD@8FRrTCRmUq4k9GYrUTiU[K9SSU6+)6XL&cS1X!GV'@`@F
DMR9,&1IFcmAIBH6$FUXFYMDcHdFkKQ6k-*BB(-rTaB2c"UNAIY5NFFH@%rB6-A'
K+9$h(P3CVKQ4'X,S%mLI!,Ra0PXLP,G60'&[MGCXII2,pZ(P*f(M3qL(+KY6,cN
qdSrVJrZc*[%jeRS9ZQK1q1l0l$qZR[IBXk9E4SD#q381R@r9@kG#M`F6eI5pC%r
iK25KXhkIf21K4K4KENi-**'F)QfhhdlJBrmpeV!VdBFf&icLN!#'pi[XjR)"(!i
[)j2j`4kCbL&")R`-I``YbbRJQ[$JF2e&'AZ+$,AQ[2H2lJ!!!)!fD'PjGfKJH(Q
!Q!#CF)Q(DA!!F'#3!*KQB)!!!!#3!(H(H@KTPhKiH&L*DAU!LS#CPRF)KhH)#BP
TD(L)!!QCJ)KhL3!!J!!*PhN*!!N!!*!!#R#3!!#)GU!!N!!!!*!!!!#!N!!!H3#
3!)#CS+!!J*!!!!N!!!!!!)!!#C!!DC!!QR#!J!#!N!"kG3d!!60&9@"JC`B!"`F
(#4-e4@"J"@"h8)LB"*hSa'm!ND1Yd1"Z9pESBA5`VG6Bl(iekfAJD@jc[qIppqE
XI*qZrRHI2bXhNjP(TI"Rk@K%dBeUh0cE(UFrSc)PeHh1J#25@rfHrkZS#,bGfTE
b2"@h*CRiAhrlhF4E4)(J!60UiXR8Ul9ADUl8RAPP#@jN`L5)QrGXrkd010rI&TQ
bNehN6G3"j(l4f20M8R4PfrmapQ5#H4EjbL-cdrbb*RGm8@,IdrCNfq$hZ&Kj@Ta
0l9Yi'a6f##Gh1[fAL&UhVrh,r8R8NkQG%cXbFbAae+F6mHR&lP@TI'"2)"2,FqE
KJU,q6hU0Rh0D6`bFb)U8+hH&Pq,+%RIPm&+c8S"#pZDe+bLMPIqLHqU[VF9DlmU
S#UH+Y0&9Z-!@BmA1HaGbhP!@f#cfD9QYT9+&c1UiATC%Al&MjE'eQ$5XdFfK5L@
21jQeAKrB08MGZT5-XHD8kh'G1UiX5P3peh8&cKG4'BES%rY0JA2QE,Bp1AG6@LP
[RGDfcepd`l-RANjQlG+jYiIFU*Nhld[D6I@ceUhHam@05MDLK4k-55Dr$XblP5R
,ZE293-(*f9mFH!Xh63K8aB[SR"DqZGP'P5P&JK&fjp&#e%b@lTAS)QbhG(a12V5
6MGjU%,RbJEbl29BXdHJek"YJ6q@U&H5DiNmL"!)f@RbDj#2i6bcGZe)D,F56AB5
m2fblI$b*GY@d2($VBdr&ir*bD2Yf10MF9-9X(+YAYqCLc23MPc,%kEbZ3Sq2d"p
#GHFE2YFr3kD%jm6i`BqVZElf,A@d01MmA`pI6SriXCRVCU(H%(DFcPi#4,J45LP
(DQDX6*Kri1HkMhS-BR&jHqY!VJacSQVp2%B0IMjZB#-5[QFV*"(%2ZiST%m6Ld)
e%rBcIpaLBaj5JcH#V'qrHVf[MTf[m`!!J%9S@'PRH@"jH@#*!'L!QCT!F!"`B(S
(GB#3!!!!!*!!H(L)DBH*HAPj@)PSH("`S*UAHCL)CSLDJ'KiLAF!UC!!!(PSL3!
!F!!)KhUJ!!N!!*!!!!N!S!L(!!U3!!#3!*!!N!!!F!!!N!!!S+!*!!#3!)#3!!!
!UJ!!N!!!N!!!N!#!DS#DJ)"`N!"`J("e$3!#*$4&3&"Q"h!(#!J-%c99Cf"`"`"
`93CJK#3"1(hi3P!5(8Kfqj`q%"2qU+'#rcF&i'CRqjR4kr@ZrdT!aCXk1IDaZPe
C)8G[Z5K(6I#9E`EQ"p408kSBL"5IDj!!f6m@Lpe`A5p9S[-D,q*S[ql4Ih0&YKY
,pA"I#TJA#A'dm*,G#mDCbr04qdrCRl1R#6ARd+2,0N3`H6N3UCPfMbJ*ZJ*[EIG
a`+KK6qr(5plCRm-qK#%e@ch`X`JXUclP(ql'P09"#TYl0M5+MRIrKJ[bVkA&@dr
P98+X%+Zd9@T$$#cN`fqNLlR[+!Uf"CcE'PCZ69G[6irm28j8-*&Mff-@FDaT4ck
YL&%24d2[jN(q`A51#qD4QKjFPe)DF[(bB8#SIcGU#Xm+a%-iF!#HBk!fqk`YbFL
MJ10&&Zmh'h`(YLA%dTpDI3i,iVRNa0LBjQm9Mh6VV`DYR[mR*KHMGK9MeB6cl@2
T8Emf44[q$ib'"bA-q@5Z,0eb3QbBB%*3@`0[A,5Da#d)4Ifrl9EX*+,pbS"&+Lr
Er4apG-ii0%N0[j`'h["mD,,F)IiAf&j!%mDk*6RfJQh5%!4KE"RfK#[r(UlJ[c3
@@pDID3PiIVSmQ2bU2*0#D$eYmX-m"-fIFNep(CGG!YN!YeG(CFI'D2B!hSE*QjH
9##"N$HINmZ1CDbqEb-6%bSpL%Z*f)9)e-2rY[IReQN-f[EhqKX2#aq8CXPbV@Vr
CaERlr$5k0keH3p@QKJ+29lP2l-1h[4U)Be+,9kYAZ95qiR&ZHAlC,HmXe!'-0CM
G*MSE$'b3!1%)T+T(lXCDG-+-&85U)kYrX$Nd*5DZ9,9k2+*LYaEP2L9lIMe))HY
diimZ,FipRr-Z,(P*"Se""[%b$!C@GTRmFbA&XaReY5JcUeH&'mdqX2UhRHm0aMr
eNb9iFq5e,5jhYU(`r)$kXY2f2JZp,UGFNm''$$M3qMBp$,Zk[8l8INl'YfSp'eR
H[RNlkS1j%R2`m$,kI@eBjr8rVUpFFpp+&L&L(c5GZ%NJmd'b,cljlLmMrQ(M!9k
F2j3T+hP#('jRYCqF"',c-lRHb"(V$Jd)Rm,LmMT`[+j&N!!G@&M1p$&bUZ#VfV1
(YAi!!!!!J%CRB'KTH("jH'#!!'B!J!"!F!"`J*QBGRG`#3!!N!#3!("hD!N!DB"
S8(GhH*KJ!!#AGSH(C@B!#AKSD@F)#*!!!!"RJ!!!F*!!!!G`J!!!!!!!!*!!!!#
!L3!)N!!!F*!!!!#!!!!!!!!!!!#3!!P`!*!!!!N!!!!!!!!!B!#*J(#3!("`F)"
`"3X!!L-d4@"Q8!!!B!B50J!'3!@%*`#6qF#!%KUq'hZfTT[Ckrlr`&U9!MpAlpR
[iGl"q9ZAHmH$,XEAKXa[fm&ZA"E[hE%m0DpHeYE(dEYfG#DCm1iI93K`qURlH@l
p3%8FM4U5EhSr2afm1lGhX'PRk(PdIVMCYiEfrSJrf1a2,HDEfpVfI[#'4TpQ[Aq
lbhX-E0l$[2eYRG[KE9rkX0jVdYVdAV0k@lKFe3EB-2T+hXc[KZCDjQ(#F6Ur+Ei
bHH6clN*hf4md+'EjS8SdXcrERA*`2#(JUA1[CiR5eq'j3m%kA+Te1@V,dq5IiX@
aL8p6V3qC$e5@MbjPcUM58aIQf-91T,P&pfkX[rrc1ZG6$8!Bc''1JQ0RLDf@1%4
26%G,@@j4#M*55T+kZI%(+d+"05dYM&(8*LR9PSpZTFq&q#RVP'2HRBjG#[lTf11
SX0'N)E'f'!bQpaRdf*f1['6J[c'kf-3`hbNi,Cr4SCZh*`5IK0d5HqERcH+YP!4
MlZ[BhjZX"1S"1L1r$+MGK4Nj+fI0e%)!M5f6*b@2dKV!*B$VpVA(@J`eT)Dc`@r
@eamhm6GAHe%GGGD$X"hGZ6mBlHYabFhfkfR!K#%(-1q1KRDI2mrp!9h)D61"K$*
(#`LIL-l6lLq3!0C[N!!!!)"&Gf"`DB"TUQKiLA"hS+N(@'!)D(QDKfDTN!!!S+#
DUC!!GhU(!'GkH9H*GhHJH3S!KhD@KQD'S)TQD(KfF*QD!+KiJ!#3!)UJ!!GJ!!!
*!!#J!+#3!!!+S*!!#)#JN!#T!!#+!!!*!!#J!!!!!)HCHJ#+!)!!F!#3!!#!#A"
`J+#+J(#!F*8J!!)d4&4$CPGRF(#!H!!!F!"`!!!!!!!!F!!!J!!!!!J5%c4'CA"
`!!!'!!!!!!!!G`"JK#)"1Eii3jJ#3d-M3LqqIkhVaaG',%fqH!P(3Lp(bG!#3Dp
(mr@p1TUHlS4pQlAV@U[Al1!'HCQDfTTH[@kd8*Hhh*MSK$Ypc$r[rVmrr!)`[8b
1Ac[fp6Y8IGl9(4l9(8l8AXDIBpr8L`Vrkri!2VAqebqGEdITa0$LaB5mFR8N[5I
Xa)3TcXLh#E(1X6iV[5jP1%RHLm(-b-U1GVEX9R+Rief+K1XBP1'c3Ta%FeYfK#2
(cqhB`,X-q&QI(U4plrrp)p6,mN-51D-Sm@aq"0QKfbUfAk*H+6X5GMBK&l8Gb%b
KF%ZQcrqf155m`KRiYMNdqkf@Z`f*QI&CRBH,p'0Cmr`B'VZD@iNpKdiHNJpLfF,
k*pMMMQT-ACG,F`m@c1*pcFDcrlr-9MM8DJ$%p4Mc%Bdqkdf6$K#-"&)ml6,B`JS
j5)P05kXF318i6#0@CZPZ4j4'-2'XiA0aE($GJNpB`SmR"hl2jFc[B1r(P*JdFd3
Eb03B$-0a62b9-(Ic)j,ef8TeTEJShSN[95ip-SDjGdbq'6`5q@KhDFi#2*NHpQI
fTdK[&Z%k2V3`*,q6Vbq-LN[MNm'"dJ1m95h,b!*aJ*jP+-+5r(5Pj2mGqAMX6Xc
[bqA*Ybq+AKf*`%FL"h(,`e2MLm`K(fjR38ffa(VF[PPi!miEj0XUAlGM3MYbq12
Tlh&,`C05AIR6iEPHKGK2T5rCXlRej96k[ZrP(SEhe91YJq)A,)eYh6h0l[P&K(1
"8Dq15rUEZPhd4VJ&@iERcU0IaN[LND"8M(r6#*e5YL%"LM[3)3rf#frk[6Pq`T0
3Ybm&5e#)$'Y#j3d*)VmdPmNK"'d$m`4kaVlj0EGT`8qpPkI"449SA!r88a5,KGE
*RipLHjfD%XaQd$8Z'AM$,N!3K"iCNDmR8MeqRZbH((e0QVEl2AUl9UhCDmIMVGD
VXeDfeAfHc(q(6[E1hAq)MfeAq(DMSDmH[rARdYcpf"QI,*[&p)SjGlprAr3"AiU
1AXK33['SrUV9qVD3!&m@MQeDelDVT'5E9VVp93c4@je9LUTV+YRCUlE3bYDfDbB
h9BY1'e@6bXFmVR%+ja!C5e%+kiKD0ED0EDBYY,@fcRY`h0`h0aMQiYcF0cH0cH0
cHBj[01B`&ad"@#RNSpRU1AQpHdRDAr$(-@Uehf,8%"5#dU9)"rESjCk$PZ2P$"M
(q5J+h#HJJ+l9ViPpFqqd+T[PH+T2'pXl@c@#mXq#CUjEQRKZFD,1BjcPVFieZLD
h4@Y63G%e'UDM9C&G9L0rF-jcIV-+2YqAPr-"AiiHbVpr#(+(m1",CP(h1MM)pEd
eHYaVm4Z@`!!!J%CiCfK@H'PkHR"kS(L3!*QSB)S!B'L*"hD!J+#J!*TTL(KRL+K
RLRPSHQGiLSU!QDGhKhCfK`PkChKfD*!!QC!!S!"UQU#JJ+#TUBN!N!!!S!#3!*!
!S!#3!!KhS!U3!*!!LT!!!!U3!+!!S!!!J+U3!!#JHS!!!!Q!S!!!!)#JN!#JS)S
+HS"`F)#+C"B!!60%9QGiH!F)#!J(!!!!!!!!!!#!%"-dC9Ch!(B(!!!!!!KRJ!D
%*3%i2rS3Q!5'TXD0[5dGDEVDpUc0QdH2cl&c,dEGc,eE9MM8IAepA6`+ZGkHA2Y
h2CeV%,iBe+R8cUr(dZ[+K(m[Ybi!4l*BHer$Upm%6*2`h104506lGM@XD9c9elA
'qjjNeq6-Pr1YDEr@jQ[EDYeNY3SG+NZU+XUeEXE0cM'86Y$"CH)A8Uh-mNI&@l&
EXD%1"qkIV`PmAAK*2N`[Se2,@l,XKd-A8mZEfRSYX3d*I3P@Cf(LphKfGlVAh5Z
elV$f(5K08pLfCRG`Y6IRb--E%Dph$aE-j(f*`l1lmXV8hfQS"M#DBmD'-hY10Q3
iK&mY)hR'@K-&'!X5NBke2%(+8*D'V-PHl2b%-BI$Xc-6&e2pl%'(Y5C2aTNPRN9
2hc**q3b$6j!!JhdZ3B'BEc623Uc*+NqYfGL+6U[G+0j+hCVG11l5aiB(,ai59E8
Gd#H-#EqhlQ-#SB0Em8r2p6hDfj@kF)8Te6Z#c"&NkYmdHp4ck8i)5EIZdFp&(4r
j$!IUVi(5VY[j91&@!+YP&@a$#&R,KYk6&fBp8"EB,2ZdFqTCT6Y[3j(%mr)KJX@
2Zf1,20Sjmr1R8B4KpATrcjX(aJfNA[p*51J2,+ENPmLR#*829HDJ[(#j%FBAJ*j
%d"Yqii@jH2'mQD+@r@lcE4AU,LjkDm*a`U&U%P,K9IBK`#FH*48X&H&49q#[!SU
B#Ya4A""AH88BeHrNSUD#Zl5i56ML8i5JGm9!YLm`H0NN+4j8jD6Q+Ika%1h5aiq
9!J%3PJ)5JQk$HRrr"Mh3Tb@&!KmqjmFGr'b)lq2GT3I6,#3))YTiC)3rBkCI'54
iD1UeZPShH,fU4)$@AhdVfeFUGcPdiACpU%kIei9UhEaXpPQfVG+R9cEQX(Vi9Eb
i3a0DVG[S!ke-p,mN1"(H0GEb-L,I$kRZSNT8B9ef4lh)ail[i-LGN3QGDTNq59h
Gc)lrrB3VIhBkd-F%5`43"&q#2X!LB#2VJMJJM""%J)596Bldke#9(GXb!LqMZkR
k%QfhqB$EqeEBFe)3lj00jXdK$D*YMZ6DVl8VcJ*L-e*HcMe&1d)3r29pU(N!LHi
N-8e-D`5m!%ll5e"5h6#Ac!6j'PX*5f3%[I!K8Phpj&,FF**"Y"TE`U@a!P8!RfQ
P[l)@I0@E0C[d42Je2QFhQeqGQj[+K6T1KF+H6PCh1345B*TjZGAk0ERU5F&dqGk
DN!"!p2T*!!,#RP)+!X+G4"3&KHraHmFF#-q2fijFHYHkPl3[GHpXA[B[AEhD1LZ
$hS5!Hrq@(lBIdKi*GpdI[-(p8(qr,QC1MDdV'XK2%KbB8)I"-Pe0I@dd)d3Mk)4
i19FdGE9dVDIa9-+9JT0k9V6XE+GP)@c!YeJY*c[al(AdEHULZrd`Vkm2ic2UCYc
C6[H`l162B$Rk8Bj1VFd8rF)ar8&IK5BFc6dpQaE46,qY$-KGPICPHY#9+#%Pelm
1K3j9c#rb#[1-6[PrD3Kj[0bXl,"&$QjI4ji)j*rN3RT%D(+m-,XBMl#K3p,U0'H
!'HAK,jaQTjar8!!!!)"(@'"JD'"RLA"JLB"R!*!!!%"JN!"`H(N)PTK`N!"`#!L
BF(GT#3"jF)PCL@KiJ'!!N!#AGjHB9AD3!)GRD)Ph!*L!!!"jN!#3!!"`!!!(J)#
3!!#!!!Q3!*!!!!!*QB!*J*!!F*!!!!"`N!!!#3!!N!!!!)!!J)J*!!N!N!!!!!!
!!)!!N!"`N!#!J)"JJ(#9#3!#*$4'9("A"3F503B!"!!'K$%!6MDN)5!*$SBXFS!
iaphC`GVXhTpIDMNkh,McHGcZE(TpVBeEpA3d[Jk-G+pYGIV3N!!aYflZPFbYEAa
)8I9pG+!#2%UrjEr8d!)TmElZ[Xhjir4HlI@dpVRiY+(+r$eEIik&k&D2`rRjXZa
,`5F2VhIkrMfl&QaIcCl0c2RVJ*NGA2RK$`!9#(HPfm[*Smi9FANZ2KRKD-mINlp
(rblB&Gh,jF+fMHK9QMT@rRaVPZEkF'X28I(UFK0a$F1@cr64`bpLAX$hpE99i+c
TL!kTMU2qXlYUX"(PbILd,p(%!Q%"22'q0TV`Tbpbel0(%3J#-,9CHjSGZ(lJ*qX
["LIjGhV8&QXY4VZJYr0hHmAJS`mc1S`fS@S22[Q!6UK4plcl-"EGDq0ir`'6Tbr
*(6k@p,i[Xf0@pIK$-pbeTHrTG(hXf%("65La,"$"%GQ&+cX`U4UBhpcF8Zfi3dE
%h&dpedYJKU8Y(%RV9l'rMcqMjC1TZA0a$eHe$MU2@*kHrM6BBe%-B+,QjAX6eLq
j122j[fa*X+c8!BaPQ216(6h@0NMK%5+a(SBbe+B899594(8h#$PU&)QTkPcFMR%
aAajkI*X6IlJJKkDR(Q5ACrDYrT*GMR*$4U#'mV)B$+lpM2Bd*,YZ-ZhJS0eFh"K
[6,YRM(Ic)C'Ep[U$lq(V3bepP#&8GY#*kI)k(KEqF!!!!)"'CfKJD@P`DA"JF!"
R!*!!!%"`J)#!Q3H'QB!!J!#3!*Q!HA!!HA"`H9#*D'Q!F!#3!*GiH!KQK`!*GhL
!G`N)N!!!!'C`N!#3!(#3!)!)J!!*!!!!!!#3!)!!!*!!!*L3!!#!N!!!!)!!!!!
!!!!!!)!(J!!!!!N!!!"`!*!!N!#!!("@J*!!F)"JKe"N#`!"0$43Ch"A"J!("a)
`B!B%!&#%+3%bTS3TJ5(eFmXFXFX2$AjqH6"2[mqEUAIVeShI$[GhmI"YlrGm%Ef
lZErKTLl5dYHlFq*`4h1p5J-DN!$$`fIip(brm#+Z9q`'U@*jq3Aj*`B#F8XNmmm
,'+K"2*BRPk36b6ciU26)$5P+MMb6iZ0"-Tq@Mf3K+@6&amD6q3EiH(SC,%U25$q
1aL"p@"19B3X0S`5@B-TkZcBA3``*NITpdTjZr0hpQ&,jSlX+QIZ`V4VCRqAU*Z"
i3eE9kMXm6TEHKXe0@PIbl0Vcjerfl92lF&c!TkcEKlc$eUr9mqCHaaV+BhTA-&Q
eIbdICZGIrrqk9l'de!-CM6(-KMXm6MCBiL+E-4lA'@c9&&GNP@9eHR$PZ&4$9qY
F`4d8-@Fkr9cE9lPhS+H[9Bk&26[r*THDRTad9KSeL'pEN!$!bbqicip5RTk8CZ$
HNPeF`''pdh"fdrCUCqa0`6GUA00k*Hc2iVH@#2AdrXe0b9!%aJ6QMZ3bipk&@Eb
@qT+K!J%F,9j[*UIP$q3*j4eqq[ilF'QZU`eqJ@rAAmIUrU@23dCBlF,F(VllJ*F
&'dpIGB,Dciq5mIS$Tl%hhaf1aij[9qIiG[Eh)3k2cflYhV`8-dBJ93bKX2$@Gp0
$TI4i[J(X2KKe@mp#&Fk+%8qPkAArerpU!!!!ki3ff`!-!*C#3N9NDA3J5&406#"
PH(4PER0TEfjc!!X,5&406#""EQ0SEh)"!!!!#%*#@&45+Q0SU,TDZULk@VX"!!a
Ape`!!J!!"J`!!!!!!!!$m`!!!!!-5&406#"MEfeYC@jd!3!!!rY#3PK88LTMD+L
k,`QS[IU0!3"6rUV-!!)!!!19!!!!!!!!!YF!!!!!#dK868`J4QpbE@&d!3!!"Y*
#3PK88LTMD+LcHVUSc'YL!3$@Tp#8!!)!!!ZH!!!!!!!!"UB!!!!!$%K868`J5'9
KC'PZC`%!!!ei3N*B9&)UBfLSZI,6U,hpT!%!#k5"3`!#!!!'X3!!!!!!!!4R!!!
!!!T)9%e-)'PYB@GP!3!!%Gp#3PK88LTMD+Lk,)#S[I[V!3"@IQG[!!)!!!4r!!!
!!!!!!dF!!!!!#8K868`JE'PZD`%!!"8Q3N*B9&)UBfLSZJQKU,hm-3%!Ff6lRJ!
#!!!'$!!!!!!!!!2-!!!!!!j)9%e-)("KFQ&RFQ&`D!%!!"Mb3N*B9&)UBfLSXQJ
XU,hk*!%!)5Tf5!!#!!!$-3!!!!!!!!*Z!!!!!!e)9%e-)(0`C@0TB@ac!3!!'f"
#3PK88LTMD+Ll10@S[Id9!3""-li#!!)!!"8S!!!!!!!!"+%!!!!!#NK868`JFh4
jE'8"!!!J!8*#@&45+Q0SU,0DdULpr&i"!$[c`b8!!J!!#&N!!!!!!!!&03!!!!!
+5&406#"8DA4XC3%!!#8f3N*B9&)UBfLSXP9)U,hmL3%!P'T0'`!#!!!$R3!!!!!
!!!+M!!!!!"4)9%e-)&4jF'9hFQPdCA)JCQpZG!%!!#IC3N*B9&)UBfLSZM(QU,h
p9`%!PR-cA`!#!!!$P3!!!!!!!!+*!!!!!)2K!!!"!!!!-A-!!$"c!!!#CJ!&!!j
J!2pS4IS!i#m+##i!"3!1C`K&qJV+B3!+CL4I'N*#4@4TG#e)9%e-,@9iG'9ZFfP
[ER-ZFf9KC3)!!!!!!%&38%a&@&45!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!U-b
9f`!!!!!!!$2CF!!`(j!!AfFb[UX!)'F#5%![!#m-2c`!8+RRB"i["bm-U9YCMkP
e3IS!k##I98m["bm&5(S!i+PS9%p"qJ$83T!!8%p`#Q!!qbTm!'%%I2mZ!am',`F
[$$mm!&bTjdjeB3!,FR3"[N"X!M!([N&[!M)(5%G)3%K"8FVrl%je51F3)#m'!!!
"TJ!!"8PMEfi0!!!!)N&eG'p&H(4bB@0dEh+U)+NJ-6Nj-5"#D@aX)%G[Ef4YB@j
#3A9dEd9iG(*KBh4[FL"bCA&eDA*PFb"dD'8J5'PPFQ&bBfKTBf&X)%CTE'8J8hP
cG'9Y)#K)4P-T)(0[CR4hBA*P*&4SCA*P)'Pc)'j[G#"PEQpeCfJJE@9YEh*j)'&
fB@PXB@*XC8K8D'9bC5"TFb"ZEh3JC@j[G@GS)(0`B@0P)'&fB@PXB@*XC5"[EL"
dD'Pc)(C[E(9YC5"dEb"PH("KEQ3JG'KP)'&bBfKTGQ8Q)("KFh0hEh*N)(0eF("
XD@9N)'Pc)'PZBfpbFQ9MG#"[FL"dD'8+G'KP)%C*6N&-)!)J)`0dD'8,B5"ND@C
QCA*PER3,4AKdFQ&MG'PZCcSJ4QPXCA-JFQ9YB@PZD@jR)(4[)'*P)'9iG(*KBh4
PC$SC3fpYF'&MG'9N)'*j)%0[EA"KBh3J8(*[UJ!!!!![!$*33808!!!*!d&&)&4
PEA!$!&!!8!#S!D3!!!!(!&m!&`&9!%Arr`")!9B!(3!+!#8"5`!!!!!!$!!5$4i
"qJ!D!!)!c!!!!!!!!#)-!&!!"Nj@rT4)j`%)+'i!#%)Yle)V61mk6VSGYK!YldZ
`,!!KCa!EE!!KldY1ZKEm5J"Q!!3+3QFr,Hp-2c`!!5mX!#*1ZL$U-"ml31pd5Qh
[G'B!!ha#CcmYle3[,Hp@,bh[1LmX!#S[,!!Q6VSHi$!I1d$[G!aYrp$[G'B!!,!
[,Hmk5'lrP%kk'h"3McY!lh4+EHpdCJ!$AK!Zrl*)J!J!!!4R'LmYlcSr2!$c6VS
EN!"FM`a!!!&R!!,HB!!$J%SYlQ4Q!!!S,bh[1Mmm!2&1ZKYZA)p1V3!k!!%!"!0
J!VJ$A!!+!!*`!4Y!lQ4#CcmYle3[,Hp@,bh[1Nkk(b3`(cY!lh4+EHpdCJ!#kN*
R2bh[9#mYleB[,Hmk,b`!+LmX!#C1ZKiS-"ml31pd5Qh[G'B!!X)[,Hmk5'lrP%k
k'VT3McY!lh4+EHpdCJ!#U$em3!$r[#eX!#lrh#eYleEra%*R5'lrP#"IF!ULB$k
!-"ml31pd5Qh[G'B!!RS),!!!!$eR%R!"'d$ZCA!"'d$Z8Nkk#PKJ"%)YlQ9`rbY
!lhBVE!"'lNSVE!!qlNj+VHj+C`!!EN*R2bh[9#mYleB[,Hmk(c`!!dKYleT1ZKd
N-"ml31pd5Qh[G'B!!KT`!4Y!le*`!X"X!$`r!%kk!S"8Mc!YlNK1V3!k!!!!!J*
!!!B"cJ(b3Lh[8N*R2bh[@Nkk(T``(cY!lh4+EHpdCJ!"eLYX!%VZ5LYX!%,Z6NU
YlNTR!!"Z3QFr,Hp8,bh[9LmYlcSI2!!$5'h[@Nkk(%S`(cY!lh4+EHpdCJ!"QR!
"'d$[8R!%`'`!2$m!6VS#!&52-#hZ5%kY!$S!!!!#!F!!"J&1!A*#,Hp53QFr,Hp
D6VSH($!I1d$[G%TYlh4Q!!&@)#h[GV#X!$KQ!!&D,bh[1NKZrj41ZKP#8)ml31p
d5Qh[G'B!!6!YE!!brq!`22lq`'`!0Me!rl`YEHp@rm4#CdKZrj3JAh!+SQ!qJ$!
I1d$[G%TYlh4Q!!$m##`!!`!pCb"#CcmYle3[,Hp@,bh[1Nkk(8i`(cY!lh4+EHp
dCJ!!e(!!%#hZA$i!B"3`4p(YlcT$lHjFdXF3%,!4CJC64dT(E1J-4rrrCJ!!FLe
YleEra%(ZrT3Y52qQF2mp32q`3QG)E[q8)&p`#D*J2S!`(cY!lh4+EHpdCN))lJ!
#rla#,[k83QG)E[q8)&p`#U*J2S!`(f!Q5Lh[8QFJ3QFr,HpD6VSG#$!I3QFr,Hp
8,bh[9LmYlcT1ZKaS-"p1ZKT)8fh[3%kk'KT`!'!!!*K+EHpdC`!!D!aYrpR[G'B
'F'3l31pd)'h[6NKS!""1ZK*X@)pJ5#mYlcT1ZK*J@)p+!'D8B$K+,HjPC`K"lIa
A)!KJ"N(Yqi)J##mYlcS[!%KYqi*)EIZ#UBY#Ccmm!2*#TkQ)-"m-3!!"C`$rA%S
Yle*R)%*R2bh[@Nkk(')`(d*R2bh[9#mYleB[,Hmk6VSE`M!IF!&-ha#!6Pj1G8j
@rN")jam)3QhZ5%*YlPT1ZJ4Q5QhZ5'B!!LiVEHpFlf!VEHk#lST+,J!*Cc4J2#!
Ylfb`VHp`CJa1ZJ3m5QhZ5'B!!J3JEHpX8Uh[E(!!%"!r!%kk"Aa8MdTYlNKQ!!(
S5UhZ6QE)B!!"fL"YlS*#+"rp)'hZJN)S(riJEHk#3LJIrcmm!3![,Hk15'lr!%k
k!Ej2l`!+5QhZ5'B!!DSr2!"!,bhZNNKZrX"1ZJ'L6qm!#NTYlNKQ!!'12c`!J#m
YlTC)E[j!6VS"KNr[!!T+EHj)CJ!"FRi!3QhZ@$mm!""1ZJ-19)p+EHj)CJ!"@Q!
!!6Sf,Hj8#!-!$fG8-$arrm"$5%"#3%K!d+hZML"!(""`!"!'5%"#3%K!d)iJ3(!
!%#Mr!&*!2`"1ZJ,'9)p+EHj)CJ!"%R!!%!Br!%kk"**8MdTYlNKQ!!$q9)GJ!!$
F-$arrm"$5%"#3%K!d+hZNL"!F!!3%$J!-%64cR!!%#Mq`&*!2`"1ZJ*i9)p+EHj
)CJ!!a$!YlP6L5%K!3N")30#YlTBJ3(!!%"!k!$"&dFj`!"!SrN!r!%kk!NC8MdT
YlNKQ!!#5-!AY5$S!-#hZ9()+iQL+3$mm!!C1ZJ)N9)p+EHj)CJ!!F$"&)#hZLT!
!L#K!ZHhZJQ3k5H`J!'!d5UhZ6QB3F!%l31j)F0Nl31pdB!!!4(!!%"3r!%kk!m4
8MdTYlNKQ-&+-ZHhZKQB%+'hZJP0%5N4XaPD($)F!!Ir`E!K+VHj1CJ$qZNUYlNj
Q!2j#6VS%kNcI%2K1ANje6PEqrNMR(cJSEJ!)*Qi!$#!Ylfb`VHp`CJa1ZJ)-5Qh
Z5'B!!ABJEHpX8Uh[E(!!%"!m!$!'d%#`EJ!3EJ!"8(B!B%JJ,HpXX+h[F'B-6VS
"f%TYlNKQ!!&#-!053dM!d)`JEHpXFJ!5%1K*)%!3J6!$8N0)`0#-)'h[E&+Ylfa
b!")3!N%!$b"!%)&64NT'E,*J$$!$8N0)`0#-)%"#%,CZ!""YlMBZ!""J#$"$dFi
43rm!8d0+3fcb3Llqrc!Z!""63$B!B%``3p(1F!!3+2m!5%"#3%K!d)``3p(1'#M
r!A)!%J4)38*"5%(5M#"")N!3%E!3Ba``3p(1-N26cK&Tr`$r!6"$dFi442m!F!%
G32lr8d0+3fbZ5LlqrfDDIJ"f!'!!!'!`3p(1'LMr!(!!%!9)3%*!5%$3M#"!'""
`!"!%5N"R2(!!%!4b$j*!F!(MD$`!-!I34NK!3N")3!b!!!#!!')QF!!`"p#,*%"
J!K6&8Flrr(!!%!3b2)!!i'RH39*$YQi!%'fFB!a`f6Y!lh4`!6Y!lNK-haci6Pj
1G8j@!!!["aiZ!!P`!"!(X'hZ@'0B)#hZ9$)YlPMMU#Y!lP5H,HjC)#h[E,#Ylh"
Q#Nkk!&4+EHj)CNBJEHpX8Uh[E"Y3lPBJ,HpXX+h[F'B+6VS!0%TYlNKQ*L"Ylfa
5VHpX'e$Z9h!31d$Z@#!YlP6[U#Y!lP33"`*!!2q4EHjB,Kp1ANje6PErr%MR!`K
+VHj+C`!"-%kk%fj+!'B!!63YI!!!%!$rr#!Zrrb`VHj+B`BYEHj+rra#CcmYlda
)E[rm,bh[D%kk&k!`(cY!lh4+EHpdCb3-EIrClh4Q!!$X8Lh[5a!YldZ`,Hk!BJ!
!eNkk$GK+!'B!!0T+V[rmCk![,[rm6VS8fPL2)#lrr*'YlNSJ,HpSd+lrr#Y!lh!
VEHpSlfa+,HjPC`!!VLKYlfJZ,[rmB'SJ,I0qi)Kb!")8XB%F!8(88S`3KR!!%!B
L,I0qXi!F!#!YmhTb'11S)LhcIZ#*J)&b!")'5%&#38K"jB&"lIH#dF%L%,1!+d$
cIL!YmhVJL()!%JC)38*"5%(PJ8(Ymi,4`5)3Xi!V320k8iG+Kfb3!%SYlP*R,%)
YlP)JEHpS8)JV51pX)#h[F,#YlfaN&($C1d$[G(!"1d$Z5'!'F!-l31j)60m3`%j
H6R919J!!,`FH,J!*)'hZLK#(8UhZLL!YlSU`VHk'CJBVEHk#lST+EHjDCLC`!"!
($%!!J@B8$+d!!!!"lNjR#R!"1d$Z@Q!!!4)E4qjLB!!!l!aY!!(Z@QB!!'a`!"!
($%!!JQB+F!)l31jDB!!!l"Ym!)(ZBL"Ylf!3[!#"8Uh[B#!Ylf#`VHpNCJa1ZJ$
55QhZ5'B!!-46VHj15UhZ6QF!!,K`!"!($%!!J@B-$+d!!!!"lNjQ!!#L3QhZ@KY
(lQ*J!!"i3QhZ@NS(Ccj6"f!Z)'h[B"#YlQ*5VHpJ)#h[B,#Ylf4Q$%kk!(C+EHj
)CJ!!D&1YlNj+VHj1C`!!A"!(8`G+!'E+B!!!8#"Ylf!3[!#"8Uh[B#!Ylf#`VHp
NCJT1ZJ!m5QhZ5'BZ8khZ6NUYlNjR*"Ym!),ZBL"Ylf!3VHjL8Uh[B#!Ylf#`VHp
NCJ41ZJ!-8khZ6LiI6Pj1G8j@rr`J,HpJN!#Yle`Y32rm,blrr#mYlea1ZK!38)p
#CcmYleT)E[rm,bh[A%kk&3!`(cY!lh4+EHpdC`K`!MY!lNKJ"LYYlec[B%jH6R9
)j`-)+h`")d9RmhSVI)QVcHrcIN(YlQFS5(!!%#hZCM`!B&T"e&+-F!!3%#)Ymhk
cJ"i!)#hcHR)BikJL,I0qi)Q!JA)!%JG)38*"5%(PJ8(Ypi,4`5)3Xi!V320q)#h
cHZ#)FJ!5"dK"3N&)3H@"3HhcJY(")K#cJ#Y!mhT64NT'E+"-ha$!6R919[mZ51F
$'%kk&A*)EIrmU'kSrMmmrrp#Cb!IS$+T%UN`UFa#TkPlU&"1ZK986VS98!airrm
$pQB35'hlTMmm!0*1ZJq'A)qTp%kk"h"1ZJ(QF!!3,Ic`5N"R3%KYr2")EIZ#5'h
lJNKYqi+TLd+R2c`"pd+R5(MrrkPm)&mY52rm5'd!QNKZrrUTN5mZrrbTJ`aZ!!(
rqQB!!C!!3UG)H8&8@%8r2!2SU"mJAbC)Y[`!!'Fi1fhpm1p8+fhpmZp@,`XJAk!
T3QG"lHp8,`K"lHp@,`JJ5b"36T!!-"rJ5"i!,`ZTSdS(C`!"3Q"%3LhqpLmYrZ"
)EIZ#5'd!FMmmrrp#TdKY!**)E[mf2c`"pNKY!)Sr2!!%UHT+,IlfC`!"$$!i!K4
%3$Y!le3VH!1BleBpEHp8rjC#E[qF3UlrNN*R5'lrJ#"ISJFqJ$!I5N"Q!!$DF!!
`,[qq,`![,[q`6Ud!3V#Yr[KN%NKYr!ir2!$56VS1@&b2B!!!XJaZdYIr`'BDF!%
E32lh3QFr2!$`3UHTL$!I$%!!!@B!!*!!5Lhqp@F%6VS$X%(Yqi)V51mk3Qh[2Lm
YlTUT&8kk$`!JEHkD3qlr,N(S!"!Lf#,B5'lr,UNU6VS0"R!"'d$qp'!`+'hmkQ!
@,`a1ZJ4D@)mm!%T'Cc3`"X(m!%lC`$!Yr1l"r!"1d+hmkVR!CGT5,Ild%#hqp,!
YlS"MaN*R3UFr,Hp86VS5H$!I6VS0&%kk"AT-haM!6Pj1G8j@rqj)j`%)5'hq!%K
Zrqj)E[r`UI8VH!1BrI)`1!)84%!l32h`3Hhpm#Y)ldj`!4Y!ldY#Cb"Yldir%#"
Yldi[+!!#)'h[6NKS!"!I2!!"5'h[6%kk$jB`(cY!lh4+EHpdCJ!#NR!"'d$[5R!
),8$rr%*R2bh[6%KZrra)EIlm6VS4QM!I1d$[G%TYlh4Q!!*QF!!3,Ilm$%!!!@F
1F!!3,Ilm$%!!!QB!!NC`!"!Yr[d-3!!"CJ!#1$YYr[lmk%UYr`"Q$N)YldY1ZJH
b5J"Q!!*!'fhqrHk!F2mV31pf3QFr,Hp-2c`!!5mYr`"1ZK'8-"ml31pd5Qh[G'B
!!IK`"be!rra#CcmYlda)E[rm5'lrp%kk%3B`(cY!lh4+EHpdCJ!"dNKi!!0)E[r
i6VS,l&#21flrq2cZ$'d&h2cZEJ!"VKYZrrVmm(!!%#hmm#e!rra#CcmYlda)E[r
m5'hmm8kk%,J`(cY!lh4+EHpdCJ!"K#mZrra)EIca6VS,RP#2IJ!SEIcUB!!",R!
",8$rr%*R2bh[6%KZrr`[$%kk%(``(cY!lh4+EHpdCJ!"5%Ki!!%[$%kk#f43Mh!
!%"3)!!!(CJ4`!'!#F!%C3!!J!K3!Ih!!%"3Y32rm$+i!!!!IrraZ!!%+3QFr,Hp
-5'lrr%KX!!&1ZK!N-"ml31pd5Qh[G'B!!2![,[rm5'`!!8kk#`T3Mh!!%#`!)!J
!!!"R0R!#,8$rr%*R2bh[6%KZrra)E!!f6VS2j$!I1d$[G%TYlh4Q!!#`,blrr%K
X!$C1ZJV+8)pJA(!Y,8$rr%*R2bh[6%KZrra)E!!K6VS2VM!I1d$[G%TYlh4Q!!"
k,blrr%KX!#&1ZJU88)m),!!!!$eR"R!"'d$qp9*Yld!J,!"'d+`!5Yk!)#`!2Y#
X!%,4VIli5H`!6P0ZrrK+E[riE!$qbL!Zrr5`VHpfCL*)H!%r,`G1V3"D+d$[3NU
Yld*Q"R!"+d$[3LYYld,[4Q!QF0Nl31pd$'hrfHpdCJC`C$Y!lh3JEHp15'J!%%k
k"+*BMdkk!Pa-ha#!6Pj1G8j@r[")j`-)3UFr2!(d3UG)H2rrUA`JAbK)5'd!JNK
Zrr#TN3aZ!!,rm'B%6VS#*#m-2c`!!dKZrrj)E[rk5'lrmUQ0,blrqNKZr[#TN!"
q!@!H-!G63!*!!!G53$`!3HhZCY$'-NI6cK!Tr[$4%&*(F!!3,[l`[N"Mf"!Zr[!
E31jQ!N!!r`a!!!KM"R!)'d$ZCLm-UB0-ha$!6Pj1G8j@!!!JEJ!-$&!!!fBL)'i
!$#!m!!!!rm#S!!)-J!!!!!eQ$#"Z!!K`!6#!F!&J&%*R,bi!%#mZ!!`[,J!)6VS
(p"!I6PiJAdr[!!`HJ%l36PErP%MR!cJSEJ!),Lh[9R!!%#`!)!J!!!"Q(K!X!#'
`,IldCJi[$%kkl5*BMdS!CJ!")(!"B!!"*(!!%#`!)!J!!!0Q!!$d5LhqpfB!!+K
)9%KZrj41ZJMU8)ml31pd5Qh[G'B!!'33,[qb5)!)!!!%C`SVE[r%leCJ!!"k5Lh
ZC'B!!#C)9$mm!2&1ZJMkA)p1V3!k!!%!"!#i!*J!Y!!+!!*`!4Y!lQ4#CcmYle3
[,Hp@5&41ZJbb-"ml31pd5Qh[G'B!!)"J#JaYrpA[G'B!!(4#CcmYle3[,Hp@5&4
)EHp@6VS-0M!I1d$[G%TYlh4Q!!"56VS(S$!X!$E!r!"1d)`'J!!!!%iQ3%(X!%i
N5'!@,`T1Z[lS@)mm!%T'Cc!`"X(m!%l9`,A,CZC1ZJI+B!B)l!!$!#!V4qp@-#`
!0P*!B"C)9%kk!PTBMdS!CZ*1ZJHQ+dI[9R!!60mF`%jH6R9+,Hp+C`a#CcmYlda
1ZJb%-"qTp%je6PErrNMR(`"#TdKi%!"1ZJaL)&mV51pS3UG)H3!"b3K1ZJa3)&m
V52cU3UG)H3!!J!"1ZJ`q)&mV51pF3UG)H#!!6VS-,L"I+dMZJN+R5(N!!)!!6VS
-(#"I+dMZMN+R5(N!!)!!6VS-#L"I+dMZNN+R5(N!!)!!6VS,q#"I+dMZPNUYr1T
R0%UYleaR,NUYlfKR+%UYlS*R)NUYlSjR(%UYlT*R&NUYlTCR%%+R6VS0##!I$)!
!!%!!E"j+VHpSC`J[,HpS)&qJ(dKYqqNr2!$56VS(1Pb2UI3JEHk#3HJJ!#Y)lSB
JEHpFdI`!!)!!+dM[C%+R5'hZRNKYr`j)EIZ#3QFr2!!"5(Mrrd*R3UHT%b"I+dM
ZQNUYlTTQ"%kkrXS[,HkDU(0#CkL(3QHSLN+R2c`!J#mYlTUT[L"IX2`!!'B%6VV
qT%*ZrrjJ!!$+H!"f!(S!2LlrrR`)B!!!IR!"`)0b!F*(5%&#38K"Xi"+J'FN)!2
LL#B!#!3!!'F%#--!(b!%iSJS!!U%lEL$)!U$lEL$)'!@)!2LL#B!#!3!!'F%#--
!(b!%iSJS!(!"`)9b!F*(5%&#38K"Xi"+J'F1)!ALL!U!lEL$)#S!B!BJ"H+)+J!
`"q*!2J"64NT'E!$rIM!Zrrj)`1@!3HhcJY(!))3`,[rq5-$PJ%(Ypi,4`##$-#l
rrNM!jB""lHpkdF!JK9*Zrri-EJ%!rrjY!2m`60m!q%jH6R919[f'51F$#$"Ylh3
[#%KZrSC1ZJZ+3HhlJLK)-#h[G%kY!#S!"`!H!'3!,2r5!#Mre!"Hrp-!@[r$!&E
rbJ"Brpi!@NSYlQ9R"N(Yr&FS5$im!34J5N(ZrBBY5!!)2@h[92qF3HlpKLe)rjK
#E[qL3QG)E[q')&qL"ck!-"ml31pd5Qh[G'F)3HhlJLe)!!Jq2!%1B!Sq2!%5B!3
q2!%4,bi!#%KZrSB[$%KYqi+TLd*R2`G#TkQ)-"mm!!a'!!&A`%3!5)"-ha$!6Pj
1G8j@r[K+,Hp+Ca"#,Hp+3QFr,Hp-6VS*EM!I3Hhq3#Y)ldj`!"!YldY+3'G#)'h
[6M!34%!a`!)8)'h[6L(S!!)$Q(!!%#h[5`a!!!&Q$%(YrI!V51p1B!!!V"!YldZ
`,Hk!C`!!S%(YrT!!+dM[6Mmm!"5Tb(!!%#h[5dT!CK4)EIaq5'hlJNKYqi*)EIZ
#UBYJ)R!!%#h[5bm!5'lr!%kk#M")EIZ#5'hmL8KZr`")EIZ#UBX[,IlJ5'hlJN+
R2c`!!8KYrZ4#Tb"Yldj)D!!'2c`"p8KY!*Sr2!!%UHSJEHp15LJ!"QB'F!&J!!&
+)'h[6L&i!jJ!!M!i!K4%3#"Yldi`J%*R)'h[6Mm3)'h[6LmS!!)JEHp15'J!%"m
m!!&)EHp-6VS'5$!I1d$[G%TYlh4Q!!$LF!JY32lm3QFr,Hp-5'lqr%KYr[a1ZJK
5-"ml31pd5Qh[G'B!!,"`!"!Yr[`-3!!"CaC`!"!Yr[`-3!!#C`T`f6Y!lh4J!!#
1-#hqrV"Yr1KQ*(!!%#h[5dT!C`S3,IlpX#h[5fB3F!!3,Hp,5N"Q@NUYr`"Q9(!
!%#hqr5m!5'lr!%kk#4B`,IlqX'hmk'B)3HhmM#!)B!C"lIb3!#!)5'lr!#m!5'h
lJNKYqi+TLd*R2c`!eN+RUBJ`(d*R2bh[6%kk"i``(f!!rRC`!4Y!ldT`!'!X3QF
r,Hp-6VS(FM!I$'hrfHpdCJC`C$Y!lh3JEHp15'J!%%kkr34BMf!!rN"1ANje6PE
rm%MR!3JSEJ!3)'i!$$!36Ud!+J!$!!i!!!#+!!-![!!'!-J[$$mm!!&)E[r`5'l
rqNKZrr+TM8*R,blrqLmZrr+TCM!I28$rrM!Zrrk`EIm@C`!!PMYZrrlr&NTYraC
R)N*R2c`!#bm-6VS""P#22c`!!6mm!!%[$%kk!2C3Mf!!!'K#Ccmm!!%[$%kk!14
3Mcmm!!%r2!!,,`a1ZJ$88)pJ4NTYraCQ3#"Z!!`J2!!!!2r!U!!#(J!3"dL!$%!
!$@F+%!G)J!a!!!0Q(#"Z!!K`#c#!F!&J%L"Z!!bjk!!#CJC`rcY!raC`!%cI%)"
1AL"I6qm!$"k!6Y"19J!!$'i!#`!-CJa`!4Y!r[C`!ce!!!``,J!-6PiJAdr[!!B
qJ%l36PB!!(!"6PiJAdr[!!3HJ%l36PB!!#"Z!!`-8!!'CL!JEJ!-)#J!!V#Z!""
Q%Mmm!!%r2!!",bi!%%kk!"*3Mh!!6PiJAdr[!!`HJ%l36PErh%KZrrbSG#mZ!!L
SFdKZrqUSQ#mZ!!Jr,J!-5'lrj%KZrqC)E[rFUBe)E[rF2ccrr$mmrrbSU6mm!!-
r2!!$U*Y)EIrXU*e+,J!2CJ4`#f!#F!Jr!+LF5'lrh$mm!"!r2!!3U,")E[rUU*N
[,[rmU(01ANje6PErP%*R2bh[9#mYleC)EIm%5(Nr2cmr5(P849K86VS$hM!I5N"
Q0NKYr`4)E[q86VS!H&#25N"Q)!MZ!!Er[#eYleEra%*R5'lrP#"IF!ULB$k!-"p
+3'F%6VS!"NjH6R9#CcmYle3[,Hp@5'hr"%kk"'!`(dje6PB!!#"Z!!JN,J!-)Lh
[GN2YlhTJ%(!!%"Lc!19))$%!!1#*XB&6JQVX+d([GNjH6R919J!!)'i!#$&Yle3
!&L"Z!!JKEHp@!$!JEJ!))@i!$!!5)'i!#%)S!"SJEJ!)3QJ!(%*R,bi!##"IF!Q
LB$k!-"p1ANje6PB!!#mZ!!T)EIZ#5'hlJNKYqi+TLd*R2bi!#%+RUBJ`(djH6R9
19[rZF!Sp32rqB!!!V+Qd3QFr22rr5'hZF+P`%"m`,Hj`6Ud!+J!$!!i!!3"L!!B
!K!!!!)4#CbmYlRT)E[rkU5``(`a!!!0Q!!"Z)#lrqV#YlTTQ!!"L5'hZHUKa3QF
[,Hjk,bhZQNKZrrDTE$!I$%!!#QC#3QF[,[rf,bhZHN+RU@J`(dT!Cbj`!@!i)#h
ZFV#YlTTQ)#mYlTUT)L"YlTT)D!!3U+01ZJ!J,bhZQUNMB!4`!'!18flrrNTZrrj
X!2p-F!"1ANjeU*j)EImLU+%r2!!+2c`!%kL65'hmR+L%6VS!KNKYrbUSS6mm!!%
r2!!'U*Xr2!!+2c`!(UL62bh[2N*RU*)r2!!+2c`!1+L65'hmU+L%3QG)EIbSU)`
`(`C!!"8l32mB6VS!8$mm!!1SKcmm!!QSLMmm!!-r2!"9U*0)EIc*U)3r2!#P2c`
!9DL65'hlJkL%3QHSKd*RU)S[,HkDU@P1G6mm!&mr2!!6U*-[,HmkU)41G8j@r`!
r,ImB2c`!1+L6-'h[3#m)5'lr!%kk!rj)E[m!U)41ANje6PErq%(Yqi)V51mk5'h
r'ULM5'lrq$mYraJr2!!X-#hr'!C!!#Br!$mm!$bSTdKZrrLSSdjH6R919J!!,`G
q!#!Z!!L4VHp'B!SJ,Hp#dDh[4P*(5Uh[4Qh`-#h[2Y"($%!"3'm+-$`"3*!!EHm
q2J!`,Hmq"N!!#Mm!2c`!(UL62`G#CkL5hfh[2LiI6Pj1G8j@riB["ceZ!"ErR#e
Z!",rYLeZ!!lrQ%)Zrk!GEJ!-rk&`!#e!rk*9MdKZriCb!"m"6VS#S$iI)'i!#$#
Zrjip4`!B,LlrJNjH)&p2l`!36Y#&5%p348i!!%j@riB["ceZ!"ErR#eZ!",rYLe
Z!!lrQ%)Zrk!GEJ!-rk&`!#e!rk*9MdKZriCb!"m"6VS#@$iI)'i!#$#Zrjip4`!
B,LlrJNjH)&p2l`!36Y#(5%p348j54J!!6PErKNMR!`!X,J!82@i!'2qF,8ErYLe
Z!"$rQ%)Zrk"9MdKZriC`!"m!6VS#&MiICMC#E[qL9Bp)E[q'F!!I!%kk!MBq(fB
J,@i!$2qU,@i!#2qQ,8ErYP@25'lrKR!!(`"1ZJ)Q2Kmp4`!D61i!`2pq6PiJAdr
[!"*1d)G)3e*&394&!!"19[q',`FpEJ!8rj`YEJ!3rlBYEJ!-rjK9MdKZriC`!"m
!6VS"AMiI)'i!###ZrlBp4`!@,LlrJNjH)&p2l`!16Y#*4%P53e*&394&!!"19[q
'2@i!%2qF,@i!$2qf,@i!#2qB3LlrS&@25'lrKR!!(`"1ZJ&D29m!%NjH)&p2l`!
+6Y#(5%4&6%9843!!6PErKMeZ!"$rR#eZ!!crYLeZ!!MrQ%)Zrk"9MdKZriC`!"m
!6VS",$eI!"*1AL"I6qm!#Nl3L8K6494'6%p$5`!!)PmJ(k%H,SK1d8j@rmiJ6c&
Z!!J!'+!"28!!#NjH)&p8Mdl38F&J!P$"6PErcL"2)@i!#!!J-@i!%!!B)Qi!$#&
4!#4#D!!X3UJ!,NS"CJ5J!Q!#S!-p3!!5)Qi!$#+S!#K1AL*I6qm!#Nl46PEr`#"
2-@i!#!!@)@i!#J!5S"-p3!!16PiLAeb26Y&19[r1)%maEJ!1!"JaEJ!-!#`KEJ!
)!#kJ4$e!!""1AL*I8)p1d5*I%"mJAfB'F!DLB'!%F!DQB$k!6Y%LAa!I)&pQ"+)
!B!+Q!$k!6Y%LAa!I)&pQ"+)+B!+Q#Mk!6Y%LAa!I)&pQ"+))B!+Q#$k!6Y%LAa!
I)&pQ"+)*B!+Q#6k!6Y%LAa!I)&pQ"+*"B!+Q36k!6Y%LAa!I)&pQ"+)-B!+Q$$k
!6Y%LAa!I)&pQ"+)0B!+Q$6k!6Y'JB5p!!!41GD"M6R@J0Nje)'m!"#![!!K#CkR
Z)&p36dl3!!!#,J!!!!S!!!"k3RJ+5Th16VS!*%*R5(N!!2rr5'm!"%KA2c`!!5)
krpj1Y4!!)'d!E%k3!+Rd@Bm[2&T&8Np#CkQJ*&GCMbmm4%&838*RUD!J9b"3)RJ
*##45B!ibf'B+-KTJ!N)C8FRrr,[*CZkTSkQM@Bm[2%4548a#CkQJ)&HJ*5"3iN!
N$@!'-KM9Y4!!8FMrq+QM6R8JAc)B0"L`@&I*rrT+3QIq6[!Jr#"I-KJd',#B9mR
rqNT#Crj1m#$k)&mb'$3BX%*Z#T!!3@d'd%""m!!#-""RrNl`!!!J,`!%,d%!"#)
[!!J[A`!%51Fm!#3!*J&)3X6$+!!U!8K&b-A84%K#3N,!`G##60m!2#)I6R8J,`!
%,d%!"#)[!!J[A`!%51Fa!%kk!*a-h`#-)Kp1G5![!!3[33!%)Lm!##pI!!4)jc%
!6VS!I#!"60m!M#)I6R8J,`!%,d%!"#)[!!J[A`!%51Fa!%kk!#a-h`#-)Kp1G5!
[!!3[33!%)Lm!##pI!!4)jc%!6VS!$#!"60m!M#)I6R9+J'SF5S&U$%5!4)&1ZJ!
J4)&1G85!6VS!&N5!4)&1G8U"DJT%J8kk!!C%J%je,M`!!2rrXS"M"L)!F!"1GE#
(BJb!`8K!-J"#3%K!6R@bKf)D,J"#3%K!J-&)3%K(2J")4il"-!G)4c)(6R8N!#B
"iSMLLE+(B[L!`F#(-J2#`#i$5%I1`%K(dSGP#*+#BJ4%J8je8d"Jj%je!!!!N!!
!!!#J!!!4Z!!!!)!!!!!J!!3r2!!"UI!!NMmm!!'Tm!#Q2c`!!DR`!,Sr2!!"UI!
!eMmm!!'Tm!%-2c`!!DR`!5`r2!!"UI!"6Mmm!!'Tm!&Z2c`!!DR`!LJr2!!"UI!
DKMmm!!+Tm!ab2c`!!UR`%Q3r2!!#UI!CB$mm!!+Tm"TH2c`!!UR`'TJr2!!#UI!
!!!!+5)!!"-`!!!6-!!!!!#FQ3A9dEd9iG(*KBh4[FL!a,M-a)+NJ-6Nj-5"#D@a
X)%G[Ef4YB@i!!!!F49K88J!!!!&*3diM!!!!!!#!4P*&4J!!!!!!J!!!!"X!+`%
C!$`"5`!!!3!!C!!!!!!!!!!!"&0dEh!!!!!(39"36!!!!!!!!3!Irrr`%!!!%"I
!"p!AJ!23&m!(d"IJ$p!9`!G3%*rb%"!3'"!3%jJ3%"!B%"!Iq"!3%"J3%"1B%"!
3'"!3(rJ3%"!B%"!6Q"!3%"J3%"ri%"!3'"!3%jJ3%"!B%"!Iq"!3MrS3&F!(8"I
J$p!A`!I3&i!$d"I!"p!3!!!3(rrrm"rrrr!Irrr`(rrrm"rrrr!Irrr`(rrrm"r
rrr!Irrr`(rrrm"rrrr!Irrr`(rrrm"rrrr!Irrr`(rrrm"rrrr!Irrr`(rrrm"r
rrr!Irrr`(rrrm"rrrr!Irrr`(rrrm"rrrr!Irrr`(rrrm"rrrr!Irrr`(rrrm"r
rrr!Irrr`!!!!&3"3!&!!Q`%L!!%"!!!!!!!!!!(d!!!!!"8!!!!!!-`"L`!"!!!
!!!!!!!!"pJ!!!!!9!!!!!!$3!C!!!!%!!!!!!!!!!!(e!!!!!"8!2!!3!2B"m!!
$!3!!!!!!!!!"p`!!!!!-!&!!8!#d!A)!dP99!!!!$!"3!%B!a!'D!0C993!!!!`
!8!"3!-3"Z!$`998!!!!-!&!!8!$b!CS!m999!!!!$!"3!&!!j!'Z!20993!!!!`
!8!"3!13"QJ%%998!!!!-!&!!8!#d!A)"$P99!!!!$!"3!&!!a!&S!4&993!!!!`
!8!"'!-3"VJ%5998!!!!-!&!!8!$N!BX!mP99!!!!*!!"!!!!!!"'!0)!@J%B"!*
25`!!!!!!#J"'!$S"')J$AM!Zr`!!!(!!!3!!!!!!9J%%!'S"5J3#6dX!!!!!!!S
!4J"+!8U)8&4SDA-JDA-JEQpd)(4SC5"bCA&eCA0dC@3JFf9RE@9ZG#"QD@aP,Jd
09'KTFb"QD@aP)'Pc)(0PCfePER3J)ei`)'pQ)&ia)'&bBfKTGQ8Z!!!!YJ!#!!!
!!!"@!4J!DJ&H"!G&H(4bB@0d!J!!!!!!9J$$!'S"#33%8A9TG!!!!!!!#J"'!%S
"ASKp9'KTFb"TFb"KEL"04P-JGQpXG@eP,L!J3A9dEd9iG(*KBh4[FL"hD@aX)'j
[G#"LC5"KBQaP)(4[)("eG#"dD'8JCQPXCA-JD@iJCQpXC'9bFbi0$84[)(P[G5"
hDA0S)(4[)'9iG(*KBh3JG'KP)'CTE'9c)'&ZHAGKH6m!!!!!cJ!%!!!!!!#%!2S
!Q!&!"!46DfP`!!!!!!"Q!2S!HJ&!"!46G'p`!!!!!!"Q!%B!HJ$Q""&5CA"XB@0
P)&4SDA-J4QPXC3)!!!!!!)3!4J#B!1B%&P*PF'aKBf8J38a-)%4eF'aTBf&dCA-
!!!!!!!S!4J"D!8#)9Y*H-0-JB@abC@&NH5"PH'PcG(-Z$3e%Eb"jEh8JGfPcD#"
dEb"bCA"XB@0P)'Pd)(GTG'JJG'KP)'CTE'8[CQpXC'9b)'CbEfdJG'KP)'&bBfK
TGQ8r!!!!U!!#!!!!!!"f!3i!LJ&8"!46DfP`!!!!!!"f!,X!LJ%""!46G'p`!!!
!!!!+!%B!DJ&8L(48D'8J4NP-45$5AM$6)'0KEQj[G#"LC5"PH(4bB@0dC@3Z$3e
")%C26%4&8L"hDA4S)(4SBA3JEQ&YC5"KE(*PB@4j)'9iDA0dFb!SH@pe)'0KEY9
d)(*PF'aKBf8JB5"'6da%49)JGfPdD#"K)%C*6%8T,J!!!%`!!3!!!!!!GJ$k!)S
"3!3#6dX!!!!!!!S!4J"U!8#),%0KEQj[G#"bC@&N)0*H-0-Z$3e8D'9H-L"KFQ0
SDACP)'Pc)'4KE@&RC@3Z!!!!@J!#!!!!!!"'!0)!@J%B"!46DfP`!!!!!!"'!(m
!@J$&"!46G'p`!!!!!!!+!%B!1J%BL#E5AM$6)'Pc)'a[BfYPC#"KEQ3JBf&ZEQp
d)'*P)'e[C'PQD@9N,J!!!'S!!J!!!!!!9J$)!'S"$J3%8fYTF!!!!!!!9J"e!'S
!Z`3%8h4[F!!!!!!!#J"'!%S"$SJf35"QD@aP)'9bFQpb)#KH-5NJD'&c)'pMBh9
bFQ9N)(GSD@aP)'&MBf9cFfPZCb!JdPi`dbiJ!!!!C!!#!!!!!!"@!4J!DJ&H"!4
6DfP`!!!!!!"@!-8!DJ%,"!46G'p`!!!!!!!+!%B!5J&HL$"8D'Pc)(C[E(9YC5"
TFb"QG@aX,Jd0dPi`db"MEh9XC#"ZEh3JBQ8JGh*TG(4PELi!!!"+!!-!!!!!!#d
!JJ""!-J%!Np,!!!!!!!Y!#m!33"e"!44G@Pd!!!!!!!*!&J!'3$)N!!!!!!!!!!
*!!S!'3"3L!P3BA0cGfpbC$S!!!!"&!!0!!!!!!#5!5X!T!&l"!42F'9Z!!!!!!5
!!$X%d!"0"!C)D@4NC@i!!!!!!(F"+`#*!AX%"N0KEQ0PE!!!!!!!)J"!!$B"#i!
!!!!!!!!K!5X!-`&l"!9&DQ9MG!)!!!!!!$`"+`"1!AX%"84bDACP!J!!!!!!63!
j!,m"%`!!!!!!!!"0!4)![`%M!!!!!!!!!'%"*`"L!Aq!!!!!!!!%&!!8"(N!G)J
!!!!!!!#Y!5X![`&l"!G&H(4bB@0d!J!!!!!!"J!'!"B!aiJD8f9XC@0d)%4PFh4
TEQ&dD@pZ)%C[E'4PFXN!!!!!!#)!"J!b!$f)"eC[E(9YC6S#!!!!!!!i!!B!5!!
hL!G'EfaNCA)k!!!!!1)!#J!!!!!!V3%d!,m"K!3%6'pKC!!!!!!!!!5l!&!%c33
'5'PNC'9Z!!!!!!#8!63!TJ'%"!C$B@jMC@`!!!!!!$%"(!"&!Bq!!!!!!!!!6J%
d!'!"K!3&4@TPBh3#!!!!!!"R!63!H3'%"!9%FQPfC3)!!!!!!$%!$!$$!4S!!!!
!!!!!-3%C!--"+J!!!!!!!!#'!6!!K`'0J!!!!!!!!!!%P!"P"25)!!!!!!!!"J!
-!"F"KSJT8'aPBA0P)'a[B@3JAM"cC@GYC@jdAM&H-L"[CL"dD'8JBA*MD'PfCFN
!!!!!G!!#!!!!!!"f!1X!LJ%a"!46DfP`!!!!!!"f!*J!LJ$H"!46G'p`!!!!!!!
+!%B!DJ%aL%$5AM$6)'0[G@aN)'j[G#"LC5"PH(4bB@0dC@3JF(*[F'9bE(NZ$3e
8D'9H-5"KFQ0SDACP)'Pc)'4KE@&RC@3Z!!!!0!!#!!!!!!#C!Bd!V3(6"!*25`!
!!!!!Q3%k!+d"J!3%8A9TG!!!!!!!$3!0!)d"diJ#AM!!!!%!!!!aF`!!-(-!!!*
Q!$N[i!@%!!!!(!*Q!!a%394"!!!!DPT&8Nm!!!"f4&*&6!!!!)*$6d4&!!)!MP0
*@N8!!!#b49K88J!!!,j#6N4-!!!!bN019%`!!!$@4P*&4J!!!1**3diM!!!!lN4
-6dF!!`$k38a59!!*!5T%594-!!d"SJ!!rrmS!!!!!$N`&!!!rrm)!!'U!$N[j!!
!rrmS!!'k!$N[k!!#rrmi!!'q!$Na-!!"rrmF!#21!!!!!!!!rrmS!#B!!!!!!2r
rrrm!!#D8!$Na1!!!rrm)!#DL!$N[q!#!rrmS!#E0!$N`+!#!rrmS!#EY!$N`-!#
!rrmS!#F-!$N[h!#!rrmS!#FA!$N`%!(drrm-!#JE!$N`#!(frrm-!#Jd!!!!!!(
errm-!#K0!!!!!!(hrrm-!#KQ!!!!!!$5rrm-!#Kr!$N`$!$@rrmS!#L2!!!!!!$
`rrmS!#LI!!!!!!$arrmS!#L[!!!!!!$crrmS!#Lr!!!!!!%%rrmS!#M2!!!!!!%
1rrmS!#MI!!!!!!%4rrmS!#M[!!!!!!%5rrmS!#Mr!!!!!!$brrmS!#N2!!!!!!$
5rrm-!#NI!$N`(!$@rrmS!#P(!!!!!!$`rrmS!#Ql!!!!!!$arrmS!#Te!!!!!!$
crrmS!#Y(!!!!!!%%rrmS!#[c!!!!!!%1rrmS!#a$!!!!!!%4rrmS!#bK!!!!!!%
5rrmS!#d2!!!!!!(drrm-!#eh!!!!!!(frrm-!#h&!!!!!!(errm-!#lG!!!!!!$
brrmS!#r$!!!!!!(hrrm-!$!l!!!!!)%(:





From guenther.fischer@hrz.tu-chemnitz.de  Wed Oct  6 17:32:14 1993 +0100 (MET)
Message-Id: <9310061632.AA04851@flash1.hrz.tu-chemnitz.de>
Date: Wed, 6 Oct 1993 17:32:14 +0100 (MET)
From: guenther.fischer@hrz.tu-chemnitz.de (Guenther Fischer)
Subject: Is there any caching ...

Hi,
my wishes:
- I want to give www clients to our users but I'm afraid because of the
  traffic (we have only 64KB bandwidth). 
- It would be nice if I could say
     xmosaic -cacheserver a_local_host:port
  and xmosaic would connect to a_local_host:port and write
  GET /host[:port/...      (full http URL without prologue http:/ )
- then I could create a cache server
  the first GET generate  a remote GET - the second can give the answer
  local and fast
- the I also need a HTTP command that gives me not the file but the
  needed information about the file like size, date etc. (is it HEAD?)
  So a cache server could implement refreshs ...

what I've done:
- to get the  nice GNN from nearnet.gnn.com, I've saved the home page
  to my local server and have created a link to it from my local root
  page
- this "cache" erver is a plexus and I've hacked in the dir.pl
  to do the job (craeting directories and getting the file and
  putting them to the clients)
  It runs on a separate port - the port number is my "mapping"
  to the mother server.

Are there other/better solutions to do such a job? How can I get 
infomations like filesize and date?

	~Guenther


-- 
Name:      Guenther Fischer
Institute: TU Chemnitz, Universitaetsrechenzentrum
Phone:     0371 668 361
mail:      fischer@hrz.tu-chemnitz.de



From knill@c3serve.c3.lanl.gov  Wed Oct  6 10:32:25 1993 -0600
Message-Id: <9310061632.AA02496@c3serve.c3.lanl.gov>
Date: Wed, 06 Oct 1993 10:32:25 -0600
From: knill@c3serve.c3.lanl.gov (Emanuel Knill)
Subject: Re: Math markups 

In-reply-to: Your message of "Wed, 06 Oct 1993 10:14:52 BST."

--------

Steve Heaney writes:
>
>I would just like to add a voice of agreement to Marc's comments.  The line 
>"Too much pain for too little gain" springs to mind.
>
>My vote (for what its worth) would be to keep math separate from HTML+.  
>
>This is not meant to be a provocative question, but how many users or 
>potential users of WWW would it really benefit ?  Perhaps this has already 
>been answered on www-talk, but I have not seen a definitive answer.

Everyone here would benefit even from minimal math capabilities.
This includes myself and at least 3 staff members and
4 graduate students. Of course, asking this question in this
forum is unlikely to get very many enthusiastic responses. It appears
that the community that would take advantage of this is not
at the moment very involved in contributing to designing and
building the interfaces.

One of our projects is a discrete
mathematics information resource (going on line by the end
of the year) which includes preprint databases among other things.
I'd love to put some papers online in an html format,
though we'll probably start with one page .ps and .dvi
abstracts together with full papers in postscript. 

Translation of simple latex documents is certainly an option,
though I have noticed that the mathematics papers I wrote
are very slow to load if converted with latex2html.
(Aside: and I would really like to customize much of the look
of the document---can I do that without hacking the code?)
The ability to have simple mathematics displayed by the browser
would speed up transfer times.

Manny




From kevin@scic.intel.com  Wed Oct  6 10:04:57 1993 -0800
Message-Id: <9310061708.AA18832@rs042.scic.intel.com>
Date: Wed, 6 Oct 1993 10:04:57 -0800
From: kevin@scic.intel.com (Kevin Altis)
Subject: Re: BBEdit HTML extensions (fwd)

There are some errors in the BBEdit extensions so that if you use them you
won't be creating valid HTML. Specifically comments should end with --> not
just > and headers should have the header style number as part of the
ending tag </H1> not just </H>. I alerted the author. If you find anything
else, please let him know.

ka




From kevin@scic.intel.com  Wed Oct  6 10:05:01 1993 -0800
Message-Id: <9310061708.AA18834@rs042.scic.intel.com>
Date: Wed, 6 Oct 1993 10:05:01 -0800
From: kevin@scic.intel.com (Kevin Altis)
Subject: special entities: < > & and "

I seem to remember that you used to have to quote the special characters <
> & and " within an HTML document so that & becomes &amp, " becomes &quot,
< and > become &lt and &gt  This is documented in the draft HTML
specification (actually the &lt and &gt aren't in there), but I've tried it
out with XMosaic and I don't have to quote the characters at all within
normal text. If the quoting rule only applies within an URL or as part of a
tag then it should be documented as such with examples. What's the real
story Tim?

ka




From sanders@bsdi.com  Wed Oct  6 12:19:09 1993 -0500
Message-Id: <9310061719.AA03480@austin.BSDI.COM>
Date: Wed, 06 Oct 1993 12:19:09 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: Is there any caching ... 

> - It would be nice if I could say
>      xmosaic -cacheserver a_local_host:port
>   and xmosaic would connect to a_local_host:port and write
>   GET /host[:port/...      (full http URL without prologue http:/ )
export WWW_http_GATEWAY=http://localcachingserver

> - this "cache" erver is a plexus and I've hacked in the dir.pl
>   to do the job (craeting directories and getting the file and
>   putting them to the clients)
>   It runs on a separate port - the port number is my "mapping"
>   to the mother server.
Very Cool.  If you ever make it production quality (and can port it to
3.0 when it comes out) I would love to integrate this into the release.

> Are there other/better solutions to do such a job? How can I get 
> infomations like filesize and date?
>From the returned Object for HTTP/1.0 servers.
You'll want to handle things like:
    Last-Modified:
    Expires:
    Content-Length:

TimBL: According to the spec data formats are per RFC850, so they are like:
    Last-modified: Tuesday, 05-Oct-93 22:58:33 GMT
I'm not sure that's the right RFC to standardize on.  Wouldn't 822 make
more sense?

--sanders



From lou@vax.ox.ac.uk  Wed Oct  6 18:19:40 1993 +0100
Message-Id: <009739FD.D2BDEB00.9362@vax.ox.ac.uk>
Date: Wed, 06 Oct 1993 18:19:40 +0100
From: lou@vax.ox.ac.uk (Lou Burnard)
Subject: advice on httpd sought

I can't believe I'm alone in wanting to do this. Nor that no-one has
thought of this way of doing it. Would someone therefore please very
kindly tell me (and preferably offline if I am asking a really dim
question)  how to tell my httpd server that when it gets a request for a
document with extension .blort it should pass said document through a
filter FOO before serving it forth? I glanced through the httpd v 0.4
from ncsa, but couldn't see any obvious place to do it. Before I roll up
my shirtsleeves and get hacking, I'd just like to find out if someone's
passed this way before... 

Why do I want to do this? because I expect to have several zigaflops of
TEI-conformant sgml text here is why, and I really don't want to have
to keep copies of them all online in html as well. Writing a filter
to translate TEI markup into html is well within the bounds of even
my C-competence.

thank you

Euro-Lou





From vinay@eit.com  Wed Oct  6 11:05:02 1993 PDT
Message-Id: <9310061805.AA18470@eit.COM>
Date: Wed, 6 Oct 93 11:05:02 PDT
From: vinay@eit.com (Vinay Kumar)
Subject: slideshow-1.2 and xmosaic-2.pre4: minor problem

For those of you who are using "ss" or slideshow-1.2 with xmosaic-2.pre4 you
might be experiencing one minor problem with seeing the first-slide in 
xmosaic-2.pre4. It always loads NCSA's home_page and not the first slide
in your file. (Thanks to Neal.McBurnett@att for pointing that out.)

My take at this point is that xmosaic-2.pre4 has hardcoded "-home" command 
line option, for obvious reasons (NCSA folks, can you verify this ?). As a 
result, ss-1.2 ignores the first slide in the URLfile as home_page and hence 
not seen at startup. This problem is not seen with older robust versions of 
xmosaic. If and when xmosaic-2.pre4 becomes robust release4 things should be
back to normal.

--
  Vinay Kumar
vinay@collage.eit.com



From Steve.Heaney@delft.sgp.slb.com  Wed Oct  6 19:07:35 1993 +0100
Message-Id: <199310061807.AA26247@mordred.delft.sgp.slb.com>
Date: Wed, 6 Oct 1993 19:07:35 +0100
From: Steve.Heaney@delft.sgp.slb.com (Steve Heaney)
Subject: Re: special entities: < > & and "


Kevin,

The requirement that < > and other characters be replaced by entity references 
(in certain situations) comes from SGML and is to do with the way that an SGML 
parser processes the text of an SGML file.

There are several "data types" which elements can have including:

#PCDATA - parsed character data.  Parser needs to determine if it contains 
          any more markup.

CDATA   - character data. All markup characters are ignored.

RCDATA  - replacable character data.  As CDATA except entity references 
          and character references are recognised.

EMPTY   - element does not have any content.

Most of the elements in the HTML DTD will be declared to have content of 
type #PCDATA.  NCSA Mosaic may not have a problem with "reserved" characters 
such as the <, >, " and & in these elements, but you can bet that an SGML 
parser will choke on it.

Here starteth the sermon ...

    That's what comes of using a browser to validate your markup :-)

Here endeth the sermon. Amen.

Steve.

------------------------------------------------------------------------
Steven Heaney

Schlumberger Geco-Prakla
Internet: heaney@delft.sgp.slb.com
------------------------------------------------------------------------



From dcmartin@library.ucsf.edu  Wed Oct  6 11:09:14 1993 PDT
Message-Id: <199310061813.AA02249@library.ucsf.edu>
Date: Wed, 06 Oct 1993 11:09:14 PDT
From: dcmartin@library.ucsf.edu (David C. Martin)
Subject: Re: Math markups 

One question that I would ask is why not just generate a TIFF image of
the mathematical formula and connect it to a representation of the
formula that would be suitable for using the formula (e.g. in whatever
format Mathematica utilizes).

That would simplify the presentation and actualy distribute the
the formula, not just some HTML+ representation (although someone could
always write an HTML+ to Mathematica converter :-)

dcm
--------
Emanuel Knill writes:

In-reply-to: Your message of "Tue, 05 Oct 1993 18:10:10 -0000."

--------

Dave Raggett writes:

>According to Phil, to get good results with TeX you need to fiddle with the
>style settings, and the code needed to run HTML+ with TeX for embedded
>formulae would be painful, particularly with the style stuff.

Is this assuming that the standard TeX program/process is run
to produce a math formula? 
Here's a question for Phil Hallam-Baker:
Do you have an encapsulated way of producing images of
elementary TeX math expressions that can be embedded in html files
with reasonable alignment? I could make immediate use of that.

> Hence the
>interest in seeing how to do this directly in HTML+. I have looked at the
>ISO 12083 Math DTD, but it is unfortunately far too complex to win support
>within the WWW community. My proposal is conceptually a cut-down version
>aimed at meeting most but not all peoples needs.
>

I have not seen ISO 12083, is your proposal
compatible with this standard? 
I like the principle of your proposal, though I must say
that the sub/superscript tags look a bit clumsy. This is of course
not really a problem with a good editor. It would be nice
if we could add easy-to-use facilities for embedding more complicated
stuff in the future (as images or other). 

>We definitely need to make sure that any proposal for maths is solid and
>easy to implement, otherwise browser writers are going to work on other
>problems first.
>
>Dave Raggett

I am looking forward to seeing the HTML+ math proposal. 
Do you have a prelimiary copy which includes the math parts?

Manny



From kevin@scic.intel.com  Wed Oct  6 11:42:12 1993 -0800
Message-Id: <9310061845.AA16939@rs042.scic.intel.com>
Date: Wed, 6 Oct 1993 11:42:12 -0800
From: kevin@scic.intel.com (Kevin Altis)
Subject: Re: Generalising inlined images

At 12:03 PM 10/6/93 +0100, Dave_Raggett wrote:
>Nathan wants to be able to inline arbitary kinds of things into
>an HTML+ document:
>
>>  ...and regardless of whether the HREF was to an image, a sound file or
>> more hypertext, it would be included in the current document.
>
>> How will/should this be done?
>
>Does the inlined object behaves like a character or a paragraph?
>
>Do you play sound immediately or when the user clicks the link?
>
>Do you retrieve an "inlined" Postscript file automatically or
>wait until the user clicks the link?
>
>HTML+ does provide some support for inlined linked HTML or plain text,
>but we need to clarify what we want.

Background
Right now we have <IMG SRC...> which allows you to include an XBM or GIF
image that is available via an URL or "local file." We also have <INC
SRV...> which allows you to include a text file or html/text file via an
URL or "local file" as well as run an arbitrary command such as "ls" or
"rm" assuming you're on a Unix machine, but in any case the result of
running the command either returns nothing or returns text or text/html.
"Local file" means different things depending on whether the client
software opens the HTML document on the local file system or gets the HTML
document via an HTTP server. In the former case, <IMG SRC...> and <INC
SRV...> allow the HTML document to include anything the user has access to
from their file system, while the latter restricts access based on the
privs. established on the http server providing the documents.

Yeah, yeah, yeah, we know all that, what's your point. Well, a couple of things.
I think we might be better off making <IMG SRC...> and <INC SRV...> into a
single "inclusion" tag with a modified syntax to support an arbitrary set
of inclusion types. What I have in mind is to put the MIME types into the
tag syntax so you might do <INC text/html="..."> or <INC image/gif="...">
or <INC sound/wav> or <INC x-command/. This simplifies the syntax and at
the same time allows a lot more flexibility than we currently have. The
biggest win comes when the client software has MIME to application mappings
so that when it encounters applicatin/tex then the client software passes
off the data to a "helper" application which returns the data as an
image/gif or some other type negotiated by the client and helper
application. The INC tag should also work differently than an HREF. An INC
would always mean load immediately or at least start the loading process,
though loading images and sounds could take a while, so they'll have to be
treated like inlined image loading today. An HREF could be used for user
invoked loading which might mean changing the use of HREF slightly or
coming up with a different tag.

Inlined should always behave like characters, otherwise you can't do tiling
and other important layout things.

My other problem with <IMG SRC...> and <INC SRV...> is that they do
different things depending on whether you're fetching via an HTTP server or
a client. I don't have any easy answers right now, but I forsee major user
confusion when people put together documents and test them locally, only to
find out they don't work off a server because of access privs. relative
pathing, etc. Any ideas?

ka




From sanders@bsdi.com  Wed Oct  6 14:13:40 1993 -0500
Message-Id: <9310061913.AA04113@austin.BSDI.COM>
Date: Wed, 06 Oct 1993 14:13:40 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: advice on httpd sought 

> filter FOO before serving it forth? I glanced through the httpd v 0.4
> from ncsa, but couldn't see any obvious place to do it. Before I roll up
> my shirtsleeves and get hacking, I'd just like to find out if someone's
> passed this way before... 
I think with the NCSA HTTPD (1.0a2 anyway) you would use htbin scripts
and write a gateway (either script or C program).  The NCSA folks might
have some more suggestions.

Plexus HTTPD can also do this.  Information about getting plexus:
    http://www.bsdi.com/server/doc/plexus.html

--sanders



From marca@ncsa.uiuc.edu  Wed Oct  6 14:14:34 1993 -0500
Message-Id: <9310061914.AA16294@wintermute.ncsa.uiuc.edu>
Date: Wed, 6 Oct 93 14:14:34 -0500
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: special entities: < > & and "

Kevin Altis writes:
> I seem to remember that you used to have to quote the special characters <
> > & and " within an HTML document so that & becomes &amp, " becomes &quot,
> < and > become &lt and &gt  This is documented in the draft HTML
> specification (actually the &lt and &gt aren't in there), but I've tried it
> out with XMosaic and I don't have to quote the characters at all within
> normal text. If the quoting rule only applies within an URL or as part of a
> tag then it should be documented as such with examples. What's the real
> story Tim?

Don't use Mosaic to *validate* your HTML -- use a DTD and an SGML
parser.  Mosaic handles many error cases cleanly, but they're still
error cases.

Marc



From marca@ncsa.uiuc.edu  Wed Oct  6 14:15:51 1993 -0500
Message-Id: <9310061915.AA16298@wintermute.ncsa.uiuc.edu>
Date: Wed, 6 Oct 93 14:15:51 -0500
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: slideshow-1.2 and xmosaic-2.pre4: minor problem

Vinay Kumar writes:
> For those of you who are using "ss" or slideshow-1.2 with xmosaic-2.pre4 you
> might be experiencing one minor problem with seeing the first-slide in 
> xmosaic-2.pre4. It always loads NCSA's home_page and not the first slide
> in your file. (Thanks to Neal.McBurnett@att for pointing that out.)
> 
> My take at this point is that xmosaic-2.pre4 has hardcoded "-home" command 
> line option, for obvious reasons (NCSA folks, can you verify this ?). As a 
> result, ss-1.2 ignores the first slide in the URLfile as home_page and hence 
> not seen at startup. This problem is not seen with older robust versions of 
> xmosaic. If and when xmosaic-2.pre4 becomes robust release4 things should be
> back to normal.

More to the point, when 2.0 is released this won't be the case.
Regular readers of my rantings will know that we've been frustrated in
the past by people taking the prereleases too seriously, distributing
them to users, and then complaining because the quality isn't as high
as it is for regular releases (surprise!).  Thus, the hardcoded
warning page.

Marc



From sanders@bsdi.com  Wed Oct  6 14:41:04 1993 -0500
Message-Id: <9310061941.AA04259@austin.BSDI.COM>
Date: Wed, 06 Oct 1993 14:41:04 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: Generalising inlined images 

> of inclusion types. What I have in mind is to put the MIME types into the
> tag syntax so you might do <INC text/html="..."> or <INC image/gif="...">
> or <INC sound/wav> or <INC x-command/. This simplifies the syntax and at
Please don't do that.  Putting the type in the link is exactly where
we don't want that information.  The way this should work is:
    <EXTERN HREF="...">

Then the browser sends the request with the list of acceptable formats:
    GET ... HTTP/1.0
    Date: Sunday, 03-Oct-93 19:37:52 GMT
    Accept: text/plain; text/html; image/gif; image/x-xbitmap

Then the server responds:
    HTTP/1.0 200 Document follows
    MIME-version: 1.0
    Content-type: image/gif
    ...

Oh BTW.  While we are talking about this part of the protocol I just want
to remind everyone that something like <EXTERN HREF="..." ISMAP> is *NOT*
needed.  This information should be part of the returned object.  The
reason I made <IMG ISMAP> is because at that time we only had HTTP0 clients
and servers.  Since all the browsers will soon support HTTP/1.0 ISMAP is
depreciated in favor of server responses like this:
    HTTP/1.0 200 Document follows
    Public: GET HEAD SPACEJUMP
    MIME-version: 1.0
    Content-type: image/gif
    ...
The "Public: SPACEJUMP" is the trick (btw it might also be "Allowed: SPACEJUMP"
browsers must check in both locations).  This means that the current
document can be manipulated in the curious way we happen to support
spatial indexing (the same way as ISMAP currently where the browser
sends the offsets in a query).  All future extensions should be along
these lines.  If you need an object to have attributes don't put them
in HTML, return them with the object.  Remember those same objects
might be used by some other system than WWW in the future.

> the same time allows a lot more flexibility than we currently have. The
> biggest win comes when the client software has MIME to application mappings
It's the wrong approach.

> Inlined should always behave like characters, otherwise you can't do tiling
> and other important layout things.
Shame on you for mentioning "layout" :-)

> My other problem with <IMG SRC...> and <INC SRV...> is that they do
> different things depending on whether you're fetching via an HTTP server or
> a client. I don't have any easy answers right now, but I forsee major user
> confusion when people put together documents and test them locally, only to
> find out they don't work off a server because of access privs. relative
> pathing, etc. Any ideas?
I think hacking <INC> into the server is a bad idea.  I've mentioned this
before.  If you do that then you have really created a new type and it
should be filename.hacked-html  instead of filename.html to make it
clear that it's not HTML.  Then format negotiation would convert
text/x-hacked-html to text/html if required (and when browsers start
support <INC> They will just Accept: text/x-hacked-html).

--sanders



From sanders@bsdi.com  Wed Oct  6 15:11:21 1993 -0500
Message-Id: <9310062011.AA04522@austin.BSDI.COM>
Date: Wed, 06 Oct 1993 15:11:21 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: looking for: WWW based reservation system

Anyone done it?  Someone should!

--sanders



From d0asta@dtek.chalmers.se  Wed Oct  6 22:37:13 1993 +0100
Message-Id: <9310062137.AA24512@hackes.dtek.chalmers.se>
Date: Wed, 6 Oct 93 22:37:13 +0100
From: d0asta@dtek.chalmers.se (Magnus Homann)
Subject: HTTP 1.0 Specs


Where are the HTTP 1.0 specs? I've tried everywhere, but I can't find
it. Somebody care to help?

Homann
--
   Magnus Homann  Email: d0asta@dtek.chalmers.se
                  URL  : "http://www.dtek.chalmers.se/DCIG/d0asta.html"



From sanders@bsdi.com  Wed Oct  6 19:02:48 1993 -0500
Message-Id: <9310070002.AA05701@austin.BSDI.COM>
Date: Wed, 06 Oct 1993 19:02:48 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: Generalising inlined images 

I'm sorry, I confused a couple of issues here (shame on me).  However,
we are further apart than I thought...

kevin@scic.intel.com (Kevin Altis) writes:
> Yeah, yeah, yeah, we know all that, what's your point. Well, a couple of things.
> I think we might be better off making <IMG SRC...> and <INC SRV...> into a
> single "inclusion" tag with a modified syntax to support an arbitrary set
> of inclusion types. What I have in mind is to put the MIME types into the
> tag syntax so you might do <INC text/html="..."> or <INC image/gif="...">
> or <INC sound/wav> or <INC x-command/. This simplifies the syntax and at
> the same time allows a lot more flexibility than we currently have. The
<INC> isn't part of HTML.  It's a hack in the NCSA server.  It's a
simple macro expansion.  It has nothing to do with HTML or <IMG>,
nor should it.
[   My personal problem with <INC> is just that it tends to generate email
    for me since people don't understand why foo.html doesn't work anymore
    when they switch servers.  If, for example, the NCSA server required
    the files to be called foo.ncsa before <INC> worked I wouldn't care.
    I understand *why* they did this (because some naughty HTTP0 browsers
    look at the URL) but that doesn't mean I have to like the email :-)
]

You are confused about the file extension issue.  I'll not explain it here
for fear of further confusion.  Suffice it to say that this is a non-issue,
HTTP/1.0 objects are self-typing, no file extensions are looked at.

On moving this type of functionality into HTML (call it <IMG> <EXTERN>
<EMBED> or whatever), my basic argument still stands, one does not want
to type the reference to an object (HREF).

For example, a particular instantiation of the object:

    <A HREF="http://www.bsdi.com/setext/usenet-email.etx">

might look like this (this is an actual example, try it):

    HTTP/1.0 200 Document follows
    Last-modified: Monday, 28-Jun-93 16:27:47 GMT
    Date: Wednesday, 06-Oct-93 22:53:02 GMT
    Server: plexus/3.0i
    MIME-version: 1.0
    Content-type: text/html

    <TITLE>Usenet and Email Hypertext</TITLE>
    ...html document here...

Note the content-type.  This does *not* depend on the file extension, it
only depends on the object.  This object happened to begin it's life as
text/x-setext and got converted on the fly to text/html because the browser
doesn't support text/x-setext.  If you had typed the link and the browser
didn't support text/x-setext you wouldn't be able to read that document.
To see the "source" try: http://www.bsdi.com/setext/usenet-email.etx.txt

--sanders



From janssen@parc.xerox.com  Wed Oct  6 17:57:00 1993 PDT
Message-Id: <0ggqZQEB0KGWI2LPlF@holmes.parc.xerox.com>
Date: Wed, 6 Oct 1993 17:57:00 PDT
From: janssen@parc.xerox.com (Bill Janssen)
Subject: 'External' viewers

Excerpts from ext.WorldWideWeb: 5-Oct-93 Re: Math markups Marc
Andreessen@ncsa.uiu (1333)

> The two options for people who want to put math online are then (a)
> use dvi or PostScript in external viewer....  We can
> possibly help (a) by considering how to make the link between external
> viewers and browsers tighter (e.g. Midas 2, which can instantiate
> ghostscript displays inside its own window just like ghostview)

This makes a lot of sense to me (surprise :-).  I've never thought that
one particular viewer should be privileged.  Perhaps the `browser'
shouldn't even have a viewer window, and all documents should be viewed
externally.  In some ways, this is what window managers were intended
for.

Bill



From robm@ncsa.uiuc.edu  Wed Oct  6 22:11:39 1993 -0500
Message-Id: <9310070311.AA06539@void.ncsa.uiuc.edu>
Date: Wed, 6 Oct 1993 22:11:39 -0500
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: advice on httpd sought

/*
 * advice on httpd sought  by Lou Burnard (lou@vax.ox.ac.uk)
 *    written on Oct  6,  6:19pm.
 *
 * I can't believe I'm alone in wanting to do this. Nor that no-one has
 * thought of this way of doing it. Would someone therefore please very
 * kindly tell me (and preferably offline if I am asking a really dim
 * question)  how to tell my httpd server that when it gets a request for a
 * document with extension .blort it should pass said document through a
 * filter FOO before serving it forth? I glanced through the httpd v 0.4
 * from ncsa, but couldn't see any obvious place to do it. Before I roll up
 * my shirtsleeves and get hacking, I'd just like to find out if someone's
 * passed this way before... 

In NCSA httpd 1.0a2, you could do this, although not quite as you are
asking. What you would probably do is have a script (which is your filter)
in /htbin, let's call it foo. HREF's to the TEI documents could then be
something like /htbin/foo?/the/document/name.blort.

In later releases, we're going to change the script interface such that when
looking in the scripts directory, if it finds an executable early, it will
send the rest of the path as an argument to the script. In this
architecture, your documents would be referenced by something like:

/htbin/foo/the/document/name.blort

And the script execution would be transparent.

 * Why do I want to do this? because I expect to have several zigaflops of
 * TEI-conformant sgml text here is why, and I really don't want to have
 * to keep copies of them all online in html as well. Writing a filter
 * to translate TEI markup into html is well within the bounds of even
 * my C-competence.
 * 
 * thank you
 * 
 * Euro-Lou
 * 
 * 
 * 
 */

Hope this helps
--Rob



From janssen@parc.xerox.com  Wed Oct  6 20:47:54 1993 PDT
Message-Id: <kggt5eEB0KGWM2LKQm@holmes.parc.xerox.com>
Date: Wed, 6 Oct 1993 20:47:54 PDT
From: janssen@parc.xerox.com (Bill Janssen)
Subject: Re: Generalising inlined images

Isn't this what Tim was calling EMBED?

<EMBED HREF="..."> or <EMBED SRC="...">, where the HREF form was used
with URL's, and the SRC form was used with local files (and was
therefore much less portable).  Good idea to have EMBED, but Tony is
right in saying that the type should go in that document, not in the
EMBED statement, although I could see a type attribute if the SRC form
were to be used.

Bill



From robm@ncsa.uiuc.edu  Wed Oct  6 22:43:16 1993 -0500
Message-Id: <9310070343.AA06822@void.ncsa.uiuc.edu>
Date: Wed, 6 Oct 1993 22:43:16 -0500
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: Generalising inlined images

/*
 * Re: Generalising inlined images  by Tony Sanders (sanders@bsdi.com)
 *    written on Oct  6,  2:41pm.
 *

[....]

 * I think hacking <INC> into the server is a bad idea.  I've mentioned this
 * before.  If you do that then you have really created a new type and it
 * should be filename.hacked-html  instead of filename.html to make it
 * clear that it's not HTML.  Then format negotiation would convert
 * text/x-hacked-html to text/html if required (and when browsers start
 * support <INC> They will just Accept: text/x-hacked-html).
 */

I put the INC stuff in because it seemed like a useful feature. It was not
one of my more popular decisions around here. I didn't make it an additional
type since I was not aware that the INC tag would be of any value to the
browsers.

I'm starting to wonder what exactly this feature is used for that is not
better satisfied another way, since:

1. Parsing every HTML file adds overhead to the server
2. The only applications I have seen are things like including the date
(which should be in the protocol) and Charles Henrich's weather server.

So my main question to those who want this support in the server is, what do
you use it for?

--Rob



From henrich@crh.cl.msu.edu  Thu Oct  7 00:43:17 1993 -0400 (EDT)
Message-Id: <9310070443.AA04929@crh.cl.msu.edu>
Date: Thu, 7 Oct 1993 00:43:17 -0400 (EDT)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: <inc> in ncsa server

I know of a couple sites who are using it to add the last modification date on
the end of the file pages.

I for one use it all over the place, its integral to all my weather stuff, as
well as system status information, inlined filesizes of items and the like.
Its mighty useful, it provides the same sort of extendability the plexus server
gives, if not more.  (And its in C :)

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                      http://rs560.msu.edu/~henrich



From robm@ncsa.uiuc.edu  Thu Oct  7 02:17:05 1993 -0500
Message-Id: <9310070717.AA09002@void.ncsa.uiuc.edu>
Date: Thu, 7 Oct 1993 02:17:05 -0500
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: <inc> in ncsa server

/*
 * <inc> in ncsa server  by Charles Henrich (henrich@crh.cl.msu.edu)
 *    written on Oct  7, 12:43am.
 *
 * I know of a couple sites who are using it to add the last modification date on
 * the end of the file pages.
 * 
 * I for one use it all over the place, its integral to all my weather 
 * stuff, as well as system status information, inlined filesizes of items and 
 * the like.
 *
 * Its mighty useful, it provides the same sort of extendability the plexus 
 * server gives, if not more.  (And its in C :)
 */

Something Tony and I were recently discussing is the possibility of making a
"standard" preprocessor for HTML documents. This way, you would have regular
HTML documents (which would not be parsed, just sent by the server), and you
would have a new type like HTML-macroized. When the client requests a
document of this type, the server would run the pre-processor on the
HTML-macroized document, which would then spit out an HTML document to
return to the client.

This way, it would be "just another document conversion" to the server, and
if we agree on a standard preprocessing format, it will work on all servers
that support it. It also does not add tags to HTML which really don't belong
in HTML itself.

What do you think?
--Rob



From Gisle.Aas@nr.no  Thu Oct  7 08:21:53 1993 +0100
Message-Id: <9310070721.AA17252@nora.nr.no>
Date: Thu, 7 Oct 93 08:21:53 +0100
From: Gisle.Aas@nr.no (Gisle.Aas@nr.no)
Subject: Re: Generalising inlined images

sanders@bsdi.com writes:
> > My other problem with <IMG SRC...> and <INC SRV...> is that they do
> > different things depending on whether you're fetching via an HTTP server or
> > a client. I don't have any easy answers right now, but I forsee major user
> > confusion when people put together documents and test them locally, only to
> > find out they don't work off a server because of access privs. relative
> > pathing, etc. Any ideas?
> I think hacking <INC> into the server is a bad idea.  I've mentioned this
> before.  If you do that then you have really created a new type and it
> should be filename.hacked-html  instead of filename.html to make it
> clear that it's not HTML.  Then format negotiation would convert
> text/x-hacked-html to text/html if required (and when browsers start
> support <INC> They will just Accept: text/x-hacked-html).

I use this code with my plexus server (it does the work for me):
--------------------------------------------------------------------------

package inc;

sub init
{
    $main'ext{'hacked-html'} = 'text/hacked-html';
    $main'trans{'text/hacked-html'} = "text/html:inc'html";
}

sub html
{
    # this is a translation filter
    while (<STDIN>) {
	s/<inc\s+([^>]*)>/&inc($1)/ige;
	print;
    }
}

sub inc
{
    local($_) = $_[0];
    return scalar(`$1`)                      if /^cmd="([^"]+)"/i;
    return "<pre>\n".scalar(`$1`)."</pre>\n" if /^precmd="([^"]+)"/i;
    return eval "$1"                         if /^perl="([^"]+)"/i;
    return scalar(`cat $1`)                  if /^file="([^"]+)"/i;
    return "<em>&lt;inc $1&gt; not understood</em>";
}
1;



From neuss@igd.fhg.de  Thu Oct  7 09:45:50 1993 +0100
Message-Id: <9310070845.AA05214@wildturkey.igd.fhg.de>
Date: Thu, 7 Oct 93 09:45:50 +0100
From: neuss@igd.fhg.de (neuss@igd.fhg.de)
Subject: Re: advice on httpd sought

Dear fellow Webbers,

> I can't believe I'm alone in wanting to do this. Nor that no-one has
> thought of this way of doing it. Would someone therefore please very
> kindly tell me (and preferably offline if I am asking a really dim
> question)  how to tell my httpd server that when it gets a request for a
> document with extension .blort it should pass said document through a
> filter FOO before serving it forth? 


Hmpf.. no very obvious way to do so. I had to do a similar hacking, so
I can give some help here. I'll include a code fragment at the end of my 

mail, if anyone out there needs further info, please feel free to send 

me e-mail to neuss@igd.fhg.de. What I mainly did was modify send_file()
so that if the file name equals "gen.html", it would call up a special
conversion routine. Please note that I used the new HTTP 1.0 compliant 

version of NCSA's httpd. 


Peace, Chris

/*
 *  Christian Neuss  %  neuss@igd.fhg.de  %  ..in the humdrum
 */
==== snip ====
void send_file(char *file, FILE *fd, char *args) {
    FILE *f;
    if(!(f=fopen(file,"r"))) {
        unmunge_name(file);
        die(FORBIDDEN,file,fd); /* we've already established that it exists  
*/
    }
    set_content_type(file);
#ifdef ICIB_HACK
{
    char *base; int found=0;
    for(base=file;*base;base++)if(*base=='/')found=1;
    if(found){
      for(;*base!='/';base--);
      base++;
    }else{
      base=file; 

    }
    if(strcmp(base,"gen.html")==0){
      FILE *f2;
      char *tmpfile;
      tmpfile = tmpnam(NULL);
      f2 = f;
      f = fopen(tmpfile,"wb+");
      if(f==NULL){
        char err[MAX_STRING_LEN];
        sprintf(err,"could not create temp file %s",tmpfile);
        log_error(err);
      }
      ConvertTable(f2,f);
      rewind(f);
      send_fd(f,fd,args);
      unlink(f);
      return;
    }
}
#endif  /* ICIB_HACK */

    send_fd(f,fd,args);
}



From guenther.fischer@hrz.tu-chemnitz.de  Thu Oct  7 10:18:06 1993 +0100 (MET)
Message-Id: <9310070918.AA06068@flash1.hrz.tu-chemnitz.de>
Date: Thu, 7 Oct 1993 10:18:06 +0100 (MET)
From: guenther.fischer@hrz.tu-chemnitz.de (Guenther Fischer)
Subject: Re: Is there any caching ...

> 
> > - It would be nice if I could say
> >      xmosaic -cacheserver a_local_host:port
> >   and xmosaic would connect to a_local_host:port and write
> >   GET /host[:port/...      (full http URL without prologue http:/ )
> export WWW_http_GATEWAY=http://localcachingserver

Oh yes - this does the job - thank you very much - I don't see this
in the documents. 

> 
> > - this "cache" erver is a plexus and I've hacked in the dir.pl
> >   to do the job (craeting directories and getting the file and
> >   putting them to the clients)
> >   It runs on a separate port - the port number is my "mapping"
> >   to the mother server.
> Very Cool.  If you ever make it production quality (and can port it to
> 3.0 when it comes out) I would love to integrate this into the release.
Is there a (Beta) version of 3.0? With your hint WWW_http_GATEWAY I'll
do some work on it.
But this is only the first step. 
Now I can create a "global" cache (not only for GNN).
But what to do with the cache after some times (days, ours ??).

The GNN solution: GNN will give updates to local distributors (weekly).
If my cache runs it could be a remove of all expired documents - the
list of expired documents I get from GNN - I hope.

This is a special solution but a good one for such a big but stable
document tree.

If I have a TTL value per file I could reget it if the value expires
or better get first only the Last-Modified: Expires:Content-Length:
but the serve must be able to give it to me.

> 
> > Are there other/better solutions to do such a job? How can I get 
> > infomations like filesize and date?
> >From the returned Object for HTTP/1.0 servers.
> You'll want to handle things like:
>     Last-Modified:
>     Expires:
>     Content-Length:

Oh yes - thats what I want. Is there a server who gives me that for a file
without the file itself?

	~Guenther
-- 
Name:      Guenther Fischer
Institute: TU Chemnitz, Universitaetsrechenzentrum
Phone:     0371 668 361
mail:      fischer@hrz.tu-chemnitz.de



From marca@ncsa.uiuc.edu  Thu Oct  7 04:28:05 1993 -0700
Message-Id: <9310070428.ZM4267@wintermute.ncsa.uiuc.edu>
Date: Thu, 7 Oct 1993 04:28:05 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Re: image/*, audio/*, etc.?

On Oct 7, 10:17am, Nick Williams wrote:
> > So... does anyone object to image/*, etc.?  (Precedent is in the
> > mailcap RFC, btw.)
>
> I definitely object. I think it is unreasonable from the viewpoints of
> both being a server maintainer and a user.
> Consider the case where a document contains:
> 	<img src="blah/blah/blah/foo">
> And the server which "owns" foo has it stored in format
> usenix-facesaver.  When Mosaic makes the request for the image, and asks
> for type "image/*", the server will respond with the easiest to produce
> version: i.e. the native usenix facesaver picture.  Mosaic doesn't
> understand this, but carries on anyway.  Perhaps the link is slow as
> well, causing the download of the picture to take a long time.  Finally,
> the picture arrives.  Mosaic doesn't understand the return type (even
> though it asked for it) and so will not include it in the document, but
> forks off xv instead.  And although the chances of xv understanding it
> are high, it is no certainty either.
>
> The alternative:
> Mosaic asks for "image/gif, image/xpm, image/xbm" (it's an inline, so
> mosaic shouldn't be speaking for xv just yet).  The server doesn't have
> the image in that format so either:
> 1) it converts it to the correct format and so the reader of the
> document gets exactly the correct view.
> 2) it responds that it is unable to provide the image in that format and
> Mosaic can immediately work around this (as opposed to waiting for all
> of the image to be downloaded).

I understand the alternative.  The problem is that we've decided to go with MIME
in the protocol; mailcaps are how MIME is traditionally supported in clients; if
we don't allow image/* etc. we do not do true mailcaps and we lose compatibility
and compliance with the MIME/email world, one of the reasons we used MIME in the
first place.

You are correct about the problems with image/*.  However, as a server
maintainer, you shouldn't need to care.  If a client doesn't think it can handle
any form of image, it shouldn't ask for image/*.  If it *does* -- and keep in
mind that I may have an external image 'viewer' that is perfectly capable of
saving formats it doesn't understand to disk rather than just puking, so I as a
user can go get a suitable viewer at my convenience (*if, as a user, I wish*) --
then the server should just say "Well, OK, here ya go."

As a result of the problems that have arisen with pre4, btw, I'm going to not
use any wildcards in the default Mosaic mailcap stuff -- image types will be
elaborated, etc. and so wildcards will never come into play unless someone
specifically wants them to -- however, I am arguing in favor of (a) compliance
with the spec and the rest of the world [which I think is a Big Deal] and (b)
allowing users to do what they want on the user/client end.

> There.  Purely from the view of a server maintainer: I put in a lot of
> working getting our server to do conversions automatically! :-)
>
> Repost this to the list if you want a discussion; I thought I'd just
> send to you because the noise in www.talk is too much right now :(

Cheers,
Marc




From dsr@hplb.hpl.hp.com  Thu Oct  7 10:53:21 1993 BST
Message-Id: <9310070953.AA03899@manuel.hpl.hp.com>
Date: Thu, 7 Oct 93 10:53:21 BST
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: Generalising inlined images

Kevin,

For this to work in general, browsers need a way of rendering arbitrary
MIME content types - the proliferation of these ensures this will remain
a problem until a standard OOP scheme is adopted to allow software re-use.

For this reason the inlined feature needs to be restricted to a very small
number of content types, e.g. XBM, GIF, plain text and HTML.

Including type info in the element is a bad idea - instead it should come
from the object itself.

Perhaps we should have INC just like IMG with ALIGN and SRC, but for plain
text and HTML only (for now).

Dave



From dsr@hplb.hpl.hp.com  Thu Oct  7 11:16:16 1993 BST
Message-Id: <9310071016.AA04913@manuel.hpl.hp.com>
Date: Thu, 7 Oct 93 11:16:16 BST
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: looking for: WWW based reservation system

Proposal for a Notification Service mechanism
=============================================

Tony suggests using WWW for a reservation system, e.g. meetings and
room bookings etc.

I see potential for showing pictures of room name vs time of day
and using ISMAP to allow people to click on the room they wish to book.
The HTML+ forms mechanism will allow you to combine such images with other
fields thanks to a suggestion by Marc Andreessen for an image widget.

One issue is how to force regular update so that you see the effects of
other people making bookings without having to ask for a refresh.
A crude approach is to use the Expires: field in the HTTP response to
get the browser to regularly refresh the document. A better approach would
use a separate protocol for soliciting notifications of changes:

You would use WWW and HTTP in the normal way, but the HTTP response would
include info on a notification server, e.g. UDP host/port number.

The browser would pick up this info and send a datagram to the notification
server with the URL for the booking document. The server responds with
an acknowledgement including its time-out period.

The notification server then sends datagrams advising changes to all
its current clients for each such booking document whenever that document
changes. Using a datagram service is ok since packet loss isn't critical here.

For robustness, the notification server times-out each client after a suitable
interval, and browsers would be expected to periodically re-register.


How about it guys? Any volunteers to implement a portable notification server?

Dave Raggett



From appel@cih.hcuge.ch  Thu Oct  7 15:39:26 1993 +0100
Message-Id: <1107*/S=appel/OU=cih/O=hcuge/PRMD=switch/ADMD=arcom/C=ch/@MHS>
Date: Thu, 7 Oct 1993 15:39:26 +0100
From: appel@cih.hcuge.ch (Ron D. Appel)
Subject: html+ specs

Where can I find the latest HTML+ specs?

Thanks.

-------------------------------------------------------------------------
| Ron D. Appel                             | Tel.:   (+41 22) 372 6264  |
| Hopital Cantonal Universitaire de Geneve | Fax.:   (+41 22) 372 6198  |
| Centre d'Informatique Hospitaliere       | e-mail: appel@cih.hcuge.ch |
| 24, rue Micheli-du-Crest                 |   (S=appel;OU=cih;O=hcuge; |
| CH-1211 Geneve 14                        |    P=switch;A=arcom;C=ch)  |
| Switzerland                              |                            |
-------------------------------------------------------------------------



From bellverc@pereiii.uji.es  Thu Oct  7 17:15:37 1993 +0000
Message-Id: <9310071520.AA18284@dxmint.cern.ch>
Date: Thu, 7 Oct 1993 17:15:37 +0000
From: bellverc@pereiii.uji.es (bellverc@pereiii.uji.es)
Subject: BBEdit HTML extensions

Many thanks for the bug reports (Kevin Altis, Jek Kian Jin). I'll try to
correct them this evening or tomorrow morning.

______________________________________________________________________________
Carles Bellver   <bellverc@si.uji.es>    No mention shall be made of coral,
Universitat Jaume I                      or of pearls: for the price of wisdom
E-12071 Castello de la Plana             is above rubies.
SPAIN                                    Job, 28:18



From henrich@rs560.cl.msu.edu  Thu Oct  7 11:27:06 1993 -0400 (EDT)
Message-Id: <9310071527.AA17441@rs560.cl.msu.edu>
Date: Thu, 7 Oct 1993 11:27:06 -0400 (EDT)
From: henrich@rs560.cl.msu.edu (Charles Henrich)
Subject: Re: <inc> in ncsa server

> This way, it would be "just another document conversion" to the server, and
> if we agree on a standard preprocessing format, it will work on all servers
> that support it. It also does not add tags to HTML which really don't belong
> in HTML itself.

> What do you think?

Well I can see one problem with it, and thats that it will take alot more work
to produce the document on the fly.  The server has to ingest it, pass it off
to the preprocessor, which then hands it back.  Also how would you include the
output of programs in such a method?  Just seems like its a lot more work for
what essentially would accomplish the same thing.  A lot more work for the
people who have to code it to.

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                      http://rs560.msu.edu/~henrich



From sanders@bsdi.com  Thu Oct  7 10:42:06 1993 -0500
Message-Id: <9310071542.AA08360@austin.BSDI.COM>
Date: Thu, 07 Oct 1993 10:42:06 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: Generalising inlined images 

[Gisle.Aas@nr.no on <INC>]
> I use this code with my plexus server (it does the work for me):
...
> package inc;

Very cool, thanks.  Mind if I put it in the release?

--sanders



From sanders@bsdi.com  Thu Oct  7 11:33:29 1993 -0500
Message-Id: <9310071633.AA08753@austin.BSDI.COM>
Date: Thu, 07 Oct 1993 11:33:29 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: looking for: WWW based reservation system 

> Tony suggests using WWW for a reservation system, e.g. meetings and
> room bookings etc.
Wow, you took me seriously..  I think it would be a cool application.

> How about it guys? Any volunteers to implement a portable notification server?
I think the IETF is doing some work in this area.  Interested parties
should check that out first.

--sanders



From sanders@bsdi.com  Thu Oct  7 11:31:13 1993 -0500
Message-Id: <9310071631.AA08727@austin.BSDI.COM>
Date: Thu, 07 Oct 1993 11:31:13 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: image/*, audio/*, etc.? 

>>>>> Marca wrote:
> > > So... does anyone object to image/*, etc.?  (Precedent is in the
> > > mailcap RFC, btw.)
>On Oct 7, 10:17am, Nick Williams wrote:
> > version: i.e. the native usenix facesaver picture.  Mosaic doesn't
> > understand this, but carries on anyway.  Perhaps the link is slow as
The solution is simple.  If you don't really want image/* then don't
ask for it.  No one is going to force the users to do this.

> mind that I may have an external image 'viewer' that is perfectly capable of
> saving formats it doesn't understand to disk rather than just puking, so I as a
Exactly.

> > There.  Purely from the view of a server maintainer: I put in a lot of
> > working getting our server to do conversions automatically! :-)
So have I, I still think "type/*" is a must, otherwise browsers will have
to translate image/* in the .mailcap file into every format known to man
and beast, an intractable solution.

For example: here is a piece of my .mailcap:
    audio/basic; /usr/local/bin/play_au %s
    audio/au; /usr/local/bin/play_au %s
    audio/aiff; /usr/local/bin/play_aiff %s
    audio/x-aiff; /usr/local/bin/play_aiff %s
    audio/wav; /usr/local/bin/play_wav %s
    audio/x-wav; /usr/local/bin/play_wav %s
    audio/*; mosiac-internal-dump %s

The server should interpert this as I want one of the known formats first,
if not go ahead and send it and I'll save it to a file and I'll see what
I can do with it by hand.  I can convert other formats (voc, sbdsp, etc),
I just don't have players setup for them.

--sanders



From kevin@scic.intel.com  Thu Oct  7 10:28:42 1993 -0800
Message-Id: <9310071732.AA14497@rs042.scic.intel.com>
Date: Thu, 7 Oct 1993 10:28:42 -0800
From: kevin@scic.intel.com (Kevin Altis)
Subject: Re: 'External' viewers

At  5:57 PM 10/6/93 -0700, Bill Janssen wrote:
>I've never thought that
>one particular viewer should be privileged.  Perhaps the `browser'
>shouldn't even have a viewer window, and all documents should be viewed
>externally.  In some ways, this is what window managers were intended
>for.

Ack!!! That's exactly what I don't want, tons and tons of windows because I
have to use an external viewer for every different content type (document)
I open and even those external viewers force you to have a different window
for each document. I wouldn't complain so loudly if the most common window
managers did a half decent job of letting you navigate around more than a
handful of windows, but they don't. Most of our current operating
system/window managers don't have a clue when it comes to color models
either (unless they're 24-bit or higher) so the more windows with different
colors the more screwed up your display gets. I absolutely refuse to spend
my entire day minimizing and maximizing all my stupid windows and trying to
decide which icon really represents the document I want to look at. The Mac
(with a system extension or two) is the only machine I've ever used that
deals with lots of windows and lots of colors in a sensible way. Since
nobody else seems to be going in that direction, I want to keep the number
of windows to a minimum.

ka




From dcmartin@library.ucsf.edu  Thu Oct  7 10:28:40 1993 PDT
Message-Id: <199310071732.AA12533@library.ucsf.edu>
Date: Thu, 07 Oct 1993 10:28:40 PDT
From: dcmartin@library.ucsf.edu (David C. Martin)
Subject: Re: looking for: WWW based reservation system 

Why not just use DTM?

dcm
--------
Dave_Raggett writes:

Proposal for a Notification Service mechanism
=============================================

Tony suggests using WWW for a reservation system, e.g. meetings and
room bookings etc.

I see potential for showing pictures of room name vs time of day
and using ISMAP to allow people to click on the room they wish to book.
The HTML+ forms mechanism will allow you to combine such images with other
fields thanks to a suggestion by Marc Andreessen for an image widget.

One issue is how to force regular update so that you see the effects of
other people making bookings without having to ask for a refresh.
A crude approach is to use the Expires: field in the HTTP response to
get the browser to regularly refresh the document. A better approach would
use a separate protocol for soliciting notifications of changes:

You would use WWW and HTTP in the normal way, but the HTTP response would
include info on a notification server, e.g. UDP host/port number.

The browser would pick up this info and send a datagram to the notification
server with the URL for the booking document. The server responds with
an acknowledgement including its time-out period.

The notification server then sends datagrams advising changes to all
its current clients for each such booking document whenever that document
changes. Using a datagram service is ok since packet loss isn't critical here.

For robustness, the notification server times-out each client after a suitable
interval, and browsers would be expected to periodically re-register.


How about it guys? Any volunteers to implement a portable notification server?

Dave Raggett



From kevin@scic.intel.com  Thu Oct  7 11:11:13 1993 -0800
Message-Id: <9310071814.AA16833@rs042.scic.intel.com>
Date: Thu, 7 Oct 1993 11:11:13 -0800
From: kevin@scic.intel.com (Kevin Altis)
Subject: Re: Generalising inlined images

At 10:43 PM 10/6/93 -0500, Rob McCool wrote:
>I put the INC stuff in because it seemed like a useful feature. It was not
>one of my more popular decisions around here. I didn't make it an additional
>type since I was not aware that the INC tag would be of any value to the
>browsers.
>
>I'm starting to wonder what exactly this feature is used for that is not
>better satisfied another way, since:
>
>1. Parsing every HTML file adds overhead to the server
>2. The only applications I have seen are things like including the date
>(which should be in the protocol) and Charles Henrich's weather server.
>
>So my main question to those who want this support in the server is, what do
>you use it for?

So far, I've done the following with <INC>, many of which might be better
as actual server commands. However, each one took me a few minutes to
provide cross-platform information access to a large base of users. I'll
never be able to do that if I have to provide a script or C program under
/htbin for every thing I think of and more importantly your basic user
won't be able to do any of this stuff without the server administrator
getting involved - for those of you that have never done System
Administration that should be read as "sorry, user, you can't have that."
1. <INC SRV "|date">
        Everyone does this right?
2. <INC SRV "|stock | /usr/bin/tail -9">
        This runs a program which goes out and gets the hourly stock quote
for Intel via a UDP "connection" then the results are piped to the "tail"
command because I only wanted the last 9 lines of output.
3. <INC SRV "telnet domain port | /usr/bin/tail -14">
        This gets the last week of stock activity via a telnet connection,
much like providing information via a finger lookup.
4. Using <INC...> on text and HTML documents so that I have controlling
documents with a <HEAD> section, then all the stuff I <INC> have only
<BODY> stuff, so they can be included in a lot of different documents
without conflicting with anything else. This is called document reuse, much
like code reuse. Obvious elements for reuse are parts of your profile or
signature, standard disclaimers, quotes, block quotes, etc.
5. A source code overview system does an <INC> which grabs part of some
source code files to show changed elements in the code (via greps,
compares...). The HTML document with the <INC> tags doesn't change,
everybody still accesses the same HTML document, but the body of the HTML
document potentially changes each time somebody loads it.

Well, that's a start. I haven't had enough time to get creative, geez I
only got the capability a week or so ago. I forsee using <INC> mostly for
including information dynamically in a document, like having <INC> provide
the default field entry for a FORM or using <INC> along with ISMAP to
provide a dynamic map front end where the click on an image causes a
command to be run at the server which generates output, which is then
incorporated into a document that is static, except for the <INC> elements.
Maybe I have to show you that one. Suffice to say, I find <INC> more useful
than many of the other tags.

ka




From heffron@falstaff.css.beckman.com  Thu Oct  7 11:30:18 1993 -0700
Message-Id: <9310071830.AA24218@dxmint.cern.ch>
Date: Thu, 07 Oct 1993 11:30:18 -0700
From: heffron@falstaff.css.beckman.com (Matt Heffron)
Subject: Re: looking for: WWW based reservation system 

>Why not just use DTM?

What's DTM?  (Pointer to more info too, please.)

Matt

TDMA!
(TOO DAMN MANY ACRONYMS! ;-)
>
>dcm
--
Matt Heffron                      heffron@falstaff.css.beckman.com
Beckman Instruments, Inc.         voice: (714) 961-3128
2500 N. Harbor Blvd. MS X-10, Fullerton, CA 92634-3100
I don't speak for Beckman Instruments unless they say so.



From knill@c3serve.c3.lanl.gov  Thu Oct  7 12:36:29 1993 -0600
Message-Id: <9310071836.AA24331@c3serve.c3.lanl.gov>
Date: Thu, 07 Oct 1993 12:36:29 -0600
From: knill@c3serve.c3.lanl.gov (Emanuel Knill)
Subject: wais through http.


I want to use wais to serve search requests on searchable
http://*/*.html documents. I do not want to provide an independent
wais server at the moment.
Does anyone have a script for
the NCSA server which can do that? Or one which can be adapted
to the purpose?  Thanks,

Manny



From kevin@scic.intel.com  Thu Oct  7 11:31:20 1993 -0800
Message-Id: <9310071834.AA15568@rs042.scic.intel.com>
Date: Thu, 7 Oct 1993 11:31:20 -0800
From: kevin@scic.intel.com (Kevin Altis)
Subject: c.i.w3 instead of mailing list

Marc and a few others have expressed the desire to move to USENET
completely so we don't carry on the technical conversations on www-talk,
which doesn't have a high reliability level. I would like to move to
USENET, but c.i.w3 has a high noise level, so if we make a complete switch
I think a proposal needs to go forth for comp.infosystems.www.programmers
or some such list. I don't remember the voting rules offhand, so besides
having to wait a few weeks or more for getting a new USENET group started
we also need enough votes and 2/3 of those YES to get started. Do we have
critical mass? What do you think?

ka




From kevin@scic.intel.com  Thu Oct  7 11:50:46 1993 -0800
Message-Id: <9310071854.AA13541@rs042.scic.intel.com>
Date: Thu, 7 Oct 1993 11:50:46 -0800
From: kevin@scic.intel.com (Kevin Altis)
Subject: Re: looking for: WWW based reservation system

At 11:33 AM 10/7/93 -0500, Tony Sanders wrote:
>> Tony suggests using WWW for a reservation system, e.g. meetings and
>> room bookings etc.
>Wow, you took me seriously..  I think it would be a cool application.

I've put some time into just such a system. It is difficult to think in
terms of protocols or language elements and then map that to an interface
at this point. The <INC> tag makes a lot possible that wasn't before. It
might be easier to start with some mockups then see if existing features
support the mockup or what would have to be changed and if those changes go
against some existing design elements, etc.

>> How about it guys? Any volunteers to implement a portable notification
>>server?
>I think the IETF is doing some work in this area.  Interested parties
>should check that out first.

Speaking of the IETF, is anybody going to Houston in November? There is
also a HyperText conference in Seattle about the same time. Since I missed
the last WWWWW meeting I would like to know the time and place many of us
might get together, any schedules or plans?

ka




From wade@cs.utk.edu  Thu Oct  7 15:28:20 1993 -0400
Message-Id: <9310071928.AA01195@galoob.cs.utk.edu>
Date: Thu, 07 Oct 1993 15:28:20 -0400
From: wade@cs.utk.edu (Reed Wade)
Subject: Re: comp.infosystems.www.programmers instead of mailing list 



>I think a proposal needs to go forth for comp.infosystems.www.programmers

>What do you think?

yes, please, this would be a good thing

Reed Wade
wade@cs.utk.edu



From sanders@bsdi.com  Thu Oct  7 14:32:26 1993 -0500
Message-Id: <9310071932.AA10353@austin.BSDI.COM>
Date: Thu, 07 Oct 1993 14:32:26 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: c.i.w3 instead of mailing list 

> USENET, but c.i.w3 has a high noise level, so if we make a complete switch
> I think a proposal needs to go forth for comp.infosystems.www.programmers
I'll second that but without the ``s'' since that's
what other groups seem to use:
   comp.infosystems.www.programmer

However, I don't think the www-talk list should go away, just become
smaller.  Maybe just for people interested in specific details of new
protocol implementations.  That will move all the new traffic into the
news group (the "how does this feature of HTTP/HTML work" type questions)
and leave www-talk open for new frontiers.

--sanders



From mvanheyn@cs.indiana.edu  Thu Oct  7 14:53:51 1993 -0500
Message-Id: <7497.750023631@prickly.cs.indiana.edu>
Date: Thu, 07 Oct 1993 14:53:51 -0500
From: mvanheyn@cs.indiana.edu (Marc VanHeyningen)
Subject: Re: c.i.w3 instead of mailing list 

Thus wrote: 
>Marc and a few others have expressed the desire to move to USENET
>completely so we don't carry on the technical conversations on www-talk,
>which doesn't have a high reliability level. I would like to move to
>USENET, but c.i.w3 has a high noise level, so if we make a complete switch
>I think a proposal needs to go forth for comp.infosystems.www.programmers
>or some such list. I don't remember the voting rules offhand, so besides
>having to wait a few weeks or more for getting a new USENET group started
>we also need enough votes and 2/3 of those YES to get started. Do we have
>critical mass? What do you think?

Are you kidding?  The mailing list has about as much noise as the
newsgroup and significantly higher volume, even if you don't count the
duplicate mailings or "Please unsubscribe me" messages.  I've
seriously considered unsubscribing several times.  At least noise in a
newsgroup can easily be removed with the "k" key and other mechanisms;
I really don't want to have to add that kind of filtering to my mail
when there's a good alternative.

- Marc
--
Marc VanHeyningen  mvanheyn@cs.indiana.edu  MIME, RIPEM & HTTP spoken here



From heffron@falstaff.css.beckman.com  Thu Oct  7 13:38:42 1993 -0700
Message-Id: <9310072038.AA08359@dxmint.cern.ch>
Date: Thu, 07 Oct 1993 13:38:42 -0700
From: heffron@falstaff.css.beckman.com (Matt Heffron)
Subject: Re: c.i.w3 instead of mailing list 

>Marc and a few others have expressed the desire to move to USENET
>completely so we don't carry on the technical conversations on www-talk,
>which doesn't have a high reliability level. I would like to move to
>USENET, but c.i.w3 has a high noise level, so if we make a complete switch
>I think a proposal needs to go forth for comp.infosystems.www.programmers
>or some such list. I don't remember the voting rules offhand, so besides
>having to wait a few weeks or more for getting a new USENET group started
>we also need enough votes and 2/3 of those YES to get started. Do we have
>critical mass? What do you think?
>
>ka
>
I am in favor of use of USENET instead of mail where possible.

An option to waiting for the voting rules procedure would be to make an
alt.infosystems.www.programmer newsgroup
alt. groups have NO rules for creation, (merely creategroup and deletegroup
message wars :-)

would use of an alt group TEMPORARILY (until we get a real comp. group created)
be a problem for anyone? (e.g. your site refuses ALL alt. groups, your newsfeed's
newsadmin requires bribes to feed you an alt. group ;-) ...)

Matt
--
Matt Heffron                      heffron@falstaff.css.beckman.com
Beckman Instruments, Inc.         voice: (714) 961-3128
2500 N. Harbor Blvd. MS X-10, Fullerton, CA 92634-3100
I don't speak for Beckman Instruments unless they say so.



From montulli@stat1.cc.ukans.edu  Thu Oct  7 17:45:32 1993 CDT
Message-Id: <9310072245.AA35250@stat1.cc.ukans.edu>
Date: Thu, 7 Oct 93 17:45:32 CDT
From: montulli@stat1.cc.ukans.edu (Lou Montulli)
Subject: Lynx core dump on GNN material

After receiving 568 different bug reports about Lynx crashing 
while reading the GNN stuff from O'reilly (http://nearnet.gnn.com/GNN-ORA.html)
I figured I had better figure out what was wrong.

It turns out that I didn't explicitly set a pointer to NULL during
declaration.  (silly me)  My compiler is smart (or is that stupid) 
enough to set it to NULL anyways so it didn't turn up during testing.

This problem only seems to manifest itself on SUN and ULTRIX systems.

Anyways, here's the solution for those of you who want to fix it in
your current sources.  (It will of course be fixed in 2.0.12 when it
is available)

on line 662 of lynx2-0-11/src/WWW/HTML.c change:
	    char *alt_string;
to:
	    char *alt_string=NULL;

:lou
-- 
  **************************************************************************
  *           T H E   U N I V E R S I T Y   O F   K A N S A S              *
  *         Lou  MONTULLI @ Ukanaix.cc.ukans.edu                           *
  *                         Kuhub.cc.ukans.edu      ACS Computing Services *
  *     913/864-0436        Ukanvax.bitnet             Lawrence, KS 66044  *
  *             UNIX! Cool! I know that!  Jurassic Park - The Movie        *
  **************************************************************************



From robm@ncsa.uiuc.edu  Thu Oct  7 17:49:41 1993 -0500
Message-Id: <9310072249.AA18949@void.ncsa.uiuc.edu>
Date: Thu, 7 Oct 1993 17:49:41 -0500
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: <inc> in ncsa server

/*
 * Re: <inc> in ncsa server  by Charles Henrich (henrich@rs560.cl.msu.edu)
 *    written on Oct  7, 11:27am.
 *
 * Well I can see one problem with it, and thats that it will take alot 
 * more work to produce the document on the fly.  The server has to ingest 
 * it, pass it off to the preprocessor, which then hands it back.  Also how 
 * would you include the output of programs in such a method?  Just seems like
 * its a lot more work for what essentially would accomplish the same thing.
 * A lot more work for the people who have to code it to.
 */

What I see is a pipeline approach, like the shell uses (which is also what
Tony has in Plexus) allowing you to apply more than one filter to a document
to get your final document. I see no reason why you would not be able to
include the output of a program in this approach, since the filter can
return whatever it wants to the server. In addition, the filter does not
necessarily have to be a separate program, it can be within the server.

My main problems with the current setup are that people are creating HTML
documents with the INC tag, then running both NCSA httpd and anoter server
(or switching to another server altogether) and having the new server not
support the INC tag. This is why I think that documents that use the INC tag
should NOT be considered HTML documents. This also alleviates the fact that
the server is currently applying the INC filter to every HTML document when
it does not have to.

I also think that a document-type to document-type filter/conversion system
is something we will eventually have to address in the protocol, and that
this sort of thing belongs more as a filter than an HTML feature.

Comments?
--Rob



From henrich@crh.cl.msu.edu  Thu Oct  7 20:07:32 1993 -0400 (EDT)
Message-Id: <9310080007.AA07296@crh.cl.msu.edu>
Date: Thu, 7 Oct 1993 20:07:32 -0400 (EDT)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: Re: <inc> in ncsa server

>What I see is a pipeline approach, like the shell uses (which is also what
>Tony has in Plexus) allowing you to apply more than one filter to a document
>to get your final document. I see no reason why you would not be able to
>include the output of a program in this approach, since the filter can
>return whatever it wants to the server. In addition, the filter does not
>necessarily have to be a separate program, it can be within the server.

The problem with this approach, is that is will probably end up being
considerably slower than the current case.

>My main problems with the current setup are that people are creating HTML
>documents with the INC tag, then running both NCSA httpd and anoter server
>(or switching to another server altogether) and having the new server not
>support the INC tag. This is why I think that documents that use the INC tag
>should NOT be considered HTML documents. This also alleviates the fact that
>the server is currently applying the INC filter to every HTML document when
>it does not have to.

Perhaps I shouldnt have chosen to patter the include directive after HTML, for
all it matters it could be #include.  Its not meant to be HTML, for example,
the C compilers do not understand '#' directives, only the preprocessor does.
In our case the NCSA server is the preprocessor, and the Web Client is the
compiler.  If it will alliviate the problem, lets just rename it to
#inc "item".  As people *shouldnt* be thinking of this as an HTML addition.

(Although now that I think about it, I had patterned it after HTML because I
was hoping at some point people would allow <inc clnt "URL"> as well.  Where
the client would then go and include the document.

-Crh



From janssen@parc.xerox.com  Thu Oct  7 19:05:39 1993 PDT
Message-Id: <kghAfnsB0KGWE2LH8J@holmes.parc.xerox.com>
Date: Thu, 7 Oct 1993 19:05:39 PDT
From: janssen@parc.xerox.com (Bill Janssen)
Subject: Re: c.i.w3 instead of mailing list

I have much better tools for handling mail than news, so I'd like it to
be kept in news.  In addition, news encourages mindless asides from
bored undergraduates to a much greater extent than mailing lists do,
because you actually have to take some action to be added to a mailing
list; nice little energy gradient that seems to keep out more of the
information-empty.

Bill



From janssen@parc.xerox.com  Thu Oct  7 19:02:20 1993 PDT
Message-Id: <4ghAcgMB0KGW42LGgg@holmes.parc.xerox.com>
Date: Thu, 7 Oct 1993 19:02:20 PDT
From: janssen@parc.xerox.com (Bill Janssen)
Subject: Re: 'External' viewers

Excerpts from ext.WorldWideWeb: 7-Oct-93 Re: 'External' viewers Kevin
Altis@scic.intel.c (1358*)

> At  5:57 PM 10/6/93 -0700, Bill Janssen wrote:
> >I've never thought that
> >one particular viewer should be privileged.  Perhaps the `browser'
> >shouldn't even have a viewer window, and all documents should be viewed
> >externally.  In some ways, this is what window managers were intended
> >for.

> Ack!!! That's exactly what I don't want, tons and tons of windows because I
> have to use an external viewer for every different content type (document)
> I open and even those external viewers force you to have a different window
> for each document. I wouldn't complain so loudly if the most common window
> managers did a half decent job of letting you navigate around more than a
> handful of windows, but they don't.

So write a better window manager.  Nothing in the protocol keeps you
from doing it the Mac way, for instance.  Or trade your X11 system for a
Mac. :-)

Another option is to lobby for a modest change to toolkits, so that the
user, when invoking a program, can specify the window which the
application will use.  If, say, both ghostscript and xv knew how to do
this, a browser like XMosaic could easily use the same window for HTML
(via its own parser/viewer), Postscript, and images.  What a win!  By
the way, neither ghostscript nor xv are built with a standard toolkit;
each uses xlib more or less directly.

Bill



From robm@ncsa.uiuc.edu  Fri Oct  8 01:16:04 1993 -0500
Message-Id: <9310080616.AA23943@void.ncsa.uiuc.edu>
Date: Fri, 8 Oct 1993 01:16:04 -0500
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: <inc> in ncsa server

/*
 * Re: <inc> in ncsa server  by Charles Henrich (henrich@crh.cl.msu.edu)
 *    written on Oct  7,  8:07pm.
 *
 * >What I see is a pipeline approach, like the shell uses (which is also what
 * >Tony has in Plexus) allowing you to apply more than one filter to a document
 * >to get your final document. I see no reason why you would not be able to
 * >include the output of a program in this approach, since the filter can
 * >return whatever it wants to the server. In addition, the filter does not
 * >necessarily have to be a separate program, it can be within the server.
 * 
 * The problem with this approach, is that is will probably end up being
 * considerably slower than the current case.

I don't see how. As I said, the filter does not have to be a separate
program to the server.

Consider this. Currently, the function send_fd is split into two versions:
the html version which does INC parsing if the option is turned on, and the
non-html version which just spits a file out. Assume we make send_fd into
separate functions. So, we have a dumb send_fd, a send_fd for the macroized
HTML (which would probably be EXACTLY like the current one, unless we change
the <inc> syntax). We would then have other send_fd's which would work on
future type conversions, which could either rely on external programs or
internal functions.

Does this seem clearer? Is there something I'm missing which would make this
approach slower?

 * >My main problems with the current setup are that people are creating HTML
 * >documents with the INC tag, then running both NCSA httpd and anoter server
 * >(or switching to another server altogether) and having the new server not
 * >support the INC tag. This is why I think that documents that use the INC tag
 * >should NOT be considered HTML documents. This also alleviates the fact that
 * >the server is currently applying the INC filter to every HTML document when
 * >it does not have to.
 * 
 * Perhaps I shouldnt have chosen to patter the include directive after HTML, 
 * for all it matters it could be #include.  Its not meant to be HTML, for 
 * example, the C compilers do not understand '#' directives, only the 
 * preprocessor does.
 *
 * In our case the NCSA server is the preprocessor, and the Web Client is the
 * compiler.  If it will alliviate the problem, lets just rename it to
 * #inc "item".  As people *shouldnt* be thinking of this as an HTML addition.

Exactly. While it doesn't really matter if it's #inc or <inc>, the point is
that it is not HTML anymore and documents which are plain HTML should not
have the processing done on them. Also, people should not be encouraged to
think that <inc> is part of HTML (at least, not the way it is right now,
since I don't believe there are any <inc> directives for clients).

 * (Although now that I think about it, I had patterned it after HTML because I
 * was hoping at some point people would allow <inc clnt "URL"> as well.  Where
 * the client would then go and include the document.
 */



--Rob



From neuss@igd.fhg.de  Fri Oct  8 12:17:29 1993 +0100
Message-Id: <9310081117.AA07165@wildturkey.igd.fhg.de>
Date: Fri, 8 Oct 93 12:17:29 +0100
From: neuss@igd.fhg.de (neuss@igd.fhg.de)
Subject: Re: wais through http.

Hiya,

> I want to use wais to serve search requests on searchable
> http://*/*.html documents. I do not want to provide an independent
> wais server at the moment.
> Does anyone have a script for
> the NCSA server which can do that? Or one which can be adapted
> to the purpose?  Thanks,
Uh.. yeah.

If you have a little patience that is.. we'll announce a public domain server
extension that can do quite sophisticated free text searches in something 

like two weeks or so. Contact me by e-mail in case it's really urgent.

Later,
Chris
--
/*
 *  Christian Neuss  %  neuss@igd.fhg.de  %  ..in the humdrum
 */




From henrich@rs560.cl.msu.edu  Fri Oct  8 08:51:03 1993 -0400 (EDT)
Message-Id: <9310081251.AA26292@rs560.cl.msu.edu>
Date: Fri, 8 Oct 1993 08:51:03 -0400 (EDT)
From: henrich@rs560.cl.msu.edu (Charles Henrich)
Subject: Re: <inc> in ncsa server

> Does this seem clearer? Is there something I'm missing which would make this
> approach slower?

Gotcha, from your original messages it seemed as though you were proposing
sending everything through a seperate preprocessor program before handing it
off to the client.  How are you planning on determining if the server should
parse the document?  (All text/html?)

-Crh



From sanders@bsdi.com  Fri Oct  8 10:20:06 1993 -0500
Message-Id: <9310081520.AA14203@austin.BSDI.COM>
Date: Fri, 08 Oct 1993 10:20:06 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: <inc> in ncsa server 

> I don't see how. As I said, the filter does not have to be a separate
> program to the server.
Right, you could special case certain conversions and just change a
pointer to the "send" function instead of using an external conversion.

For example:
    send_fp = default_send;
    if ("converting from macro-html to html")	# use internal conversion
	send_fp = send_macro_html;
    if ("converting from xyz to html")	# uses external conversion
        open(stdout, "|xyz2html");	# this is perl, but you get the idea
    ...
    (*send_fp)(stdin, stdout);
Of course, it'll need to be more robust (e.g., you wouldn't use two internal
conversions unless you wrote a streams object to move the data around).
However, if you just setup pipe()'s and fork() you can easily use muliple
internal conversions (that just read stdin and write stdout) and the system
will handle the streams for you.  This is efficient enough for most systems,
esp on systems with copy-on-write.  This is how Plexus handles it.

    +--+
    |  |____   --------------------------------------------------------------
  __|       |  Tony Sanders               Development and US Customer Support
  \         |  sanders@BSDI.COM           Berkeley Software Design, Inc.
   \/\  * _/   Voice   + 1 512 251 1937   1801 Wells Branch Parkway, #2111
      \_ /     Support + 1 800 ITS BSD8   Austin, TX  78728
        \|     Orders  + 1 800 800 4BSD



From putz@parc.xerox.com  Fri Oct  8 09:36:29 1993 PDT
Message-Id: <93Oct8.093638pdt.2445@spoggles.parc.xerox.com>
Date: Fri, 8 Oct 1993 09:36:29 PDT
From: putz@parc.xerox.com (Steve Putz)
Subject: Re: c.i.w3 instead of mailing list

I support the proposal for creating comp.infosystems.www.programmer



From kevin@scic.intel.com  Fri Oct  8 09:29:07 1993 -0800
Message-Id: <9310081632.AA13025@rs042.scic.intel.com>
Date: Fri, 8 Oct 1993 09:29:07 -0800
From: kevin@scic.intel.com (Kevin Altis)
Subject: Re: <inc> in ncsa server

>Exactly. While it doesn't really matter if it's #inc or <inc>, the point is
>that it is not HTML anymore and documents which are plain HTML should not
>have the processing done on them. Also, people should not be encouraged to
>think that <inc> is part of HTML (at least, not the way it is right now,
>since I don't believe there are any <inc> directives for clients).
>
>--Rob

I agree that the current syntax <INC...> etc. is confusing since it isn't
HTML. If it can't be HTML, I have no problem with the concept of
preprocessing and use of #inc or maybe it should be <--pre inc...--> so
that an SGML parser will treat it as a comment. I don't want to see the
power of <INC> disappear though. So now can we have <--pre if then else
...--> ;-)

ka




From fenner@herman.cmf.nrl.navy.mil  Fri Oct  8 13:47:51 1993 -0400
Message-Id: <9310081747.AA11529@herman.cmf.nrl.navy.mil>
Date: Fri, 08 Oct 1993 13:47:51 -0400
From: fenner@herman.cmf.nrl.navy.mil (William C Fenner)
Subject: Re: c.i.w3 instead of mailing list 

You should know that alt groups are very hard to remove.
Since alt.* has no rules, one person in particular has taken
it upon himself to champion the existence of every single
alt.* group -- his argument is "If someone posts there, then
the group deserves to exist".  If you don't want to have
two *.infosystems.www.programmer groups, then I'd reccomend
against creating alt.infosystems.www.programmer .

  Bill
(instigator of the alt.bbs.waffle -> comp.bbs.waffle "move")



From henrich@crh.cl.msu.edu  Fri Oct  8 13:57:29 1993 -0400 (EDT)
Message-Id: <9310081757.AA09468@crh.cl.msu.edu>
Date: Fri, 8 Oct 1993 13:57:29 -0400 (EDT)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: Re: <inc> in ncsa server    

Will this other config file have all the names of the html files in it to
process?  If so can I suggest either a) parse all .html files or create a new
type text/html-preprocess and call it .htmlp or somesuch.  Nearly every page on
my server use <inc> :)

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                      http://rs560.msu.edu/~henrich



From montulli@stat1.cc.ukans.edu  Fri Oct  8 12:46:54 1993 CDT
Message-Id: <9310081746.AA31897@stat1.cc.ukans.edu>
Date: Fri, 8 Oct 93 12:46:54 CDT
From: montulli@stat1.cc.ukans.edu (Lou Montulli)
Subject: Re: c.i.w3 instead of mailing list

> 
> I have much better tools for handling mail than news, so I'd like it to
> be kept in news.  In addition, news encourages mindless asides from
> bored undergraduates to a much greater extent than mailing lists do,
> because you actually have to take some action to be added to a mailing
> list; nice little energy gradient that seems to keep out more of the
> information-empty.
> 
> Bill
> 
I agree. I also like the fact that I recieve mail about 5000 times
faster than news.  It can take up to a day for a news message to
get around and sometimes longer.

I think the solution it to fix the listserv software.  I'm probably
opening myself up to all kinds of problems but I'll volunteer
our listserv for the purpose.  Or Tim could put up a listserv on
his AIX machine which will work much more reliably than whatever is
going now.

:lou
-- 
  **************************************************************************
  *           T H E   U N I V E R S I T Y   O F   K A N S A S              *
  *         Lou  MONTULLI @ Ukanaix.cc.ukans.edu                           *
  *                         Kuhub.cc.ukans.edu      ACS Computing Services *
  *     913/864-0436        Ukanvax.bitnet             Lawrence, KS 66044  *
  *             UNIX! Cool! I know that!  Jurassic Park - The Movie        *
  **************************************************************************



From robm@ncsa.uiuc.edu  Fri Oct  8 13:34:50 1993 -0500
Message-Id: <9310081834.AA05338@void.ncsa.uiuc.edu>
Date: Fri, 8 Oct 1993 13:34:50 -0500
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: <inc> in ncsa server

/*
 * Re: <inc> in ncsa server  by Charles Henrich (henrich@crh.cl.msu.edu)
 *    written on Oct  8,  1:57pm.
 *
 * Will this other config file have all the names of the html files in it to
 * process?  If so can I suggest either a) parse all .html files or
 * create a new type text/html-preprocess and call it .htmlp or somesuch.  
 * Nearly every page on my server use <inc> :)
 */

What I had in mind was to call them .mhtml, or .shtml (server-html) or
something like that. If you don't want to rename all of your html files, you
can always just fool the server into thinking that .html is really the
macroized type.

You probably don't have to worry about this for next release, it probably
won't be in until 1.0a4 since I have to put in user authentication.

--Rob



From henrich@crh.cl.msu.edu  Fri Oct  8 14:45:08 1993 -0400 (EDT)
Message-Id: <9310081845.AA09577@crh.cl.msu.edu>
Date: Fri, 8 Oct 1993 14:45:08 -0400 (EDT)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: Re: <inc> in ncsa server

> What I had in mind was to call them .mhtml, or .shtml (server-html) or
> something like that. If you don't want to rename all of your html files, you
> can always just fool the server into thinking that .html is really the
> macroized type.

Good deal.  Perhaps I can convice the folks out there to add the <inc clnt>
directive to HTML, Dave?

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                      http://rs560.msu.edu/~henrich



From smc@goshawk.lanl.gov  Fri Oct  8 13:48:29 1993 MDT
Message-Id: <9310081948.AA15286@goshawk.lanl.gov>
Date: Fri, 8 Oct 93 13:48:29 MDT
From: smc@goshawk.lanl.gov (Susan M Coghlan)
Subject: Re: c.i.w3 instead of mailing list


My vote: stick with the mail list. 

   As Bill mentioned,
> ... In addition, news encourages mindless asides from
> bored undergraduates to a much greater extent than mailing lists do,
> ...
painfully true!

filtering mail is fairly easy (for an example, check out procmail) and
the difficulties experienced with the www-talk are not common with mail
lists - I'm on several other large-volume lists that work great.

Susan.



From sanders@bsdi.com  Fri Oct  8 14:54:32 1993 -0500
Message-Id: <9310081954.AA15860@austin.BSDI.COM>
Date: Fri, 08 Oct 1993 14:54:32 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: <inc> in ncsa server 

> Good deal.  Perhaps I can convice the folks out there to add the <inc clnt>
> directive to HTML, Dave?
Doing this on the client side involves much more thought than a simple
server side macro expansion.  We should base any extensions to HTML on
what the HTML+ folks are doing.  These should be completely seperate tags,
and not rolled into one.

--sanders



From janssen@parc.xerox.com  Fri Oct  8 14:26:56 1993 PDT
Message-Id: <EghRgUYB0KGWQ2LFsg@holmes.parc.xerox.com>
Date: Fri, 8 Oct 1993 14:26:56 PDT
From: janssen@parc.xerox.com (Bill Janssen)
Subject: News vs. Mail considered mindless discussion, for WWW (was: c.i.w3 instead of mailing list)

Of course, this news vs. mail discussion seems really narrow-minded. 
WWW should certainly have a completely different mechanism, based on
http and a special server, that combines the *best* of news and mail
*and* includes a searchable archive, thread linking, and annotations. 
More like free Notes.

Bill



From ctrbdo%iapa@mailhost.ecn.uoknor.edu  Fri Oct  8 13:12:39 1993 CDT
Message-Id: <9310081812.AA01459@hickory.iapa>
Date: Fri, 8 Oct 93 13:12:39 CDT
From: ctrbdo%iapa@mailhost.ecn.uoknor.edu (bryan d oakley)
Subject: re: HTML+ : questions, and a suggestion for a graph or tree tag

Facinating set of circumstances here...  back on Sept. 27th I posted a
fairly long message on HTML+, what it's status is, and whether or not
it would be possible to add a tag for a graph or tree.  As luck would
have it, my (*gack*) uucp connection died and resurfaced with a
different name, changing my email address and forever losing a couple
weeks worth of mail.  I'm curious to know if there were any responses.
I would appreciate it if someone might be kind enough to clue me in to
any response.  Note my email address below:

ctrbdo%iapa@constellation.ecn.uoknor.edu

Thanks.  If I need to repost my original letter I will, but will
refrain for the time being.

---------------------------------------------------------------------
Instrument Approach Procedures Automation             DOT/FAA/AMI-230
---------------------------------------------------------------------
Bryan D. Oakley              ctrbdo%iapa@constellation.ecn.uoknor.edu
KENROB and Associates, Inc.              voice: (405) 954-7176 (work)
5909 NW Expwy Suite 209                         (405) 366-6248 (home)
Oklahoma City, Ok.  73132            



From kevin@scic.intel.com  Fri Oct  8 16:07:48 1993 -0800
Message-Id: <9310082311.AA17388@rs042.scic.intel.com>
Date: Fri, 8 Oct 1993 16:07:48 -0800
From: kevin@scic.intel.com (Kevin Altis)
Subject: the mindless discussion can end

My original posting was intended to get us away from a perpetually broken
mail server (if possible) without having to deal with the noise level of
c.i.w3. My mail tool is  better for filtering than my News tool, so I would
just as well stay with a mailing list as long as it works.

At  2:26 PM 10/8/93 -0700, Bill Janssen wrote:
>Of course, this news vs. mail discussion seems really narrow-minded.
>WWW should certainly have a completely different mechanism, based on
>http and a special server, that combines the *best* of news and mail
>*and* includes a searchable archive, thread linking, and annotations.
>More like free Notes.

Bill gets credit for starting this one...
On the subject of a special WWW server combining the best of news and mail
we can do it today given a publically writeable area (either directly or
via one or more servers) and working group annotations. People could post
text, some rich text format or text/html and replies would be annotations
with URL links to other messages and a periodically updated WAIS index...
Might even be a good test of some of the URN ideas since the server could
generate unique ids for messages as they come in and the whole lot could be
distributed across several sites.

ka




From mcharity@hq.lcs.mit.edu  Fri Oct  8 22:49:07 1993 EDT
Message-Id: <9310090249.AA04582@hq.lcs.mit.edu>
Date: Fri, 8 Oct 93 22:49:07 EDT
From: mcharity@hq.lcs.mit.edu (Mitchell N Charity)
Subject: WWW news indexing gateway

In the two hour hack category...

There is a usenet news indexer, "ni", created by Mike Burrows of DEC.
The client which comes with the distribution was never really intended
to be used by users, and it shows.  So, why not do a WWW gateway?

A WWW-ni gateway should (1) provide a friendly query language, and (2)
process results for readability.  General query mangling was too
difficult for the 2hr hack category, and I didnt even get to the
several easy special cases which would make a big difference.
Doing presentation was simple.

So, the result, unfortunately not globally accessible, is an index
page which describes the bare ni client's somewhat painful query
language, and which hands off queries to the perl script abstracted
below.  An example result follows.

"ni" is available from gatekeeper.dec.com.  It supports fielded, full
text search.  The current(?) version does _not_ do word adjacency.  A
500MB news spool is said to require 200MB of index, 45MB memory, and
to scale linearly.

Mitchell

-----[presentation code]-----
print "<title>ni</title><isindex><ul>\n";

open(IN,"-|") || exec $ni,"c $query";
chop($c = <IN>);
close(IN);

&fail if($c !~ /^[0-9]+$/o);
print "<b>$query <i>matched</i> $c <i>articles at $d</i></b><p>\n\n";
exit(0) if $c == 0;

open(IN,"-|") || exec $ni,"h $query";

for($i=0; $i<=$limit_n && $i <$c; $i++) {
  $l = &next_paragraph;
  $l =~ /Message-Id: <([^>]+)>/oi || &fail; $id = $1;
  $l =~ /Newsgroups: +(.+)/oi || &fail;     $gr = $1;
  $l =~ /Subject: +(.+)/oi || &fail;        $su = $1;
  $l =~ /From: +(.+)/oi || &fail;           $fr = $1;
  $l =~ /Date: +(.+)/oi || &fail;           $da = $1;
  $fr =~ s/.*\(([^\)]+)\).*/$1/;
  $gr =~ s/,([^,]+)/,<a href=\"news:$1\">$1<\/a>/g;
  $gr =~ s/^([^,]+)/<a href=\"news:$1\">$1<\/a>/;
  print "<li>[$gr] <a href=\"news:$id\"><b>$su</b> ($da) - $fr</a>\n";
}
print "</ul>\n";
----[end of code]----
----[example result (cleaned up fragment)]----
<title>ni</title>
<isindex>
<ul>
<b>subj(cite)&g(www) <i>matched</i> 8 <i>articles at 08 Oct 93 (22:21)
</i></b><p>

<li>[<a href="news:comp.infosystems.www">comp.infosystems.www</a>,
     <a href="news:alt.hypertext">alt.hypertext</a>]
   <a href="news:28d0nh$ds2@bradley.bradley.edu">
   <b>How to cite a web document</b> (29 sep 1993) - Jerry Whelan</a>
<li>[<a href="news:comp.infosystems.www">comp.infosystems.www</a>,
     <a href="news:alt.hypertext">alt.hypertext</a>]
   <a href="news:MARCA.93Sep29190059@wintermute.ncsa.uiuc.edu">
   <b>Re: How to cite a web document</b> (29 sep 1993) - Marc Andreessen</a>
<li>[<a href="news:comp.infosystems.www">comp.infosystems.www</a>,
     <a href="news:alt.hypertext">alt.hypertext</a>]
   <a href="news:28d82j$kdq@bradley.bradley.edu">
   <b>Re: How to cite a web document</b> (30 sep 1993) - Jerry Whelan</a>
</ul>
----[end of example]----



From janssen@parc.xerox.com  Fri Oct  8 20:49:50 1993 PDT
Message-Id: <0ghXHSsB0KGW02LM8B@holmes.parc.xerox.com>
Date: Fri, 8 Oct 1993 20:49:50 PDT
From: janssen@parc.xerox.com (Bill Janssen)
Subject: Re: the mindless discussion can end

Excerpts from ext.WorldWideWeb: 8-Oct-93 the mindless discussion can..
Kevin Altis@scic.intel.c (1238*)

> My mail tool is  better for filtering than my News tool, so I would
> just as well stay with a mailing list as long as it works.

Great!  Lou's volunteered a working listserv, so I imagine he and Tim
will work out the details.

Bill



From janssen@parc.xerox.com  Fri Oct  8 20:54:01 1993 PDT
Message-Id: <wghXLNoB0KGWM2LMhc@holmes.parc.xerox.com>
Date: Fri, 8 Oct 1993 20:54:01 PDT
From: janssen@parc.xerox.com (Bill Janssen)
Subject: Re: the mindless discussion can end

Excerpts from ext.WorldWideWeb: 8-Oct-93 the mindless discussion can..
Kevin Altis@scic.intel.c (1238*)

> On the subject of a special WWW server combining the best of news and mail
> we can do it today given a publically writeable area (either directly or
> via one or more servers) and working group annotations.

So the race is on to see who can do it in the most interesting fashion! 
A great challenge...

Excerpts from ext.WorldWideWeb: 8-Oct-93 the mindless discussion can..
Kevin Altis@scic.intel.c (1238*)

People could post text, some rich text format or text/html

Please, application/html (at least, I *hope* it's registered that way). 
But any MIME type should be eligible, just as it is in mail and news. 
This would spur the development of decent indexing technology both for
structured or rich text ("show me all anchors that HREF my document"?)
and for images or movies!

Bill



From kevin@scic.intel.com  Sat Oct  9 20:17:44 1993 -0800
Message-Id: <9310100321.AA19283@rs042.scic.intel.com>
Date: Sat, 9 Oct 1993 20:17:44 -0800
From: kevin@scic.intel.com (Kevin Altis)
Subject: additional HTML+ FORM types

We have checkboxes, radio buttons, and rudimentary fields. What other types
would people like to see for FORMs? How about sliders (vertical,
horizontal, knobs)? Selection lists? Should the user be able to queue
clicks in an ISMAP area to go along with some other checkbox and field
selections before being sent off as a single query?

ka




From wei@xcf.berkeley.edu  Sat Oct  9 22:03:14 1993 -0700
Message-Id: <9310100503.AA07070@xcf.Berkeley.EDU>
Date: Sat, 9 Oct 93 22:03:14 -0700
From: wei@xcf.berkeley.edu (Pei Y. Wei)
Subject: Re:  additional HTML+ FORM types

kevin@scic.intel.com (Kevin Altis) wrote:
> How about sliders (vertical, horizontal, knobs)? 

Yes, please. In the re-incarnated-but-not-yet-release ViolaWWW, 
there's an <INPUT type="percent"> which maps to a horizontal slider. 
Perhaps we should add min and max constraints for number inputs.

> Selection lists?

Not sure we have the same thing in mind, but I've got an <OPTIONS> 
tag (gonna change that name before release...) that is mapped to a 
pull-down menu. In the following example, the menu GUI is initially
labeled ``San Francisco'':

	<OPTIONS name="cities">
	<OPTI value="berlin">Berlin</OPTI>
	<OPTI value="cairo">Cairo</OPTI>
	<OPTI value="sf" checked>San Francisco</OPTI>
	</OPTIONS>

Here's the DTD for it:

	<!ATTLIST OPTIONS
		name	CDATA		#IMPLIED
		type	CDATA		#IMPLIED
		size	CDATA		#IMPLIED
		disabled (disabled) 	#IMPLIED
		envvar	CDATA		#IMPLIED>
	<!ATTLIST OPTI
		value	CDATA		#IMPLIED
		checked (checked) 	#IMPLIED
		disabled (disabled) 	#IMPLIED>


Also, just for the fun of it, there's a signature thingy (type="doodle"),
which draws and collects mouse positions when the mouse is dragged on it. 
Has "clear" button for the doddle pad. Perhaps this is useful enough to 
be part of the HTMLplus standard.


-Pei



From robm@ncsa.uiuc.edu  Sun Oct 10 02:40:01 1993 -0500
Message-Id: <9310100740.AA00232@void.ncsa.uiuc.edu>
Date: Sun, 10 Oct 1993 02:40:01 -0500
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: IMPORTANT: NCSA httpd 1.0a3



NCSA httpd 1.0a3 has been released and can be found on ftp.ncsa.uiuc.edu
  under /Web/ncsa_httpd/httpd-1.0a3. 

IF YOU ARE USING NCSA httpd 1.0a2 OR EARLIER, OR KNOW SOMEONE WHO IS,
PLEASE UPGRADE OR FORWARD THEM THIS NOTE!

Versions of httpd 1.0 previous to a3 had a serious bug in init_mime which
would cause them to incorrectly type certain files. 


All documentation is online, and can be found at http://hoohoo.ncsa.uiuc.edu/

<A HREF="http://hoohoo.ncsa.uiuc.edu/">That's here.</A>

New in version 1.0a3: 

 o .htaccess files now affect subdirectories
 o Added option FollowSymLinks for security
 o Fixed MAJOR bug in init_mime function
 o Enhanced Makefile and httpd.h for people compiling httpd themselves

--Rob, Marc, and Eric (httpd@ncsa.uiuc.edu)




From marca@ncsa.uiuc.edu  Sun Oct 10 03:05:06 1993 -0700
Message-Id: <9310101005.AA13399@wintermute.ncsa.uiuc.edu>
Date: Sun, 10 Oct 93 03:05:06 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: proposal for INPUT TYPE=options

I don't speak SGML, but here's what I mean:

        <INPUT TYPE="options" OPTIONS="option1,option2,option3"
         VALUE="option2" NAME="myoptions"> 

Instantiation in Mosaic will be a Motif option menu.  Separator in
OPTIONS is comma; any leading whitespace in each option is ignored.
The rest is straightforward.

Comments?  We'd like to do this for Mosaic 2.0pre5, and I don't think
the basic idea is objectionable, so please comment fairly quickly if
you have problems with it...

Thanks,
Marc



From wmperry@mango.ucs.indiana.edu  Sun Oct 10 07:53:29 1993 -0500
Message-Id: <16232.750257609@mango.ucs.indiana.edu>
Date: Sun, 10 Oct 1993 07:53:29 -0500
From: wmperry@mango.ucs.indiana.edu (William M. Perry)
Subject: Re: additional HTML+ FORM types 

In response to your message dated: Sat, 09 Oct 1993 20:17:44 PST
>We have checkboxes, radio buttons, and rudimentary fields. What other
>types would people like to see for FORMs? How about sliders
>(vertical, horizontal, knobs)? Selection lists? Should the user be
>able to queue clicks in an ISMAP area to go along with some other
>checkbox and field selections before being sent off as a single
>query?

   These all sound great, but could we please stick to generalized
types like 'sliders' or 'pick lists', not 'knobs'.  Remember - a lot
of people are going to want to use this on a dumb terminal.

   It was extremely easy to put the current forms support into my
emacs browser - all the typechecking is finished.  For things like
sliders and selection lists I imagine it would take twice as long.

   I think extending the INT/FLOAT types to have a minimum and maximum
range would be a better idea than sliders.  Browsers that have that
capacity could automatically display them as sliders or spinners or
whatever.

   I hate to bring up a religious issue, but HTML is supposed to be
presentation-free, so things like <INPUT TYPE="int" MIN="10"
MAX="100"> would be more appropriate.

   Am I way off base here?  Forms are going to be an extremely
powerful part of the web, and all browsers should be able to access
them.

-Bill P.



From luotonen@ptsun00.cern.ch  Sun Oct 10 20:20:53 1993 +0100
Message-Id: <9310101920.AA18867@ptsun00.cern.ch>
Date: Sun, 10 Oct 93 20:20:53 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: AA Documents updated


   Ciao,

I have (finally) finished updating WWW AA documentation. Enter either
by "CERN Home Page / World-Wide Web / Technical / Access Authorization"
or direct URL:

    http://info.cern.ch/hypertext/WWW/AccessAuthorization/Overview.html

If there is too much stuff just look at

    "Protocol examples" and
    "how to set up protection in the CERN Daemon"

in the "Quick References" section to get a picture of what's going on.

-- Salut, Ari --

                     \\\\Ari Luotonen//////
                      \\\\WWW Person//////
                       \\\\\\/\\\\\//////
                        \\\\//\\\\//////
                         \\////\\//////
                          \/\/\/\/\/\/




From d0asta@dtek.chalmers.se  Sun Oct 10 22:43:18 1993 +0100
Message-Id: <9310102143.AA28850@hackes.dtek.chalmers.se>
Date: Sun, 10 Oct 93 22:43:18 +0100
From: d0asta@dtek.chalmers.se (Magnus Homann)
Subject: html-mode.el

Who is maintaing html-mode for Emacs?

What is the current version?

How much work is put into it at this moment?

(I have made some changes and would like to incorporate them)

--
   Magnus Homann  Email: d0asta@dtek.chalmers.se
                  URL:   http://www.dtek.chalmers.se/DCIG/d0asta.html



From marca@ncsa.uiuc.edu  Sun Oct 10 17:40:21 1993 -0700
Message-Id: <9310110040.AA14620@wintermute.ncsa.uiuc.edu>
Date: Sun, 10 Oct 93 17:40:21 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: html-mode.el

Magnus Homann writes:
> Who is maintaing html-mode for Emacs?

Nominally, me.

> What is the current version?

Whatever's in the elisp archive...

> How much work is put into it at this moment?

None :-).  I'm too busy on Mosaic proper -- so anyone who wants should
feel free to distribute modified (renamed) versions or to just take
over the maintenance...

Marc



From jer@bagheera.jax.org  Sun Oct 10 21:37:46 1993 EDT
Message-Id: <9310110137.AA01036@bagheera.jax.org>
Date: Sun, 10 Oct 93 21:37:46 EDT
From: jer@bagheera.jax.org (Joel Richardson)
Subject: Re:  additional HTML+ FORM types

> We have checkboxes, radio buttons, and rudimentary fields. What other types
> would people like to see for FORMs? How about sliders (vertical,
> horizontal, knobs)? Selection lists? Should the user be able to queue
> clicks in an ISMAP area to go along with some other checkbox and field
> selections before being sent off as a single query?

Yes, all of these! (What else?) We are planning to provide as much of
a database front end through WWW as we can. Right now, we are concentrating
on querying. But adding things like selection lists to forms would make it
feasible to do the editorial interfaces as well. Would it make sense to 
keep the list in a separate document and have a form's input field specify
the URL? The usual document caching mechanisms would then save a lot of
unnecessary traffic in many situations.

Another wish I have for forms is to associate different action URLs with
different submit buttons rather than one for the whole form. One could make
this upward compatible with the existing HTMP+ spec by stating that any
INPUT (of type "submit") that does not specify an action URL uses the form's
action URL by default.

--Joel

=============================================================
Joel Richardson                 Email:  jer@jax.org
The Jackson Laboratory          Phone:  (207) 288-3371 x1425
600 Main Street                 Fax:    (207) 288-8982
Bar Harbor, Maine 04609
=============================================================



From montulli@stat1.cc.ukans.edu  Sun Oct 10 21:23:30 1993 CDT
Message-Id: <9310110223.AA32956@stat1.cc.ukans.edu>
Date: Sun, 10 Oct 93 21:23:30 CDT
From: montulli@stat1.cc.ukans.edu (Lou Montulli)
Subject: Re: additional HTML+ FORM types

> 
> We have checkboxes, radio buttons, and rudimentary fields. What other types
> would people like to see for FORMs? How about sliders (vertical,
> horizontal, knobs)? Selection lists? Should the user be able to queue
> clicks in an ISMAP area to go along with some other checkbox and field
> selections before being sent off as a single query?
> 
> ka
> 
Input types need to be content specified not implementation
specified.  A slider or knob can only be implemented on some
platforms.  If you want a slider call it a range feild or something.
On a GUI client it can be implemented as a slider and on a text
client it can be implemented as a pair of digits.

:lou
-- 
  **************************************************************************
  *           T H E   U N I V E R S I T Y   O F   K A N S A S              *
  *         Lou  MONTULLI @ Ukanaix.cc.ukans.edu                           *
  *                         Kuhub.cc.ukans.edu      ACS Computing Services *
  *     913/864-0436        Ukanvax.bitnet             Lawrence, KS 66044  *
  *             UNIX! Cool! I know that!  Jurassic Park - The Movie        *
  **************************************************************************



From marca@ncsa.uiuc.edu  Sun Oct 10 22:53:59 1993 -0700
Message-Id: <9310110553.AA15219@wintermute.ncsa.uiuc.edu>
Date: Sun, 10 Oct 93 22:53:59 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: addendum to NCSA Mosaic for X 2.0 prerelease 5 available

A slight addition was made to the app-defaults files and fallback
resources included in the 2.0pre5 distribution to support option menus
in forms.  If you already have a personalized app-defaults file in
place, you may need to add these lines:

XMosaic*XmCascadeButton*fontList: -*-helvetica-bold-o-normal-*-14-*-iso8859-1
XMosaic*XmCascadeButtonGadget*fontList: -*-helvetica-bold-o-normal-*-14-*-iso8859-1

Cheers,
Marc



From marca@ncsa.uiuc.edu  Sun Oct 10 22:45:48 1993 -0700
Message-Id: <9310110545.AA15199@wintermute.ncsa.uiuc.edu>
Date: Sun, 10 Oct 93 22:45:48 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: NCSA Mosaic for X 2.0 prerelease 5 available

......ftp.ncsa.uiuc.edu in /Mosaic/prerelease.  Source, plus binaries
for Sun, IBM, SGI.

This prerelease is another step on the road to 2.0.  It is not quite
stable and should not be released to normal users.  However, we
encourage those of you who are interested to bash on it and let us
know what you think.

Changes and additions include:

 o Added INPUT elements of type RADIO for fill-out forms as per
   HTML+ spec. 
 o Added INPUT elements of type PASSWORD for fill-out forms as per
   HTML+ spec. 
 o Added INPUT elements of type OPTION for option menus in fill-out
   forms (not in HTML+ spec yet). 
 o Added resource twirlingTransferIcon, default true, can be set to false to
   turn off twirling NCSA logo on transfers (interruption is still possible). 
 o Added resource twirlIncrement, default 4096, to indicate how many bytes
   (minimum) are transferred between icon twirls in interface for normal
   (FTP, Gopher, HTTP) transfers, if twirlingTransferIcon is on. 
 o FTP interface now has icons, byte counts (courtesy Charles Henrich). 
 o Gopher icons are back. 
 o Gopher type handling is back up to par, including support for
   tweakGopherTypes. 
 o Brought default mailcap and extension mapping stuff up to speed;
   enumerated previously wildcarded types (image/*, audio/*) for
   debatably broken CERN server. 
 o External viewers need not have "%s" as part of their names anymore; if
   they don't, then the data will be piped through stdin when they are
   executed. 
 o Added "Reload Config Files" menubar entry, to cause mailcaps and
   extension maps to be reloaded on the fly. 
 o Multiformat WAIS support is now working; testcase here; sample query. 
 o MIME types returned from WAIS servers are now handled correctly. 
 o Telnet/rlogin/tn3270 works again. 
 o Upon startup, now writes own pid into ~/.mosaicpid. 
 o Clip anchor ("#...") off of current URL, if present, before doing search,
   for both forms and isindex. 
 o Widget creation now deferred as long as possible, to eliminate ugliness of
   index field, etc. showing up too early. 
 o It should now be impossible to do anything interface-wise during a
   transfer except click on the interrupt button for the current window. 
 o Fixed memory problem introduced in pre4 triggered when opening a new
   window with middle mouse click. 
 o Fixed HTML widget crash condition that hit HP-UX. 
 o Fixed problem jumping to anchors in the same document (jump to "#a" in
   a document, the "#b", then go back and you were still at "#b" instead of
   "#a"). Also nailed down jumping back and forth between anchors in
   general. Performance maybe could be better. 
 o Handle 403 return codes better ("Forbidden"). 
 o Fixed problem with icon not righting itself after reloading inlined images
   (testcase). 
 o Fixed problem with invalid content-type returned as part of HTTP/1.0
   reply (was causing bad memory corruption; now unrecognized
   content-types default to HTML). Testcase -- click on "Help". 
 o Fixed problem introduced in pre4 with confused history mechanism and
   internal anchors. 
 o Fixed minor problem with news formatting. 
 o Ignore SIGPIPE; error EPIPE is also considered to be a sign of the
   HTTP1/0 protocol incompatibility problem. 
 o Fixed problem with -dil and images that aren't accessible at all. 
 o Merged in useful fixes from 2.11, including ignoring of ":80" for HTTP
   URLs and ":70" for Gopher URLs in URL parsing for improved history
   tracking. 
 o Killed use of const structs in HTML-PSformat.c to make compilation
   under Ultrix easier. 
 o Added patches for Esix 4.0.4 and Solaris x86 2.1. 
 o Reported bug: "Found a bug with the maxlength parm, if you set a size to
   something other than the specified maxlength, it will allow data of any
   length to be entered" fixed. 
 o Cleaned up communication notification mechanisms. 

Comments and feedback much appreciated -- however, beware: THIS IS
UNSUPPORTED CODE.  If you want stability, get Mosaic 1.2
(ftp.ncsa.uiuc.edu, /Mosaic/xmosaic-binaries and
/Mosaic/xmosaic-source).

Cheers,
Marc & Eric

--
Marc Andreessen & Eric Bina
Software Development Group
National Center for Supercomputing Applications
marca@ncsa.uiuc.edu, ebina@ncsa.uiuc.edu



From waterbug@epims1.gsfc.nasa.gov  Mon Oct 11 00:22:09 1993 EDT
Message-Id: <9310110422.AA06358@epims1.gsfc.nasa.gov>
Date: Mon, 11 Oct 93 00:22:09 EDT
From: waterbug@epims1.gsfc.nasa.gov (Steve Waterbury)
Subject: Re: additional HTML+ FORM types (Long)


Kevin Altis writes:

> We have checkboxes, radio buttons, and rudimentary fields. What other types
> would people like to see for FORMs? How about sliders (vertical,
> horizontal, knobs)? Selection lists? Should the user be able to queue
> clicks in an ISMAP area to go along with some other checkbox and field
> selections before being sent off as a single query?

I think what we have includes "toggle buttons" rather than radio buttons -- 
the distinction as I understand it is the on/off state of each toggle in 
as set of toggle buttons is independent, whereas in a set of radio buttons 
there can only be one on at a time (hence the "radio" metaphor) ... when 
you select one, the one that was on turns off, etc.  

Having said that, the two highest priority widgets for my apps 
are (ta-da!) RADIO BUTTONS and (perhaps even more important) 
SELECTION LISTS (see further discussion below).  

Pei Y. Wei writes (about the new ViolaWWW [!]):  

> Not sure we have the same thing in mind, but I've got an <OPTIONS> 
> tag (gonna change that name before release...) that is mapped to a 
> pull-down menu.

Pull-down menus seem to have about the same semantics as selections lists, 
except that selection lists can be scrollable (in our applications, we 
tend to use pull-downs unless they get too long, in which case we have to 
go to a scrollable selection list).  So I guess SELECTION LISTS have a 
higher priority for me, since they are slightly more versatile ... but if 
we can have both -- oh goody goody!

Joel Richardson writes:

> Yes, all of these! (What else?) We are planning to provide as much of
> a database front end through WWW as we can. 

I am of a mind with Joel on using WWW and Mosaic as a database front-end.  
We (the NASA Parts Project Office) have a database application called 
EPIMS (see the CERN WWW Virtual Library subject catalog under 
Engineering) of which at least the public parts I would very much like 
to "Web-ize".  To make the front-end ergonomic, it is essential to have 
"pick-lists" (or selection lists) to assist in composing a query -- i.e., 
the pick-list is actually created by executing a "mini-query" to show what 
is available in the database to include in the principal query.  

Joel continues:

> Right now, we are concentrating
> on querying. But adding things like selection lists to forms would make it
> feasible to do the editorial interfaces as well. Would it make sense to 
> keep the list in a separate document and have a form's input field specify
> the URL? The usual document caching mechanisms would then save a lot of
> unnecessary traffic in many situations.

As it happens, I was just today thinking (in the shower of course) of how 
one might have a viewer to call for presenting pick-lists.  I guess that 
is still possible, but I like this idea of the list coming back in a 
separate "document" very much for several reasons:  

1)  it avoids gratuitously adding another widget (or viewer for that 
matter) for lists (although if it's easy to do, the pull-down menu and 
scrollable list widgets might still be nice ... at least for small 
lists)

2)  selection lists could work fine as hypertexted lists in the same way 
directories are presented now (he said glibly) if they could pass a 
selection from the list as a parameter back to the main query form 
(hmmm ... seems doable ... maybe another remote-control from the config 
file type thing)

3)  would work nicely with the idea of doing a "mini-query" from a 
button ("Select foo-bar from list") in your main form that would 
return a hypertexted list in a separate window, from which your 
selection would be sent back to the window with your main form.  
This could be nice and flexible:  the "mini-query" could a) access 
an existing HTML list (hard-coded), b) access the database server 
that your main query will go to, or c) access a specialty server 
that maintains that particular data item.  

E.g., in the case of our application, we let users select parts by 
classification (Federal Supply Class) and manufacturer (as encoded 
by Defense Logistics Supply Center into the "Commercial And 
Government Entity" codes).  We give them the option of popping up 
lists of FSC's and CAGE codes to include in their query.  The ideal 
situation (I think!) would be to have some national-scale server on 
which FSC's and CAGE codes are maintained, and when your app needs 
one, you just do a query against one of those servers.  Of course 
most sites would cache either the whole database or large parts of 
it if it's used frequently, but the servers should still be there 
to keep your cache up to date.  (Actually, in the case of CAGE 
codes, another level of query is needed, since there are about 
90,000 active ones and you _probably_ don't want a pick-list 
that long!)  

This points to one of my pet ideas (not that it is mine alone!), 
whose time for discussion (or at least reality checking!!) perhaps 
has come:  while it's great to be able to hyperlink around the Web 
discovering things by serendipity, I for one would like to see 
some servers dedicated to systematic indexes of what is out there.  
In my concept, this involves a couple of things:  

*  A consensual set of logical tags (in database parlance, "data 
elements") that would *not* be part of HTML, but could be used to 
logically tag info in an HTML document -- invisible to Mosaic, 
but visible to the indexing engine that is looking for it and that 
would maintain an index of all occurrances of that tag, with the 
corresponding URL (and perhaps position in the doc. somehow) 
and the value tagged in each instance.  

*  A (hopefully simple) indexing server that would accept queries 
on the particular data it supports.  This would probably need at 
least one level of indirection:  a hierarchy of servers of which 
the top level ones would be meta-data servers (knowing all the 
data elements/tags and the data servers for each -- sort of a 
Web-ized "active data dictionary").  

*  A way of agreeing on and "registering" data elements/tags, 
their names and definitions.  Here we go with the urban renewal 
project for the Tower of Babel (which is what we have right now, 
in case you hadn't noticed!).  I am working with Michael McLay 
of NIST on the idea of setting up a server to do this sort of 
registration (a big part of the concept we are working on is 
"object registration", but that's whole nother can of worms!).  

You will notice this scheme needs a bit of bootstrapping:  
it would be great to have at least the meta-data servers set up 
before one starts logically tagging things, so you can see what 
logical tags are "registered" and being indexed.  

I guess this would get us closer (in my view) to the "concept of 
a universal information database" that Kevin Hughes mentions in 
his Guide to Cyberspace.  

This promises to become quite an active and elaborate thread, 
judging by the initial responses.  I think the forms capability 
and the associated database access functionality are features 
that will raise Mosaic to ... uh, what status comes after 
"Killer App"?  "Psychokiller App"??  (naah)  Anyway, onward 
in fulfilling its destiny to be the "Mother of All Clients".  
(But enough vicarious megalomania!)  

Steve Waterbury
NASA/GSFC



From jfg@infodesign.ch  Sun Oct 10 13:59:26 1993 +0100
Message-Id: <9310101259.AA01279@infodesign.ch>
Date: Sun, 10 Oct 93 13:59:26 +0100
From: jfg@infodesign.ch (Jean-Francois Groff)
Subject: Re: 'External' viewers

>>> On Thu, October 7, Kevin Altis said:
 > I wouldn't complain so loudly if the most common window
 > managers did a half decent job of letting you navigate around more than a
 > handful of windows, but they don't. Most of our current operating
 > system/window managers don't have a clue when it comes to color models
 > either (unless they're 24-bit or higher) so the more windows with different
 > colors the more screwed up your display gets. I absolutely refuse to spend
 > my entire day minimizing and maximizing all my stupid windows and trying to
 > decide which icon really represents the document I want to look at. The Mac
 > (with a system extension or two) is the only machine I've ever used that
 > deals with lots of windows and lots of colors in a sensible way. Since
 > nobody else seems to be going in that direction, I want to keep the number
 > of windows to a minimum.

-- Begin blatant praise --

  Try NEXTSTEP ! It looks great on Intel boxes now (486 and Pentium),
and will also run on HP/PA, Power PC and DEC Alpha next year. It does
windows and colors right, crisp and fast, and it's a delight to program.

-- End blatant praise --

  I'm working on a new WWW browser/viewer/editor under NEXTSTEP. The
design goal is to reconcile ease of use for mere mortals with power
features for WWWWizards, and to bring authoring capabilities to everyone.
Those of you interested are welcome to contact me offline for discussion.

	Jean-Francois Groff <jfg@infodesign.ch>
	http://info.cern.ch/hypertext/WWW/People.html#groff



From waterbug@epims1.gsfc.nasa.gov  Mon Oct 11 01:00:27 1993 EDT
Message-Id: <9310110500.AA06431@epims1.gsfc.nasa.gov>
Date: Mon, 11 Oct 93 01:00:27 EDT
From: waterbug@epims1.gsfc.nasa.gov (Steve Waterbury)
Subject: Re: additional HTML+ FORM types - P.S. to (Long)


Well excuuuuse me!  Just as I was sending my humongous message, 
Marc's announcement of Pre5 came.  I should have downloaded it 
before I sent my message, because yes, Virginia, there ARE 
radio buttons in Mosaic forms!  AND toggles (a.k.a. checkboxes).  

My apologies to Kevin!!   :-) 

Boy, you don't have to wait long for things to happen around 
here!

Steve Waterbury



From waterbug@epims1.gsfc.nasa.gov  Mon Oct 11 02:23:54 1993 EDT
Message-Id: <9310110623.AA06466@epims1.gsfc.nasa.gov>
Date: Mon, 11 Oct 93 02:23:54 EDT
From: waterbug@epims1.gsfc.nasa.gov (Steve Waterbury)
Subject: Re: additional HTML+ FORM types (Long)


Marc Andreessen writes (off-line):

> next up is multiline text entry
> areas (which will require an alternative form submission method --
> don't want to be packing 10K of text into a URL).

Great!! That one is very important for something I want to do, which 
is basically set up an input form that creates an HTML doc at the 
same time as it sends the parameters out (well I guess you could 
just say it is sending the parameters to another server that is 
putting them into HTML ... and tagging the non-HTML "logical tag" 
items I mentioned).  Is that perhaps a candidate for the 
"alternative form submission method" -- hmm ... guess you would 
have to build a little "server" functionality into the client 
so it could "serve" the HTML back to the query server in the form 
of an HTML document plus parameters (and/or "logical tags"), and 
then have an HTML and logical tag filter in the interface of your 
query server.  

We definitely need multiline entry for some things, but 
perhaps for "input form" apps that create documents or big 
data objects with really large text and graphics and multi-media 
stuff it would be better to have a capability to "attach" files to 
the other stuff being sumitted from the form.  That could be 
along the lines of the "query" or form results creating an HTML 
doc, with in-line images, links, etc.  

This is getting closer and closer to an HTML editor of sorts!  
But that (using a Mosaic form to create an HTML document, rather 
than a free-form HTML editor -- especially for novices) seems 
appropriate for VERY structured types of data objects, such as 
technical reports.  Our applications include, e.g., Failure 
Analysis reports, which contain several well-defined fields like 
"part number", "manufacturer (CAGE Code)" etc., plus the main 
body -- lots of text -- plus photos.  This is pretty typical of 
a lot of engineering publications, for which a certain amount of 
standardization would be very useful....

> Also, since we have option menus, will it be useful to have scrolled
> selection lists in addition?  (Depends on how many things you think
> you want to put in a single set of options, I suppose...)

Incidentally, your option menus look great ... well, I guess and 
option menu is an option menu, but it`s a trip to see one in an 
HTML document!!  As I say, some of our option menus got too big 
(as in off-the-screen!), so we had to make them scrollable selection 
lists.  To tell the truth, I _think_ I would be just as happy with 
a selection list in a separate document window, if that were 
feasible ... i.e., if the inter-window communications weren't too 
hairy.  But it would also be real nice to have the selection list 
widget adjust to the width of the selections so it doesn't take 
so much screen space.  That may be asking a bit much, though!  

You're doing great.  

Steve.


----- End Included Message -----



From robm@ncsa.uiuc.edu  Mon Oct 11 03:06:33 1993 -0500
Message-Id: <9310110806.AA17847@void.ncsa.uiuc.edu>
Date: Mon, 11 Oct 1993 03:06:33 -0500
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: NCSA httpd 1.0a3.1 released




In my rush to get NCSA httpd 1.0a3 out the door, I neglected to notice a bug
in which symlinks that were files and not directories were followed
regardless of the FollowSymLinks option. A fix has been released as NCSA
httpd 1.0a3.1. A source patch is attached for those who are using the source
and do not want to get the entire package again.

Thanks for your patience.
--Rob

The patch follows:

*** http_access.c.orig	Sun Oct 10 20:30:13 1993
--- http_access.c	Mon Oct 11 01:58:08 1993
***************
*** 154,159 ****
--- 154,172 ----
              }
          }
      }
+     if((!(opts[num_dirs-1] & OPT_SYM_LINKS))&&(!(S_ISDIR(finfo->st_mode)))) {
+            struct stat fi;
+            strcpy(d,path);
+            lstat(d,&fi);
+            if(!S_ISDIR(fi.st_mode)) {
+                 char errstr[MAX_STRING_LEN];
+                 sprintf(errstr,"httpd: will not follow link %s",d);
+                 log_error(errstr);
+                 *allow = 0;
+                 *allow_options = OPT_NONE;
+                 return;
+            }
+     }
      if(need_auth)
          check_auth(sec);
      *allow = will_allow;



From qq15@liverpool.ac.uk  Mon Oct 11 09:30:02 1993 BST
Message-Id: <9310110830.AA14611@chad3-14.liv.ac.uk>
Date: Mon, 11 Oct 93 9:30:02 BST
From: qq15@liverpool.ac.uk (Pete)
Subject: Re: c.i.w3 instead of mailing list (fwd)

> > 
> > I have much better tools for handling mail than news, so I'd like it to
> > be kept in news.  In addition, news encourages mindless asides from
> > bored undergraduates to a much greater extent than mailing lists do,
> > because you actually have to take some action to be added to a mailing
> > list; nice little energy gradient that seems to keep out more of the
> > information-empty.
> > 
> > Bill
> > 
> I agree. I also like the fact that I recieve mail about 5000 times
> faster than news.  It can take up to a day for a news message to
> get around and sometimes longer.

I agree as well.  I happen to spend a large proportion of my day
handling email and it is much more convenient for me to have a
permanently open incoming mailbox than to flit around news AND
have a permanently open incoming mailbox.

Pete



From marca@ncsa.uiuc.edu  Mon Oct 11 05:48:22 1993 -0700
Message-Id: <9310111248.AA16287@wintermute.ncsa.uiuc.edu>
Date: Mon, 11 Oct 93 05:48:22 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: request for new forms submission consensus

Can we come to a consensus on a forms submission method that uses
HTTP/1.0 to deliver the contents of large forms (including multiline
edit fields) to smart servers in the next week or two?  (Unless we
already have and I missed it...)

All things being equal, I think I'd be happy with the current encoding
method (name=value&name=value with escaping) just slapped into the
body of an HTTP/1.0 'SUBMIT' request -- keeps things simple and
straightforward, avoids creating a new syntax, is known to properly
handle escaping issues, and servers and code already exist for
decoding/handling it.

To be honest, the idea of encoding it in some kind of SGML format does
not excite me in the least -- what would be the added value?

Also, I'd like to suggest that multiline text fields have a different
type (e.g. "textarea") than single-line fields ("text"), as they
really are different types of things, and imply different issues
(semantics) for client-side handling.

Cheers,
Marc



From timbl@www3.cern.ch  Mon Oct 11 12:20:33 1993 +0100
Message-Id: <9310111120.AA00625@www3.cern.ch>
Date: Mon, 11 Oct 93 12:20:33 +0100
From: timbl@www3.cern.ch (Tim Berners-Lee)
Subject: Re: URL paper final edits


>From: Larry Masinter <masinter@parc.xerox.com>
>Date: 	Fri, 8 Oct 1993 15:20:18 PDT
>
>mailto: followed by an internet address isn't adequate to reference
>document objects that require more text to be sent to an external  
mail
>server. I'm thinking of those things that you can call out with
>access-type=mail-server
>
>where there is a 'phantom body'.
>
>Is this a totally different kind of URL?


	Yes.  It does not represent a document to be RETRIEVED
	by mail (mail is not a retrieval protocol _really_).
	The URL represents the mail address.
	Sending a message to a mail address is the equivalent
	function to posting an article to a newsgroup, or linking
	an annotation to a document.  There is a new object created
	and an association made with an existing object.
	A minor difference is that you can't read a mail address,
	though you can read a newsgroup or an annotated document.

	In fact, of copurse, a good client can do quite a lot to
	_represent_ the mail address, with some kind of
	icon and perhaps a list of messages the user has in her
	some mailboxes which were from or to that mail address.
	
	A current implementation (Cello) puts up a window
	for writing messages to the mail address.
	
	Tim

>================================================================
>>From RFC 1341:
>
>   7.3.3.4 The "mail-server" access-type
>
>The "mail-server" access-type indicates that the actual body is
>available from a mail server. The mandatory parameter for this
>access-type is:
>
>  SERVER -- The email address of the mail server
>  from which the actual body data can be obtained.
>
>Because mail servers accept a variety of syntax, some of which is
>multiline, the full command to be sent to a mail server is not
>included as a parameter on the content-type line. Instead, it may be
>provided as the "phantom body" when the content-type is
>message/external-body and the access-type is mail-server.
>
>Note that MIME does not define a mail server syntax.  Rather, it
>allows the inclusion of arbitrary mail server commands in the  
phantom
>body. Implementations should include the phantom body in the body of
>the message it sends to the mail server address to retrieve the
>relevant data.
>
>
>



From wmperry@mango.ucs.indiana.edu  Mon Oct 11 06:42:22 1993 -0500
Message-Id: <23894.750339742@mango.ucs.indiana.edu>
Date: Mon, 11 Oct 1993 06:42:22 -0500
From: wmperry@mango.ucs.indiana.edu (William M. Perry)
Subject: Re: request for new forms submission consensus 

In response to your message dated: Mon, 11 Oct 1993 05:48:22 MST
>Can we come to a consensus on a forms submission method that uses
>HTTP/1.0 to deliver the contents of large forms (including multiline
>edit fields) to smart servers in the next week or two?  (Unless we
>already have and I missed it...)
>
>All things being equal, I think I'd be happy with the current
>encoding method (name=value&name=value with escaping) just slapped
>into the body of an HTTP/1.0 'SUBMIT' request -- keeps things simple
>and straightforward, avoids creating a new syntax, is known to
>properly handle escaping issues, and servers and code already exist
>for decoding/handling it.

  What about issuing a real MIME-message?  multipart/text or something
like that (not a MIME guru, so somthing else might be more
appropriate).  Each variable could have its own 'part'.  Would this be
too much of a pain on the server side?  (Imagine it would)

>To be honest, the idea of encoding it in some kind of SGML format
>does not excite me in the least -- what would be the added value?
>
>Also, I'd like to suggest that multiline text fields have a different
>type (e.g. "textarea") than single-line fields ("text"), as they
>really are different types of things, and imply different issues
>(semantics) for client-side handling.

  Definitely agree with this!  I'm going to have a few hours of coding
ahead of me to add all the forms options you guys put into Mosaic2p5
into my emacs browser.

  Popup lists are great, but as I said in an earlier message, I think
we need to stay away from things like sliders and knobs.

  Looking forward to playing with pre5 when I get to my xterm!

-bill p



From waterbug@epims1.gsfc.nasa.gov  Mon Oct 11 09:19:33 1993 EDT
Message-Id: <9310111319.AA06924@epims1.gsfc.nasa.gov>
Date: Mon, 11 Oct 93 09:19:33 EDT
From: waterbug@epims1.gsfc.nasa.gov (Steve Waterbury)
Subject: Re:request for new forms submission consensus


Marc writes, 

> All things being equal, I think I'd be happy with the current encoding
> method (name=value&name=value with escaping) just slapped into the
> body of an HTTP/1.0 'SUBMIT' request -- keeps things simple and
> straightforward, avoids creating a new syntax, is known to properly
> handle escaping issues, and servers and code already exist for
> decoding/handling it.
> 
> To be honest, the idea of encoding it in some kind of SGML format does
> not excite me in the least -- what would be the added value?

I think that was my reality check I heard.  

I definitely agree with the "KISS" principle espoused here. 
The stuff I was talking about in my previous message about 
composing requests as globs of HTML with non-HTML tags thrown 
in for logical tagging would unnecessarily complicate what is 
right now an elegant and effective protocol, the 'SUBMIT' 
request.  I take it back!

The application I want to make that uses forms to assemble 
structured documents could still be implemented within this 
context by the use of smart servers to handle the stuff 
submitted with the existing SUBMIT protocol (and it makes 
more sense to direct this task to a special server anyway, 
rather than to gum up what is working now).  

(meanwhile, back on Planet of the Data...)

I'm still interested in more reality checks ... on the idea 
of logical tags, "index" servers (basically servers that would 
maintain the indexes for the implicit database that is the 
whole contents of the Web), "meta-data" servers, etc.  Is that 
too much of a traditional database thing, or do some of you 
have applications that need that stuff?  Does the idea of 
putting in non-HTML logical tags (invisible to HTML browsers 
but visible to indexing filters) sound reasonable or does it 
give people the creeps?  

It would have to be decided how the indexes would be maintained:  
my idea is that it would be at the "Web object" author's 
initiative.  E.g., the author could send the URL to the 
indexing server (or a meta-server that knows which index 
servers to contact) for "registration" and indexing.  

Is this an appropriate forum for this topic, or should I 
take this application-oriented noise to c.i.w3?  
(Go ahead, be brutally honest ... I can take it!)

Steve Waterbury.



From timbl@www3.cern.ch  Mon Oct 11 14:08:47 1993 +0100
Message-Id: <9310111308.AA00827@www3.cern.ch>
Date: Mon, 11 Oct 93 14:08:47 +0100
From: timbl@www3.cern.ch (Tim Berners-Lee)
Subject: libwww v2.12: Authorization - aware 



Version 2.12 of the WWW

	Libray,
	LineMode  and
	Daemon
	
is now released, <ftp://info.cern.ch/pub/www/src> as usual.
This contains Ari's access control work, as mentioned in
his earlier message.

There a number of small bug fixes too.
(And the line mode browser knows what screen size it has
at least on ultrix and osf.)

Tim BL



From timbl@www3.cern.ch  Mon Oct 11 14:09:04 1993 +0100
Message-Id: <9310111309.AA00832@www3.cern.ch>
Date: Mon, 11 Oct 93 14:09:04 +0100
From: timbl@www3.cern.ch (Tim Berners-Lee)
Subject: Re: c.i.w3 instead of mailing list



I hope that the www-talk reliability is improved now that we are
exploding on machine which has a newer version of sendmail.
I send out a message asking about duplicates and noone said
they got it twice.

I am very open to puttting up new listserv software, if there is
an accepted secure version.  Suggestions please.  I'm less
inclined to move it to Kansas because of the general disruption,
forwarding of things, etc, though I appreciate the offer.
Whatever we use we will have to add the mail URL document server
to it.

Unfortunately a RARE/EARN guide to network information gave
www-talk-request as somewhere to go for "more information" on WWW!
So Arthur is checking that new subscribers who use that human addess
really want developer chat.

I would suggest that c.i.w should get a ".programmer" subgroup,
but that we keep www-talk for the core developers.  Casual
people dropping in should pass by the newgroups.

I TOTALLY agree with Bill that we need a good annotation system
 and we can dispense with the whole works.  I think we are very
 close.
 

I would also suggest that we create two mailing lists
for the discssion of HTTP and HTML specifically.
This is to keep the discussions focussed, to make it clear to
those who are involved in the discussion of the standards-to-be
that they have got the right forum.  I would see those groups
as being either IETF working groups or the equivalent if the IESG
aren't interested in giving them than name.  They would be  
specifically aimied at getting the specs buttoned down and
discussing implications, interpretations, etc.
Of course, alternatives would be comp.protocols.http and
comp.text.sgml.html, but I think mailing lists would be more
appropriate.


What do you think?

Tim BL



From sanders@bsdi.com  Mon Oct 11 10:53:43 1993 -0500
Message-Id: <9310111553.AA26916@austin.BSDI.COM>
Date: Mon, 11 Oct 1993 10:53:43 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: request for new forms submission consensus 

> All things being equal, I think I'd be happy with the current encoding
> method (name=value&name=value with escaping) just slapped into the
> body of an HTTP/1.0 'SUBMIT' request -- keeps things simple and
> straightforward, avoids creating a new syntax, is known to properly
> handle escaping issues, and servers and code already exist for
> decoding/handling it.
As you know I'm for just using the POST method.  See example below of how
I think this should work.

As you can see I've used a "www" class content-type.  I think that it's
important to allocate a www class for our internal protocol messages.
A content-type of text/plain might have a different affect
(like just sending the owner of the posted to document email, or
maybe making an annotation).

If the form required authentication to submit then the user could edit
the returned URL before the form was processed.

> To be honest, the idea of encoding it in some kind of SGML format does
> not excite me in the least -- what would be the added value?
Agreed.

Example form:
    <FORM ACTION="http://www.bsdi.com/hyplan/sanders.html">
    <INPUT NAME="name">
    </FORM>

Client:
    POST /hyplan/sanders.html HTTP/1.0
    Content-Length: 13
    MIME-Version: 1.0
    Content-type: www/form

    name=testing

Server:
    HTTP/1.0 201 URI follows
    Last-modified: Sunday, 03-Oct-93 19:32:54 GMT
    Date: Sunday, 03-Oct-93 19:37:52 GMT
    Server: plexus/3.0i
    Location: http://www.bsdi.com/forms/form000023.form
    MIME-Version: 1.0
    Content-type: text/html

    <TITLE>Posted</TITLE>
    <A HREF="http://www.bsdi.com/forms/form000023.form">Retrieve
    to lock and edit</A>



From hotsand!rhb  Mon Oct 11 13:27:30 1993 EDT
Message-Id: <9310111727.AA19149@hotsand.dacsand>
Date: Mon, 11 Oct 93 13:27:30 EDT
From: hotsand!rhb (Rich Brandwein)
Subject: Re: News vs. Mail


I like keeping the mailing list.  I'm using procmail to sort
out my mail based on FROM/TO and the mlist2html from Markus Stumpf
to automatically convert the mail to html lists.  Works like
a charm in generating a news-like service running under 
WWW (it's seems better than a usenet news list, since it seems many
people around here don't have proper access to our local NNTP server).

What would really be nice is a response mechanism from within Mosaic
and Lynx... (if you ask enough, it will come...).

Rich 

---
Rich Brandwein
rich.brandwein@att.com



From wei@sting.berkeley.edu  Mon Oct 11 10:48:57 1993 -0700
Message-Id: <9310111748.AA12632@sting.Berkeley.EDU>
Date: Mon, 11 Oct 93 10:48:57 -0700
From: wei@sting.berkeley.edu (Pei Y. Wei)
Subject: Re: request for new forms submission consensus

One more vote for using POST. Just as long as we're not munging the 
data onto a one liner URL. 

Yes, using SGML for this seems fairly non useful, but using MIME as 
wrappers can still be useful in the long run. I just think that not
too long from now one of those forms will be "type=audio" :), and when
that happens we'll start to wish we had started with a system with
smarter data block delimeters (ie MIME? don't know MIME too well myself),
rather than having to (again) escape the whole data block.

But a part of me also says to just get this going, and leave MIME 
out for now.

-Pei



From sanders@bsdi.com  Mon Oct 11 13:27:49 1993 -0500
Message-Id: <9310111827.AA27717@austin.BSDI.COM>
Date: Mon, 11 Oct 1993 13:27:49 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: request for new forms submission consensus 

[on forms submission]
> too long from now one of those forms will be "type=audio" :), and when
Very good point.  I second the vote to use MIME encodings.  However, this
doesn't preclude using the encoding we have now under POST with a simple
MIME header.  Then we can easily move to more complex forms like
multipart/mixed (example below).

A simple form example:
    POST /hyplan/sanders.html HTTP/1.0
    MIME-Version: 1.0
    Content-type: application/x-www-textform

    name=test&address=data

A complex example (with an audio part):
    POST /hyplan/sanders.html HTTP/1.0
    MIME-Version: 1.0
    Content-type: multipart/mixed; boundary="unique string"

    --unique string
    Content-Type: application/x-www-textform

    name=test&address=data
    --unique string
    Content-Type: audio/basic
    Content-Transfer-Encoding: BASE64

    SDFLKjfllkjLKJhJHhjGjHGjHSJfhLSKDJFHjsdhfkJSDHFKSJH
    --unique string--

--sanders



From kevin@scic.intel.com  Mon Oct 11 12:33:45 1993 -0800
Message-Id: <9310111937.AA18283@rs042.scic.intel.com>
Date: Mon, 11 Oct 1993 12:33:45 -0800
From: kevin@scic.intel.com (Kevin Altis)
Subject: Re: request for new forms submission consensus

At  1:27 PM 10/11/93 -0500, Tony Sanders wrote:
>[on forms submission]
>> too long from now one of those forms will be "type=audio" :), and when
>Very good point.  I second the vote to use MIME encodings.  However, this
>doesn't preclude using the encoding we have now under POST with a simple
>MIME header.  Then we can easily move to more complex forms like
>multipart/mixed (example below).

I "third" the vote for MIME encodings, I think we will we in great shape
for the future. Not only can we do complex types such as audio, video...
but we can also do complex encodings, including encryption when standards
become available. The current MIME standard explicitly forbids use of
encodings other than 7bit, 8bit, or binary with content types that
recursively include other content-type fields (multipart and message); I
think Tony's example was illegal. However, a multi-part query could be sent
which includes some encrypted content-types within a multi-part message.
Multi-part messages should also clean up requests so we don't get a lot of
gopher looking strings between the client and server. Did I just go off the
deep end and lose everyone or is the text above clear?! MIME experts please
speak up.

ka




From strick@osc.versant.com  Mon Oct 11 13:15:51 1993 PDT
Message-Id: <9310112015.AA29513@osc.versant.com>
Date: Mon, 11 Oct 93 13:15:51 PDT
From: strick@osc.versant.com (henry strickland)
Subject: Re: request for new forms submission consensus

# I "third" the vote for MIME encodings, I think we will we in great shape
# for the future. Not only can we do complex types such as audio, video...
# but we can also do complex encodings, including encryption when standards
# become available. 

MIME has thought about all these issues and come up with
*practical* approaches to them.  WWW should use MIME whenever possible,
even when other approaches are "better" from some points of view.

MIME has a lot of experience behind it in Andrew, which had 
lots of hypertextish (www-ish) aspects.  And the internet future
is MIME.

It should not be hard to find an extensible way to embed MIME
in HTML and HTML in MIME.  Notice MIME documents can already 
have anchor-names in them (Content-Id:), references to
external documents, etc.
  
					strick
					strick@versant.com



From sanders@bsdi.com  Mon Oct 11 15:21:54 1993 -0500
Message-Id: <9310112021.AA28466@austin.BSDI.COM>
Date: Mon, 11 Oct 1993 15:21:54 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: request for new forms submission consensus 

> become available. The current MIME standard explicitly forbids use of
> encodings other than 7bit, 8bit, or binary with content types that
> recursively include other content-type fields (multipart and message); I
> think Tony's example was illegal. However, a multi-part query could be sent
My example was not illegal, it's practically identical to examples in
RFC1521.  You can't use content-transfer-encoding: on the multipart itself,
that doesn't mean the other content type's inside can't use it (in fact
they must).

--sanders




From marca@ncsa.uiuc.edu  Mon Oct 11 16:39:22 1993 -0700
Message-Id: <9310112339.AA17542@wintermute.ncsa.uiuc.edu>
Date: Mon, 11 Oct 93 16:39:22 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Re: request for new forms submission consensus 

Tony Sanders writes:
> > All things being equal, I think I'd be happy with the current encoding
> > method (name=value&name=value with escaping) just slapped into the
> > body of an HTTP/1.0 'SUBMIT' request -- keeps things simple and
> > straightforward, avoids creating a new syntax, is known to properly
> > handle escaping issues, and servers and code already exist for
> > decoding/handling it.
> As you know I'm for just using the POST method.  See example below of how
> I think this should work.
> 
> As you can see I've used a "www" class content-type.  I think that it's
> important to allocate a www class for our internal protocol messages.
> A content-type of text/plain might have a different affect
> (like just sending the owner of the posted to document email, or
> maybe making an annotation).
> 
> If the form required authentication to submit then the user could edit
> the returned URL before the form was processed.
> 
> > To be honest, the idea of encoding it in some kind of SGML format does
> > not excite me in the least -- what would be the added value?
> Agreed.
> 
> Example form:
>     <FORM ACTION="http://www.bsdi.com/hyplan/sanders.html">

How about, then, <FORM ACTION="POST http://www.bsdi.com/hyplan/sanders.html">
in this case?  That meshes with the consensus we came to a while back
about using the URL encoding method only as a stopgap and adding
methods to the ACTION attribute in the future.  (Or, would be fine
with me to use a different attribute also -- whichever.)

>     <INPUT NAME="name">
>     </FORM>
> 
> Client:
>     POST /hyplan/sanders.html HTTP/1.0
>     Content-Length: 13
>     MIME-Version: 1.0
>     Content-type: www/form
> 
>     name=testing

Looks good, except -- is Content-Length to be required?  (And if so, why?)

> Server:
>     HTTP/1.0 201 URI follows
>     Last-modified: Sunday, 03-Oct-93 19:32:54 GMT
>     Date: Sunday, 03-Oct-93 19:37:52 GMT
>     Server: plexus/3.0i
>     Location: http://www.bsdi.com/forms/form000023.form
>     MIME-Version: 1.0
>     Content-type: text/html
> 
>     <TITLE>Posted</TITLE>
>     <A HREF="http://www.bsdi.com/forms/form000023.form">Retrieve
>     to lock and edit</A>

Cheers,
Marc



From robm@ncsa.uiuc.edu  Mon Oct 11 16:55:28 1993 -0500
Message-Id: <9310112155.AA01050@void.ncsa.uiuc.edu>
Date: Mon, 11 Oct 1993 16:55:28 -0500
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: One more time, NCSA httpd 1.0a3.2



Apparently, there were other bugs with the include files in 1.0a3.1, and
also the symlinks for files had a stupid copy-and-paste problem in it.

So, NCSA httpd 1.0a3.2 is released, docs at http://hoohoo.ncsa.uiuc.edu/

Also, in this release, I have made a bin directory on ftp.ncsa.uiuc.edu in
/Web/ncsa_httpd/httpd-1.0a3.2 which contains just binaries for those of you
who have already done a previous installation, and a tar file containing
just the src directory for those who have installed but maintain their own
source.

Thanks for your patience with this release. When I patched the init_mime bug
in 1.0a2 I should have patched 1.0a2, but instead decided to use the version
I was currently working on, which had all of these untested bugs.

Sorry for all confusion. It won't happen again.

--Rob



From sanders@bsdi.com  Mon Oct 11 16:59:06 1993 -0500
Message-Id: <9310112159.AA29016@austin.BSDI.COM>
Date: Mon, 11 Oct 1993 16:59:06 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: request for new forms submission consensus 

> How about, then, <FORM ACTION="POST http://www.bsdi.com/hyplan/sanders.html">
I would just say that forms always get POST'ed, why would you ever need
some other method?

> >     Content-Length: 13
> Looks good, except -- is Content-Length to be required?  (And if so, why?)
Because you need to know where the end of the message is, the client can't
close the connection until it gets back a reply.  You either need a
Content-Length: or you can use a message boundary by encoding a multipart:

    POST /hyplan/sanders.html HTTP/1.0
    MIME-Version: 1.0
    Content-type: multipart/mixed; boundary="somestring"

    --somestring
    Content-type: application/x-www-textform

    name=testing
    --somestring--

--sanders



From marca@ncsa.uiuc.edu  Mon Oct 11 17:36:25 1993 -0700
Message-Id: <9310120036.AA17731@wintermute.ncsa.uiuc.edu>
Date: Mon, 11 Oct 93 17:36:25 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Re: request for new forms submission consensus 

Tony Sanders writes:
> > How about, then, <FORM ACTION="POST http://www.bsdi.com/hyplan/sanders.html">
> I would just say that forms always get POST'ed, why would you ever need
> some other method?

Because it offers flexibility -- slapping query information into the
URL is simple and will often be useful and easier to prototype for.

> > >     Content-Length: 13
> > Looks good, except -- is Content-Length to be required?  (And if so, why?)
> Because you need to know where the end of the message is, the client
> can't close the connection until it gets back a reply.  You either
> need a Content-Length: or you can use a message boundary by encoding
> a multipart:

Duh.  I'm apparently dropping IQ points left and right...

Marc



From janssen@parc.xerox.com  Mon Oct 11 17:40:41 1993 PDT
Message-Id: <UgiTo9UB0KGW5Dk78n@holmes.parc.xerox.com>
Date: Mon, 11 Oct 1993 17:40:41 PDT
From: janssen@parc.xerox.com (Bill Janssen)
Subject: Re: request for new forms submission consensus

Excerpts from ext.WorldWideWeb: 11-Oct-93 Re: request for new forms s..
henry strickland@osc.ver (824)

> MIME has thought about all these issues and come up with
> *practical* approaches to them.  WWW should use MIME whenever possible,
> even when other approaches are "better" from some points of view.

> MIME has a lot of experience behind it in Andrew, which had 
> lots of hypertextish (www-ish) aspects.  And the internet future
> is MIME.

> It should not be hard to find an extensible way to embed MIME
> in HTML and HTML in MIME.  Notice MIME documents can already 
> have anchor-names in them (Content-Id:), references to
> external documents, etc.

Some things are being confused here, I think.  MIME does not define a
document format, or reflect the experience with the Andrew Toolkit's
(then, ATK; now called AUIS) support for `embedding' in data formats,
particularly in their text format.  Some of us on the MIME list thought
about using MIME and mail headers to form a document format, and it
never came to much.  What MIME provides is a stylized, uniform way of
indicating the format of a mail message; this may also be useful for
specifying the format of a document.  Yes, the multipart has
"Content-Id", but so do many things.  Compound document formats
typically require more powerful infrastructure.

ATK had very little in the form of hypertextish objects; just the
"link", so far as I can remember.  A lot of multimedia aspects, though.

Embedding HTML in MIME should be easy, sure, as it amounts to just putting

	Content-Type:  application/html

in a header, before the actual HTML document.  But embedding MIME in
HTML sounds like a type mismatch.  You might be able to use the MIME
registered types in some fashion in HTML; perhaps that's what you meant.

Bill



From janssen@parc.xerox.com  Mon Oct 11 19:36:02 1993 PDT
Message-Id: <EgiVUGoB0KGW5Dk=Ne@holmes.parc.xerox.com>
Date: Mon, 11 Oct 1993 19:36:02 PDT
From: janssen@parc.xerox.com (Bill Janssen)
Subject: Re: request for new forms submission consensus

Excerpts from ext.WorldWideWeb: 11-Oct-93 Re: request for new forms s..
Bill Janssen@parc.xerox. (1790)

> Some of us on the MIME list thought
> about using MIME and mail headers to form a document format, and it
> never came to much.

Though it seems to be developing again on comp.mail.mime...

Bill



From marca@ncsa.uiuc.edu  Mon Oct 11 21:48:14 1993 -0700
Message-Id: <9310120448.AA18431@wintermute.ncsa.uiuc.edu>
Date: Mon, 11 Oct 93 21:48:14 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Sun networking question

Anyone know if there's any reason *not* to always link a Sun
executable that uses networking to libresolv.a?

Marc



From mcarthur@fit.qut.edu.au  Tue Oct 12 12:50:31 1993 EST
Message-Id: <199310120250.WAA11837@sleet.fit.qut.edu.au>
Date: Tue, 12 Oct 93 12:50:31 EST
From: mcarthur@fit.qut.edu.au (Mr Robert McArthur)
Subject: HTML+ compliant browsers?

Hi,
As the subject asks, which browsers comply with the HTML+ (12 July 1993)
document?  I take it that this "standard" is in the process of refinement
given the recent discussion.  At what stage do the changes become shoes-
fit-for-walking-at-the-bottom-of-the-river (if ever ;-)?

Thanx
Robert



From marca@ncsa.uiuc.edu  Mon Oct 11 22:21:47 1993 -0700
Message-Id: <9310120521.AA18515@wintermute.ncsa.uiuc.edu>
Date: Mon, 11 Oct 93 22:21:47 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: mosaic pre6 coming soon, and more forms stuff

pre6 will be released shortly, as (thanks to many users, particularly
frans van hoesel) I have discovered one really stupid bug and some
others that are hitting a lot of people.

Since pre5, Eric has implemented scrolled lists and multiline text
fields for fill-out forms forms.  I have promised him that no one
would use multiline text fields until we have a real submission method
(which we now have, I think, from the recent discussion).  But we
should settle on the syntax for them (and for scrolled lists) ASAP...

As I noted last night (and Bill Perry, at least, agreed), I think
multiline texts fields should have a different name than single-line
text fields.  Is "textarea" OK?  Also, we have three choices for
declaring the size of a "textarea":

    o SIZE="32x4" as in the original spec
    o SIZE="32,4" to fit in a little better with other things
    o COLUMNS=32 ROWS=4 for extreme cleanliness (which is what we
      currently have)

Dave R, your final judgment please?  :-)

Anyone object to type LIST for (possibly scrolled) lists?  Same basic
behavior as OPTION but more than one option is visible at a time (the
number visible can be set by the SIZE attribute); same OPTIONS
argument (comma-separated list of options).

Cheers,
Marc



From sanders@bsdi.com  Mon Oct 11 23:06:31 1993 -0500
Message-Id: <9310120406.AA03604@austin.BSDI.COM>
Date: Mon, 11 Oct 1993 23:06:31 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: mosaic pre6 coming soon, and more forms stuff 

> fields for fill-out forms forms.  I have promised him that no one
> would use multiline text fields until we have a real submission method
> (which we now have, I think, from the recent discussion).  But we
One issue is what to call the content...  I vote we use:
    application/x-www-form-simple	for the current encoding style
    multipart/mixed			for complex forms (e.g., audio)

If we put the string in the message body (application/x-www-form-simple)
and treat it as binary it shouldn't matter how long the line is like it
does for the URL part.  MIME will take care of the rest (e.g., if it
needs to go through a mail gateway it could get encoded as BASE64).
BTW: I vote we start explicitly using:
    Content-Transfer-Encoding: BINARY
In the HTTP/1.0 protocol.  This will make it easier on mail based
transports to do the right thing.

multipart/mixed we can worry about later.

--sanders



From timbl@www3.cern.ch  Tue Oct 12 09:49:39 1993 +0100
Message-Id: <9310120849.AA01289@www3.cern.ch>
Date: Tue, 12 Oct 93 09:49:39 +0100
From: timbl@www3.cern.ch (Tim Berners-Lee)
Subject: HTTP mods: Variants, Derived-From:



I have changed
<http://info.cern.ch/hypertext/WWW/Protocols/HTTP/Object_Headers.html> 
in two ways.  One is to merge the live-uri: and version-uri: fields
into one uri: field with a "vary=" parameter to speecify the  
granularity of the URI in
question, as I proposed on the list a week of so ago, with no  
objections.

I have added the obvious "Version:" field for symetry with
Content-Type: and Language: which are all now variant specifiers.
I have also added "Derived from" which is necessary to keep
track of parallel modifications a la CVS/RCS/SCCS/CMS etc.

I append some cut and splurdge from the spec.

Tim Berners-Lee


______________________________________________________________

This gives a URI with which the object may be found.  There is no  
guarantee that the object can be retrieved using the URI specified.  
However, it is guaranteed that if an object is successfully retrieved  
using that URI it will be to a certain given degree the same object  
as this one. 



If the URI is used to refer to a set of variants, then the dimensiosn  
in which the variants may differ must be given with the "vary"  
parameter:

	Syntax		URI: <uri>  [ vary = dimension [ , dimension  
]* ]
	dimension	content-type | language | version


If no "vary" parameters are given, then the URI may not return  
anything other than the same bit stream as this object.

Multiple occurencies of this field give alternative access names or  
addresses for the object.

Examples

		URI:  http://info.cern.ch/pub/www/doc/url6.multi   
vary=content-type

This indicates that retrieval given the URI will return the same  
document, never an updated version, but optionally in a different  
rendition.

		URI:  http://info.cern.ch/pub/www/doc/url.multi
		    vary=content-type, language, version

This indicates that the URI will return the smae document, possibly  
in a different rendition, possibly updated, and without excluding the  
provision of translations into different languages.

		URI:  http://info.cern.ch/pub/www/doc/url6.ps   
vary=content-type

This indicates that accessing the URI in question will return exactly  
the same bitstream.

______________________________________________________________[...]

Version:
	This is a string defining the version of an evolving object.  
Its format is currently undefined, and so it should be treated as  
opaque to the reader, defined by the informatiuon provider.  The  
version field is used to indicate evolution along a single path of a  
partucular work.  It is NOT used to indicate derived works (use a  
link), translations, or renditions in different representations.

Note: It would be useful to have sufficient  semantics to be able to  
deduce whether one version predated or postdated another.  However,  
it may also be useful to be able to insert a particular local code  
management system's own version stamp in this field.  Typically,  
publishers will have quite complex version information containing  
hidden local semantics, giving value to the idea of this field being  
opaque to other readers ofthe document.

Derived-From:
When an editied object is resubmitted using PUT for example, this  
field gives the value of the Version . This typically allows a server  
to check for example that two concurrent modifications by different  
parties will not be lost, and for example to use established version  
management techniques to merge both modifications.



From dsr@hplb.hpl.hp.com  Tue Oct 12 13:18:16 1993 BST
Message-Id: <9310121218.AA27649@manuel.hpl.hp.com>
Date: Tue, 12 Oct 93 13:18:16 BST
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: request for new forms submission consensus

Here are my (current) views on forms. I have nearly finished the new
draft for HTML+ but will revise the forms stuff to match recent events.

First as a general principle, I feel we want to avoid presentation specific
stuff as much as possible. I would prefer to keep the number of attributes
down, but detect that other people don't feel the same way. So learning
from history :-)

Range controls: e.g. <INPUT NAME="f1" TYPE=range MIN=10 MAX=100>

    These offer the user a choice between the lower and upper values
    and can be rendered in various ways: sliders, spin buttons, and
    direct entry of the number. Initially restricted to integer ranges.

Multiline text fields: e.g.<INPUT NAME="f2" TYPE=text COLUMNS=32 ROWS=4>

    I am not convinced this needs a distinct name from TYPE=text, since
    the presence of the ROWS attribute is clear enough!

Password fields: e.g. <INPUT NAME="f3" TYPE=password>

    Like TYPE=text but not echoed to the screen.

Image fields: e.g. <INPUT NAME="f4" TYPE=image SRC="map.gif" ALIGN=middle>

    These allow users to click on an image/icon within the form. The
    x and y coords of the event are included with the other fields
    only when the image is clicked.  Compound names are used to specify
    the coords as parameters to the field, e.g. f4.x=12&f4.y=17
    This paves the way to more complex objects with multiple parameters.

Option lists:

    These are already supported via TYPE=checkbox and TYPE=radio
    which support multi and single selection lists respectively.

These field types force the author to list each option as part of
an HTML list. The browser can't do anything clever like drop-down
scrollable combo-boxes. I felt this was quite reasonable as it fits
well with paper forms and simple text-only terminals. Everyone will
find them easy to use!

NCSA propose a TYPE=options field with the list as an attribute value:

 <INPUT TYPE="option" NAME="what-to-do" OPTIONS="Drink Coffee,
     Read A Book, Take A Walk, Buy A Bagel, Watch TV" VALUE="Read A Book">

This design leads to arbitrarily long attribute values, which is bad SGML,
and could break some parsers. I recommend instead, the SELECT tag as in:

    <SELECT NAME="what-to-do">
        <LI>Read A Book
        <LI>Take A Walk
        <LI>Buy A Bagel
        <LI>Watch TV
    </SELECT>

You use <SELECT SEVERAL NAME="what-to-do"> if several selections are possible
simultaneously.

TYPE=submit and TYPE=reset
==========================

It seems to me that this is a kludge, and that it would be much better to
leave it up to the browser and platform specific form conventions. For most
systems, the browser should show Submit and Reset buttons automatically at
the end of the form. For a form with a single text input field, the browser
can omit these buttons and assume use of the "Enter" key instead. This
doesn't cost much since by the time the browser reaches the </FORM> tag it
already knows what fields there are in the form.

Transfer formats
================

For simple implementations the URL?name=value&name=value&... scheme is fine.
But in the near future we will want fields that can accept scribble (e.g.
hand-written signatures) and voice input. MIME multipart messages seem like
the right way to go:

    MIME-Version: 1.0
    Content-Type: multipart/mixed;
        boundary=unique-boundary-1

    --unique-boundary-1
    Content-Type: application/html-form

    name: value
    name: value
    name: @part-name
    --unique-boundary-1
    Content-Type: audio/basic
    Content-Transfer-Encoding: Base64
    Part-Name: part-name

    ... the encoded audio data goes here
    --unique-boundary-1--

The above uses the new MIME content type "application/html-form" to
transfer the basic form data as one or more lines each of which
has one of the following formats:

    a)    field-name: field-value

    b)    field-name: @part-name

The second one specifies the field's value indirectly as a named MIME
message part. This allows us to use the normal MIME mechanisms for
different data types, in this case audio/basic with base64 encoding.
The header "Part-Name:" should be used to declare the name of each
part in a multipart message.

I am worried about using % followed by the hexadecimal code as a means
of escaping significant characters in attribute values. It seems to
closely linked to using 7 or 8 bit US ASCII. What should we use instead?

Comments please as soon as possible so that I can get the draft out.

Dave Raggett



From dsr@hplb.hpl.hp.com  Tue Oct 12 16:01:53 1993 BST
Message-Id: <9310121501.AA28753@manuel.hpl.hp.com>
Date: Tue, 12 Oct 93 16:01:53 BST
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: comments on input form

Pei Wei writes:

> I'd suggest adding ID/NAME to these <LI>'s so it will not be
> necessary to have to use list data to identify the selection. 
> But as convention, browsers may still simply use the list content 
> if no NAMEs are specified.

> The point is to be able to do something like this, where you 
> want to get back a simple selection identifier (ie "coke"), and not
> the actual whatever is marked in the list:

>    <SELECT NAME="directions">
>        <LI NAME="7up"><ICON SRC="7up">Seven Up.
>        <LI NAME="coke"><ICON SRC="coke">Coke Cola
>    </SELECT>

I omitted the details in my message, but assumed it would work in the same
way as other INPUT fields. That is the NAME attribute for the SELECT element
applies to the list items, and that these need a VALUE attribute, e.g.

        <SELECT NAME="directions">
            <LI VALUE="7up" CHECKED SRC="7up.gif">
            <LI VALUE="coke" SRC="coke.gif">
        </SELECT>

This also shows how the CHECKED attribute can be used to set the initial
selection(s), and the use of the SRC attribute for iconic list items. The
latter is borrowed from the use of LI with bulleted lists, where you can
substitute an icon for a bullet symbol.

Dave



From davis@dri.cornell.edu  Tue Oct 12 11:30:32 1993 -0400
Message-Id: <199310121530.AA08847@willow.tc.cornell.edu>
Date: Tue, 12 Oct 1993 11:30:32 -0400
From: davis@dri.cornell.edu (Jim Davis)
Subject: Re: request for new forms submission consensus


I agree with nearly everything Dave Raggett suggests.

But I suggest we can dispense with the PASSWORD type.  Instead
add (for all types) an attribute ECHO which defaults to TRUE.
Then a password is just:

<INPUT TYPE=text ECHO=false>

This would thus also allow e.g. numeric entry with no echo.
Why would you want that?  Well, it's far-fetched I suppose, but
you might use HTML forms as part of a game playing interface.

It occurs to me that one might also like a way to instruct the 
client to not send certain field in cleartext, but I don't
think that was the rationale for PASSWORD, and in any case
that's not the right place to put that piece of function; not
the least reason being that many other types of fields might
require just as much encryption.

best wishes



From dsr@hplb.hpl.hp.com  Tue Oct 12 17:01:55 1993 BST
Message-Id: <9310121601.AA28850@manuel.hpl.hp.com>
Date: Tue, 12 Oct 93 17:01:55 BST
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: request for new forms submission consensus

Frans van Hoesel has pointed out the value in being able to
use a checkbox or an icon or whatever to submit forms. In 
a tax return there might be a load of questions that become
irrelevant when you click the checkbox to indicate that you
are "single". In this case the form would be submitted and
the server would then return it with the irrelevant questions
greyed-out:

        Single? <INPUT NAME="single" TYPE=checkbox SUBMIT>

The idea here is to make SUBMIT an independent attribute
that can be used with arbitrary field types. You could
have multiple "submit buttons" in the same form. This way
authors can choose whether the form contents gets checked
after each field on a per field basis.

How about it?

-- Dave



From kevin@scic.intel.com  Tue Oct 12 09:34:11 1993 -0800
Message-Id: <9310121637.AA12860@rs042.scic.intel.com>
Date: Tue, 12 Oct 1993 09:34:11 -0800
From: kevin@scic.intel.com (Kevin Altis)
Subject: Re: mosaic pre6 coming soon, and more forms stuff

At 10:21 PM 10/11/93 -0700, Marc Andreessen wrote:
>As I noted last night (and Bill Perry, at least, agreed), I think
>multiline texts fields should have a different name than single-line
>text fields.  Is "textarea" OK?  Also, we have three choices for
>declaring the size of a "textarea":
>
>    o SIZE="32x4" as in the original spec
>    o SIZE="32,4" to fit in a little better with other things
>    o COLUMNS=32 ROWS=4 for extreme cleanliness (which is what we
>      currently have)

What I don't understand, is why you have to specify the column and row size
at all? Are the row and column attributes simply to tell the client what
size box to create for text entry? Is the multiline text field only going
to apply to text entry of a particular line length? It seems like we should
just have a textblock entry where the user can enter an arbitrary amount of
text and the widget will handle text wrapping and scrolling.

ka




From kevin@scic.intel.com  Tue Oct 12 10:43:23 1993 -0800
Message-Id: <9310121747.AA19301@rs042.scic.intel.com>
Date: Tue, 12 Oct 1993 10:43:23 -0800
From: kevin@scic.intel.com (Kevin Altis)
Subject: Re: request for new forms submission consensus

At  1:18 PM 10/12/93 +0100, Dave_Raggett wrote:
>Range controls: e.g. <INPUT NAME="f1" TYPE=range MIN=10 MAX=100>
>
>    These offer the user a choice between the lower and upper values
>    and can be rendered in various ways: sliders, spin buttons, and
>    direct entry of the number. Initially restricted to integer ranges.

The range control above will cover sliders, but a "knob" control doesn't
necessarily have continuous steps. For example, the range may be 10 to 100,
but the steps are by 10, not 1, as the control above suggests. We can take
care of that by adding "STEP=number" to the syntax above. Also, some ranges
and steps won't be integers or even numbers ("A", "B", "C"...); does
"range" have to work with just integers?

>Multiline text fields: e.g.<INPUT NAME="f2" TYPE=text COLUMNS=32 ROWS=4>
>
>    I am not convinced this needs a distinct name from TYPE=text, since
>    the presence of the ROWS attribute is clear enough!
>
>Password fields: e.g. <INPUT NAME="f3" TYPE=password>
>
>    Like TYPE=text but not echoed to the screen.

Just as an interface point. We already have the problem of "focus" in
XMosaic, where depending on configuration, if the user doesn't have the
pointer over a field, their keystrokes don't go into the field. I forsee
many X people thinking they're typing in their password, only to find out
they entered nothing. This is not a problem for the Mac or Windows or
character based displays since those interfaces have no concept of focus.

>Image fields: e.g. <INPUT NAME="f4" TYPE=image SRC="map.gif" ALIGN=middle>
>
>    These allow users to click on an image/icon within the form. The
>    x and y coords of the event are included with the other fields
>    only when the image is clicked.  Compound names are used to specify
>    the coords as parameters to the field, e.g. f4.x=12&f4.y=17
>    This paves the way to more complex objects with multiple parameters.

So the coordinates will be integers with "0,0" at the bottom left of the
image/icon? What happened to mapping all coordinates to 0-1?

>Option lists:
>
>    These are already supported via TYPE=checkbox and TYPE=radio
>    which support multi and single selection lists respectively.
>
>These field types force the author to list each option as part of
>an HTML list. The browser can't do anything clever like drop-down
>scrollable combo-boxes. I felt this was quite reasonable as it fits
>well with paper forms and simple text-only terminals. Everyone will
>find them easy to use!

Will people be able to embed the INPUT lists and other INPUT elements
within tables or any other multi-column or compact setup? Though we have
many of the elements of traditional forms, HTML+ forms don't currently
allow for a compact display, so a single page converted paper form often
takes two or three pages. I believe this is an important issue since the
user of various forms might spend quite a bit of time scrolling (or jumping
via hypertext) back and forth between FORM elements in order to see various
INPUT elements.

>I am worried about using % followed by the hexadecimal code as a means
>of escaping significant characters in attribute values. It seems to
>closely linked to using 7 or 8 bit US ASCII. What should we use instead?

I don't suppose anyone wants to make explicit support for 16-bit
characters, maybe UNICODE? UNICODE is biased towards European languages
(according to my Japanese friends) but I don't think we have enough people
on this list (if any) versed in Hebrew, Arabic, Kanji, etc. to give us
direction. OS vendors are quickly adopting UNICODE as their standard (some
products already use UNICODE internally for everything), we at least need
to think about it, if we want HTML+ to be truly international.

ka




From dcmartin@library.ucsf.edu  Tue Oct 12 10:52:07 1993 PDT
Message-Id: <199310121756.AA25305@library.ucsf.edu>
Date: Tue, 12 Oct 1993 10:52:07 PDT
From: dcmartin@library.ucsf.edu (David C. Martin)
Subject: Re: request for new forms submission consensus 

Completely agree!  But eventually I want to see local processing of
actions from the user (e.g. indicating zipcode and getting state
defaulted correctly :-)  We need to start discussing the ability to
download a script to accompany the document, e.g. in a stripped down TCL
with TCL hooks into client (e.g. Mosaic) functionality for making the
buttons, scrollbars, etc... *do* something interesting at the local machine.

dcm
--------
Dave_Raggett writes:

Frans van Hoesel has pointed out the value in being able to
use a checkbox or an icon or whatever to submit forms. In 
a tax return there might be a load of questions that become
irrelevant when you click the checkbox to indicate that you
are "single". In this case the form would be submitted and
the server would then return it with the irrelevant questions
greyed-out:

Single? <INPUT NAME="single" TYPE=checkbox SUBMIT>

The idea here is to make SUBMIT an independent attribute
that can be used with arbitrary field types. You could
have multiple "submit buttons" in the same form. This way
authors can choose whether the form contents gets checked
after each field on a per field basis.

How about it?

-- Dave



From moore@cs.utk.edu  Tue Oct 12 14:03:28 1993 -0400
Message-Id: <9310121803.AA27829@thud.cs.utk.edu>
Date: Tue, 12 Oct 1993 14:03:28 -0400
From: moore@cs.utk.edu (Keith Moore)
Subject: Content-length header (was Re: request for new forms...)

Tony Sanders writes...

> As you know I'm for just using the POST method.  See example below of how
> I think this should work.
[...]
> 
> Example form:
>     <FORM ACTION="http://www.bsdi.com/hyplan/sanders.html">
>     <INPUT NAME="name">
>     </FORM>
> 
> Client:
>     POST /hyplan/sanders.html HTTP/1.0
>     Content-Length: 13
>     MIME-Version: 1.0
>     Content-type: www/form

[...]

I know HTTP isn't SMTP, but I feel compelled to point out that the
Content-Length header is not blessed by any standard.  In fact, there is no
definition.  The MIME working group explicitly decided NOT to include such a
header in MIME, because it could not be made to work correctly over the
variety of mail transports in existance.

(The current popular use of Content-Length in RFC 822 based email is both
nonstandard and hazardous.  At best it is useless information.)

You could call this use of Content-Length a part of the HTTP protocol, but I
believe it will confuse the issue to use Content-Length in this manner.  It
looks too much like a email header, and I fear this usage will only add to
the confusion.

Keith



From sanders@bsdi.com  Tue Oct 12 13:18:00 1993 -0500
Message-Id: <9310121818.AA06256@austin.BSDI.COM>
Date: Tue, 12 Oct 1993 13:18:00 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: Content-length header (was Re: request for new forms...) 

> I know HTTP isn't SMTP, but I feel compelled to point out that the
> Content-Length header is not blessed by any standard.
It is in the HTTP standard, which explictly requires a full "BINARY"
transport system.  Mail based transports will have to encode/decode
BASE64 on either end.

> In fact, there is no
> definition.  The MIME working group explicitly decided NOT to include such a
> header in MIME, because it could not be made to work correctly over the
> variety of mail transports in existance.
That's a stupid reason (restrict the software because current systems are
broken), but it still doesn't affect HTTP.

--sanders



From marca@ncsa.uiuc.edu  Tue Oct 12 13:15:56 1993 -0700
Message-Id: <9310122015.AA19919@wintermute.ncsa.uiuc.edu>
Date: Tue, 12 Oct 93 13:15:56 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Re: mosaic pre6 coming soon, and more forms stuff

Kevin Altis writes:
> At 10:21 PM 10/11/93 -0700, Marc Andreessen wrote:
> >As I noted last night (and Bill Perry, at least, agreed), I think
> >multiline texts fields should have a different name than single-line
> >text fields.  Is "textarea" OK?  Also, we have three choices for
> >declaring the size of a "textarea":
> >
> >    o SIZE="32x4" as in the original spec
> >    o SIZE="32,4" to fit in a little better with other things
> >    o COLUMNS=32 ROWS=4 for extreme cleanliness (which is what we
> >      currently have)
> 
> What I don't understand, is why you have to specify the column and row size
> at all? Are the row and column attributes simply to tell the client what
> size box to create for text entry? Is the multiline text field only going
> to apply to text entry of a particular line length? It seems like we should
> just have a textblock entry where the user can enter an arbitrary amount of
> text and the widget will handle text wrapping and scrolling.

The client needs to have an indication as to how big to make the entry
area on the display (text or GUI).  This need not restrict the amount
of text that the user can actually enter -- I'd expect scrolling to be
available.

Marc



From marca@ncsa.uiuc.edu  Tue Oct 12 13:32:43 1993 -0700
Message-Id: <9310122032.AA20050@wintermute.ncsa.uiuc.edu>
Date: Tue, 12 Oct 93 13:32:43 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Re: request for new forms submission consensus 

David C. Martin writes:
> Completely agree!  But eventually I want to see local processing of
> actions from the user (e.g. indicating zipcode and getting state
> defaulted correctly :-) We need to start discussing the ability to
> download a script to accompany the document, e.g. in a stripped down
> TCL with TCL hooks into client (e.g. Mosaic) functionality for
> making the buttons, scrollbars, etc... *do* something interesting at
> the local machine.

Too much (and, in any case, too soon).  I feel like reposting my
"kitchen sink" speech -- we are not creating an actual full-featured
user interface builder (or building environment) here.  We are getting
close in *some* respects, but we aren't going to be able to offer the
range of functionality needed to deliver true GUI-building
capabilities, including flexibly and customizably reactive interfaces.
Therefore, I'd like to veto both the idea of arbitrarily tying
submission to any interface element (there are user interface problems
there, also -- it's not going to be clear to a user what's going on
and why) and the idea of forms behavior scripting.

Anticipating objections to my objection: During WWWWW this summer, I
was termed "closed minded" by at least one person for trying to draw
the line as to what we're willing to implement and support.  It's not
closed-mindedness, it's triage -- we just can't do everything.

Cheers,
Marc

> dcm
> --------
> Dave_Raggett writes:
> 
> Frans van Hoesel has pointed out the value in being able to
> use a checkbox or an icon or whatever to submit forms. In 
> a tax return there might be a load of questions that become
> irrelevant when you click the checkbox to indicate that you
> are "single". In this case the form would be submitted and
> the server would then return it with the irrelevant questions
> greyed-out:
> 
> Single? <INPUT NAME="single" TYPE=checkbox SUBMIT>
> 
> The idea here is to make SUBMIT an independent attribute
> that can be used with arbitrary field types. You could
> have multiple "submit buttons" in the same form. This way
> authors can choose whether the form contents gets checked
> after each field on a per field basis.
> 
> How about it?
> 
> -- Dave



From dcmartin@library.ucsf.edu  Tue Oct 12 11:41:37 1993 PDT
Message-Id: <199310121845.AA26019@library.ucsf.edu>
Date: Tue, 12 Oct 1993 11:41:37 PDT
From: dcmartin@library.ucsf.edu (David C. Martin)
Subject: Re: request for new forms submission consensus 

Now, Marc; don't ever think that I would expect this out of NCSA.  In fact,
I would like to offer code to augment Mosaic, specifically support for TIFF
images.  I don't think that having a scripting language is too much, but it
probably is too soon.

What you are creating is a client application that needs to be able to handle
displaying and navigating through an increasingly diverse network information
sea, and part of the functionality required is going to be local client
processing of interaction.

You should note that I didn't say "implement a fully scriptable viewer," nor
did I say that I even wanted such a beast.  What I was attempting to discuss
was the potential to have bindings to the new functionality you're implementing
and doing that binding in such a way as to leverage the ability of the
document creator.

Anyway, keep up the good work.

dcm
--------
Marc Andreessen writes:

David C. Martin writes:
> Completely agree!  But eventually I want to see local processing of
> actions from the user (e.g. indicating zipcode and getting state
> defaulted correctly :-) We need to start discussing the ability to
> download a script to accompany the document, e.g. in a stripped down
> TCL with TCL hooks into client (e.g. Mosaic) functionality for
> making the buttons, scrollbars, etc... *do* something interesting at
> the local machine.

Too much (and, in any case, too soon).  I feel like reposting my
"kitchen sink" speech -- we are not creating an actual full-featured
user interface builder (or building environment) here.  We are getting
close in *some* respects, but we aren't going to be able to offer the
range of functionality needed to deliver true GUI-building
capabilities, including flexibly and customizably reactive interfaces.
Therefore, I'd like to veto both the idea of arbitrarily tying
submission to any interface element (there are user interface problems
there, also -- it's not going to be clear to a user what's going on
and why) and the idea of forms behavior scripting.

Anticipating objections to my objection: During WWWWW this summer, I
was termed "closed minded" by at least one person for trying to draw
the line as to what we're willing to implement and support.  It's not
closed-mindedness, it's triage -- we just can't do everything.

Cheers,
Marc

> dcm
> --------
> Dave_Raggett writes:
> 
> Frans van Hoesel has pointed out the value in being able to
> use a checkbox or an icon or whatever to submit forms. In 
> a tax return there might be a load of questions that become
> irrelevant when you click the checkbox to indicate that you
> are "single". In this case the form would be submitted and
> the server would then return it with the irrelevant questions
> greyed-out:
> 
> Single? <INPUT NAME="single" TYPE=checkbox SUBMIT>
> 
> The idea here is to make SUBMIT an independent attribute
> that can be used with arbitrary field types. You could
> have multiple "submit buttons" in the same form. This way
> authors can choose whether the form contents gets checked
> after each field on a per field basis.
> 
> How about it?
> 
> -- Dave




From sanders@bsdi.com  Tue Oct 12 14:09:08 1993 -0500
Message-Id: <9310121909.AA06729@austin.BSDI.COM>
Date: Tue, 12 Oct 1993 14:09:08 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: request for new forms submission consensus 

dcmartin@library.ucsf.edu (David C. Martin) writes:
> images.  I don't think that having a scripting language is too much, but it
> probably is too soon.
In my opinion this is the wrong path to be heading down, the client should
be kept simple.  All "application" things should be handled on the server
end or by external programs (if you want TCL then run TCL, don't build it
into the client).

--sanders



From hoesel@chem.rug.nl  Tue Oct 12 20:05:06 1993 +0100 (MET)
Message-Id: <9310121905.AA02599@Xtreme>
Date: Tue, 12 Oct 1993 20:05:06 +0100 (MET)
From: hoesel@chem.rug.nl (frans van hoesel)
Subject: Re: request for new forms submission consensus

Initially Dave_raggett didn't like type=submit at all! He suggested to have
only one submit button for each form.
I pointed out to him that it can be very useful to have more.
He came up with the suggestion not to add SUBMIT to type=, but put
in a separate item.

I too think that the browser should evolve slowly over time, 
but I don't see the point why we cannot use dave suggestion. It doesn't
imply that you must actually implement it in all cases. But you could
implement it for those cases that you use submit.

why not simply change from
type=submit
to
type=button submit

and dave will be happy, you don't have to change a lot, and it would
allow future extensions like <.. type=text submit>
where the submit is done as soon as the user finished the text with a return,
or <.. type=radio submit> (the form is submitted as soon as the user
selects one of the radio buttons)

I don't expect you to implement all those possibilities, but at least it
opens the possibility to implement them, without loosing anything.
I just want to keep the way to the futur open.

- frans

> Too much (and, in any case, too soon).  I feel like reposting my
> "kitchen sink" speech -- we are not creating an actual full-featured
> user interface builder (or building environment) here.  We are getting
> close in *some* respects, but we aren't going to be able to offer the
> range of functionality needed to deliver true GUI-building
> capabilities, including flexibly and customizably reactive interfaces.
> Therefore, I'd like to veto both the idea of arbitrarily tying
> submission to any interface element (there are user interface problems
> there, also -- it's not going to be clear to a user what's going on
> and why) and the idea of forms behavior scripting.
> 
> Anticipating objections to my objection: During WWWWW this summer, I
> was termed "closed minded" by at least one person for trying to draw
> the line as to what we're willing to implement and support.  It's not
> closed-mindedness, it's triage -- we just can't do everything.
> 
> Cheers,
> Marc




From marca@ncsa.uiuc.edu  Tue Oct 12 15:43:12 1993 -0700
Message-Id: <9310122243.AA20464@wintermute.ncsa.uiuc.edu>
Date: Tue, 12 Oct 93 15:43:12 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Re: request for new forms submission consensus

frans van hoesel writes:
> Initially Dave_raggett didn't like type=submit at all! He suggested to have
> only one submit button for each form.
> I pointed out to him that it can be very useful to have more.
> He came up with the suggestion not to add SUBMIT to type=, but put
> in a separate item.
> 
> I too think that the browser should evolve slowly over time, but I
> don't see the point why we cannot use dave suggestion. It doesn't
> imply that you must actually implement it in all cases. But you
> could implement it for those cases that you use submit.
> 
> why not simply change from
> type=submit
> to
> type=button submit
> 
> and dave will be happy, you don't have to change a lot, and it would
> allow future extensions like <.. type=text submit>
> where the submit is done as soon as the user finished the text with a return,
> or <.. type=radio submit> (the form is submitted as soon as the user
> selects one of the radio buttons)
> 
> I don't expect you to implement all those possibilities, but at least it
> opens the possibility to implement them, without loosing anything.
> I just want to keep the way to the futur open.

Under those criteria, the way to the future is open already.

Marc

> - frans
> 
> > Too much (and, in any case, too soon).  I feel like reposting my
> > "kitchen sink" speech -- we are not creating an actual full-featured
> > user interface builder (or building environment) here.  We are getting
> > close in *some* respects, but we aren't going to be able to offer the
> > range of functionality needed to deliver true GUI-building
> > capabilities, including flexibly and customizably reactive interfaces.
> > Therefore, I'd like to veto both the idea of arbitrarily tying
> > submission to any interface element (there are user interface problems
> > there, also -- it's not going to be clear to a user what's going on
> > and why) and the idea of forms behavior scripting.
> > 
> > Anticipating objections to my objection: During WWWWW this summer, I
> > was termed "closed minded" by at least one person for trying to draw
> > the line as to what we're willing to implement and support.  It's not
> > closed-mindedness, it's triage -- we just can't do everything.
> > 
> > Cheers,
> > Marc
> 



From dcmartin@library.ucsf.edu  Tue Oct 12 13:59:05 1993 PDT
Message-Id: <199310122103.AA27904@library.ucsf.edu>
Date: Tue, 12 Oct 1993 13:59:05 PDT
From: dcmartin@library.ucsf.edu (David C. Martin)
Subject: Re: request for new forms submission consensus 

I am not saying that the client shouldn't be kept simple; what I am
saying is that the functionality that the client supports should be
accessible to the document author.

Has anyone considered the requirements for the communication between
Mosaic and external applications?  If you are viewing a document that
has portions of it viewed by external programs, how do you plan to
communicate with those programs when the user follows another link?  Do
the items stay as they do today, or do you have some mechanism to
coordinate the transmission (and sharing) of information from the
network, with sound files being delivered to the soundtool and video
files to the videotool, etc... 

Anyway, don't underestimate what people are going to want to do with the
software.  I don't expect to dedicate *my* server to acting as some kind
of application back-end that is required to interact with every user
action that may or may not require some modification of the display.

dcm
--------
Tony Sanders writes:

dcmartin@library.ucsf.edu (David C. Martin) writes:
> images.  I don't think that having a scripting language is too much, but it
> probably is too soon.
In my opinion this is the wrong path to be heading down, the client should
be kept simple.  All "application" things should be handled on the server
end or by external programs (if you want TCL then run TCL, don't build it
into the client).

--sanders



From marca@ncsa.uiuc.edu  Tue Oct 12 16:54:41 1993 -0700
Message-Id: <9310122354.AA20711@wintermute.ncsa.uiuc.edu>
Date: Tue, 12 Oct 93 16:54:41 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Re: request for new forms submission consensus

Kevin Altis writes:
> (Dave Raggett writes one level deeper:)
> >Password fields: e.g. <INPUT NAME="f3" TYPE=password>
> >
> >    Like TYPE=text but not echoed to the screen.
> 
> Just as an interface point. We already have the problem of "focus"
> in XMosaic, where depending on configuration, if the user doesn't
> have the pointer over a field, their keystrokes don't go into the
> field. 

This was a design decision, as the alternative is even more confusing
(normal Motif focus tracking and traversal).  As it is, you *always*
just put the pointer where you want to type and then you type.  This
can be overridden at the system or user level using X resources (see
src/xresources.h for the gory details).

> I forsee many X people thinking they're typing in their password,
> only to find out they entered nothing.

Nope, you get asterisks instead of characters -- it's completely
obvious what's happening.

> >Option lists:
> >
> >    These are already supported via TYPE=checkbox and TYPE=radio
> >    which support multi and single selection lists respectively.

No, they're different -- they support explicit specification of toggle
buttons with either one or n of many behavior, with other intermixed
elements, including text.

> >These field types force the author to list each option as part of
> >an HTML list. 

Yup.  I don't see how that's a problem.

> >The browser can't do anything clever like drop-down scrollable
> >combo-boxes.

What?  What's a "drop-down scrollable combo-box", and how would option
menus and lists prohibit their use?

> >I felt this was quite reasonable as it fits well with paper forms
> >and simple text-only terminals. Everyone will find them easy to
> >use!

Everyone will find what easy to use?

I'm confused...

> >I am worried about using % followed by the hexadecimal code as a
> >means of escaping significant characters in attribute values. It
> >seems to closely linked to using 7 or 8 bit US ASCII. What should
> >we use instead?

The reason we're doing it in the first place is to adhere cleanly to
the URL schema, which is used as a "level 0" submission method.  

The reason we'll do it for at least one "real" (HTTP/1.0) submission
method -- sending an application/x-www-form-simple body via a POST
message to the server, or something very similar -- is because it is
very close to the URL method, but provides the advantage of shipping
the data as a real message rather than slapped in a URL.

Future submission methods can use better encoding methods if they
want, and I expect they will.

In any case, it really shouldn't matter (except for reasons of
efficiency), since it's just back-end plumbing -- users never need to
see it.

> I don't suppose anyone wants to make explicit support for 16-bit
> characters, maybe UNICODE? UNICODE is biased towards European
> languages (according to my Japanese friends) but I don't think we
> have enough people on this list (if any) versed in Hebrew, Arabic,
> Kanji, etc. to give us direction. OS vendors are quickly adopting
> UNICODE as their standard (some products already use UNICODE
> internally for everything), we at least need to think about it, if
> we want HTML+ to be truly international.

NOOOOOOOOOOOOOOOOOOOOOOOOOOO!  Not a character set debate!  Not here!
I'm still having nightmares from the 822 list debates...

Marc



From strata@fenchurch.mit.edu  Tue Oct 12 20:02:07 1993 EDT
Message-Id: <CMM.0.90.0.750470527.strata@fenchurch>
Date: Tue, 12 Oct 93 20:02:07 EDT
From: strata@fenchurch.mit.edu (M. Strata Rose)
Subject: Re: request for new forms submission consensus


David,

I am currently building a browser based on Mosaic which uses a "console" or
"dashboard" metaphor for browsing and navigating info-space.  This means
things like constrained  image-viewing windows, the ability to play or store
sounds and to replay them at the touch of a button instead of having to
reload them, a "port" for mpeg movies and so on.  I am exploring strategies
for having these application windows communicate with the main browsing agent
so that their displays will be updated, as well as issues of user
configurability (how many GIFs do I get to stack up) vs. resources.

My design notes call for the browser to essentially have its own mini-API so
that other  display agents can be used by the browser and "assigned" their
position and constraints in console-space.  Since the target application of
the browser is browsing a virtual environment comprised of many different
data types, I am tackling issues ranging from protocol (how does my server
tell all the apps at once which data files to load) to user interface (what
happens to the mpeg movie that came with the last space when we move into a
new space-- does the screen blank out, is this configurable, etc).

As soon as I have a formal design spec and something of a prototype I plan to
throw it to the wolve, err, list members and see what y'all think of it.

The browser will be public-domain freeware in the manner of Mosaic, and in
fact the initial versions will have significant chunks of Mosaic code in them
and thus be bound by the NCSA copyleft terms as well as standard ones.  I
have discussed this briefly with Marc A, BTW, to determine the status of the
code.  I'll append the faq/announcement for the Virtual City(tm) Network to
this post, as that is the environment that the browser is being designed for.

Anyone else doing similar work?  Would like to share ideas, etc.  A
couple of items not mentioned above are a) looks like Tcl/Tk is what
I'll be implementing this in and b) I'm putting in the concept of
encrypted streams which are decrypted by the client ala Kerberos and c)
I'm planning on supporting international character sets (which system,
ugh).

_Strata

#############################################################
NB: PGP info misleading, rev 1.0.1 to follow shortly, that's what
posting a faq at 3am gets you...
		
		VIRTUAL CITY (TM) NETWORK FAQ, REV 1.0



SO WHAT EXACTLY IS THE VIRTUAL CITY (tm) NETWORK?

The Virtual City(tm) Network is an ambitious Networked Virtual Reality
Infrastructure which will link current Internet information technology
with the emerging capabilities of on-line virtual reality
environments.  Using existing software which implements shared,
interactive virtual spaces we will extend the paradigm of the FreeNet
community into virtual reality by creating online cities and
communities in which people may share text, graphics, and multimedia
in a cooperative real-time environment.  These online communities will
be able to make use of cutting edge tools such as network
conferencing, collaboration & visualization tools, multimedia
electronic mail, online access to government data, networked library
catalogs & facilities, electronic books online and Internet-accessible
public data repositories.  The Virtual City(tm) Network will also be a
proving ground for privacy technologies such as public key
cryptography, PGP, and Digital Cash(tm).


DIDN'T YOU RUN AN AD IN _WIRED_ RECENTLY?

NO.  And again, No.  The Virtual City (tm) Network is the brainchild
of one M. Strata Rose, longtime net.lurker and sometime visionary, who
has been developing the concept since roughly June 1992.  I started
serious feasibility exploration in December of '92 and have been on
track on a timeline which formally started in May '93.  The folks who
put an ad in _WIRED_ are Objective Communications of Illinois.
Virtual City (tm) is a trademark of M. Strata Rose and VirtualNet
(currently undergoing formal incorporation).  We are registered with
the NIC as VIRTUAL.NET and VIRTUAL-CITY.COM.


OH, COME ON-- TRADEMARKING THE PHRASE "VIRTUAL CITY"?

The concept of creating virtual communities in a Mush/MUD/MOO
environment has been kicking around for many years, and quite a bit of
work has been done by a great many people.  However, there is a
particular on-line public access service concept which I call the
Virtual City (tm) Network.  As it says in the terrifying amount of
paperwork required to file a trademark, "this application in no way
attempts to restrict the usage of the terms 'virtual' or 'city',
merely their usage in conjunction where applicable to services in this
class".  Or something highly similar but in stricter legalese, as per
professional advice.



WELL, HOW IS YOUR "VIRTUAL CITY (tm) NETWORK" DIFFERENT 
FROM THEIR "VIRTUAL CITY"?

Obviously there is a limit to the extent to which I can comment, as
both of our offerings seem to be in a pre-release state.  However, a
brief telephone conversation with an individual at Objective
Communications indicated some important differences:


1) The Virtual City (tm) Network will be free for individuals to
access; charges will only be levied on entities attempting to conduct
profitable business activities.  My understanding is that Objective
plans to charge fees at all levels of participation in their service.

2) The Virtual City (tm) Network has been designed for multimedia and
information service access from the ground up.  My understanding is
that Objective's service is text-only and the gentleman on the phone
indicated that they had no current plans to expand it to multimedia.

3) VirtualNet incorporates both a for-profit corporation and a 
not-for-profit research arm.  One of our primary goals for the Virtual
City(tm) Network is to take the Cleveland FreeNet model into virtual
space.  The Virtual City (tm) Metropolitan Transit Authority, VCMTA,
is being designed concurrently as an object transport model between
instantiations of various Virtual City (tm) Sites.  We will be
offering templates for instantiations of our city model to be used by
communities and organizations, with a true distributed model allowing
users and information to flow freely throughout the Virtual City (tm)
Network.

We are attempting to build an expandable, scalable piece of Internet
infrastructure that will support a rich model of growth and
self-determination as well as support research on virtual communities
and cyberspaces in general.  Look for abstracts, research papers,
RFC's and API's from us in the coming year.


NO KIDDING.  TELL ME MORE.

One of my design goals in building the Virtual City(tm) Network is to
challenge people's assumptions about "the real world" versus "the
virtual world"; many if not most of people's interactions today
take place in a virtual world which has been largely co-opted by the
real world.  Newspapers, television, and radio are all prime
examples-- most of these rely on mental constructions based on
primarily verbal input or on finely crafted presentations which have
little to do with "reality", yet few people consider to what degree
these omnipresent factors constitute much of their information flow.

A wonderful example is the Android Sisters' "Money" (radioplay "Ruby",
ZBS Productions).  The Sisters hold up two items, described as two
pieces of paper, to a "viewer" and ask for her description.  Her
reply, "well, one is a piece of paper, but the other is money" elicits
the ruefully exasperated reply "two pieces of paper!".  The well-made
point is that people's cognitive mappings have become so rigidly
codified that they view their world through highly constrained filters
to the point of shutting out other options.

In the Virtual City(tm) Network, the line between the real and the
virtual has the inherent ability to be deliberately blurred.
Information from "the real world" can be presented as often as
possible in a matter of fact way.  I hope to feature several space
station designs from the cutting edge of the aerospace industry, and
the reported weather in the outdoor sections of the city will come
from weather data live from local feeds, updated to the San Mateo
Bridge area, the putative location of the site.  Our virtual
coffeehouses will tie into Internet game servers of various sorts and
we are investigating links to real-world coffeehouses via terminals
in the field.  Imagine chatting on a virtual terminal via the Internet
to folks on real terminals in coffeehouses.  Now who's real and who's
virtual?


OKAY, WHAT'S YOUR TECHNOLOGY BASE?

We are currently using LambdaMOO, an object-oriented virtual
environment designed at Xerox PARC.  Instantiations of LambdaMOO are
already being used to provide virtual spaces in which researchers,
educators, and interested folks can meet and interact online, such as
MIT Media Lab's "MediaMOO", "JaysHouseMOO". the original "LambdaMOO"
and a growing plethora of others.  Various university and individual
projects are adding the capability to access certain Internet
information resources such as the "archie" FTP search engine and
University of Minnesota's Internet Gopher browser [JaysHouse MOO].
Xerox PARC is working on a project called "AstroVR" in which
extensions to the text-based MOO software allow astrophysicists to
share graphical images and data.  The PARC team is also working on
MBONE extensions to LambdaMOO; these extensions will allow LambdaMOO
users to use the Multicast Backbone to do real-time audio and video
conferencing using tools which are being developed concurrently by the
greater networking community.  We are working on extensions which will
combine the functionality of NCSA's Mosaic information browser with
the virtual environment capabilities of LambdaMOO.

Mosaic is a hypertext browser through which individuals may access
various Internet services such as World Wide Web, Gopher, WAIS, and
archie.  The World Wide Web in particular uses a format called HTML
(HyperText Markup Language) to create documents which can access other
documents with a single mouse click from the browser.  We are adding
the ability for SGML or HTML documents to be valid MOO objects; this
single extension opens up a significant range of possibilities which
represent needed interconnectivity between the MOO environment and the
wider world of Internet information.  Virtual spaces in the MOO can
then lead directly to an information cache, and information browsers
on the Internet can interact with MOO spaces as well.

This is just the beginning.  In particular, the Virtual City (tm)
Network is being designed to allow encapsulation of other information
formats and explicit handoff to both public and proprietary
information servers.  Our model is very similar to the one which NCSA
developed with Mosaic.  You interact with our virtual spaces using
custom clients or browsers which can invoke various service handlers
or interaction programs on your host machine.  Just as Mosaic will
bring up a GIF viewer when you reference a GIF file, the Virtual City
(tm) browser could invoke Virtus Walkthrough (tm Virtus) or the BRL-CAD
environment on a virtual space.  You might enter a virtual space with
encapsulated or referenced data available in several formats that your
client or browser could handle.


WHY IS THIS IMPORTANT?

Ah, this is one of the really great parts-- if we can hand you off to
some other viewer or program or even another server, then the Virtual
City (tm) Network is truly expandable and extensible.  We will be able
to offer services that no one has even thought of yet as long as they
run over the Internet infrastructure (ie, TCP/IP or something that can
encapsulate itself in it).  The Virtual City (tm) Network will grow
along with virtual reality and internet information technology, since
new services can be accessed in a plug-and-play fashion.  What we're
trying to do here is essentially spawn a meta-infrastructure context
in which to tie together highly varied services.  This is also where
VCMTA comes in.


WHAT'S VCMTA?


VCMTA, the Virtual City(tm) Metropolitan Transit Authority, will be
developed concurrently.  This facility will provide authentication
services for moving database objects between servers on different
hosts, as well as implementing state-of-the-art privacy enhancements
for secure communication & transactions.  VCMTA will allow us to
network instances of the Virtual City (tm) Template together and allow
people to "move" between them in one ever-growing virtual space.

We realize that there are hard problems to solve in building any sort
of object transport facility; however, our philosophy is that we can't
work miracles but can make something that works, is customizable and
configurable, and will make most people happy.

Obviously you can't "move" objects, however you can build objects
which rely on a core object library, are "registered" with VCMTA, and
follow certain rules as to their behavior on other servers and in
other conditions.  The nature of our distributed architecture already
means that resources you access are not necessarily on the VC server,
this is the logical next step.


WELL THIS IS ALL VERY NICE, BUT I DON'T PROGRAM AT ALL SO I 
PROBABLY WON'T BE ABLE TO USE IT MUCH.

Current implementations of MOOs and MUDS require that users be able to
program at a fairly sophisticated level in order to enjoy the full
power of MOO/MUD environments, especially in constructing new objects.
We feel that this encourages "second-class citizen" status for those
virtual citizens who cannot or will not learn to program proficiently.

Accordingly, the Virtual City(tm) Network is being designed with
virtual storehouses of objects which can be drawn from and user
friendly front-ends with which to customize those objects to create
personalized and useful virtual spaces.  The full power of the MOO
internal programming language will still be available to those who
care to use it, but those who have neither the time nor desire to do
so will be able to interact as fully as the programming hoi-polloi.

As part of this effort, we are designing interactive front-ends to
interface with the storehouses of objects and handle simple
customization.  Certain "city services" such as phones, chat lines,
radios, gopher slates, etc will be available as well as common objects
(and unusual ones!) from various individuals.  By the way, if you
register an object for public use and it passes the Virtual City (tm)
Architectural Board (no Trojan horses or duds, please!), it no longer
counts against your quota.  Keen, eh?


THIS IS STARTING TO SOUND PRETTY COOL.  ARE YOU SURE IT'S 
FREE?

There will be no charge for private individuals to access the Network
and to engage in building and programming activities (up to a generous
initial quota, as in most other MOOs or MUDs).  Non- profit and
government organizations will be allocated space at no charge in the
Virtual City(tm) Marketplace, Business District, and other public
areas.  Cultural attractions such as art galleries, museums, and music
halls are placed throughout the Virtual City(tm) Network; space in
these attractions will be donated to artists and community projects to
publicize their work.  The several museums will feature examples of
the growing number of online exhibits such as the Library of Congress'
current Vatican Project.

Corporations and other for-profit entities may be charged membership
fees on a monthly basis, as well as rent for virtual spaces in which
to transact business.  Our basic paradigm is that if you're in the
Virtual City (tm) Network to generate professional profitable activity
then you should pay a fee to do so.  Ie., the customary net.forsale or
net.jobs type of stuff is just fine, whereas setting up a virtual
office in which to run a real-time on-line consulting business would
require paying rent.  Arrangements can be made on a rental or
percentage basis, or both.

We are very interested in supporting subscription-based services where
subscribers are allowed access to custom objects or facilities.  This
can be a very economical way to do rich text or multimedia electronic
publishing in a small-press model, or provide specialized databases or
services at a modest cost to subscribers.  


WHAT SORT OF FACILITIES ARE YOU PLANNING?

In addition to those mentioned above, we will have all the standard
amenities-- Alexandria, the Virtual Library, a business district,
arcade and game areas, residential streets, a campus area where
several interesting projects are being designed, transit facilities,
and so on.  We're choosing to leave MBONE facilities out on this pass
due to bandwidth considerations; however, we plan on supporting such
diverse applications and protocols as Netjam MIDI, CUSeeMe network
video conferencing, various whiteboard tools, IRC with local client
enhancements, connections to other MOOs/MUDS, NCSA & BRL-CAD
visualization environments, group collaboration tools, interactive
game servers, Internet Talk Radio, etc.  We're exploring support for
proprietary and vendor environments as well, such as Autodesk, Virtus,
SGI, and other virtual reality software interfaces.

We also have several original-design projects up our virtual sleeves
such as the Virtual Coffeehouses, the Twilight Lands where
storytellers roam the campfires, the UpAbove and DownBelow space and
marine research station simulators, a Virtual Physics Lab, and so on.

Not to mention the Virtual City (tm) Marketplace, Information Center,
and On-Line Technical Support Center where you can sell your products
or services with minimal overhead and rely on our expertise to deliver
your information to the Internet community.  


WOW, I'M CONVINCED.  HOW DO I LOG ON? 

We're terribly sorry, but you can't log in quite yet.  We will be
opening the database to key implementors once we finish the C
modifications to the LambdaMOO server and to the LambdaCore.  We had
planned a general announcement in mid to late November, but
circumstances required otherwise.  We are taking lists of pre-
registrants, though.  Send email to "vcreg@virtual.net" with pertinent
info: your name, your requested character name, and a short blurb
which will become your initial description.  Oh yes, and your Public
Key.

Don't have one?  Tsk, tsk, they're a good thing to have in general; go
out and connect to a public key server and get yourself a key-- we'll
send out your initial password encrypted to you, and you can decipher
it with our public key.  Fun, eh?  If you're a sufficiently
enthusiastic cyberspace denizen to pre-reg, you probably already have
a public key...

We are planning a Virtual New Year's Party at the very least, even if
all net services are not on-line yet.  The HTML/SGML capability is
really the critical factor-- we will open as soon as that is reliably
running and add other services as our range of interfaces expands.
Even if our (free) custom browser is not finished by then you will
still be able to use standard MUD/MOO clients in conjunction with
Mosaic or similar HTML browsers to enjoy the multimedia capabilities.


WELL, DO YOU NEED ANY HELP?  HOW DO I GET INVOLVED?

I'm glad you asked that question.  :-) Since a critical aspect of our
project is free public access, we need volunteers!  Our schedule has
been accelerated fairly rapidly at this point and we could use a hand
fairly soon.  Send email to "vcbuild@virtual.net" with some brief
notes about what you're interested in implementing and your level of
familiarity with MOO coding.  If you have experience with server and
core-level mods, there may be funding in it as well, though we are
primarily looking for volunteers at this time.


ISN'T THIS GETTING PRETTY LONG FOR A "FAQ" FOR SOMETHING 
NEW THAT NOT MANY FOLKS OUTSIDE OF THE BAY AREA HAVE 
EVEN HEARD OF?

Totally correct.  Send questions, suggestions, pointers, flames, and
so on to "vc@virtual.net".  If you'd like to be on a mailing list for
discussion of virtual communities, network services, and other Virtual
City (tm) Network related themes, send mail to
"virtual-citizens@virtual.net".  There's plenty more where this came
from, look for technology updates, facility updates, and GIF &
Postscript (tm Adobe) maps.  See you in cyberspace!


Virtual City (tm) Network FAQ 1.0 copyright 1993 M. Strata Rose &
VirtualNet; permission to distribute in its entirety, including this
notice, freely granted.

M. Strata Rose
Unix & Network Consultant, SysAdmin & Internet Information 
Virtual City (TM) Network
strata@virtual.net | strata@hybrid.com | strata@fenchurch.mit.edu



From marca@ncsa.uiuc.edu  Tue Oct 12 17:17:24 1993 -0700
Message-Id: <9310130017.AA20763@wintermute.ncsa.uiuc.edu>
Date: Tue, 12 Oct 93 17:17:24 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Re: request for new forms submission consensus

Dave_Raggett writes:
> Multiline text fields: e.g.<INPUT NAME="f2" TYPE=text COLUMNS=32 ROWS=4>
> 
>     I am not convinced this needs a distinct name from TYPE=text, since
>     the presence of the ROWS attribute is clear enough!

Makes the browser code cleaner -- they have to be handled differently
internally.  Not a big deal, but I always thought following the
"different things have different names" philosophy led to greater
cleanliness.

> Option lists:
> 
>     These are already supported via TYPE=checkbox and TYPE=radio
>     which support multi and single selection lists respectively.
> 
> These field types force the author to list each option as part of
> an HTML list. The browser can't do anything clever like drop-down
> scrollable combo-boxes. I felt this was quite reasonable as it fits
> well with paper forms and simple text-only terminals. Everyone will
> find them easy to use!
> 
> NCSA propose a TYPE=options field with the list as an attribute value:
> 
>  <INPUT TYPE="option" NAME="what-to-do" OPTIONS="Drink Coffee,
>      Read A Book, Take A Walk, Buy A Bagel, Watch TV" VALUE="Read A Book">
> 
> This design leads to arbitrarily long attribute values, which is bad
> SGML, and could break some parsers.

Whatttttttt?????  Really???  Ick.  SGML is starting to look worse and
worse.

> I recommend instead, the SELECT tag as in:
> 
>     <SELECT NAME="what-to-do">
>         <LI>Read A Book
>         <LI>Take A Walk
>         <LI>Buy A Bagel
>         <LI>Watch TV
>     </SELECT>
> 
> You use <SELECT SEVERAL NAME="what-to-do"> if several selections are
> possible simultaneously.

That's not very elegant -- looks and feels like bastardized text
markup (which it is :-).

> TYPE=submit and TYPE=reset
> ==========================
> 
> It seems to me that this is a kludge, and that it would be much
> better to leave it up to the browser and platform specific form
> conventions. For most systems, the browser should show Submit and
> Reset buttons automatically at the end of the form. For a form with
> a single text input field, the browser can omit these buttons and
> assume use of the "Enter" key instead. This doesn't cost much since
> by the time the browser reaches the </FORM> tag it already knows
> what fields there are in the form.

And that, in fact, is what we already do -- except we provide the
document writer the flexibility to have, if he so chooses, arbitrary
layout and numbers of the buttons.  All else being equal, flexibility
is good, experience has shown, otherwise we get blamed for making the
wrong decision by someone -- this avoids that.

> Transfer formats
> ================
> 
> For simple implementations the URL?name=value&name=value&... scheme is fine.
> But in the near future we will want fields that can accept scribble (e.g.
> hand-written signatures) and voice input. MIME multipart messages seem like
> the right way to go:
> 
>     MIME-Version: 1.0
>     Content-Type: multipart/mixed;
>         boundary=unique-boundary-1
> 
>     --unique-boundary-1
>     Content-Type: application/html-form
> 
>     name: value
>     name: value
>     name: @part-name
>     --unique-boundary-1
>     Content-Type: audio/basic
>     Content-Transfer-Encoding: Base64
>     Part-Name: part-name
> 
>     ... the encoded audio data goes here
>     --unique-boundary-1--
> 
> The above uses the new MIME content type "application/html-form" to
> transfer the basic form data as one or more lines each of which
> has one of the following formats:
> 
>     a)    field-name: field-value
> 
>     b)    field-name: @part-name
> 
> The second one specifies the field's value indirectly as a named MIME
> message part. This allows us to use the normal MIME mechanisms for
> different data types, in this case audio/basic with base64 encoding.
> The header "Part-Name:" should be used to declare the name of each
> part in a multipart message.
> 
> I am worried about using % followed by the hexadecimal code as a means
> of escaping significant characters in attribute values. It seems to
> closely linked to using 7 or 8 bit US ASCII. What should we use instead?

Oops, disregard most of my previous message replying to this -- I
didn't see all the context.  (My mail reading skills are declining
rapidly...)

Cheers,
Marc



From marca@ncsa.uiuc.edu  Tue Oct 12 19:28:56 1993 -0700
Message-Id: <9310130228.AA21020@wintermute.ncsa.uiuc.edu>
Date: Tue, 12 Oct 93 19:28:56 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Re: request for new forms submission consensus

"M. Strata Rose" writes:
> The browser will be public-domain freeware in the manner of Mosaic,
> and in fact the initial versions will have significant chunks of
> Mosaic code in them and thus be bound by the NCSA copyleft terms as
> well as standard ones.  

Ummm, just to nip any possible misconceptions in the bud, Mosaic is
not "public-domain", "freeware", or "copylefted".  It is copyrighted
and freely available for certain classes of use.

However, your project does sound fascinating :-).

Cheers,
Marc



From luotonen@ptsun00.cern.ch  Wed Oct 13 13:59:32 1993 +0100
Message-Id: <9310131259.AA12059@ptsun00.cern.ch>
Date: Wed, 13 Oct 93 13:59:32 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: AA BUGS and test page


   Blaah,

as one might expect, the moment the release is out you find a bug.

However, these do NOT affect client-side, only the daemon. As for
the daemon, wait a couple of days for a new release, the main bug
cripples the daemon AA completely when using ACLs :-(.

Major problem is that Daemon 2.12 cannot read ACL files correctly;
about every other entry is skipped (and this was because of one single
extra damn line HTGroup.c :-( :-( :-().
Another thing was that multiple IP masks in group-mask didn't work
unless they were in all grouped by parentheses @(... , ... , ...).
Third thing was that the daemon didn't like the idea of not knowing
the group file name.

One might ask didn't I test this at all... My only excuse is that the
new group definition syntax allowing also IP addresses was put in
in the nick of time, and it wasn't as well tested as it should have
been, and for that I feel terrible.  And all the bugs were related to
that.  Oh well, these things tend to happen no matter how careful you
think you are...

These all have already been corrected, and a brand new daemon is
already running on www1.cern.ch.  You can use the AA testing page
for testing client AA:

    http://www1.cern.ch/AAtest/Welcome.html

or enter from the bottom of AA Overview page.


-- Sorry about all the mess, cheers, over and out, Ari --



From dcmartin@library.ucsf.edu  Wed Oct 13 06:49:34 1993 PDT
Message-Id: <199310131353.AA05195@library.ucsf.edu>
Date: Wed, 13 Oct 1993 06:49:34 PDT
From: dcmartin@library.ucsf.edu (David C. Martin)
Subject: Re: request for new forms submission consensus 

Dave_Raggett writes:

> I recommend instead, the SELECT tag as in:
> 
>     <SELECT NAME="what-to-do">
>         <LI>Read A Book
>         <LI>Take A Walk
>         <LI>Buy A Bagel
>         <LI>Watch TV
>     </SELECT>
> 
> You use <SELECT SEVERAL NAME="what-to-do"> if several selections are
> possible simultaneously.

You could also indicate it by:

     <SELECT NAME="what-to-do">
         <XC>Read A Book
         <XC>Take A Walk
         <XC>Buy A Bagel
         <XC>Watch TV
     </SELECT>

Where <XC> is an exclusive choice.  Seems more appropriate, if you're
inclined to that mechanism, since the method of choosing is in the
context of exclusivity is static, not dynamic (e.g. non-selectability).

dcm



From sanders@bsdi.com  Wed Oct 13 12:23:50 1993 -0500
Message-Id: <9310131723.AA12095@austin.BSDI.COM>
Date: Wed, 13 Oct 1993 12:23:50 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: log file format for HTTP/1.0 requests

Has anyone figured out a good way to log all the interesting information
in HTTP/1.0 requests?  For example: Referer: User-Agent: etc.

--sanders



From montulli@stat1.cc.ukans.edu  Wed Oct 13 15:49:09 1993 CDT
Message-Id: <9310132049.AA16944@stat1.cc.ukans.edu>
Date: Wed, 13 Oct 93 15:49:09 CDT
From: montulli@stat1.cc.ukans.edu (Lou Montulli)
Subject: HTML Nested Lists

Does there need to be infinite nesting support for HTML lists,
or is 7 nesting levels enough. (sort-of like Headers)

Once a decision is made on this I suppose it needs to be written
into the spec.  (If nested lists ever make it in)

Opinions?
:lou
-- 
  **************************************************************************
  *           T H E   U N I V E R S I T Y   O F   K A N S A S              *
  *         Lou  MONTULLI @ Ukanaix.cc.ukans.edu                           *
  *                         Kuhub.cc.ukans.edu      ACS Computing Services *
  *     913/864-0436        Ukanvax.bitnet             Lawrence, KS 66044  *
  *             UNIX! Cool! I know that!  Jurassic Park - The Movie        *
  **************************************************************************



From cwilson@ncsa.uiuc.edu  Wed Oct 13 17:26:24 1993 CDT
Message-Id: <9310132226.AA02831@void.ncsa.uiuc.edu>
Date: Wed, 13 Oct 93 17:26:24 CDT
From: cwilson@ncsa.uiuc.edu (Chris Wilson)
Subject: re: HTML Nested Lists

lou: sez-
>Does there need to be infinite nesting support for HTML lists,
>or is 7 nesting levels enough. (sort-of like Headers)

I dunno about what other browsers do - NCSA Mosaic for Microsoft Windows
will nest to an arbitrary depth.  (Well, actually, I suppose the limit
is 32k. :^))

>Once a decision is made on this I suppose it needs to be written
>into the spec.  (If nested lists ever make it in)

Doesn't the spec sort of assume they're nested, but not specify any depth?
I don't remember...

-Chris Wilson
 NCSA WinMosaic developer
 cwilson@ncsa.uiuc.edu



From dsr@hplb.hpl.hp.com  Thu Oct 14 10:03:54 1993 BST
Message-Id: <9310140903.AA04907@manuel.hpl.hp.com>
Date: Thu, 14 Oct 93 10:03:54 BST
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: HTML Nested Lists

> Does there need to be infinite nesting support for HTML lists,
> or is 7 nesting levels enough. (sort-of like Headers)

The HTML+ DTD permits infinite nesting, but people are unlikely to want
more than about three levels in practice. Browsers must cater for more
though with a graceful degradation for deeply nested lists.

> Once a decision is made on this I suppose it needs to be written
> into the spec.  (If nested lists ever make it in)

The HTML DTD formally prohibits nested lists.

(see http://info.cern.ch/hypertext/WWW/MarkUp/HTML.dtd.html)

Dave Raggett



From luotonen@ptsun00.cern.ch  Thu Oct 14 14:53:44 1993 +0100
Message-Id: <9310141353.AA13714@ptsun00.cern.ch>
Date: Thu, 14 Oct 93 14:53:44 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: New AA release


   Ok,

the bugs I mentioned yesterday have been fixed, new release 2.12a
is available from info.cern.ch, /pub/www/...

This library also doesn't open the connection before the password
is given by the user.

-- Salut, Ari --


                     \\\\Ari Luotonen//////
                      \\\\WWW Person//////
                       \\\\\\/\\\\\//////
                        \\\\//\\\\//////
                         \\////\\//////
                          \/\/\/\/\/\/



From knill@c3serve.c3.lanl.gov  Thu Oct 14 09:20:47 1993 -0600
Message-Id: <9310141520.AA11885@c3serve.c3.lanl.gov>
Date: Thu, 14 Oct 1993 09:20:47 -0600
From: knill@c3serve.c3.lanl.gov (Emanuel Knill)
Subject: Re: previous message. 

In-reply-to: Your message of "Wed, 13 Oct 1993 22:23:42 CDT."

--------
>From:   robm@ncsa.uiuc.edu (Rob McCool)
>Subject: Re: previous message.

About NCSA httpd by directory access controls:

>Also, if you have any suggestions for the access setup as far as making it
>less confusing, or more powerful, send them this way. We don't use them at
>all on our server, so I really don't have much of an idea of what people
>want.
>

On our system basically everyone is able to link in any
information they want in controlled subdirectories
using a couple of perl scripts to generate listings.html.
I set this up just before you came out with the ~username
feature. I was hoping to disable features
such as <inc srv...> where arbitrary users can
add their scripts, but not disable access control.
That way a user can further restrict access if they want.

I would have liked it if there was an ordering
on access controls (less strict than) such that
local access in a directory is determined
by the strictest restriction in this directory or a parent directory.
Following symbolic links is determined by the access restriction
in the directory where the symbolic link is found (I think
this is almost how it works now, though an entry
with Options None for directory x in access.conf will deny
access to the directory if the directory itself is a symbolic
link). Anyway, consistent access operation of this nature
could be easily described, simply by specifying the
strictness ordering on access types.
On the other hand, it is desirable to be able
to override parent's access control locally to some extent, even
if that complicates things a bit. 
One possibility is to have a modifier for each access type,
depending on whether it can be overridden in subdirectories.

Before I think more about it, what are your priorities?
How are these by directory access controls going to interact
with the access controls which are part of the http/1.0 spec?
How much interest in these types of access controls is there?

Manny



From sanders@bsdi.com  Thu Oct 14 10:52:54 1993 -0500
Message-Id: <9310141552.AA16929@austin.BSDI.COM>
Date: Thu, 14 Oct 1993 10:52:54 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: HTML Nested Lists 

> > Once a decision is made on this I suppose it needs to be written
> > into the spec.  (If nested lists ever make it in)
> 
> The HTML DTD formally prohibits nested lists.
> 
> (see http://info.cern.ch/hypertext/WWW/MarkUp/HTML.dtd.html)

We voted on this at W^5 and decided to put nested lists in the HTML spec.

Here is a list of other stuff that was decided...

Defined Implementation Levels -- HTML: Level 0
----------------------------------------------

It was decided to add the following items to the HTML spec before it
goes out for RFC.  Browser writers should be implementing these features
RSN.  This is not the definitive list, I don't know who owns the problem
for sure.  Whoever is going to own this should speak up so people doing
implementations can ask questions.

<BR>
    I forget what this was supposed to be, I think it means force a line
    break.

<HR>
    Horizontal rule, replaces use of ---------------------

&nbsp
    Other entities will added also, wait for the spec for details
    nbsp means non-breakable white space

allow nested lists (DL NL DL)
    ala NCSA Mosaic

<IMG ALT="text to display if you can't display the image" SRC="" ISMAP>
    (ISMAP is depreciate, see below about "Accepted: SPACEJUMP")

Allow <DT>'s without <DD>'s
    e.g., <DL><DT>one<DT>two<DT>three</DL>

White Space is to be folded
    This means "foo  bar" should render the same as "foo bar".

--sanders



From roeber@axcrnb.cern.ch  Thu Oct 14 19:10:47 1993 +0100
Message-Id: <9310141810.AA11832@dxmint.cern.ch>
Date: Thu, 14 Oct 1993 19:10:47 +0100
From: roeber@axcrnb.cern.ch (Frederick G.M. Roeber)
Subject: CERN server and HTTP/1 clash?

A couple days ago I started playing with NCSA Mosaic 2.0.5 (yes, I know it's 
unsupported).  Using it, I receive a lot of errors from http servers, 
particularly the info.cern.ch server (which is presumably the CERN httpd).  The 
error is the usual "Error / Requested document (URL blah) could not be accessed. 
 The information server either is not accessible or is refusing to serve the 
document to you."  Bouncing on reload doesn't help.

I've tried telnetting to port 80 of info when I receive this message, and sure 
enough "Connection refused."  If I wait a little while, then I can telnet or 
reload.

This can't be just a server problem (like overload) -- it started exactly when I 
started using 2.0.5.  But it can't be just Mosaic, or telnetting would work 
fine.  So I wonder: might 2.0.5's new HTTP/1 support annoy old HTTP/0 servers 
like what's running on info?  

<a href="http://info.cern.ch/roeber/fgmr.html">Frederick</a>



From marca@ncsa.uiuc.edu  Thu Oct 14 13:29:37 1993 -0700
Message-Id: <9310142029.AA00983@wintermute.ncsa.uiuc.edu>
Date: Thu, 14 Oct 93 13:29:37 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: CERN server and HTTP/1 clash?

Frederick G.M. Roeber writes:
> A couple days ago I started playing with NCSA Mosaic 2.0.5 (yes, I
> know it's unsupported).  Using it, I receive a lot of errors from
> http servers, particularly the info.cern.ch server (which is
> presumably the CERN httpd).  The error is the usual "Error /
> Requested document (URL blah) could not be accessed.  The
> information server either is not accessible or is refusing to serve
> the document to you."  Bouncing on reload doesn't help.
> 
> I've tried telnetting to port 80 of info when I receive this
> message, and sure enough "Connection refused."  If I wait a little
> while, then I can telnet or reload.
> 
> This can't be just a server problem (like overload) -- it started
> exactly when I started using 2.0.5.  But it can't be just Mosaic, or
> telnetting would work fine.  So I wonder: might 2.0.5's new HTTP/1
> support annoy old HTTP/0 servers like what's running on info?

Nope, that's not it -- the CERN server is the original HTTP/1.0
server.

Believe it or not, I think the CERN server is dying on a SIGPIPE in
some circumstances (i.e. when the connection is interrupted on the
client end -- the socket breaks, the server tries to keep writing, the
client isn't trapping the signal, and boom).  I sent a note around a
while back but never got a response from Tim, and I don't know what he
plans to do about it (if anything), or even if it really is the
problem.

Marc



From qq15@liverpool.ac.uk  Fri Oct 15 09:51:02 1993 BST
Message-Id: <9310150851.AA09430@chad3-14.liv.ac.uk>
Date: Fri, 15 Oct 93 9:51:02 BST
From: qq15@liverpool.ac.uk (Pete)
Subject: Lynx / httpd / me being thick problem

I'm doing something wrong but can't see what - can anyone help ?

I am running XMosaic 1.2 and Lynx 2-0-11 clients and httpd 1.0a3.2 server
and have the following problem trying to access links of the form:

   HREF=abc_xyz.html#xyz

using Lynx at my site.

XMosaic works fine - and so does Lynx if I point it at a server at
another site that has the same sort of links.  But when I point
directly to the files at my site (file:/.....) or access them via
my server (http://....) I get the following ..

> 
> The link   file:/..../tasks_.html#files :?:  
> was requested but was not available.
> 
> Thought you might want to know.
> 
> This message was automatically generated by Lynx
> 

Any ideas ?

Pete (Mallinson)



From marca@ncsa.uiuc.edu  Fri Oct 15 08:43:32 1993 -0700
Message-Id: <9310151543.AA01968@wintermute.ncsa.uiuc.edu>
Date: Fri, 15 Oct 93 08:43:32 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: new SGML/MIME Internet Draft

Newsgroups: ncsa.ietf.announce
From: Internet-Drafts@cnri.reston.va.us
Subject: ID ACTION:draft-ietf-mime-sgml-00.txt
Originator: daemon@newton.ncsa.uiuc.edu
Reply-To: Internet-Drafts@CNRI.Reston.VA.US
Organization: National Center for SuperComputing Applications
Date: 15 Oct 93 05:06:28 GMT

--NextPart

A New Internet Draft is available from the on-line Internet-Drafts 
directories. This draft is a work item of the Mime Content Working Group of
the IETF.                                                                  

       Title     : MIME Content-types for SGML Documents                   
       Author(s) : E. Levinson
       Filename  : draft-ietf-mime-sgml-00.txt
       Pages     : 11

This document specifies how a specific compound object, a complete SGML 
document, is to be carried within a MIME message. MIME provides a flexible 
mechanism for structuring RFC 822 message bodies.  To use that mechanism 
for compound documents requires additional agreements on how the compound 
document is represented and labelled within the message body.  In addition,
this document specifies the requirements for using MIME to carry SGML 
documents within a data stream in conformance with the SGML Document 
Interchange Format (SDIF).  That format provides a mechanism for 
transferring one or more SGML documents.  Subtypes are proposed for the 
Multipart and Application content types to support SGML documents and SDIF 
within MIME.        
                                                       
Compound documents, including SGML, consist of a number of files, some of 
which may contain references to other files. Explicit indications of the 
bindings between the sender's file names and the MIME body parts are needed
to re-bind the sender's file names to ones on the recipient's system.  A 
content reference header field makes the bindings explicit.                

Internet-Drafts are available by anonymous FTP.  Login with the	
username "anonymous" and password "guest".  After logging in,
Type "cd internet-drafts".
     "get draft-ietf-mime-sgml-00.txt".
 
Internet-Drafts directories are located at:	
	                                                
     o  East Coast (US)                          
        Address:  ds.internic.net (198.49.45.10)	
	                                                
     o  West Coast (US)                          
        Address:  ftp.nisc.sri.com (192.33.33.22)
							
     o  Pacific Rim                              
        Address:  munnari.oz.au (128.250.1.21)	
	                                                
     o  Europe                                   
        Address:  nic.nordu.net (192.36.148.17)	
	                                                
Internet-Drafts are also available by mail.	
	                                                
Send a message to:  mail-server@nisc.sri.com. In the body type: 
     "SEND draft-ietf-mime-sgml-00.txt".
							
For questions, please mail to internet-drafts@cnri.reston.va.us.
							

Below is the data which will enable a MIME compliant Mail Reader 
implementation to automatically retrieve the ASCII version
of the Internet Draft.

--NextPart
Content-Type: Multipart/Alternative; Boundary="OtherAccess"

--OtherAccess
Content-Type:  Message/External-body;
        access-type="mail-server";
        server="mail-server@nisc.sri.com"

Content-Type: text/plain

SEND draft-ietf-mime-sgml-00.txt

--OtherAccess
Content-Type:   Message/External-body;
        name="draft-ietf-mime-sgml-00.txt";
        site="ds.internic.net";
        access-type="anon-ftp";
        directory="internet-drafts"

Content-Type: text/plain

--OtherAccess--

--NextPart--



From secret@hpwww.cern.ch  Fri Oct 15 17:39:02 1993 MET
Message-Id: <9310151639.AA26375@dxmint.cern.ch>
Date: Fri, 15 Oct 93 17:39:02 MET
From: secret@hpwww.cern.ch (Arthur Secret)
Subject: Gopher server dedicated to WWW presentation

:> In "marketing" WWW, it's important that information be accessible to
:> *folks who are not yet on the Web*. I've suggested to TimBL
:> that CERN run a tiny Gopher for this purpose, with perhaps a single
:> descriptive document, a Telnet Lynx session, and a GIF screen image from
:> Mosaic. This newsgroup layout would be similarly accessible to the
:> masses who haven't yet seen the Web, while splitting off the voluminous
:> developer dialogue.
:> 
:> /Rich Wiggins, Gopher Coordinator, Michigan State U
:> 
There is now a gopher server at info.cern.ch dedicated to WWW presentation !
(HREF="gopher://info.cern.ch/")

It is new and surely has plenty of omissions. Please mail them to
www-request@info.cern.ch, as well as places where to pick up screen dumps
of new products.

Arthur
--
       Arthur Secret,       phone:(41-22) 767-37-55     
Technical Student at CERN,   e-mail: secret@dxcern.cern.ch



From dale@ora.com  Fri Oct 15 10:53:12 1993 -0700
Message-Id: <9310151053.ZM29936@rock.west.ora.com>
Date: Fri, 15 Oct 1993 10:53:12 -0700
From: dale@ora.com (Dale Dougherty)
Subject: Re: Lynx / httpd / me being thick problem

We experienced the same problem with Lynx, when referencing an internal
anchor (#xyz).   Lou Montulli told me there was a bug that affected
that produced this behavior when you referenced the file using FILE:
type, but that it did not occur when you referenced the file through
the server using HTTP:.  The workaround is to run a local server and
access the files through it, rather than directly.

-- 
Dale Dougherty (dale@ora.com) 
Publisher, Global Network Navigator, O'Reilly & Associates, Inc.
103A Morris Street, Sebastopol, California 95472 
(707) 829-3762 (home office); 1-800-998-9938



From montulli@stat1.cc.ukans.edu  Fri Oct 15 13:23:20 1993 CDT
Message-Id: <9310151823.AA30938@stat1.cc.ukans.edu>
Date: Fri, 15 Oct 93 13:23:20 CDT
From: montulli@stat1.cc.ukans.edu (Lou Montulli)
Subject: Re: Lynx / httpd / me being thick problem

> 
> We experienced the same problem with Lynx, when referencing an internal
> anchor (#xyz).   Lou Montulli told me there was a bug that affected
> that produced this behavior when you referenced the file using FILE:
> type, but that it did not occur when you referenced the file through
> the server using HTTP:.  The workaround is to run a local server and
> access the files through it, rather than directly.
> 
I was able to track that bug down a little more and discovered the
problem was coming out of HTParse withing LibWWW.  The workaround
is actually a little easier than I first descibed.  If you
simple reference the file with "localhost" as the host name
you can read off of the local disk and make it work.  The reference
would look something like this.

file://localhost/PATH/FILE

Where PATH and FILE are replaced with the pathname and filename
respecively.

:lou
-- 
  **************************************************************************
  *           T H E   U N I V E R S I T Y   O F   K A N S A S              *
  *         Lou  MONTULLI @ Ukanaix.cc.ukans.edu                           *
  *                         Kuhub.cc.ukans.edu      ACS Computing Services *
  *     913/864-0436        Ukanvax.bitnet             Lawrence, KS 66044  *
  *             UNIX! Cool! I know that!  Jurassic Park - The Movie        *
  **************************************************************************



From dale@ora.com  Fri Oct 15 11:45:22 1993 -0700
Message-Id: <9310151145.ZM1732@rock.west.ora.com>
Date: Fri, 15 Oct 1993 11:45:22 -0700
From: dale@ora.com (Dale Dougherty)
Subject: ALT attribute & Conformance levels

My initial interest in writing this message was to find out
which non-graphical browsers support the ALT attribute
for the IMG tag (or for that matter do anything but ignore the
IMG tag.)  Lynx does support it and we have used it in GNN for
navigational icons.  It solves a problem for us, allowing us
to put the label in the graphic icon rather than in the markup,
while making the text available for non-graphical browsers.

We have had complaints from users of the line-mode browser
and the VMS browser as well as the curses-browser at NJIT.  
This raises a general point of interest and concern in
the WWW community.  Unfortunately,
we have to tell people that we can't accommodate those browsers
by changing the documents.

There are a number of browsers out there
that I regard as having "inactive" status.  They aren't
keeping up with current developments, and may not work 
properly for a wide range of WWW documents.  Should the WWW
project continue to list these browsers?  Is there any
kind of conformance-level test that we might devise?  I
do believe users will decide for themselves, and choose
the browsers that do perform reasonably well on the widest
range of information.  However, as Mosaic adds new 
functionality to the Web in a manner that's agreed upon
by participants of the Web, such as input forms, we
are going to find more incompatible browsers.  I would
rather see us be proactive in classifying browsers, so
that we help users identify the right browser for their
needs.  

If I can get some agreement on classification, I will
begin tell GNN subscribers that we recommend they use
a Level 1 WWW client (for example).

I'm not sure I understand all the details but we might
classify functionality according to HTML, HTTP and URLs.
Here's a first cut at defining three conformance levels. 
Please feel free to elaborate on the details.


Level 0

Supports original HTML, pre-DTD.
Supports HTTP/.9.   

Level 1

Supports HTML extensions introduced by Mosaic such as the
IMG tag.  Currently, the 1.x Mosaic clients and 
Lynx are level 1 conformant. 

Level 2

Supports HTML Input forms extensions, (partial) support
for HTML+.   Supports HTTP/1.0.

I'd appreciate any feedback.  

-- 
Dale Dougherty (dale@ora.com) 
Publisher, Global Network Navigator, O'Reilly & Associates, Inc.
103A Morris Street, Sebastopol, California 95472 
(707) 829-3762 (home office); 1-800-998-9938



From montulli@stat1.cc.ukans.edu  Fri Oct 15 15:04:20 1993 CDT
Message-Id: <9310152004.AA20509@stat1.cc.ukans.edu>
Date: Fri, 15 Oct 93 15:04:20 CDT
From: montulli@stat1.cc.ukans.edu (Lou Montulli)
Subject: Re: Gopher server dedicated to WWW presentation

> 
> :> In "marketing" WWW, it's important that information be accessible to
> :> *folks who are not yet on the Web*. I've suggested to TimBL
> :> that CERN run a tiny Gopher for this purpose, with perhaps a single
> :> descriptive document, a Telnet Lynx session, and a GIF screen image from
> :> Mosaic. This newsgroup layout would be similarly accessible to the
> :> masses who haven't yet seen the Web, while splitting off the voluminous
> :> developer dialogue.
> :> 
> :> /Rich Wiggins, Gopher Coordinator, Michigan State U
> :> 
> There is now a gopher server at info.cern.ch dedicated to WWW presentation !
> (HREF="gopher://info.cern.ch/")
> 
> It is new and surely has plenty of omissions. Please mail them to
> www-request@info.cern.ch, as well as places where to pick up screen dumps
> of new products.
> 

How about adding a script onto the info.cern.ch telnet site to give
the user a choice between the linemode browser and Lynx?  I'll
volunteer to write the script/program if desired.

:lou
-- 
  **************************************************************************
  *           T H E   U N I V E R S I T Y   O F   K A N S A S              *
  *         Lou  MONTULLI @ Ukanaix.cc.ukans.edu                           *
  *                         Kuhub.cc.ukans.edu      ACS Computing Services *
  *     913/864-0436        Ukanvax.bitnet             Lawrence, KS 66044  *
  *             UNIX! Cool! I know that!  Jurassic Park - The Movie        *
  **************************************************************************



From marca@ncsa.uiuc.edu  Fri Oct 15 16:52:02 1993 -0700
Message-Id: <9310152352.AA03512@wintermute.ncsa.uiuc.edu>
Date: Fri, 15 Oct 93 16:52:02 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: new resources meta-index

I'm starting to put together a meta-index of Internet information
resource indices:

http://www.ncsa.uiuc.edu/SDG/Software/Mosaic/MetaIndex.html

Suggestions for additions will be appreciated... when this gets
whipped into shape it'll go on the Mosaic home page, probably in the
Mosaic 2.0 menu, etc. so I'm hoping to get pretty wide coverage of the
various "real" indices and directories available out there.

Cheers,
Marc



From wmperry@mango.ucs.indiana.edu  Fri Oct 15 16:57:57 1993 -0500
Message-Id: <27825.750722277@mango.ucs.indiana.edu>
Date: Fri, 15 Oct 1993 16:57:57 -0500
From: wmperry@mango.ucs.indiana.edu (William M. Perry)
Subject: Re: ALT attribute & Conformance levels 

In response to your message dated: Fri, 15 Oct 1993 11:45:22 MST
[...]
>If I can get some agreement on classification, I will begin tell GNN
>subscribers that we recommend they use a Level 1 WWW client (for
>example).
>
>I'm not sure I understand all the details but we might classify
>functionality according to HTML, HTTP and URLs.  Here's a first cut
>at defining three conformance levels.  Please feel free to elaborate
>on the details.
>
>Level 0: Supports original HTML, pre-DTD. Supports HTTP/.9.   
>Level 1: Supports HTML extensions introduced by Mosaic such as the
>         IMG tag.  Currently, the 1.x Mosaic clients and Lynx are
>         level 1 conformant.  
>Level 2: Supports HTML Input forms extensions, (partial) support 
>         HTML+.   Supports HTTP/1.0.

    I think this is a good idea - things like the line mode browser
appear to be being left behind in the dust by the Mosaic crew.

    How about something like 'native WAIS support'?

    Just want to point out that my w3 browser for emacs would be
considered a 'Level 2'.  It has support for HTML, HTML+ (mostly), the
ALT tag in IMG, and HTTP/1.0. :) It also supports most of the <INPUT>
tags for FORMS (no pulldown menus or password entry fields yet - but
its being worked on) No native WAIS support yet though.  It should be
coming out of beta soon (end of the month hopefully)

    -Bill Perry




From marca@ncsa.uiuc.edu  Fri Oct 15 17:13:58 1993 -0700
Message-Id: <9310160013.AA03640@wintermute.ncsa.uiuc.edu>
Date: Fri, 15 Oct 93 17:13:58 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Re: ALT attribute & Conformance levels, and WAIS

"William M. Perry" writes:
>     How about something like 'native WAIS support'?

I don't think that should necessarily be a criterion -- it is much
easier to do this under Unix than on other platforms, as far as I can
tell.  What the world *really* needs is a WAIS gateway that does full
HTTP/1.0 and can pull binary data down from WAIS servers and do
comprehensive type matching.  Wouldn't be too hard to graft HTWAIS.c
from Mosaic 2.0pre5 and freeWAIS 0.1 onto, e.g., NCSA httpd, to get
that.  Then everyone could have "almost native WAIS support".  We may
do this at some point anyway but anyone who wants to jump in should be
encouraged :-).

Cheers,
Marc



From wei@sting.berkeley.edu  Fri Oct 15 22:02:10 1993 -0700
Message-Id: <9310160502.AA18380@sting.Berkeley.EDU>
Date: Fri, 15 Oct 93 22:02:10 -0700
From: wei@sting.berkeley.edu (Pei Y. Wei)
Subject: Re:  ALT attribute & Conformance levels

Before we label "levels" to various browsers, I think it'd help if we,
the Web community, collect and maintain some basic information about
different browsers. 

Up to a point, I think labeling browser conformance levels is roughly 
like viewing evolution as a ladder, rather than a branching tree. 
Sure, most browsers now share lots of common functionality, but there's
going to be specializations. 

But I agree that some basic set/group/level designation is very useful.

So, how about we flesh out a "WWW Browsers Capabilities Tabulation" chart,
then group the capabilites into some conformance designations. Such info
is useful in anycase-- as you can see below, I'm no longer sure of what's
in what browser.

			Keys:
			a = available for use.
			e = experimental status. in development but unstable.
			i = incomplete implementation.
			u = unavailable to public (yet), but exists.

			Cello
			|   Emacs
			|   |	Erwise
			|   |	|   LineMode
		        |   |   |   |   Lynx
		        |   |   |   |   |   MidasWWW
		        |   |   |   |   |   |   Mosaic-Mac
		        |   |   |   |   |   |   |   Mosaic-Win
                        |   |   |   |   |   |   |   |   Mosaic-X
		        |   |   |   |   |   |   |   |   |   TkWWW
	                |   |   |   |   |   |   |   |   |   |   ViolaWWW
		        |   |   |   |   |   |   |   |   |   |   |

Pre-DTD HTML		a   a   a   a   a   a   a   a   a   a   a

HTTP/0.9		a   a   a   a   a   a   a   a   a   a   a
HTTP/1.0		                        a?  a?  a?

mailto:						a?  a?  a?      u

HTML  <PRE>             a   a   a   a   a   a   a   a   a   a   u

      <IMG>		                    a   a   a   a       u

      <ISMAP>                               a   a   a   a       u

HTML+ <FIGURE>							ui

HTML+ input str	                                        a       u
            int	                                        a       u
            check	                                a       u
            radio	                                a       u

HTML+ tables		                                        u

Stylesheets		                                        uie


-Pei



From sanders@bsdi.com  Sat Oct 16 14:45:20 1993 -0500
Message-Id: <9310161945.AA24430@austin.BSDI.COM>
Date: Sat, 16 Oct 1993 14:45:20 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: request for new forms submission consensus 

> Tony Sanders responds:
> | I would just say that forms always get POST'ed, why would you ever need
> | some other method?

Chris McRae writes:
> Perhaps a more pertinent example is available in constructing an HTML WAIS
> interface.  After receiving search results including interesting documents
> and some additional WAIS sources, the user will want to refine the search
> by selecting the interesting items and re-searching:
> <FORM ACTION="TEXTSEARCH wais://cnidr.org:210/$search_spec?blah">
I understand what you want to do, I just disagree with putting this
into HTML and the client.

    FYI: TEXTSEARCH isn't a valid method it's just an attribute of an
    object (e.g., Accept: TEXTSEARCH).  Same goes for SPACEJUMP.  The
    query is still done with a GET like always.

All of this can be done in the protocol within the confines of POST
*and* be much more flexible.  For example, redoing your example:

document:
    Select A stored query:
    <FORM ACTION="http://server1/select"> <SELECT NAME=query> ...

request:
    POST /select HTTP/1.0
    ...
    query=BLAH-directory-of-servers.src?foobarbatbaz

response:
    HTTP/1.0 302 Found
    Location: wais://waisserver/BLAH-directory-of-servers.src?foobarbatbaz
    ...

Ta-da.  And now I can redirect all the queries on the fly (gee, think.com
is down, lets try xyz.edu) *without* having change ANY of the documents.
You need to use a different method than POST?  No problem, just reply
like this:

    HTTP/1.0 303 Method
    Method: ADMIN http://blah.com/BLAH-directory-of-servers.src
    ...

See, no need to change the protocol, or add crap to HTML or add a limitless
amount of code to EVERY client.   Hacking stuff like this into client is
an intractable solution to the problem, there are too many variables and
things are changing too fast.  The server side solution that HTTP implements
let's you scale the solution with the problem.

--sanders



From Christopher.McRae@library.ucsf.edu  Sun Oct 17 12:01:27 1993 PDT
Message-Id: <199310171854.AA17613@library.ucsf.edu>
Date: Sun, 17 Oct 1993 12:01:27 PDT
From: Christopher.McRae@library.ucsf.edu (Christopher McRae)
Subject: Re: request for new forms submission consensus 

Tony Sanders writes:
> All of this can be done in the protocol within the confines of POST
> *and* be much more flexible.  For example, redoing your example:
> 
[ examples deleted ]
> 
> Ta-da.  And now I can redirect all the queries on the fly (gee, think.com
> is down, lets try xyz.edu) *without* having change ANY of the documents.
> You need to use a different method than POST?  No problem, just reply
> like this:
> 
> See, no need to change the protocol, or add crap to HTML or add a limitless
> amount of code to EVERY client.   
> 

Nuff said.  I didn't realize you could use the protocol in that way, but it's
obviously better to do so rather than encoding such things within the document.

Is such functionality already available within plexus?  the other WWW servers?
What about client support?

Chris
--------------------------------------------------------------------------------
Christopher McRae			mail: mcrae@ckm.ucsf.edu
UCSF Center for Knowledge Management	at&t: 415/476-3577
530 Parnassus Avenue, Box 0840	 	fax: 415/476-4653
San Francisco, California 94143



From germuska@antioch.acns.nwu.edu  Sun Oct 17 14:00:27 1993 -0500 (CDT)
Message-Id: <9310171900.AA05161@antioch.acns.nwu.edu>
Date: Sun, 17 Oct 1993 14:00:27 -0500 (CDT)
From: germuska@antioch.acns.nwu.edu (Joe Germuska)
Subject: Re: Jughead (fwd)

Rich Wiggins wrote:
> From daemon@nxoc01.cern.ch  Sat Oct 16 23:02:01 1993
> Message-Id: <9310170351.AA14774@dxmint.cern.ch>
> Date:         Sat, 16 Oct 93 23:48:32 EDT
> From: Rich Wiggins <WIGGINS@msu.edu>
> Subject:      Re: Jughead
> To: Oscar Nierstrasz <oscar@cui.unige.ch>, www-announce@nxoc01.cern.ch
> In-Reply-To:  Your message of Wed, 13 Oct 1993 12:05:20 +0100
> 
> 
> It's nice to see an Archie-like service for the Web, but are you
> aware that a tool by the name Jughead has been out in the Gopher
> community for many months now?  It's not as widely used as
> Veronica, but it is in use at numerous sites, especially as a
> local index tool.  You might minimize confusion by choosing
> a different name for the WWW index tool.
> 
> /Rich Wiggins, Gopher Coordinator, Michigan State U
> 


I found WWW-Jughead to be a nice tool on my first couple of tries as well,
although I still don't have a good idea of what to ask for -- I was trying
to locate URLs of the HTML spec and other stuff, and ended up giving up and
going to the major home pages...

Anyway, don't forget "reggie" and "betty"; or maybe "Mr. Weatherbee?"

	Joe
-- 
joe germuska | j-germuska@nwu.edu | +1 708 467 4456 | ACNS Northwestern Univ. 
       Instructional Technologies Group - Technical Support Services
"Free the people with music..." 



From marca@ncsa.uiuc.edu  Sun Oct 17 14:15:50 1993 -0700
Message-Id: <9310172115.AA09416@wintermute.ncsa.uiuc.edu>
Date: Sun, 17 Oct 93 14:15:50 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: gopher+ ask blocks to wais -- why not html+ forms?

Newsgroups: comp.infosystems.gopher
From: gilbertd@sunflower.bio.indiana.edu (Don Gilbert)
Subject: Go-Ask-WAIS customizes WAIS searches for Gopher+
Nntp-Posting-Host: sunflower.bio.indiana.edu
Organization: Biology, Indiana University - Bloomington
Date: Sun, 17 Oct 1993 19:08:02 GMT


Go-ask-wais provides a link from Gopher+ ASK dialogs to WAIS index files,
allowing you to add various customizations to the Gopher-WAIS query.
Basically it is a script that processes the ASK query, and a subprogram
that queries WAIS indices and returns the matches in Gopher directory
format.

Example usage:

 -->  1.  Search FlyBase Genes data/ <??>
      2.  Search GenBank (latest full release)/ <??>

 +-------------------------Search FlyBase Genes data--------------------------+
 |                                                                            |
 | _____ Search data by key words _____                                       |
 | Search for?       red                                                      |
 | Maximum matches:  100                                                      |
 | ___________________________________________________                        |
 | The default search finds records matching all words.                       |
 | Use `and' and `not' to eliminate useless matches.                          |
 | Use `*' (as in gen*) to match partial words.                               |
 | Want more help?   no                                                       |
 |                                                                            |
 |       [Switch Fields: TAB] [Cancel: ^G] [Erase: ^U] [Accept: Enter]        |
 |                                                                            |
 +----------------------------------------------------------------------------+

The main ASK script processes the above query and returns the results below
including 
  1. a list of all matches as one document
  2. a second ASK dialog that lets user select subset items to return
     as one document. 
  3. optional help files
  4. optionally various VIEW formats.
-------------------
                           Search FlyBase Genes data

 -->  1.  Titles of matches to "red".
      2.  Select items to return as one document. <??>
      3.  (1)  Act88F  Actin-88F  genemap: 3-57.1  cytomap: Placed in 88F by...
      4.  (2)  Aldox-1  Aldehyde-oxidase-1  genemap: 3-57.2.
      5.  (3)  amb  amber  genemap: 1-6.8..
		...


Installing Go-ask-wais on your Gopher server

Assumptions:
	have U.Minnesota gopherd server version 2.04 or later, and its working.
	have some WAIS variant linked in and working w/ gopherd
	have perl interpreter

Available:
	gopher or ftp to ftp.bio.indiana.edu, find it as
	IUBio-Software+Data/util/gopher/go-ask-wais.tar.Z	
	
Author:  
	don gilbert, software@bio.indiana.edu, October 1993
	no copyright restrictions are imposed.

-- 
-- d.gilbert--biocomputing--indiana u--bloomington--gilbertd@bio.indiana.edu



From Christopher.McRae@library.ucsf.edu  Sun Oct 17 12:34:04 1993 PDT
Message-Id: <199310171927.AA17807@library.ucsf.edu>
Date: Sun, 17 Oct 1993 12:34:04 PDT
From: Christopher.McRae@library.ucsf.edu (Christopher McRae)
Subject: Re: request for new forms submission consensus 

Dave Raggett writes:
> Frans van Hoesel has pointed out the value in being able to
> use a checkbox or an icon or whatever to submit forms. In 
> a tax return there might be a load of questions that become
> irrelevant when you click the checkbox to indicate that you
> are "single". In this case the form would be submitted and
> the server would then return it with the irrelevant questions
> greyed-out:
> 
>	 Single? <INPUT NAME="single" TYPE=checkbox SUBMIT>
> 
> The idea here is to make SUBMIT an independent attribute
> that can be used with arbitrary field types. You could
> have multiple "submit buttons" in the same form. This way
> authors can choose whether the form contents gets checked
> after each field on a per field basis.

  Why not allow/define the use of MIME multipart messages for such applications?
That is, rather than using the SUBMIT attribute as above to retreive a
customized version of the form, why not include named sections of a document
section and define EXPAND/COLLAPSE attributes to control display?  For instance,

    MIME-Version: 1.0
    Content-Type: multipart/mixed;
        boundary=unique-boundary-1

    --unique-boundary-1
    Content-Type: application/html-form

    [some stuff here]
    <INPUT NAME="single" TYPE=checkbox EXPAND=single_form COLLAPSE=couple_form>
    [more stuff here]

    --unique-boundary-1
    Content-Type: application/html-form
    Part-Name: single_form

    [ single-specific stuff goes here ]

    --unique-boundary-1--
    Content-Type: application/html-form
    Part-Name: couple_form

    [ couple-specific stuff goes here ]

    --unique-boundary-1--

  Note that one could also use only one of EXPAND or COLLAPSE to toggle display
of a document section as opposed to selecting between alternate sections.

Another example:
<SELECT SEVERAL NAME="what-to-do">
<LI EXPAND=book_selection_form> Read A Book
<LI EXPAND=walking_trail_map> Take a Walk
<LI EXPAND=bagelry_menu> Buy a Bagel
<LI EXPAND=tv_guide> Watch TV
</SELECT>

  This model would work well for those applications where the overhead of
transferring possibly irrelevant sections of a document was low relative to
the overhead of performng multiple GETs.

Chris
--------------------------------------------------------------------------------
Christopher McRae			mail: mcrae@ckm.ucsf.edu
UCSF Center for Knowledge Management	at&t: 415/476-3577
530 Parnassus Avenue, Box 0840	 	fax: 415/476-4653
San Francisco, California 94143



From marca@ncsa.uiuc.edu  Sun Oct 17 17:09:14 1993 -0700
Message-Id: <9310180009.AA09929@wintermute.ncsa.uiuc.edu>
Date: Sun, 17 Oct 93 17:09:14 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: mtv.com

Note second-to-last paragraph...

Marc

----====----====----====----====----====----====----====----

Welcome to MTV.COM!!!

Well, it's been an interesting startup, I've been learning alot about UNIX
and the Net as I go along, and so far it's been fun.

Here's a brief rundown on this site:

First and foremost I have to make it very clear that mtv.com is NOT
sponsored by MTV Networks. Although they are aware of my cyberspace
dwellings they aren't yet ready to commit to a project like this, but I
have their bessing in spreading the gospel ofcourse ;-)

So this ofcourse means that I am paying for my T1 connection myself, which
is maintained by the fine folks at Digital Express.

Although the startup has been rather slow, look for this site to be really
hoppin' within the next couple of weeks. My personal assistant Ken Clark
(ken@mtv.com) will be posting a weekly newsletter, we'll be putting
bloopers and outtakes up in quicktime format, look for digital presskits
to appear, and yes, even mailboxes for Beavis and Butthead, huh, huh,heh.heh.

I intend to post programming grids for MTV along with important
development in the music bizz.

Please also note the "Cyber-Sleaze" which is available through gopher, ftp
or the extended versions which are on the listprocessor, the mailing list
is cyber-sleaze-request@mtv.com and you should place the following in the
message :

subscribe CYBER-SLEAZE your name

This extended reports are shareware, and donations are appreciated.


>This just in...I'm in the process of of setting up a WWW server that will
blow the socks off your Mosaic viewer!<

This is just the start of mtv.com and I hope that you will enjoy your stay
here. Suggestions and comments are always welcome!

All for now.

Adam Curry
----====----====----====----====----====----====----====----



From boydll@tansei.cc.u-tokyo.ac.jp  Mon Oct 18 13:41:11 1993 JST
Message-Id: <9310180441.AA17963@tansei1.tansei.cc.u-tokyo.ac.jp>
Date: Mon, 18 Oct 93 13:41:11 JST
From: boydll@tansei.cc.u-tokyo.ac.jp (Boydll)
Subject: Subscribe to mailing lists

subscribe www-talk



From bellverc@pereiii.uji.es  Mon Oct 18 08:30:47 1993 +0000
Message-Id: <9310180730.AA25258@dxmint.cern.ch>
Date: Mon, 18 Oct 1993 08:30:47 +0000
From: bellverc@pereiii.uji.es (bellverc@pereiii.uji.es)
Subject: Macintosh BBEdit HTML extensions beta 2

Release beta 2 of BBEdit HTML extensions corrects some bugs reported by
Kevin Altis <kevin@scic.intel.com> and Jek Kian Jin <kianjin@ncb.gov.sg>
(many thanks).

Fixed features are:

- the comment extension now puts a --> at the end of
  commented line, not just >

- the header extension closes headers withn </Hn>, not </H>

And a new feature:

- the specials translation extension now gives you two choices:
  translating eight bit characters and/or "special" characters
  (<, >, &, and ") that must be quoted. Please note that you
  should translate these special characters *before* inserting
  any HTML tag that uses them.

The extensions package is available at sumex-aim.stanford.edu,
directory /info-mac/text

______________________________________________________________________________
Carles Bellver   <bellverc@si.uji.es>    No mention shall be made of coral,
Universitat Jaume I                      or of pearls: for the price of wisdom
E-12071 Castello de la Plana             is above rubies.
SPAIN                                    Job, 28:18



From Christopher.McRae@library.ucsf.edu  Mon Oct 18 12:36:15 1993 PDT
Message-Id: <199310181929.AA27570@library.ucsf.edu>
Date: Mon, 18 Oct 1993 12:36:15 PDT
From: Christopher.McRae@library.ucsf.edu (Christopher J. McRae)
Subject: FOLLOW-UP REPORT: Initial SIG-Web meeting (held 10/7/93)

10/18/93

FOLLOW-UP REPORT: Initial SIG-Web meeting (held 10/7/93)

  I'm very pleased to report that the first SIG-Web meeting was a definite
success!  We had about 70 people show up from many different sorts of
institutions from all over the Bay Area and beyond; I believe most of the
people found on the "List of Attendees" actually showed up.  That means we
had participants from Industry, Government (including local, state, and
federal levels), Education (including high school, college, and university
levels), and also from the Public Service sector.
  
  I failed to post the original SIG-Web announcment to the gopher list.  I
thought I had, but apparently I screwed up.  My apologies to those on that
list who would have come, but didn't know about it.  Thanks to Mitra for
pointing out the omission.  

- The SIG-Web home page is at
    <http://www.library.ucsf.edu/www/public/sig-web/index.html>

- A text version of the original announcement is at
    <file://www.library.ucsf.edu/www/public/sig-web/announcement.txt>

- The list of attendees is at
    <file://www.library.ucsf.edu/pub/sig-web/attendees.txt>
    OR
    <http://www.library.ucsf.edu/pub/sig-web/attendees.txt>
    OR
    <http://www.library.ucsf.edu/pub/sig-web/attendees.html>
- My notes are at
    <file://www.library.ucsf.edu/pub/sig-web/notes.071093.txt>
    OR
    <http://www.library.ucsf.edu/pub/sig-web/notes.071093.txt>
- A recording of the meeting will be available in sometime soon; we'll let you
know when we get it installed.

Here is a brief outline of the meeting -

2:00 PM	-- Meeting Begins
    - Welcome
	- SIG-Web is a Special Interest Group devoted to distributed information
	systems and related standards.  This includes, but is not necessarily
	limited to WorldWideWeb, WAIS and Gopher, as well as the Z39.50, HyTime,
	and SGML standards.  
    - Announcements
	- Thank you WAIS, Inc. and O'Reilly & Associates for generously donating
	$100 per meeting, as well as for providing moral support to the SIG-Web
	effort.
    - Who's who (or who's here)
	- We are a rather diverse group in many respects.  We have people here
	from the computer and telecommunications industries, from university
	libraries and other academic research institutions, from the education
	community, publishers, historians-and-museum-curators, and from the
	state government.  There are representatives here from eight University
	of California institutions, as well as from Stanford University, San
	Francisco State University, the University of San Francisco, and even
	Cal Poly San Luis Obispo.  In addition, we have members of the San
	Francisco Art Institute, San Francisco Public Library the California
	Academy of Sciences, California Historical Society, the American
	Astronomical Society and from NASA's Ames Research Center.  Pacific
	Bell, Xerox PARC, the Santa Cruz Operation, Silicon Graphics, Amdahl,
	Lockheed, and Netcom are among the *high-tech* companies with us today.
	The publishing industry is represented by O'Reilly & Associates, and
	also by John Wiley & Sons.
    - SIG-Web: how and why
	- We are all here because we share an interest in information and
	communication, even though we may each tend to focus on different
	aspects of the information production and delivery process.  
	- Hopefully, this SIG will be able to serve the needs and interests of
	both the software developers and the content providers among us, and
	thereby ultimately serve the interests of the entire community.
	- One of the goals of this SIG is to inform and educate.  With support
	from all of you, we will be working to make all of these technologies
	more accessible to novice and non-technical users.
	- More later
    - Brief description of Gopher, WWW, WAIS and underlying technologies
        - See <http://www.library.ucsf.edu/pub/sig-web/notes.071093.txt> for
	full text.
    - Terry Allen's SGML talk
	- Terry Allen is the Editor of O'Reilly & Associates Digital Media Group
	- SGML references
	    - The SGML Handbook, by Charles F. Goldfarb
		- The definitive reference, but not quite as readable
	    - Practical SGML, by Eric van Herwijnen
		- Best of the bunch, perhaps (but watch out for the cover!)
	    - SGML, An Author's Guide, by Martin Bryan
		- Well written, but primarily intended for authors
	- Description of SGML and how it is being used at various places,
	including O'Reilly & Associates.
	- Terry's presentation was followed by a lively and rather interesting
	discussion.
	- See the audio recording for more details. (not available yet)
    - Break (more discussion)
    - About the CKM
	- The Center for Knowledge Management, or CKM, is a branch of the UCSF
	Medical Library.  Our mission is to boldly go where no librarian, or
	computer scientist for that matter, has gone before.  We are focused on
	developing state-of-the-art academic information systems, specifically
	with respect to the needs of the Health-Care research community.
	- In the course of fulfilling this mission, the library will be
	transformed from a static repository of published materials to an online
	source of information-related expertise and services.  We see the
	library as the campus' gateway to the internet's universe of online
	information.
	- Classes are taught through the Library's Interactive Learning Center,
	which maintains a lab of computers and audio-visual equipment.
	- As part of our commitment to becoming a nexus of information-
	processing expertise for the campus community, the library is building
	what we call an "Informatics Federation" by providing space and support
	services to the Laboratory for Radiological Imaging and to people from
	the Computer Graphics Lab.
	- The CKM is composed of two groups.  The Computer and Communication
	Services group is primarily dedicated to providing support services for
	the library and campus information systems.  The other half of the CKM
	is the Innovative Software and Systems Group, which is focused on
	developing software systems for Knowledge Management such as the
	WorldWideWeb.
	- Michael Doyle is the Director of the CKM.
	- ISSG
	    - Staff
		- David Martin is Asst. Dir. of CKM in charge of the ISSG.
		- In addition to David, the ISSG is Chris McRae, Marc Salomon,
		and Cheong Ang.
		- Marc is, among other things, our WAIS and Postgres expert.
		- Cheong is working mostly on computer graphics, visualization,
		and distributed processing.
		- Chris knows a little bit about everything, but not much about
		anything; lately, he spends a lot of time answering email.
	    - Projects
		- Added support for TIFF images and postscript printing to
		Xmosaic, a WorldWideWeb client.
		- Worked on image decoding, WAIS searching, and access control
		for Plexus, a WorldWideWeb server.
		- RedSage
		    - Delivers an online collection of Springer-Verlag medical
		    journals, complete with full-text searching and automatic
		    notification on the arrival of new issues which match a
		    user's specified interests.
		    - For more information, see <http://www.library.ucsf.edu/www/public/Applications/RedSage/Abstract.html>
		- Visible Embryo
		    - An effort to electronically preserve a medically valuable
		    collection of hundreds of human embryos.
		    - Please see <http://www.library.ucsf.edu/www/public/Applications/VisibleEmbryo/Abstract.html>
    - About the CKM and SIG-Web
	- The Center for Knowledge Management is commited to supporting SIG-Web.
	- We are maintaining the sig-web mailing list, and a WorldWideWeb/FTP
	server with related information.
	- We intend to build up an archive of related software, papers,
	newsgroups, and mailing lists.  We are investigating automatically
	waisindexing those archives and converting them to HTML hypertext.
	- We will be building a biblography of books and papers of interest to
	the SIG-Web community.
	- We will be teaching various internet-related courses through the
	Interactive Learning Center.  Priority for these classes would go first
	to UCSF people, and then to SIG-Webbers.
	- We're investigating the possibility of using our staff of professional
	librarians to formally catalogue network resources.
	- We will be able to provide limited support to new sites which need
	some help in getting started.
	- We may be able to provide hardware resources to information providers
	who do not yet have network connectivity or who would otherwise be
	unable to publish their material.
	- We will help coordinate a volunteer-based mentorship program through
	which experienced people help set-up and educate new users.
	- We will be continuing to develop documentation and software tools
	for online publishing, and continue to make those resources available
	via FTP and the Web.
	- We will help coordinate a volunteer effort to get experts talking to
	those in need of help.
    - Other Projects
	- San Francisco Freenet (community network)
	    - a network which available free of charge all members of the
	    community.
	    - Now forming
	    - For more information contact Professor Gerald Eisman, who is
	    Chair of the Computer Science department at San Francisco State
	    University (eisman@walnut.sfsu.edu).
	- Richmond High School (Getting them networked)
	    - Currently on the internet as coco.ca.rop.edu.
	    - Part of a larger project called the Regional Occupational Program,
	    or ROP, which includes networking the entire school district there
	    in Richmond, CA.
	    - ROP is the brainchild of Les Radke, who has really done most of
	    the work.  His email address is les@coco.ca.rop.edu.
	    - The wires are in place, and a good deal of equipment is available.
	    The internet feed has been live for the last few weeks and we've
	    been using it.
	    - We need more money, more equipment, and especially volunteers who
	    have some technical expertise and who would be willing to act as an
	    email mentor to a high school student learning about the technology.
	    - Note that the primary focus of ROP is to give the students an
	    opportunity to learn skills which will make them competitive in
	    seeking the best jobs available.
    - SIG-Web organization/administrivia
	- Chris McRae of UCSF-CKM was nominated/elected President.
	- Marc Salomon of UCSF-CKM was nominated acting V.P.
	- Robert Hartman of Informix graciously volunteered to act as
	Treasurer/Secretary.
	- Next meeting: 11/19/93, 2-5 PM
	    - At Xerox PARC in Palo Alto, courtesy of Larry Masinter.
	    - Additional information coming soon.
        - Future Meetings
	    - No specific dates yet, working...
	    - WAIS, Inc. will host our December meeting.  Brewster Kahle will
	    be the speaker.  More info when it's available.
	    - In addition, the following organizations have committed to hosting
	    a SIG-Web meeting (but not necessarily in this order)
		- Silicon Valley Public Access Link
		- Pacific Bell
		- Stanford Linear Accelerator Center
		- UC Office of the President/UC Berkeley
	    - If you would like to host a meeting or have any other
	    administrative comments/suggestions/questions, please send email
	    to mcrae@ckm.ucsf.edu.

Chris
-----------------------------------------------------------------------
Christopher McRae			mail: mcrae@ckm.ucsf.edu
UCSF Center for Knowledge Management	at&t: 415/476-3577
530 Parnassus Avenue, Box 0840	 	fax: 415/476-4653
San Francisco, California 94143



From germuska@antioch.acns.nwu.edu  Tue Oct 19 10:00:28 1993 -0500 (CDT)
Message-Id: <9310191500.AA12920@antioch.acns.nwu.edu>
Date: Tue, 19 Oct 1993 10:00:28 -0500 (CDT)
From: germuska@antioch.acns.nwu.edu (Joe Germuska)
Subject: <OWNER> tag in head? and other things that would be nice...

I am sure this has been talked about, but I don't see any answers...

It'd be nice to be able to easily contact the owner of a document you are
reading on the web... specifically, I was browsing GNN and wanted to
suggest a change to a reference to info I maintain; unfortunately, there
wasn't even a tag at the end of the page listing a contact (I know I could
find the address as soon as I really looked, but...).

But why shouldn't you just be able to fire a message off to the owner of
a document.  It seems like it'd be easy enough to declare a new tag that
would only be in the header of docs... <OWNER> seems best to me.  Really
cool browsers could then use that to automatically address mail, and
not-so-cool browsers could at least provide that information on demand.
Obviously, I think this info should be a legal e-mail address, although
maybe (don't know why) it should be a real name and a separate tag created
for a corresponding e-mail address...

Another direction I think would be quite useful would be the development of
HTTP "environment variables"...  work out a method so that servers can ask
clients for certain frequently useful information, such as the users e-mail
address, perhaps the user's snail mail address or shirt-size...  couldn't
it even be open-ended?  That is, if a client receives a request for an
undefined variable, it could ask, and add that variable to a .browserrc
type file...

As forms get more widely implemented, I think this would become quite
useful...

	Joe
(who's on the verge of actually getting paid to develop hypertext - yay!)

-- 
joe germuska | j-germuska@nwu.edu | +1 708 467 4456 | ACNS Northwestern Univ. 
       Instructional Technologies Group - Technical Support Services
"Everything is music." - Billy Higgins



From wmperry@mango.ucs.indiana.edu  Tue Oct 19 10:45:44 1993 -0500
Message-Id: <29321.751045544@mango.ucs.indiana.edu>
Date: Tue, 19 Oct 1993 10:45:44 -0500
From: wmperry@mango.ucs.indiana.edu (William M. Perry)
Subject: HTTP/1.0 & HTML+ questions

Hello all,

   I am real close to having all the redirection from HTTP/1.0 and most of
the stuff for HTML+ finished in my emacs browser, and just had a few
questions that I'm not sure have been specified yet.

1. When a URL has been moved, and a response code of 301, 302, or 303 has
   been returned, must the url be fully specified or could it be returned
   as Location: somefile.html, where the original URL was
   http://someserver/thisfile.html?

2. In HTML+, are forms allowed inside of <PRE> formatted sections?  I know
   <PRE> is outdated in HTML+, but should it be allowed?  If its not, I
   think it should be added to the spec - the only thing a <FORM> shouldn't
   be allowed inside of is another form.

I might also just be overlooking something in the spec, but I couldn't find
anything in the most recent HTTP spec from cern - it just says it is
expecting a url.

Thanks,
   Bill P.



From sanders@bsdi.com  Tue Oct 19 11:46:54 1993 -0500
Message-Id: <9310191646.AA01484@austin.BSDI.COM>
Date: Tue, 19 Oct 1993 11:46:54 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: <OWNER> tag in head? and other things that would be nice... 

> It'd be nice to be able to easily contact the owner of a document you are
> reading on the web... specifically, I was browsing GNN and wanted to
> suggest a change to a reference to info I maintain; unfortunately, there
> wasn't even a tag at the end of the page listing a contact (I know I could
> find the address as soon as I really looked, but...).
How about just using
    <LINK REV="made" HREF="http://www.bsdi.com/hyplan/sanders.html">
Which is already in the spec.  If you want to send the "owner" (aka the
"maker") then your browser should use the POST method to that address.
This would also allow you to point to things like newsgroups (which the
browser would clearly point out before you posted the article of course).

--sanders



From kevin@scic.intel.com  Tue Oct 19 10:43:31 1993 -0800
Message-Id: <9310191747.AA13082@rs042.scic.intel.com>
Date: Tue, 19 Oct 1993 10:43:31 -0800
From: kevin@scic.intel.com (Kevin Altis)
Subject: sgmls HTML validation

It has been mentioned here a few times that you can't validate HTML with
WWW client X. In order to do validation you have to have an SGML parser and
an HTML(+) DTD, right? A few more questions and a suggestion.
Is "sgmls" the only public domain or maybe free SGML parser available? What
are people using commercially?
Do we have working DTDs for HTML and HTML+?
Which machines has sgmls been ported to? It seems like validation may be
Unix centric right now.
How long does validation usually take say for a formatted 3-4 page HTML file?

If validation doesn't take too long and an HTML file could be passed on to
an HTTP server (PUT?) then maybe sgmls validation could be handled like any
other server query though it would be big query? On the ncsa httpd this
might be /htbin/sgmls. I'm sure Tony will have support in Plexus, fifteen
minutes after he receives this post ;-)

If sgmls has been ported to a lot of Unix platforms, DOS/Windows and the
Mac... maybe this isn't an issue, but after asking around it seems a lot of
people are "validating" their HTML by seeing if it works with their main
client software!

ka




From montulli@stat1.cc.ukans.edu  Tue Oct 19 12:53:42 1993 CDT
Message-Id: <9310191753.AA15129@stat1.cc.ukans.edu>
Date: Tue, 19 Oct 93 12:53:42 CDT
From: montulli@stat1.cc.ukans.edu (Lou Montulli)
Subject: Re: <OWNER> tag in head? and other things that would be nice...

> 
> I am sure this has been talked about, but I don't see any answers...
> 
> It'd be nice to be able to easily contact the owner of a document you are
> reading on the web... specifically, I was browsing GNN and wanted to
> suggest a change to a reference to info I maintain; unfortunately, there
> wasn't even a tag at the end of the page listing a contact (I know I could
> find the address as soon as I really looked, but...).
> 
> But why shouldn't you just be able to fire a message off to the owner of
> a document.  It seems like it'd be easy enough to declare a new tag that
> would only be in the header of docs... <OWNER> seems best to me.  Really
> cool browsers could then use that to automatically address mail, and
> not-so-cool browsers could at least provide that information on demand.
> Obviously, I think this info should be a legal e-mail address, although
> maybe (don't know why) it should be a real name and a separate tag created
> for a corresponding e-mail address...

There is already a structure that does this.  
<link rev=made href="mailto:montulli@ukanaix.cc.ukans.edu">
defines me as the "maker" of a document.

Unfortunatly the only really cool browser that currently supports
this feature is Lynx :)

> 
> Another direction I think would be quite useful would be the development of
> HTTP "environment variables"...  work out a method so that servers can ask
> clients for certain frequently useful information, such as the users e-mail
> address, perhaps the user's snail mail address or shirt-size...  couldn't
> it even be open-ended?  That is, if a client receives a request for an
> undefined variable, it could ask, and add that variable to a .browserrc
> type file...

A From: tag is passed to the server from clients.  From: is often
the mail address of the user.  Again, the only really cool browser
that I know supports this is Lynx, :) which passes the mail address
if the user chooses to fill it in.

> 
> As forms get more widely implemented, I think this would become quite
> useful...
> 
> 	Joe
> (who's on the verge of actually getting paid to develop hypertext - yay!)
> 

:lou
-- 
  **************************************************************************
  *           T H E   U N I V E R S I T Y   O F   K A N S A S              *
  *         Lou  MONTULLI @ Ukanaix.cc.ukans.edu                           *
  *                         Kuhub.cc.ukans.edu      ACS Computing Services *
  *     913/864-0436        Ukanvax.bitnet             Lawrence, KS 66044  *
  *             UNIX! Cool! I know that!  Jurassic Park - The Movie        *
  **************************************************************************



From marca@ncsa.uiuc.edu  Tue Oct 19 13:39:53 1993 -0700
Message-Id: <9310192039.AA18491@wintermute.ncsa.uiuc.edu>
Date: Tue, 19 Oct 93 13:39:53 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: HTTP/1.0 & HTML+ questions

"William M. Perry" writes:
> 1. When a URL has been moved, and a response code of 301, 302, or 303 has
>    been returned, must the url be fully specified or could it be
>    returned as Location: somefile.html, where the original URL was
>    http://someserver/thisfile.html?

Let's say "fully specified", to keep things straightforward.

> 2. In HTML+, are forms allowed inside of <PRE> formatted sections?  

YES!

>    I know <PRE> is outdated in HTML+, but should it be allowed?  If
>    its not, I think it should be added to the spec - the only thing
>    a <FORM> shouldn't be allowed inside of is another form.

Agreed.

Marc



From terry@ora.com  Tue Oct 19 12:17:56 1993 PDT
Message-Id: <199310191917.AA25948@rock.west.ora.com>
Date: Tue, 19 Oct 1993 12:17:56 PDT
From: terry@ora.com (Terry Allen)
Subject: FORM, allowable contexts

In response to W Perry, 

>    I know <PRE> is outdated in HTML+, but should it be allowed?  If
>    its not, I think it should be added to the spec - the only thing
>    a <FORM> shouldn't be allowed inside of is another form.

Surely a FORM shouldn't be allowed inside a H1 or B?

-- 
Terry Allen  (terry@ora.com)
Editor, Digital Media Group
O'Reilly & Associates, Inc.
Sebastopol, Calif., 95472



From SNGABY%LSUVM.BITNET@cearn.bitnet  Tue Oct 19 15:30:52 1993 CDT
Message-Id: <9310192100.AA10839@dxmint.cern.ch>
Date: Tue, 19 Oct 93 15:30:52 CDT
From: SNGABY%LSUVM.BITNET@cearn.bitnet (Gabriela Segarra)
Subject: Question: volume generated by WWW vs. Gopher

To the WWW people,
I have a question about the volume of messages generated by the WWW.
Our University has been running a gopher server for some time and we
have now a brand new WWW server. The people running the gopher server
are reluctant to this new initiative and are asking me wether the WWW
transactions will increase the traffic on our almost saturated network.
So, I was wondering if somebody has any numbers to help me defend the
WWW, possibly comparing the amount of data transferred in a transaction
by gopher and the WWW. I think it should not make any difference, but
still ...
I would appreciate any information or pointer to the proper place.
Thanks,
Gaby


........................................................................
:  Gabriela Segarra, M.Sc.         : e-mail:                           :
:  Information Technology Support  :         SNGABY@LSUVM.bitnet       :
:  Louisiana State University      :   or    SNGABY@LSUVM.SNCC.LSU.EDU :
........................................................................



From marca@ncsa.uiuc.edu  Wed Oct 20 06:10:55 1993 -0700
Message-Id: <9310201310.AA03127@wintermute.ncsa.uiuc.edu>
Date: Wed, 20 Oct 93 06:10:55 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: NCSA Mosaic for X 2.0 prerelease 6 available

Ladies and gentlemen, the moment you've all been waiting for...

......ftp.ncsa.uiuc.edu in /Mosaic/prerelease.  Source, plus binaries
for Sun, IBM, SGI.

This prerelease is another step on the road to 2.0.

There are no known crash conditions, other than a few obscure
system-related problems (e.g. crash in XtKeysymToKeycodeList) that we
can't find ways to work around.  If this prerelease crashes on you for
any reason, please report the crash with a full dbx stack traceback.

There are no known hang conditions, except for one obscure problem
we're having with certain files on certain FTP servers (well, only
uxc.cso.uiuc.edu, as far as we know).  Apparently the expected final
response from the FTP server during a file retrieval transaction isn't
being sent in some cases, causing Mosaic to hang in a network read.
It's unclear whose fault this is, but the problem will probably go
away one way or the other since we'll be doing interruptable read()'s
by 2.0.  Suggestions are welcome... 

Finally, transparent uncompression still doesn't work.  Sorry :-).

If you make this prerelease available to normal users, please make
sure they understand that it is not a full, stable release and that it
is bound to have problems and instabilities that will be fixed by the
time 2.0 is really released.

Changes and additions in this prerelease include:

 o Added CERN authentication code with GUI support (see CERN docs and 
   testcases). 
 o Added/revised scrolled lists, option menus, multiline text areas support in
   fill-out forms; see docs. 
 o Added local directory icons and enhanced FTP icons (thanks to Charles
   Henrich). 
 o New toggle button for selecting delayed image loading on the fly. 
 o New "Load Images In Current" menu option to load all (delayed) images
   in current document. 
 o Improved handling of wide range of HTTP/1.0 response codes (see BSDI
   testcases). 
 o Fixed really stupid problem with networking -- numeric addresses were
   being handled incorrectly. 
 o Fixed coredump when reloading initial document that had been interrupted
   first time it was being loaded; also added internal fixes to make doing
   things with no document loaded at least not crash the program. 
 o Fixed bug when retrieving ftp://mailbase.ac.uk/pub/lists-k-o/nir (it's not
   accessible but a spurious bug report was getting dumped to stderr). 
 o Made FTP directory handling more flexible/accurate (testcase here --
   should see "lists" directory). 
 o Handle HTTP0/HTTP1 socket-level protocol clash a little better (e.g. 
   http://sunsite.unc.edu:8988/expo/nobeamup_map.html?49,51 -- might not
   be a valid testcase anymore). 
 o Binary transfer bug fixed -- it works right now. 
 o Transparent uncompression still doesn't work (sorry), but the mutant
   compressed filename munging code that was alive in pre5 is disabled now,
   and compressed files are treated as binary. 
 o Worked around strange Motif bug causing crashes on some platforms with
   message about accelerators. 
 o Now properly recognize comments ('#' first character in line) in extension
   maps. 
 o Fixed problem with encoding of 8-bit characters in fill-out forms and
   elsewhere. 
 o Made MIME type handling case insensitive in HTTP and WAIS code. 
 o Enhanced URL canonicalization (safe handling of trailing period in fully
   qualified hostnames, plus lowercasing of all hostnames). 
 o Cleaned up some big direct WAIS and other memory leaks. 
 o Improved handling of Gopher errors. 
 o Improved handling of binary transfer mode (now "Load To Local Disk")
   -- local tmp file properly removed when cancel button is hit, and dialog
   box is now modal to prevent problems. 
 o Fixed bug in delayed inlined image icon handling with multiple delayed
   inlined images on the same line. 
 o Gopher/FTP icons are now part of anchors, so they can be clicked on (even
   though they're normal color -- trust us on this one). 
 o Fixed memory corruption problem with remote control newwin
   directive. 
 o Changed FTP client code to always pass fully qualified machine name in
   anonymous password whenever possible (actual username is already being
   passed). 
 o Cleaned up menubar. 
 o Lots of little cleanups, performance tweaks, and portability fixes. 

Comments and feedback much appreciated -- however, beware: THIS IS
UNSUPPORTED CODE.  If you want stability, get Mosaic 1.2
(ftp.ncsa.uiuc.edu, /Mosaic/xmosaic-binaries and
/Mosaic/xmosaic-source).

Cheers,
Marc & Eric

--
Marc Andreessen & Eric Bina
Software Development Group
National Center for Supercomputing Applications
marca@ncsa.uiuc.edu, ebina@ncsa.uiuc.edu




From timbl@www3.cern.ch  Wed Oct 20 13:05:23 1993 +0100
Message-Id: <9310201205.AA03770@www3.cern.ch>
Date: Wed, 20 Oct 93 13:05:23 +0100
From: timbl@www3.cern.ch (Tim Berners-Lee)
Subject: Re: IETF work and UR*


>Date: Tue, 19 Oct 93 12:46:04 +0100
>From: "Erik Huizer (SURFnet BV)" <Erik.Huizer@surfnet.nl>


Erik says, 


>The IETF is an open standards process that works by consensus.  
Concensus on
>the mailing list rather than in a meeting where attendance is rather
>haphazard. Meetings are usefull to help get consensus, they are not  
always a
>guarantee of concensus. Therefore I am not (yet) buying Tim's  
argument of
>the 29:1 vote in Amsterdam.

	Fair.

> First of all voting is not necessarily consensus
>(although with 29:1 it seems to come close :-), second the last few  
days and
>over 200 mails have convinced me that there is no concensus.

	There are many points under the URI umbrella, ranging
	from standardization of existing practice at the URL
	end to inventive creation of new techniques at the URN
	end.
	
	If there is a lot of discussion, that does not mean that
	some issues are not ripe for the guiguillotinelotine.
	
	Even if a topic is discussed, the size of the list is
	sufficient that there will always be new people coming in
	who ask "I am new to this list, but coming from a background
	in porpoise farming, if I am not missing something,
	surely..."  which will create a lot of traffic.
	
	There is also always the possibility of directly
	obstructive behavior delaying consensus for any amount
	of time.
	
	It is the duty of the chairs to isolate issues where
	consensus can be obtained.
	
	In this case, the URL issue is ripe.  If consensus cannot
	be reached now then it never will be able to be.


>As an Area Director for Applications Area I will thus be very  
hesitant to
>accept the latest URL draft as an RFC submission. 



	What, then, will happen?  The essential requirement
	for a universal printable representation for
	any name spaces on the net was defined in Boston.
	Soon afterward, rewriting and much refinement of
	the document was performed, down to details of
	punctuation.
	
	In Amsterdam, one member suggested that the whole
	work should be changed to the definition of a binary
	representation, threatening the entire effort at
	a point when small changes in allowed characters
	were being decided.
	
>It is important ( in my view even essential to the success of an  
Integrated
>Information Architecture for the Internet) that we get the URL/URN  
stuff
>right. And we wont get multiple chances.

	To think that we will defining *everything* absolutely
	*correctly* *now* is foolish, and and ideal way to
	extend happy debate indefinitely.

	First we define some basic, easily agreeable things,
	a mixture of good design, and in some places arbitrary
	choice.  Like the principle of URI. And its basic
	allowed characters.
	
	Later we can define URNs, URN resolution protocols.
	In time, probably many. But we can represent them
	as URIs.
	
	Where would we be if the RFC822 authors had waited
	to get MIME right?  We still wouldn't have email.

> To get it right we need something
>that everyone can live with. I mean all the implementors, service  
providers
>and user support people on the uri-list. I do not necessarily mean  
that
>everyone should agree that the solution is optimal, that will not be
>achieved evidently, however I feel that concensus can be reached on
>something that is acceptable to all of us. 



	I think that was reached on the net and in the
	flesh at Amsterdam.  There had been very little net
	traffic, and discussion was at a detailed level.
	
>Threats like : " we have an installed base, so we won't support  
this" are
>perpendicular to an open standards process and are undermingin for
>concensus. Parties that argue like that have no wish to get an open  
standard
>but merely a wish to further their own inventions. This will NOT  
lead to an
>integrated information Architecture.

	I personally have not argued in this way I hope.
	There is however a
	rather successful convention that the Internet respects
	working code.  A typical ISO member's ploy is to
	deliberately change a standard to put all developers
	back on the same footing. Hence ISO's attempt to put
	Europe back into the networking picture with ISO
	protocols.  The IETF is big enough and commercial
	interests are present enough for it to have to guard
	against such behavior.
	
	
> In an open standards process as the
>IETF, accepting that an NIH idea might have merit is the basis of  
concensus.

	Yes.

>Finally I'd like to remark that on top of all this we have another  
boundary
>condition for this WG (it is not in the USV area for nothing): The  
user.

>One of the UR* will be visible to the user (which one depends on  
your
>position in the discussions :-). The user wants something as  
understandable
>as possible, easy to remind and easy to pass on to a  
friend/colleague. 


	Currently users are however passing URLs around and
	have been since 1990.  But now we are talking
	criteria which were addressed agreed and defined in Boston.
	I hope we all still agree on that one!

>So to get back to the question:
>The policy is:
>- get concensus in the URI WG (not per se in a physical meeting)
>- submit the paper to the ADs (Joyce, John and me)
>- The ADs will do a review (together with some people outside of  
URI)
>- We will keep eye on Internet Architecture aspects, overlap with  
other
>protocols, user perspective.
>- After this iteration the paper will be put forward to the IESG.
>- Then a last call is issued, for anyone to comment on the paper and  
the
>process that lead to it's current contents.
>- If no problems then it goes to the RFC-editor.
>
>
>If anyone does not agree with any part of the process, the complaint
>hierarchy is:
>1 - WG-chair,  if that does not resolve it:
>2-  AD     if that does not resolve...
>3-  IESG  if....
>4-  IAB   if.....
>5-  ISOC ombudsman

	What actually happens?
	
	Brewster simply disconnected WAIS from the Z39.50 discussions
	because they rambled on for too long.  He did not follow
	a complaint hierarchy. He just left.
	
	The gopher people have never bothered to wait for the IETF
	to do anything.  They have made fun of WWW's waiting for
	RFCs to be produced.  They didn't follow the hierarchy
	or the IETF.  They have the IIIR WG with a mandate
	to document what they have done.
	
	I have tried earnestly to separate the WWW specs (URI,
	HTTP, HTML) into independent individually useful specs
	for the internet community, and had thought that the
	IETF would be like-minded enough to join in with what I
	see as a very important effort for the future. Maybe it
	is simply that the discussion group is above a critical
	mass and will never cool.

	The WWW specs have all been thrashed out in open
	debate amongst people who are actually writing code.
	There is some overlap with the IETF.
	The WWW specs benefit from the Internet -- do they
	have to benefit from the IETF?  The
	IETF must address the issue of global information and the
	underpinning standards, and if it ignores the
	working code it end up right up there with ISO.

	One of the difficulties is that the Web in its conception
	was an Integrated Information Architecture.  By defining
	URIs (and a few other things) it addressed (and basically
	solved) half of the IIIR issues, incorporating already
	gopher, FTP, WAIS, and whatever. Those who felt that it
	was their mandate to "Integrate WWW and the others"
	necessarily were going to have metaproblems

	IETF working group chairs have a difficult job.  If they
	really cannot produce consensus they should time out
	the debate and issue (a) informational RFCs on the
	proposals as they stand (eg URLs) and (b) pointers to the
	IRTF to do some concrete research about the fluffy
	problems for which no engineering exists (eg URNs)
	
	Sometimes in practice to produce a consensus requires
	doing more than just vote counting and message counting.
	If means being able to separate strands of argument,
	condemn obfuscation, and declare irrelevance as such
	when it appears. It requires recognition of attempts
	to make arbitrary changes for NIH reasons.
	It requires dedication to a timely concrete result.
	

>Erik

	Tim


__________________________________________________________
Tim Berners-Lee                       timbl@info.cern.ch
World Wide Web development leader	
CERN, CN Division                     Tel: +41(22)767 3755
1211 Geneva 23, Switzerland           Fax: +41(22)767 7155








From Erik.Huizer@surfnet.nl  Wed Oct 20 15:21:03 1993 +0100
Message-Id: <9310201421.AA16298@survival.surfnet.nl>
Date: Wed, 20 Oct 93 15:21:03 +0100
From: Erik.Huizer@surfnet.nl (Erik Huizer)
Subject: Re: IETF work and UR*

Tim,

I feel we agree vehemently on most points:-)

Several points:

1)
I hope we can get concensus on URL in Houston. Mitra's actions on the list
since yesterday try to focus the discussion, and if this does not diverge I
can see a possibillity for concensus in Houston.


2) 
I don't want to ignore running code. However As we both argued (with
different goals obviously) documenting running code is not standardisation.
At least not IETF OPEN standardisation. We'd be foolish however to ignore
running code and I appreciate very much your/WEB efforts to contribute. I
also don't intent to get a standard that sets all implemnentors bak. However
I want a standard that is acceptable to all implementors, so none will go of
and do their own thing. I hope we can get to that in Houston.

3)
I feel that it would be VERY USEFULL to have a short e-mail/document BEFORE
Houston, that explains what URI, URN, URL etc. stand for, and that gives a
short description of what goal they serve, how they will be used, and what
the main arguments were for structuring them as they are.
I will immediately admit that I would benefit from such a document to get
up-to-date, but I'll add that it will serve other purposes:
- can be included in IETF report to get other people up-to-date
- can be included in an informational RFC on UR*, that describes the
principles
- can be used by Joyce, John and me to bring the rest of the IESG up-to-date


Is there anyone out there that cares to draft such a summary?

Thanks,
Erik



From bajan@bunyip.com  Wed Oct 20 13:28:18 1993 -0400
Message-Id: <9310201728.AA15250@mocha.bunyip.com>
Date: Wed, 20 Oct 1993 13:28:18 -0400
From: bajan@bunyip.com (Alan Emtage)
Subject: Re: IETF work and UR*

Erik,

> I feel that it would be VERY USEFULL to have a short e-mail/document BEFORE
> Houston, that explains what URI, URN, URL etc. stand for, and that gives a
> short description of what goal they serve, how they will be used, and what
> the main arguments were for structuring them as they are.
> I will immediately admit that I would benefit from such a document to get
> up-to-date, but I'll add that it will serve other purposes:
> - can be included in IETF report to get other people up-to-date
> - can be included in an informational RFC on UR*, that describes the
> principles
> - can be used by Joyce, John and me to bring the rest of the IESG up-to-date
> 
> 
> Is there anyone out there that cares to draft such a summary?

Cliff Lynch had written such a beast which was presented at Columbus. I
will try to contact him and ask him to resubmit it to the list this week.


-- 
-Alan

------------------------------------------------------------------------------
Alan Emtage,				"The Left in Canada is more gauche
Bunyip Information Systems,		 than sinister"
Montreal, CANADA			 -The Economist

bajan@bunyip.com
Voice: +1 (514) 875-8611		Fax: +1 (514) 875-8134




From clw@merit.edu  Wed Oct 20 16:45:05 1993 -0400
Message-Id: <9310202045.AA28884@merit.edu>
Date: Wed, 20 Oct 93 16:45:05 -0400
From: clw@merit.edu (Chris Weider)
Subject: Re: IETF work and UR*

Alan:
  I have the document on-line, but it might need his permission for reposting.
Chris



From bajan@bunyip.com  Wed Oct 20 17:16:58 1993 -0400
Message-Id: <9310202116.AA15953@mocha.bunyip.com>
Date: Wed, 20 Oct 1993 17:16:58 -0400
From: bajan@bunyip.com (Alan Emtage)
Subject: Re: IETF work and UR*

> Alan:
>   I have the document on-line, but it might need his permission for reposting.

I sent him mail today and asked for the new version... he'll get the
message unless he's at 35,000 feet and what are the chances of that? :-)



-- 
-Alan

------------------------------------------------------------------------------
Alan Emtage,				"The Left in Canada is more gauche
Bunyip Information Systems,		 than sinister"
Montreal, CANADA			 -The Economist

bajan@bunyip.com
Voice: +1 (514) 875-8611		Fax: +1 (514) 875-8134




From mitra@path.net  Wed Oct 20 21:25:08 1993 GMT
Message-Id: <CF7stx.14y@pandora.sf.ca.us>
Date: Wed, 20 Oct 1993 21:25:08 GMT
From: mitra@path.net (Mitra)
Subject: Re: IETF work and UR*

I dont remember the details of Cliffs paper, but seem to remember it was a 
fairly long thoughtfull peice about the concepts and problems. 

John's list was - I think - a more concise description of points already agreed
on and not therefore open to re-opened discussion.

Probably both are needed.

- Mitra



From robm@ncsa.uiuc.edu  Wed Oct 20 16:25:25 1993 -0500
Message-Id: <9310202125.AA01439@void.ncsa.uiuc.edu>
Date: Wed, 20 Oct 1993 16:25:25 -0500
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: NCSA httpd Beta testers


Hi, I would like to find a group of web server administrators who use NCSA
httpd and would be willing to test new versions of httpd on their servers
before the release, on a different port but with the same config. This will
help me ensure that future releases are not as buggy as 1.0a3* was, and can
also help you provide feedback and/or suggestions about new features before
the features go into general use and become more troublesome to change.

If you're interested, mail me back and I'll set something up.

Thanks
--Rob




From WIGGINS@msu.edu  Thu Oct 21 00:36:57 1993 EDT
Message-Id: <9310210452.AA16322@dxmint.cern.ch>
Date: Thu, 21 Oct 93 00:36:57 EDT
From: WIGGINS@msu.edu (Rich Wiggins)
Subject: Re: Question: volume generated by WWW vs. Gopher


Garbiela,

It depends entirely on what you do with the Web versus Gopher.

Our root Gopher menu is maybe 3K in size; our home page for WWW is about
the same, including our university logo in color. But due to the very
richness of WWW, and the liberal use of images within documents in
particular, many Web documents are large; a single click can cause
several hundred K bytes (or more) to be sent down the pipe. The full
motion weather satellite loops delivered as MPEGs by my colleague Chuck
Henrich can be a meg or larger.

So it's really a question of what you put under the Web. In a sense, if
you don't do anything interesting you won't have a problem. :-)
Seriously, a Webified Gopher tree shouldn't cause any more load than
delivery via Gopher. Conversely, you could offer large files via a Gopher
(images, software libraries) and generate lots of load that way.

You might look at John Franks' Gn server as an interesting bridge
between the two worlds.

/Rich Wiggins, Gopher Coordinator, Michigan State U


>To the WWW people, I have a question about the volume of messages
>generated by the WWW. Our University has been running a gopher server
>for some time and we have now a brand new WWW server. The people
>running the gopher server are reluctant to this new initiative and are
>asking me wether the WWW transactions will increase the traffic on our
>almost saturated network. So, I was wondering if somebody has any
>numbers to help me defend the WWW, possibly comparing the amount of
>data transferred in a transaction by gopher and the WWW. I think it
>should not make any difference, but still ... I would appreciate any
>information or pointer to the proper place. Thanks, Gaby



From timbl@www3.cern.ch  Thu Oct 21 18:02:45 1993 +0100
Message-Id: <9310211702.AA06441@www3.cern.ch>
Date: Thu, 21 Oct 93 18:02:45 +0100
From: timbl@www3.cern.ch (Tim Berners-Lee)
Subject: Re: Question: volume generated by WWW vs. Gopher

>To the WWW people, I have a question about the volume of messages
>generated by the WWW. Our University has been running a gopher  
server
>for some time and we have now a brand new WWW server. The people
>running the gopher server are reluctant to this new initiative and  
are
>asking me wether the WWW transactions will increase the traffic on  
our
>almost saturated network.

	Of course, it may be that the WWW information is so much
	easier to read and more exciting that you get many
	more customers, and that could increase the network traffic.
	
	To really solve the traffic problem, you can always
	turn both servers off, or reduce the information available
	to something extremely boring.
	
	;-)))



From stumpf@informatik.tu-muenchen.de  Fri Oct 22 00:01:56 1993 +0100
Message-Id: <93Oct22.000200mesz.311357@hprbg5.informatik.tu-muenchen.de>
Date: Fri, 22 Oct 1993 00:01:56 +0100
From: stumpf@informatik.tu-muenchen.de (Markus Stumpf)
Subject: problem with gatewaying

Hello!

I have just noticed a problem with xmosaic-2.0pre6 which may be in
the new generic libwww code.

I have
	WWW_http_GATEWAY=http://hpsystem2.informatik.tu-muenchen.de:8100
	WWW_gopher_GATEWAY=http://hpsystem2.informatik.tu-muenchen.de:8100
	export WWW_http_GATEWAY WWW_gopher_GATEWAY

On this gateway machine is a server based on ncsa-httpd-0.5 which only
forwards html requests and tries to handle gopher-requests (formatting,
etc) by itself.

Now I have noticed a problem which hasn't been there at least in
xmosaic-2.0pre2 (which used the old libwww I think).

Prior my server got gateways-requests as
    GET http://www.informatik.tu-muenchen.de/tum.informatik/HOME-PAGE.html
but now I only get
    GET /www.informatik.tu-muenchen.de/tum.informatik/HOME-PAGE.html

Anyone knows what to do?
Thanks
	\Maex

P.S. Marc (Andreessen): I had problems with xmosaic-pre6 not loading certain
     images (inlined AND "direct") which went away when I used
     ncsa-httpd-1.0a3 instead of ncsa-httpd-0.5. Maybe this is a
     HTTP-1.0/not-HTTP-1.0 problem. However the 0.5 server said the image
     was delivered.
     Saw this topic in the "bugs" list.
-- 
______________________________________________________________________________
 Markus Stumpf                        Markus.Stumpf@Informatik.TU-Muenchen.DE 



From jeff.grover@gtri.gatech.edu  Thu Oct 21 19:42:56 1993 -0400
Message-Id: <199310212342.AA24545@gtri.gatech.edu>
Date: Thu, 21 Oct 1993 19:42:56 -0400
From: jeff.grover@gtri.gatech.edu (Jeffrey L. Grover)
Subject: W4W WYSIWYG authoring tool release

GT_HTML.DOT (ver 0.1a) Release Notice
--------------------------------------------
The Georgia Tech Research Institute (GTRI) 
is pleased to announce the initial alpha 
release of  a set of Microsoft Word for 
Windows macros to facilitate  HTML document 
authoring.  The macros are contained in a 
document template (GT_HTML.DOT) which provides 
a pseudo WYSIWYG authoring environment.


Read more about it at:

        <http://www.gatech.edu/word_html/release.htm>

TEMPORARY distribution point at:

        <ftp://ftp.gatech.edu/submissions/gt_html.zip>

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
Jeffrey L. Grover         voice:  (404)894-8961
Ga Tech/GTRI/ITTL         fax:    (404)894-9081
347 Ferst Dr. N.W.             noman@gatech.edu
Atlanta, Ga 30332   jeff.grover@gtri.gatech.edu




From hotsand!ellson  Thu Oct 21 21:18:55 1993 EDT
Message-Id: <9310220118.AA15940@hotsand.dacsand>
Date: Thu, 21 Oct 93 21:18:55 EDT
From: hotsand!ellson (John Ellson)
Subject: image caching and image deferment control

I'm presently putting together an httpd server program that produces an
up-to-the-minute graph of the http access statistics of the server. 
I'm using ncsa-httpd, a shell script in the htbin directory to collect
and process the data, gnuplot to generate the graph and pbmplus to convert
the result to xbm.  The final result is returned to the client,
xmosaic-2.0pre6, as an inline image.

Two issues arise from this use (abuse?) of the inline image feature:

1. Each time you click on this link the server updates the statistics
and the graph image should change, therefore it would be useful to be able to
explicitly disable caching for these images, either in the URL, or
better with some sort of "valid-lifetime" parameter in the response
which could be set to zero. (At the moment I'm generating a unique
filename in each response, which works, but which leaves known useless
images in the client's cache.)

2. The graph is the information bearing response to an explicit action
by the user.  It makes no sense to defer image loading even if the browser
is in a dil mode for other graphics.  There should be a way to over-ride
dil mode for individual images either in the URL or in the response.

Specific proposals:  Problem 1. should be handled with a valid-lifetime
parameter because the server is in the best position to know the 
life of the data.  Problem 2. should be controlled by a flag in the
html because the html document author is the best judge of the display
context.  I suggest "<img no_dil src=xxx.xbm>"

Sound ok?

John.Ellson@att.com



From sanders@bsdi.com  Thu Oct 21 21:07:39 1993 -0500
Message-Id: <9310220207.AA01087@austin.BSDI.COM>
Date: Thu, 21 Oct 1993 21:07:39 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: image caching and image deferment control 

[ellson@hotsand.att.com writes about wanting images to refresh and the like]

Read up on ``URI:'' and ``Expires:'' in:
    http://info.cern.ch/hypertext/WWW/Protocols/HTTP/Object_Headers.html

There is all kinds of good stuff in there that no one implements :-(
See also:
    http://info.cern.ch/hypertext/WWW/MarkUp/Relationships.html

> "<img no_dil src=xxx.xbm>"
If the user doesn't want images then they don't want images.  Why should
the author be able to override the users preferences?

--sanders



From hotsand!ellson  Thu Oct 21 22:33:16 1993 EDT
Message-Id: <9310220233.AA01898@hotsand.dacsand>
Date: Thu, 21 Oct 93 22:33:16 EDT
From: hotsand!ellson (John Ellson)
Subject: Re: image caching and image deferment control

> Date: Thu, 21 Oct 1993 21:07:39 -0500
> From: Tony Sanders <sanders@bsdi.com>
> 
> > "<img no_dil src=xxx.xbm>"
> If the user doesn't want images then they don't want images.  Why should
> the author be able to override the users preferences?

I thought about that too, but dil says that the user wants deferred
image loading, not that the user doesn't want images.  Perhaps
no images should be a separate flag?

John.Ellson@att.com



From /S=falken/OU=tnt/@uni-hannover.de  Thu Oct 21 19:16:06 1993 +0100
Message-Id: <9310211816.AA24470@helios.tnt.uni-hannover.de>
Date: Thu, 21 Oct 1993 19:16:06 +0100
From: /S=falken/OU=tnt/@uni-hannover.de ()
Subject: can provide images (was cannot provide images)

>
>I have a problem in providing images with a current CERN httpd_2.12, when
>I use a new xmosaic 2.0pre_x browser. 
>
>I have tried several combinations of server and browser, but with 
>xmosaic 2.0pre_x and any httpd I always get the xmosaic logo instead of an
>inline gif image, when I look at my own pages. With xmosaic 1.x it still works,
>and xmosaic 2.0pre_x browses throught images provided by other servers.
>
>Can anybody tell me what protocoll changes I have missed? 
>
>Thanks in advance
>
Sorry, but I made the mistake of mixing two rule files and addressing 
an old httpd directly in the documents with the gif inline images. 
Now the images are provided correctly.

	Lutz



From /S=falken/OU=tnt/@uni-hannover.de  Thu Oct 21 17:40:51 1993 +0100
Message-Id: <9310211640.AA24299@helios.tnt.uni-hannover.de>
Date: Thu, 21 Oct 1993 17:40:51 +0100
From: /S=falken/OU=tnt/@uni-hannover.de ()
Subject: cannot provide images


I have a problem in providing images with a current CERN httpd_2.12, when
I use a new xmosaic 2.0pre_x browser. 

I have tried several combinations of server and browser, but with 
xmosaic 2.0pre_x and any httpd I always get the xmosaic logo instead of an
inline gif image, when I look at my own pages. With xmosaic 1.x it still works,
and xmosaic 2.0pre_x browses throught images provided by other servers.

Can anybody tell me what protocoll changes I have missed? 

Thanks in advance

	Lutz

________________________________________________________________________________

Dipl.-Ing. Lutz Falkenhagen	   Universitaet Hannover
				   Institut fuer Theoretische Nachrichtentechnik
				   und Informationsverarbeitung
phone:  +49-511-762-5312           Appelstrasse 9A
fax:    +49-511-762-5333           D-30167 Hannover, Germany
email: falken@tnt.uni-hannover.de
X400: s=falken;ou=tnt;p=uni-hannover;a=d400;c=de;      
________________________________________________________________________________



From jeff.grover@gtri.gatech.edu  Fri Oct 22 09:26:06 1993 -0400
Message-Id: <199310221326.AA00982@gtri.gatech.edu>
Date: Fri, 22 Oct 1993 09:26:06 -0400
From: jeff.grover@gtri.gatech.edu (Jeffrey L. Grover)
Subject: Re: W4W WYSIWYG authoring tool release



>
>I tried to check it out, but it wasn't there....
>

ftp://ftp.gatech.edu/pub/submissions/gt_html.zip
                     ^^^

sorry for the confusion

+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
Jeffrey L. Grover         voice:  (404)894-8961
Ga Tech/GTRI/ITTL         fax:    (404)894-9081
347 Ferst Dr. N.W.             noman@gatech.edu
Atlanta, Ga 30332   jeff.grover@gtri.gatech.edu




From ccoprmm@oit.gatech.edu  Fri Oct 22 11:59:24 1993 EDT
Message-Id: <199310221559.AA26798@oit.oit.gatech.edu>
Date: Fri, 22 Oct 93 11:59:24 EDT
From: ccoprmm@oit.gatech.edu (Michael Mealling)
Subject: Re: W4W WYSIWYG authoring tool release

Jeffrey L. Grover said this:
> GT_HTML.DOT (ver 0.1a) Release Notice
> --------------------------------------------
> The Georgia Tech Research Institute (GTRI) 
> is pleased to announce the initial alpha 
> release of  a set of Microsoft Word for 
> Windows macros to facilitate  HTML document 
> authoring.  The macros are contained in a 
> document template (GT_HTML.DOT) which provides 
> a pseudo WYSIWYG authoring environment.
> 
> 
> Read more about it at:
> 
>         <http://www.gatech.edu/word_html/release.htm>
> 
Now in it's permanent home at:
	<ftp://ftp.gatech.edu/put/www/gt_html.zip>
as well as it's old temporary one (for now).

Let me know if you have any problems getting that....


-MM
-- 
------------------------------------------------------------------------------
Michael Mealling                     ! Hypermedia WWW, WAIS, and gopher will be
Georgia Institute of Technology      ! here soon via MIME. Your view of the 
Michael.Mealling@oit.gatech.edu      ! internet is about to change completely!



From jonm@ncsa.uiuc.edu  Fri Oct 22 11:39:32 1993 CDT
Message-Id: <9310221639.AA15041@void.ncsa.uiuc.edu>
Date: Fri, 22 Oct 93 11:39:32 CDT
From: jonm@ncsa.uiuc.edu (Jon E. Mittelhauser)
Subject: Re:  image caching and image deferment control

>2. The graph is the information bearing response to an explicit action
>by the user.  It makes no sense to defer image loading even if the browser
>is in a dil mode for other graphics.  There should be a way to over-ride
>dil mode for individual images either in the URL or in the response.

If the image is the "only" information bearing response, it should simply
be returned as an external image and will be displayed regardless of the
inlined image setting...

If the image is NOT the "only" information in the response, it is reasonable
for the user to still not want to see it or to delay its retrieval until
he/she specifies.

>Problem 2. should be controlled by a flag in the
>html because the html document author is the best judge of the display
>context.  I suggest "<img no_dil src=xxx.xbm>"

>Sound ok?

No, the server doc should not be able to overide my user's preference to
delay inlined image loading...

-Jon

----
Jon E. Mittelhauser (jonm@ncsa.uiuc.edu)
Research Programmer, NCSA                          (NCSA Mosaic for MS Windows)
More info <a href="http://www.ncsa.uiuc.edu/SDG/People/jonm/jonm.html">here</a>



From jeff.grover@gtri.gatech.edu  Fri Oct 22 13:48:36 1993 -0400
Message-Id: <199310221753.AA05972@gtri.gatech.edu>
Date: Fri, 22 Oct 1993 13:48:36 -0400
From: jeff.grover@gtri.gatech.edu (Jeffrey L. Grover)
Subject: Re: W4W WYSIWYG authoring tool release

for a *PUB*lic institute of higher education we sure
do seem to have difficulty getting the "pub" into
our URLs.  Not to worry, the link from:

        <http://www.gatech.edu/word_html/release.htm>

has it correct. Read, Down-load, un-zip, enjoy.



At 11:59 AM 10/22/93 EDT, Michael Mealling wrote:
>> 
>Now in it's permanent home at:
>	<ftp://ftp.gatech.edu/put/www/gt_html.zip>
                                ^
                                |
                              pub

>as well as it's old temporary one (for now).
>


+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
Jeffrey L. Grover         voice:  (404)894-8961
Ga Tech/GTRI/ITTL         fax:    (404)894-9081
347 Ferst Dr. N.W.             noman@gatech.edu
Atlanta, Ga 30332   jeff.grover@gtri.gatech.edu




From nop@ccs.neu.edu  Fri Oct 22 14:17:17 1993 EDT
Message-Id: <9310221817.AA26492@amber.ccs.neu.edu>
Date: Fri, 22 Oct 93 14:17:17 EDT
From: nop@ccs.neu.edu (Jay Carlson)
Subject: Re:  image caching and image deferment control

> No, the server doc should not be able to overide my user's preference to
> delay inlined image loading...

I agree; perhaps we should compromise on hinting of some form.

Jay Carlson
nop@io.com    nop@ccs.neu.edu

Flat text is just *never* what you want.   ---stephen p spackman



From bajan@bunyip.com  Fri Oct 22 16:03:00 1993 -0400
Message-Id: <9310222003.AA19651@mocha.bunyip.com>
Date: Fri, 22 Oct 1993 16:03:00 -0400
From: bajan@bunyip.com (Alan Emtage)
Subject: Current documents

The current documents for the Uniform Resource Identifier WG of the IETF
due to be discussed at the upcoming IETF meeting in Houston are now
available on archive.cc.mcgill.ca via anonymous FTP in the
pub/Network/uri directory. The draft agenda and position statements (in
the position.statments subdirectory) may also be found there.

Alternatively, these documents may also be found later on today on the
InterNic repository at ds.internic.net via gopher and anonymous FTP.

Those intending to attend the URI sessions in Houston are urged to be
familiar with these documents in advance of the meeting.

Sessions are currently scheduled for Monday November 1 from 1600-1800 and
Tuesday November 2, 09030-1200.

Please feel free to redistribute this announcement to appropriate groups.


-- 
-Alan

------------------------------------------------------------------------------
Alan Emtage,				"The Left in Canada is more gauche
Bunyip Information Systems,		 than sinister"
Montreal, CANADA			 -The Economist

bajan@bunyip.com
Voice: +1 (514) 875-8611		Fax: +1 (514) 875-8134




From wei@sting.berkeley.edu  Fri Oct 22 14:03:11 1993 -0700
Message-Id: <9310222103.AA03264@sting.Berkeley.EDU>
Date: Fri, 22 Oct 93 14:03:11 -0700
From: wei@sting.berkeley.edu (Pei Y. Wei)
Subject: Stylesheet Language

Hi.

I'm working on a stylesheet library that will hopefully be useful for
all W3 browsers. A prototype is implemented in viola, but before I 
get too far on this-- producing a more formal RFC and stand-alone
library and testing code, I'd like to get people's impression on it. 

Particularly, any problem with the the syntax of the style description
language?

Here is a sample stylesheet:

(HEAD,BODY				fontSize=normal
					BGColor=white
					FGColor=black
    (H1					fontSize=largest
					BGColor=red
					FGColor=white)
    (H2					fontSize=large)
    (P)
    (A					FGColor=red)
    (CMD,KBD,SCREEN,LISTING,EXAMPLE	fontFamily=fixed)
    (BOLD,EMPH,STRONG			fontWeight=bold)
    (I				 	fontSlant=italic)
    (ADDRESS
        (P				fontSlant=italic))
    (OL
	(LI				numStyle=roman
	    (LI                         numStyle=number
		(LI			numStyle=alpha)
	    )
	)
    )
    (FOOTNOTE				fontSize=small
	(P)
    )
)

From this stylesheet, you can derive the following information:

* <P> inside of <HEAD> and <BODY> gets fontSize of "normal".
* <P> inside of <ADDRESS> gets italic slant font.
* <P> inside of <FOOTNOTE> gets a "small" font.
* List items in first, second, and third levels are numbered differently.
* Since <BOLD> and <STRONG> look the same, they are succintly lumpped
  together.

Note that properties are inherited down the tree, unless overridden.
So, the color information that is specifed at the top is used all over,
except for <H1> which redefines its own colors. 

Having this inheritance behaviour also helps to keep the description
short, as lots of information can be derived by the context in the 
tree structure.

The lone "(P)"s are there to engage the respective <P> tags to be in
those particular contexts. 

A document uses a <LINK REL="STYLE" HREF="URL_to_a_stylesheet">
to associate to a stylesheet. It's an open question as to whether
we should allow multiple stylesheets in a document, and where
this link can be specified (once only, in the <HEAD>?).


-Pei				Pei Y. Wei
				O'Reilly & Associates



From marca@ncsa.uiuc.edu  Fri Oct 22 23:48:42 1993 -0700
Message-Id: <9310230648.AA13847@wintermute.ncsa.uiuc.edu>
Date: Fri, 22 Oct 93 23:48:42 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Stylesheet Language

What's the relationship between this and Rob Raisch's stylesheet
proposal from this summer?  (Rob, are you out there? :-)

Cheers,
Marc

Pei Y. Wei writes:
> I'm working on a stylesheet library that will hopefully be useful for
> all W3 browsers. A prototype is implemented in viola, but before I 
> get too far on this-- producing a more formal RFC and stand-alone
> library and testing code, I'd like to get people's impression on it. 
> 
> Particularly, any problem with the the syntax of the style description
> language?
> 
> Here is a sample stylesheet:
> 
> (HEAD,BODY				fontSize=normal
> 					BGColor=white
> 					FGColor=black
>     (H1					fontSize=largest
> 					BGColor=red
> 					FGColor=white)
>     (H2					fontSize=large)
>     (P)
>     (A					FGColor=red)
>     (CMD,KBD,SCREEN,LISTING,EXAMPLE	fontFamily=fixed)
>     (BOLD,EMPH,STRONG			fontWeight=bold)
>     (I				 	fontSlant=italic)
>     (ADDRESS
>         (P				fontSlant=italic))
>     (OL
> 	(LI				numStyle=roman
> 	    (LI                         numStyle=number
> 		(LI			numStyle=alpha)
> 	    )
> 	)
>     )
>     (FOOTNOTE				fontSize=small
> 	(P)
>     )
> )
> 
> >From this stylesheet, you can derive the following information:
> 
> * <P> inside of <HEAD> and <BODY> gets fontSize of "normal".
> * <P> inside of <ADDRESS> gets italic slant font.
> * <P> inside of <FOOTNOTE> gets a "small" font.
> * List items in first, second, and third levels are numbered differently.
> * Since <BOLD> and <STRONG> look the same, they are succintly lumpped
>   together.
> 
> Note that properties are inherited down the tree, unless overridden.
> So, the color information that is specifed at the top is used all over,
> except for <H1> which redefines its own colors. 
> 
> Having this inheritance behaviour also helps to keep the description
> short, as lots of information can be derived by the context in the 
> tree structure.
> 
> The lone "(P)"s are there to engage the respective <P> tags to be in
> those particular contexts. 
> 
> A document uses a <LINK REL="STYLE" HREF="URL_to_a_stylesheet">
> to associate to a stylesheet. It's an open question as to whether
> we should allow multiple stylesheets in a document, and where
> this link can be specified (once only, in the <HEAD>?).
> 
> 
> -Pei				Pei Y. Wei
> 				O'Reilly & Associates




From henrich@crh.cl.msu.edu  Sat Oct 23 02:21:34 1993 -0400 (EDT)
Message-Id: <9310230621.AA15015@crh.cl.msu.edu>
Date: Sat, 23 Oct 1993 02:21:34 -0400 (EDT)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: Re:  image caching and image deferme

This has all been hashed over before, and the conclusion was that this sort of
information has no place in the HTML document.  It is truly a client/user
issue.  If the user wants inlined images, he gets them, if not, not.  Or
perhaps the client may even use some sort of heuristic to determine when to
grab images or not.  But it has no place in the actual HTML doc.

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                      http://rs560.msu.edu/~henrich



From marca@ncsa.uiuc.edu  Sat Oct 23 02:31:34 1993 -0700
Message-Id: <9310230931.AA14797@wintermute.ncsa.uiuc.edu>
Date: Sat, 23 Oct 93 02:31:34 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: agggggggggggh

OK, when I do this:

------------------------------------------------------------------------------
(marca@void 195) telnet www.ncsa.uiuc.edu 80
Trying 141.142.4.5 ...
Connected to rs5.ncsa.uiuc.edu.
Escape character is '^]'.
GET /bullshit.html HTTP/1.0

HTTP/1.0 404 Not Found

<HEAD><TITLE>404 Not Found</TITLE></HEAD>
<H1>404 Not Found</H1><BODY>
The requested URL /bullshit.html was not found on this server.<P>
</BODY>
Connection closed by foreign host.
------------------------------------------------------------------------------

When I do this:

------------------------------------------------------------------------------
(marca@void 193) telnet www.bsdi.com 80
Trying 153.39.128.11 ...
Connected to BSDI.COM.
Escape character is '^]'.
GET /bullshit.html HTTP/1.0

HTTP/1.0 404 Not Found
Date: Saturday, 23-Oct-93 07:25:48 GMT
Server: plexus/3.0j
MIME-version: 1.0
Content-type: text/html

<HEAD><TITLE>Server Error: 404 Not Found</TITLE></HEAD>
<BODY><H1>Server Error: 404 Not Found</H1>
document ``bullshit.html'' does not exist <P>
If you feel this is a server problem and wish to report it, please
include the error code, the requested URL, which and what version
browser you are using, and any other facts that might be relevant to: <P>
<ADDRESS>webmaster@www.bsdi.com</ADDRESS>
</BODY>
Connection closed by foreign host.
------------------------------------------------------------------------------

When I do this:

------------------------------------------------------------------------------
(marca@void 196) telnet info.cern.ch 80
Trying 128.141.201.74 ...
Connected to nxoc01.cern.ch.
Escape character is '^]'.
GET /bullshit.html HTTP/1.0

HTTP/1.0 500 Access forbidden by rule
MIME-Version: 1.0
Content-Type: text/HTML

<BODY><H1>Error 500</H1>

  Access forbidden by rule</BODY>
Connection closed by foreign host.
------------------------------------------------------------------------------

SO FAR SO GOOD!

Now...

------------------------------------------------------------------------------
(marca@void 199) telnet guarani.cos.ufrj.br 8000
Trying 146.164.34.14 ...
Connected to guarani.cos.ufrj.br.
Escape character is '^]'.
GET /bullshit.html HTTP/1.0

HTTP/1.0 404 Not Found
<HEAD><TITLE>404 Not Found</TITLE></HEAD>
<H1>404 Not Found</H1><BODY>
The requested URL /bullshit.html was not found on this server.<P>
</BODY>
Connection closed by foreign host.
------------------------------------------------------------------------------

There's no blank line between the response code (aka MIME header block
area of the response) and the HTML, as should be required, right?

(I don't know what server they're using in Rio, but is it safe to say
it's borken?)

Marc




From raisch@internet.com  Sat Oct 23 08:49:41 1993 -0700 (PDT)
Message-Id: <Pine.3.03.9310230840.C9831-8100000@hmmm.internet.com>
Date: Sat, 23 Oct 1993 08:49:41 -0700 (PDT)
From: raisch@internet.com (Rob Raisch, The Internet Company)
Subject: Re: Stylesheet Language


Yup, still here.

No idea.  I guess Pei has other ideas.

I am no longer directly associated with O'Reilly & Associates, so better
ask them.

	</rr>





From peveritt@pandora.ncts.navy.mil  Sat Oct 23 14:43:50 1993 +0600
Message-Id: <9310231943.AA01749@voltaire.ncts.navy.mil>
Date: Sat, 23 Oct 1993 14:43:50 +0600
From: peveritt@pandora.ncts.navy.mil (Paul Everitt)
Subject: Re: agggggggggggh


Speaking of agggggggggggh, here's one for the books.  This
concerns running different flavors of servers, different flavors 
of clients, and different flavors of OSes.

My biggest problem is with 2.0 pre5+ on Solaris 2.x (NIS+).  
I have been running the sun4 binaries, from 1.1 to 2.0pre4,
fine under the binary compatability package.  Then, when 
pre5 came out, it stop allowing me to connect to servers 
other than my local one, giving the "Information server 
not available" message.  This is the sequence in the status bar:
	Looking up www.ncsa.uiuc.edu
	Making http connection to www.ncsa.uiuc.edu
	..followed by "ERROR info server is not accessible.." msg.
And, it works fine when opening on my server.

This same binary, when I run it remotely on a SunOS 4.1.3 
machine (running NIS), works fine.

So, pre5/6 on 2.x/NIS+ will connect to my local machine, but no
other URL (http, gopher, etc.).  And pre5/6 works on 1.x/NIS.


Now, on the ncsa httpd1.03x side, I can't get anything to connect.
Going from 1.01 to 1.03b broke it, giving 403 errors when getting
the URL with no .html file specified (i.e. index.html), and 404
errors when specifying something.  The connections are shown
in the httpd_log file, but not the error_log file.


HELP!!  Is it just Solaris 2.x/NIS+?  If someone has a native binary,
I'll shut up and take it!!

Paul.Everitt@ncts.navy.mil



From hotsand!rhb  Sat Oct 23 16:42:57 1993 EDT
Message-Id: <9310232042.AA25389@hotsand.dacsand>
Date: Sat, 23 Oct 93 16:42:57 EDT
From: hotsand!rhb (Rich Brandwein)
Subject: MIF and PDF mime types

Can we add experimental mime types for mif (FrameMaker)
and pdf (Adobe Acrobat), e.g.:

/application/x-mif	mif
/application/x-pdf	pdf

We're pulling mif files directly into an external maker session
via the .mailcap settings here and appropriate changes to
the mime types in the servers.  None of the other external servers
sets the mime types for mif, so I can't handle mif files 
automagically from them.

Rich Brandwein



From robm@ncsa.uiuc.edu  Sat Oct 23 15:54:40 1993 -0500
Message-Id: <9310232054.AA08080@void.ncsa.uiuc.edu>
Date: Sat, 23 Oct 1993 15:54:40 -0500
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: agggggggggggh

/*
 * agggggggggggh  by Marc Andreessen (marca@ncsa.uiuc.edu)
 *    written on Oct 23,  2:31am.
 *
 * OK, when I do this:
 * 
 * (marca@void 199) telnet guarani.cos.ufrj.br 8000
 * Trying 146.164.34.14 ...
 * Connected to guarani.cos.ufrj.br.
 * Escape character is '^]'.
 * GET /bullshit.html HTTP/1.0
 * 
 * HTTP/1.0 404 Not Found
 * <HEAD><TITLE>404 Not Found</TITLE></HEAD>
 * <H1>404 Not Found</H1><BODY>
 * The requested URL /bullshit.html was not found on this server.<P>
 * </BODY>
 * Connection closed by foreign host.
 * -------------------------------------------------------------------------
 * 
 * There's no blank line between the response code (aka MIME header block
 * area of the response) and the HTML, as should be required, right?
 * 
 * (I don't know what server they're using in Rio, but is it safe to say
 * it's borken?)
 */

It's ours. 1.0a2. I never saw the error messages because Mosaic before pre5
didn't print them. It's fixed in 1.0a3. 1.0a4 is actually civil about it and
prints the rest of the header (server, date, etc.).

--Rob



From marca@ncsa.uiuc.edu  Sat Oct 23 16:46:39 1993 -0700
Message-Id: <9310232346.AA16869@wintermute.ncsa.uiuc.edu>
Date: Sat, 23 Oct 93 16:46:39 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: MIF and PDF mime types

rhb@hotsand.att.com writes:
> /application/x-pdf	pdf

Should be 'application/pdf' (it's already been registered).

Cheers,
Marc




From hotsand!rhb  Sun Oct 24 13:18:47 1993 EDT
Message-Id: <9310241718.AA08529@hotsand.dacsand>
Date: Sun, 24 Oct 93 13:18:47 EDT
From: hotsand!rhb (Rich Brandwein)
Subject: <HELP URL>

Is there a proper URL construct for indicating an associated "help" page?
The idea is to be able to hit <F1> or help=>"on current page", much 
like in many ms windows constructs.

Rich



From montulli@stat1.cc.ukans.edu  Sun Oct 24 23:53:03 1993 CDT
Message-Id: <9310250453.AA40020@stat1.cc.ukans.edu>
Date: Sun, 24 Oct 93 23:53:03 CDT
From: montulli@stat1.cc.ukans.edu (Lou Montulli)
Subject: Re: <HELP URL>

> 
> Is there a proper URL construct for indicating an associated "help" page?
> The idea is to be able to hit <F1> or help=>"on current page", much 
> like in many ms windows constructs.
> 
> Rich
> 
That's not a bad idea.  I think the appropriate way to define it
would be with a <link> relationship.  I think that
<link rev=help href="URL"> might be a suitable format. 

:lou
-- 
  **************************************************************************
  *           T H E   U N I V E R S I T Y   O F   K A N S A S              *
  *         Lou  MONTULLI @ Ukanaix.cc.ukans.edu                           *
  *                         Kuhub.cc.ukans.edu      ACS Computing Services *
  *     913/864-0436        Ukanvax.bitnet             Lawrence, KS 66044  *
  *             UNIX! Cool! I know that!  Jurassic Park - The Movie        *
  **************************************************************************



From wei@sting.berkeley.edu  Sat Oct 23 23:03:57 1993 -0700
Message-Id: <9310240603.AA09858@sting.Berkeley.EDU>
Date: Sat, 23 Oct 93 23:03:57 -0700
From: wei@sting.berkeley.edu (Pei Y. Wei)
Subject: Re: Stylesheet Language

Well, after Rob left ORA I've basically inherited the stylesheet 
problem-- finish the design, prototype, and final implementation.
As Rob has done the good work of writing the initial proposal, 
I will try to reuse as much of the collected material as possible. 
But there were and will be changes since Rob presented the proposal 
this past summer.

-Pei



From decoux@moulon.inra.fr  Mon Oct 25 06:56:08 1993 +0100
Message-Id: <9310250556.AA06429@moulon.moulon.inra.fr>
Date: Mon, 25 Oct 93 06:56:08 +0100
From: decoux@moulon.inra.fr (ts)
Subject: field "METHOD" in "<FORM>"


 Hello,

 I want to update a database, and to do it I need a new field "METHOD" in
the tag "<FORM>". Example :

  - <FORM ACTION="table name"> to retrieve a row (default value "GET")
  - <FORM METHOD="PUT" ACTION="table name"> to update a row
  - <FORM METHOD="POST" ACTION="table name"> to add a row
  - <FORM METHOD="DELETE" ACTION="table name"> to delete a row

 Any other ideas ?

 Thanks,

Guy Decoux



From mcclanah@dlgeo.cr.usgs.gov  Mon Oct 25 06:45:47 1993 -0500
Message-Id: <9310251145.AA19147@dlgeo.cr.usgs.gov>
Date: Mon, 25 Oct 1993 06:45:47 -0500
From: mcclanah@dlgeo.cr.usgs.gov (mcclanah@dlgeo.cr.usgs.gov)
Subject: EARN paper

I have been trying to get to the EARN guide at vms.huji.ac.il
through Oreilly's GNN but I get:

<BODY><H1>Error 501</H1>

  Sorry, can't convert from application/postscript to www/present.</BODY>

when I click on the 'select' button. Then when I try to download
each chapter seperately I get to the "Getting Files - TRICKLE"
chapter I get an error saying that the resource doesn't 
exist or that the server is unwilling to serve it up.

Anyone have any ideas??

Thanks,
Pat McClanahan		Internet:mcclanah@dlgeo.cr.usgs.gov
EROS Data Center 		 mcclanah@edcserver1.cr.usgs.gov
Sioux Falls, SD
605-361-4607



From kgamiel@vinca.cnidr.org  Mon Oct 25 10:51:16 1993 -0400 (EDT)
Message-Id: <Pine.3.05.9310251025.B25664-c100000@vinca.cnidr.org>
Date: Mon, 25 Oct 1993 10:51:16 -0400 (EDT)
From: kgamiel@vinca.cnidr.org (Kevin Gamiel)
Subject: SIGNIDR

       SIGWAIS/SIGNIDR III At the NLM (12 November 1993)

----------------------------------------------------------------------------
After the successes of SIGWAIS I and II (held at the US Geological Survey
and the Library of Congress), the Lister Hill Center at the National Library
of Medicine is pleased to be sponsoring SIGWAIS/SIGNIDR III, to be held at
the NLM on Friday 12 November 1993, planned in collaboration with CNIDR
(the Clearinghouse for Networked Information Discovery and Retrieval).

This special interest group dealing with network-based information retrieval
is in the process of being renamed from SIGWAIS to SIGNIDR (Special Interest
Group for Networked Information Discovery and Retrieval), reflecting the
diversity of methods in use for information retrieval, and avoiding any
appearance of affiliation with the recently formed commercial venture,
WAIS, Inc.

SIGWAIS/SIGNIDR III is open to all interested parties, though the number of
attendees will be limited by the seating capacity of the meeting facilities.

This session of SIGWAIS/SIGNIDR will take full advantage of the
high bandpass audiovisual and Ethernet networks at the Lister Hill Center;
the session will be televised live over the Internet network by means
of the experimental MBONE multicasting technology,
and taped highlights will be made available after the meeting.
The technology the meeting is intended to discuss will be made an
integral part of the meeting: we have banned overhead projectors,
and speakers will be presenting their lecture aids using multimedia/hypertext
displayed via NCSA Mosaic and projected on a large screen in the auditorium
(we hope to preserve the meeting in on-line form for later access over
the Internet).

You may obtain fuller details and a registration application by one
of four means:

1) Point your Mosaic or other World Wide Web client to the URL:

      http://www.nlm.nih.gov

   and examine the section entitled Calendar of Events

2) Use anonymous ftp to connect to the host lhc.nlm.nih.gov, 
   and copy the file: ~ftp/pub/signidr.txt

3) Send electronic mail to: signidr.nlm.nih.gov

4) Contact the meeting registrar:

      Capitol Consulting Corp.
      Attn.: Janis E. Brose / SIGNIDR
      11900 Parklawn Drive, Suite 350
      Rockville MD 20852 USA
      (301)468-6001  (301)468-0338 (fax)

DEMONSTRATIONS: If you are interested in holding a demonstration in one of
the special areas to be set up in the lobby area, please contact either
R. P. C. Rodgers (rodgers@nlm.nih.gov, 301-496-9300) or Kevin Gamiel
(kgamiel@cnidr.org, 919-248-1499).

----------------------------------------------------------------------------


----------------------------------------------------------------------
Kevin Gamiel - KEVIN.GAMIEL@CNIDR.ORG
MCNC CNIDR - 919-248-1911 
Clearinghouse for Networked Information Discovery and Retrieval

Proud charter member of 
Tar Heel Information Services - "Nothing but net!"
-----------------------------------------------------------------------





From sanders@bsdi.com  Mon Oct 25 10:42:20 1993 -0500
Message-Id: <9310251542.AA01090@austin.BSDI.COM>
Date: Mon, 25 Oct 1993 10:42:20 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: field "METHOD" in "<FORM>" 

>  I want to update a database, and to do it I need a new field "METHOD" in
> the tag "<FORM>". Example :
>   - <FORM METHOD="DELETE" ACTION="table name"> to delete a row
How about:
    <FORM ACTION="http://server/database">
    <SELECT NAME="action"><OPTION>update<OPTION>create<OPTION>delete</SELECT>
    ...
We should strive for a design where the method is implicit in the users
actions (e.g., when selecting a hypertext the GET method is implicit,
however shift-right_button might imply HEAD instead) and not hardcoded in
the link.

This (a database interface) does bring up another issue.  Let's say I have
a database where one of the elements is a large piece of text (e.g., a
bug report).  You cannot currently represent this with forms.  Why?
Because when you try and put the "VALUE" in <INPUT SIZE="64,30"
VALUE="...50K of text..."> I'll bet just about every parser we have is
going to break.  The "easy" way around this is to define a new input tag
that is a container
   <h2>Bug report contents</h2>
   <TXTIN SIZE="64,30">
   default text in container
   </TXTIN>
I'll leave it to the SGML folks to solve this problem (which I believe
is important).  Attributes in SGML are next to useless.  Note that you
could it like this:
   <INPUT><VALUE>...</VALUE><LABEL>press here</LABEL></INPUT>
That way, browsers that don't understand INPUT would still show
the textual content and get an idea about what was going on.

--sanders



From decoux@moulon.inra.fr  Mon Oct 25 17:35:24 1993 +0100
Message-Id: <9310251635.AA14245@moulon.moulon.inra.fr>
Date: Mon, 25 Oct 93 17:35:24 +0100
From: decoux@moulon.inra.fr (ts)
Subject: field "METHOD" in "<FORM>" 


> How about:
>     <FORM ACTION="http://server/database">
>     <SELECT NAME="action"><OPTION>update<OPTION>create<OPTION>delete</SELECT>
>     ...
> We should strive for a design where the method is implicit in the users
> actions (e.g., when selecting a hypertext the GET method is implicit,
> however shift-right_button might imply HEAD instead) and not hardcoded in
> the link.

 I want a french version, i.e. :

     <FORM ACTION="http://server/database">
     <SELECT NAME="action"><OPTION>modification<OPTION>creation<OPTION>destruction</SELECT>

 When I select "modification", client don't know that it must use method
"PUT", example :

 When I select "modification", I don't want receive :

     GET /database?action=modification&....

   but I want receive :

     PUT /database?...



> This (a database interface) does bring up another issue.  Let's say I have
> a database where one of the elements is a large piece of text (e.g., a
> bug report).  You cannot currently represent this with forms.  Why?
> Because when you try and put the "VALUE" in <INPUT SIZE="64,30"
> VALUE="...50K of text..."> I'll bet just about every parser we have is
> going to break.  The "easy" way around this is to define a new input tag
> that is a container
>    <h2>Bug report contents</h2>
>    <TXTIN SIZE="64,30">
>    default text in container
>    </TXTIN>
> I'll leave it to the SGML folks to solve this problem (which I believe
> is important).  Attributes in SGML are next to useless.  Note that you
> could it like this:
>    <INPUT><VALUE>...</VALUE><LABEL>press here</LABEL></INPUT>
> That way, browsers that don't understand INPUT would still show
> the textual content and get an idea about what was going on.
> 

 I've very large piece of text in a database (PostScript graphic) I don't
store the text in the database but the pathname (or URL) of the documents.

Guy Decoux



From sanders@bsdi.com  Mon Oct 25 12:49:49 1993 -0500
Message-Id: <9310251749.AA01445@austin.BSDI.COM>
Date: Mon, 25 Oct 1993 12:49:49 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: WWW meta indexes (proposal)


WWW Indexing
============

  Ok folks.  It's time we got busy and made this better.  Here is a proposal
  for a simple site definition file.  Let's hash out some of the issues and
  then do it.  The sample file is on my server right now
  (http://www.bsdi.com/site.idx).

What we need to accomplish
--------------------------
1) agree on the filename of the site.idx file
2) agree on the format of the file (either "foo: data" or something else).
3) agree on the initial content and semantics of the index file
4) setup an email address where people can send registration forms
   (these don't have to be processed right away, yet).

Constraints
-----------
1) The data format must be extensible (need I even say it)
2) It must be simple enough that we can get started soon
3) It must allow for meta-indexing other protocols in the future
4) the database must be distributed (so you can do the search on
   a nearby site).

What we will need next
----------------------
1) software to accept and process registration forms (via email)
2) software for updating registration (a robot)
3) software for building the indexes (wais?)
4) software for searching the index and a site to host it

  I believe that the above is all fairly easy.

Let the indexing begin!
-----------------------

  This document is a proposal.  Discussion to take place on:
	www-talk@info.cern.ch
  Or send electronic mail to Tony Sanders _<sanders@bsdi.com>_

  The latest version of this document_ is available online at:
	http://www.bsdi.com/HTTP:TNG/www-indexing.etx

  To get the process of a WWW global index started I would like to propose
  the following for a site registration file format.  This data should
  be accessible on your server as http://server/site.idx_

  To jumpstart the registration process you will have to email one of
  these to some address yet to be determined (thereafter, your file will
  be occasionally updated by an automated retrieval process).  Of course,
  you can always email in a new one if something important changes.

  We can extend the syntax later to include pointers to other resources.
  WWW-wondering-robots would use this file to determine the server's
  preferences for indexing.  For example, we could add a field "wwwwr:
  never" (or "0000 / 2400" for always).  If you would like additional
  information to be indexed we could invent a tag that points to those
  documents (or whatever we want to do).

  I believe this covers the basics and sufficiently allows for future
  extension.

  First an example, then I will explain each field
  (this file is http://www.bsdi.com/site.idx_):

Name:                   www.bsdi.com:80
Organization:           Berkeley Software Design, Inc
Organization-Type:      Commercial software developer
Contact:                Tony Sanders
Postal-Address:         3110 Fairview Park Dr, Suite 580;
			Falls Church, VA 22042
Electronic-address:     webmaster@www.bsdi.com
Telephone:              +1 800 800 BSDI
Location:               Fairfax County, VA, USA
Latitude-Longitude:     77 12 00 - / 38 51 37 +
Timezone:               -0500 (Eastern Standard Time)
Written-By:             sanders@www.bsdi.com (Tony Sanders);
			Mon Oct 25 11:39:14 CDT 1993
Access times:           0000 / 2400
Policy:                 None
Description:            This site contains public sources and information
			related to BSDI's software products (eg: BSD/386).
			Currently all sources are for publicly contributed
			BSD/386 utilities.
Keywords:       	BSD, OS, source, berkeley, BSD/386, BSDI
Index:			/info/ BSDI and BSD/386 Information
Index:			/bsdi-man/ BSD/386 hypertext manual pages
Index:			/official_patches/ BSDI 1.0 Official Patches Archive

  Continuation lines begin with white space.
  Case is only significant in data that requires it (e.g., inside URLs).

  The following isn't a complete specification, but I think it's enough to
  get us started.  Most of this is stolen from other formats.

Name
----
  Server name (including an option port number).

host[:port]

  Host is a fully qualified domain name or a dot-quad ip address.
  port should be a numeric.  For example:
	Name: www.bsdi.com:80

Organization
------------
  Organization name.  For example:
	Organization: Berkeley Software Design, Inc

Organization-Type
-----------------
  A general classification of what you do.  For example:
	Organization-Type: Commercial software developer

Contact
-------
  Name of a human to contact.  For example:
	Contact: Tony Sanders

Postal-Address
--------------
  Postal address.  For example:
	Postal-Address: 3110 Fairview Park Dr, Suite 580;
			Falls Church, VA 22042

Electronic-address
------------------
  Email address contact for the server.  For example:
	Electronic-address: webmaster@www.bsdi.com

Telephone
---------
  Telephone number for contact.  For example:
	Telephone: +1 800 800 BSDI

Location
--------
  General geographical location.  For example:
	Location: Fairfax County, VA, USA

Latitude-Longitude
------------------
  Degrees minutes and seconds, for drawing cute maps.  For example:
	Latitude-Longitude: 77 12 00 - / 38 51 37 +

Timezone
--------
  Offset from GMT and then a textual name.  For example:
	Timezone: -0500 (Eastern Standard Time)

Written-By
----------
  Author of this text, including the last update time.  For example:
	Written-By: sanders@www.bsdi.com (Tony Sanders);
		    Mon Oct 25 11:39:14 CDT 1993

Access-times
------------
  When the server is available (in local 24 hour time).  For example:
	Access-times: 0000 / 2400
  Multiple entries are allowed.

Policy
------
  Any policy statement you wish to make (e.g., the GNN server might
  wish to give registration information here).  For example:
	Policy: None

Description
-----------
  A brief description of the server (used for building meta-indexes).
  For example:
	Description: This site contains public sources and information
		     related to BSDI's software products (eg: BSD/386).
		     Currently all sources are for publicly contributed
		     BSD/386 utilities.

Keywords
--------
  Keywords for constrained searches.  The words are comma separated,
  use "text, text" if you need to embed a comma, but it's best to have
  simple words and not phrases.  For example:
	Keywords: BSD, OS, source, berkeley, BSD/386, BSDI
  Multiple entries are allowed.

Index
-----
  These are pointers to information indexes that the server supplies.
  The first word is a partial URL (relative to the top of the server)
  and the rest of the text is used to build the meta-index.  For example:
	Index: /info/ BSDI and BSD/386 Information
  Multiple entries are allowed.

Tony_Sanders_

.. _Tony_Sanders http://www.bsdi.com/hyplan/sanders.html
.. _document http://www.bsdi.com/HTTP:TNG/www-indexing.etx
.. _http://www.bsdi.com/site.idx http://www.bsdi.com/site.idx



From sanders@bsdi.com  Mon Oct 25 13:57:10 1993 -0500
Message-Id: <9310251857.AA01736@austin.BSDI.COM>
Date: Mon, 25 Oct 1993 13:57:10 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: WWW meta indexes (proposal) 

George Phillips <phillips@cs.ubc.ca> asks:
> Seems a little biased towards HTTP.  Any reason why the "Name:" field
> can't be a URL which will give you the host and port number along
> with the access mechanism and a starting point.  If we do that,
> then your index format can be used for other WWW servers such
> as gopher or FTP sites.
Sounds like a good idea, the changes have been made to the online
copy.  After all I did say:
    Constraints:
    3) It must allow for meta-indexing other protocols in the future

Name:			http://www.bsdi.com:80/
Index:			http://www.bsdi.com:80/info/ BSDI and BSD/386 Information
Index:			http://www.bsdi.com:80/bsdi-man/ BSD/386 hypertext manual pages
Index:			http://www.bsdi.com:80/official_patches/ BSDI 1.0 Official Patches Archive

We need to decide what this means.  For example, what does "Name:
http://www.bsdi.com:80/foobar" mean? Do you really want Index: to point
to other services? or should they be indexed separately?

--sanders



From marca@ncsa.uiuc.edu  Mon Oct 25 14:30:21 1993 -0700
Message-Id: <9310252130.AA23783@wintermute.ncsa.uiuc.edu>
Date: Mon, 25 Oct 93 14:30:21 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: EARN paper

mcclanah@dlgeo.cr.usgs.gov writes:
> I have been trying to get to the EARN guide at vms.huji.ac.il
> through Oreilly's GNN but I get:
> 
> <BODY><H1>Error 501</H1>
> 
>   Sorry, can't convert from application/postscript to www/present.</BODY>
> 
> when I click on the 'select' button. Then when I try to download
> each chapter seperately I get to the "Getting Files - TRICKLE"
> chapter I get an error saying that the resource doesn't 
> exist or that the server is unwilling to serve it up.
> 
> Anyone have any ideas??

Depends what browser you're using -- if you're using Mosaic 2.0
prerelease 6, you should be getting a popup dialog to name a local
filename (unless you have defined a viewer for application/postscript
or are using the default settings).

May I suggest that other browsers default to "save to local disk" on
unrecognized MIME types rather than just giving up?

Marc




From jay@bogle.eit.COM  Mon Oct 25 12:51:45 1993 -0700
Message-Id: <9310251952.AA05263@eit.COM>
Date: Mon, 25 Oct 1993 12:51:45 -0700
From: jay@bogle.eit.COM (Jay Glicksman)
Subject: New WWW service for the www-talk mail archive

Enterprise Integration Technologies (EIT) announces the availability
of a WWW server that includes a threaded version of the www-talk
archive. It uses the Hypermail program developed by Tom Gruber at
KSL/Stanford University to put email archives into html format
(including embedded URLs).

A description of Hypermail can be found at
http://gummo.stanford.edu/html/hypermail/hypermail.html
The www-talk archive index is at
http://gummo.stanford.edu/html/hypermail/archives.html
The archive covers the entire history of the mailing list (divided
into years and quarters). It is updated every night.

This server is being set up as part of the SHARE project, a
collaboration between CDR and SIMA at Stanford University and EIT
(http://gummo.stanford.edu/). SHARE is developing tools and services
to support mechanical engineering design, one example of which is the
ME210 design class at Stanford. We will announce other WWW services
developed through this project as they become available.

	Jay Glicksman



From putz@parc.xerox.com  Mon Oct 25 14:56:54 1993 PDT
Message-Id: <93Oct25.145700pdt.2445@spoggles.parc.xerox.com>
Date: Mon, 25 Oct 1993 14:56:54 PDT
From: putz@parc.xerox.com (Steve Putz)
Subject: Interactive WWW Folk Song Database

There is a new World-Wide Web Server for the Digital Tradition folk song
database which allows users with an Internet connection to search for and
display songs interactively using any of several freely available WWW clients.
The WWW server can even provide audio of the song tunes for some systems.  
The Digital Tradition server is located at:

	http://web2.xerox.com/digitrad

To find out about more about the Digital Tradition database, access the above
WWW server or send email to digitrad@world.std.com (Dick Greenhaus).

If you have questions or comments about the Digital Tradition World-Wide Web
server, please contact me:

Steve Putz <putz@parc.xerox.com>
Xerox Palo Alto Research Center
Palo Alto, California




From Colin.Panisset@nms.otc.com.au  Tue Oct 26 11:05:36 1993 +1000 (EST)
Message-Id: <9310260105.AA00940@ra.pad.otc.com.au>
Date: Tue, 26 Oct 1993 11:05:36 +1000 (EST)
From: Colin.Panisset@nms.otc.com.au (Colin Panisset)
Subject: HTML+ spec -- is it anywhere?


I've looked through the back archives of the www-talk list, but I 
can't find any reference to a published spec of HTML+ -- is it
still growing (and as a result, unpublished), or have I just
missed something along the way?

--
  +61 2 339 3938 Fax: +61 2 339 3818 | It rolls down stairs, alone or in
  Colin Panisset *:^)    PGP 2.3 key | pairs, runs over your neighbor's dog.
  colinp@nms.otc.com.au    available | It's good for a snack, it fits on your
  So There.               on request | back, it's Log! Log! Log!  - R & S
  ------------------ PGP 2.3 key available on request. ----------------



From sanders@bsdi.com  Mon Oct 25 23:21:02 1993 -0500
Message-Id: <9310260421.AA03392@austin.BSDI.COM>
Date: Mon, 25 Oct 1993 23:21:02 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: WWW meta indexes (proposal) 

BTW: I found a pointer to the spec that my proposal was based on.  It's
the IAFA (Internet Anonymous Ftp Archives) work which you can read about on:
    ftp://sunsite.unc.edu/pub/docs/iafa/
namely:
    ftp://sunsite.unc.edu/pub/docs/iafa/draft.part.II

I'll work through it and update the proposal (though on a first pass
I didn't see much that needs to be changed).  I did add a Fax: field
on request from Terry Allen <terry@ora.com>.

I also changed Policy: to allow a URL using the <URL> notation.

And I added a Frequency: (per the draft) which is the "preferred" frequency
(in days) that index information should be updated.
    Frequency: 5
I suppose, smart browsers/gateways could also use this information to aid
in setting a caching strategy (when more specific information is not
provided).

The full IAFA draft covers all kinds of information (abstracts,
packages, news and mailing list archives, etc).  Once we have a
list of servers in place, we can worry about the other stuff.
We just need to keep in it mind.

The IAFA draft split SITEINFO (physical information) and DESCRIPT (logical
ifnormation) into two seperate files.  They use filenames like IAFA-SITEINFO
which I think is a very unix centric thing to do.  I choose site.idx
because it will work everywhere.  I have no problem splitting this info
into two files if everyone thinks it's ok.

--sanders



From Jon.Tetzchner@nta.no  Tue Oct 26 09:45:42 1993 +0100
Message-Id: <199310260845.AA02135@hal.nta.no>
Date: Tue, 26 Oct 1993 09:45:42 +0100
From: Jon.Tetzchner@nta.no (Jon von Tetzchner Stephenson)
Subject: 

> I second the motion on this subject.
> 
> I have been looking for this software for sometime now. I did get a
> copy of the MIF2HTML at one time but this didn't address the following:
> 
>    generation of a hierarchy of interlinked HTML files 
>      (Chapter, Section, etc.) 
>    links with external HTML documents, 
>    generation of tables of contents and indices, 
>    cross-references 
>    inclusion of pictures. 
> 
> Thanks in advance for the info.
> Omy
> > 
> > I was browsing through the "ADAMO Users Guide", at the following URL
> > http://www1.cern.ch:80/Adamo/guide/NoNumSection-2-2.html
> > and noticed that the document had been converted from FrameMaker to HTML.
> > 
> > The following paragraph makes reference to the conversion tools, but no
> > reference to where one can retrieve these tools from.  I have tried to
> > contact Bertrand Rousseau, but have not received a reply yet.  I would
> > greatly appreciate any help in locating these tools, since we have many
> > FrameMaker documents that we would like to put up on the Web.
> > 
> > > The converter has been developed by Bertrand Rousseau, in awk and Lisp.
> > > It can be modified easily to process FrameMaker documents structured
> > > differently than ours, or to generate other kinds of WWW file organisations.
> > 
> > Thanks!
> > 
> > -- 
> > Mark A. Krause			mkrause@mitre.org
> > The MITRE Corporation		Mail Stop W273
> > 7525 Colshire Drive		(703)883-7642 (Voice)		
> > McLean, VA 22102		(703)883-6478 (Fax)
> 

I am working on a Frame2html filter. I have a working version, which
I intend to make available in a while on the internet. The filter
makes use of a number of products. I think all of them are available
on the net.

The filter generates a table of contents automatically. It handles
FrameMaker books as well as files and makes a hierarky that copies
the Book hierarky.

Pictures are handled as well as tables. X-references in the Frame
documents become html links in the html documents.

The filter can be easily modified (one file that links Frame tags
to the internal tags of the filter) so that the filter can take
any Framemaker file.

If you are interested, I can give you more information, or send
the filter to you at a later stage.

	Jon.




From m.koster@nexor.co.uk  Tue Oct 26 09:43:54 1993 +0000
Message-Id: <9310260944.AA15707@dxmint.cern.ch>
Date: Tue, 26 Oct 1993 09:43:54 +0000
From: m.koster@nexor.co.uk (Martijn Koster)
Subject: Re: WWW meta indexes (proposal)


> 
> WWW Indexing
> ============
> 
>   Ok folks.  It's time we got busy and made this better.

Hehe... I was just planning to start doing some perling on thursday night
based on the indexing discussion I started on c.i.www before going on
holiday :-) Did you have a look at
	http://www.nexor.co.uk/mak/doc/summarising/proposal.html ?

>  Let's hash out some of the issues and then do it.

Yes. You got my full support there :-)

 
> What we need to accomplish
> --------------------------
> 1) agree on the filename of the site.idx file

/site.idx is fine for me.

> 2) agree on the format of the file (either "foo: data" or something else).

I vote yes for foo: data (with RFC-822 like continuation line.

> 3) agree on the initial content and semantics of the index file

In your site.idx you have single index lines that are of the form
Index: <url> <description>. I have some comments about that:

To allow nice presentation of the search results I'd like some more info
here: URL, title and description at least. Somebody suggested some 
indication to the level of document, like "Service", "document", "mention".
I think this might be useful; I for one will hapily run a search engine
on a resulting database of services, whereas a database of all
documents is to big for my liking.
If you allow HTML in the description (which again would be nice for
presentation) it might be useful to have explicit keywords as well 
(to prevent people searching for HREF picking up references in the
description for example. 

If you start using all these different fields per URL it makes more sense
to split them up into records with separate "foo: data" fiels, and 
separated by blank lines. As the URLs are the main reason we want to do
indexing I don't think that is unreasonable.

However, if the concencsus is that this makes creating and maintaining
the index to much effort then I say go for the single line (it's easier
to grep through too :-).

> 4) setup an email address where people can send registration forms
>    (these don't have to be processed right away, yet).

I suggest this is actually a distribution list (that I'd like to
be on :-) That way we can have multiple servers on the net.
Unfortunately I am not in a position where I can offer to setup/
maintain such a list (oh, I'd love a WWW job... :-)

> Constraints
> -----------
> 1) The data format must be extensible (need I even say it)

I think this is an argument for a record-based url description;
you can add fields if / when you like. 

> 2) It must be simple enough that we can get started soon

Yes

> 3) It must allow for meta-indexing other protocols in the future

Isn't that implicit in using UR?s

> 4) the database must be distributed (so you can do the search on
>    a nearby site).

I think the only quick way we are going to decide on that is to run multiple
identical servers (like Archie). If we start to discuss distributed protocols
like X.500/whois++ I think we'll be here for a while.

> What we will need next
> ----------------------
> 1) software to accept and process registration forms (via email)
> 2) software for updating registration (a robot)
> 3) software for building the indexes (wais?)
> 4) software for searching the index and a site to host it
> 
>   I believe that the above is all fairly easy.

Should be.

>   To get the process of a WWW global index started I would like to propose
>   the following for a site registration file format.  This data should
>   be accessible on your server as http://server/site.idx_

Sure.

>   I believe this covers the basics and sufficiently allows for future
>   extension.

Summary: Yes, let's sort out the indexing. I like the host-specific 
information. I don't think the single "Index" lines allow for
future extension.

-- Martijn

__________
Internet: m.koster@nexor.co.uk
X-400: C=GB; A=Mark400; P=Nexor; O=Nexor; S=koster; I=M
X-500: c=GB@o=NEXOR@cn=Martijn Koster
WWW: http://web.nexor.co.uk/mak/mak.html



From dsr@hplb.hpl.hp.com  Tue Oct 26 10:20:43 1993 GMT
Message-Id: <9310261020.AA05313@manuel.hpl.hp.com>
Date: Tue, 26 Oct 93 10:20:43 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: field "METHOD" in "<FORM>"

> We should strive for a design where the method is implicit in the users
> actions (e.g., when selecting a hypertext the GET method is implicit,
> however shift-right_button might imply HEAD instead) and not hardcoded in
> the link.

Previous discussions suggested including the HTTP method as an optional prefix
in the action e.g. ACTION="POST http://..." but I agree that where possible
authors should design the form so that the effect of submitting the form is
explicitly chosen by the user's actions and not via the HTTP method.

> This (a database interface) does bring up another issue.  Let's say I have
> a database where one of the elements is a large piece of text (e.g., a
> bug report).  You cannot currently represent this with forms.  Why?
> Because when you try and put the "VALUE" in <INPUT SIZE="64,30"
> VALUE="...50K of text..."> I'll bet just about every parser we have is
> going to break.

Don't worry! The HTML+ Internet Draft (due out by the end of this week :)
covers this. The HTML/HTML+ DTD limits attribute literals to 1024 characters,
(the SGML default is only 240 chars!). You can include line breaks in literals
as these are mapped to spaces. In fact, any contiguous sequence of white space
characters in attribute literals are defined by SGML to map to a single space
character.

The spec now uses a separate element for multiline text fields to allow
the value to be arbitrarily long. You can specify the visible extent of
the field in rows and columns, but browsers are free to allow users to
enter arbitrarily amounts of text - not restricted by the visible extent.
Option lists will also be represented by a separate element <SELECT> to
allow arbitrarily long option lists.

The spec also covers scribble fields upon which you can write with a pointing
device such as a pen, and audio fields for entering spoken messages. This
is made possible through the use of multipart MIME messages for sending
form contents to servers.

Cheers,

Dave Raggett



From sanders@bsdi.com  Tue Oct 26 10:56:14 1993 -0500
Message-Id: <9310261556.AA04126@austin.BSDI.COM>
Date: Tue, 26 Oct 1993 10:56:14 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: WWW meta indexes (proposal) 

Ok, great, my spec now only covers the physical and contact information,
then refers to yours for the url index information.  Feel free to merge
my stuff into yours and then mine will go away.  http://www.bsdi.com/site.idx
has been updated to refelect the current spec.

Building a test database should be our first priority now so Martijn can
write some perl code.

The next big thing we need to do (and we should probably start now so it
will be ready by the time we have software) is to allocate a www.org domain
(or whatever) to own the server name.  This domain would be taken over by
the WWW consortium when it springs into existence.  Then register@www.org
will be the registration daemon (which will validate and distribute
submissions).  If we don't do this we will regret it later on.  Seems like
TimBL should own this problem for now (unless he can sign up someone else
to own it).

--sanders



From m.koster@nexor.co.uk  Tue Oct 26 16:01:15 1993 +0000
Message-Id: <9310261602.AA16002@dxmint.cern.ch>
Date: Tue, 26 Oct 1993 16:01:15 +0000
From: m.koster@nexor.co.uk (Martijn Koster)
Subject: Re: WWW meta indexes (proposal)


>     ftp://sunsite.unc.edu/pub/docs/iafa/draft.part.II
> ...
> The full IAFA draft covers all kinds of information (abstracts,
> packages, news and mailing list archives, etc).  Once we have a
> list of servers in place, we can worry about the other stuff.
> We just need to keep in it mind.

After reading the draft I'm a bit confused where your proposal fits in.
If you want to have only server information (hardly usfeull IMHO) you
wouldn't need the "Index: " line, so I assume you are also after the
contents (URLs).

They correspond more to the "Document Abstracts" section of the IAFA
draft, and that proposes records with >1 fields, which is what I argued
for before (albeit with fields more specificly for a WWW context).

-- Martijn
__________
Internet: m.koster@nexor.co.uk
X-400: C=GB; A=Mark400; P=Nexor; O=Nexor; S=koster; I=M
X-500: c=GB@o=NEXOR@cn=Martijn Koster
WWW: http://web.nexor.co.uk/mak/mak.html



From m.koster@nexor.co.uk  Tue Oct 26 17:15:06 1993 +0000
Message-Id: <9310261716.AA11109@dxmint.cern.ch>
Date: Tue, 26 Oct 1993 17:15:06 +0000
From: m.koster@nexor.co.uk (Martijn Koster)
Subject: Re: WWW meta indexes (proposal)


> Ok, great, my spec now only covers the physical and contact information,
> then refers to yours for the url index information.  Feel free to merge
> my stuff into yours and then mine will go away.  http://www.bsdi.com/site.idx
> has been updated to refelect the current spec.

OK... I'm happy with the current situation as a basis for a pilot.

> Building a test database should be our first priority now so Martijn can
> write some perl code.
 
Other people can feel free too :-) 

-- Martijn
__________
Internet: m.koster@nexor.co.uk
X-400: C=GB; A=Mark400; P=Nexor; O=Nexor; S=koster; I=M
X-500: c=GB@o=NEXOR@cn=Martijn Koster
WWW: http://web.nexor.co.uk/mak/mak.html



From Steve.Heaney@delft.sgp.slb.com  Tue Oct 26 18:55:51 1993 +0100
Message-Id: <199310261755.AA15602@mordred.delft.sgp.slb.com>
Date: Tue, 26 Oct 1993 18:55:51 +0100
From: Steve.Heaney@delft.sgp.slb.com (Steve Heaney)
Subject: Re: Stylesheet Language


All,

Could I suggest that rather that re-invent the wheel, we consider using an 
SGML DTD for specifying stylesheets.

Below is Pei Wei's example reimplemented using an *existing* SGML DTD that was 
designed as a page description language.

<outspec>
<docdesc>
<charlist>
<font size="12pt" bckcol="white" fontcol="black">
</charlist>
</docdesc>

<e-i-c gi="h1"><font size="24pt" bckcol="red", fontcol="white">
</e-i-c>

<e-i-c gi="h2"><font size="20pt" bckcol="red", fgcol="white">
</e-i-c>

<e-i-c gi="a"><font fgcol="red">
</e-i-c>

<e-i-c gi="cmd kbd screen listing example"><font style="monoser">
</e-i-c>

<e-i-c gi="bold emph strong"><font weight="bold">
</e-i-c>

<e-i-c gi="i"><font posture="italic">
</e-i-c>

<e-i-c gi="p" context="address"><font posture="italic">
</e-i-c>

<e-i-c gi="li" context="ol"><counter style="romanlc">
</e-i-c>

<e-i-c gi="li" context="ol li ol"><counter style="alphalc">
</e-i-c>

<e-i-c gi="footnote"><font size="10pt">
</e-i-c>

</outspec>

(The e-i-c tag is element in context - I hope the rest are reasonably 
self evident).

This compares to the example below in Pei Wei's original posting.

(HEAD,BODY				fontSize=normal
					BGColor=white
					FGColor=black
    (H1					fontSize=largest
					BGColor=red
					FGColor=white)
    (H2					fontSize=large)
    (P)
    (A					FGColor=red)
    (CMD,KBD,SCREEN,LISTING,EXAMPLE	fontFamily=fixed)
    (BOLD,EMPH,STRONG			fontWeight=bold)
    (I				 	fontSlant=italic)
    (ADDRESS
        (P				fontSlant=italic))
    (OL
	(LI				numStyle=roman
	    (LI                         numStyle=number
		(LI			numStyle=alpha)
	    )
	)
    )
    (FOOTNOTE				fontSize=small
	(P)
    )
)


There are several advantages to this - and several disadvantages.

On the plus side:

1. It is SGML and so it can be validated with the tools some of us already 
   use.
2. Once we have a public domain SGML editor, we can use that to write 
   our stylesheet.
3. It is a standard already. The Formatting Output Specification Instance 
   DTD is used as the page description language as part of the US Dod CALS 
   initiative.
4. It is supported by several commercial SGML editors.
5. Given that it is a standard, implementations of tools supporting it 
   may/will appear in the public domain.
6. As the requirements made of stylesheets expand (as they undoubtedly 
   will) there is the framework already there to guide development.  (The 
   FOSI DTD has many features not demonstrated in the example above).
7. Why reinvent the wheel?

On the minus side:

1. it is probably less easy to read.
2. it is therefore less easy to write without assistance.

How about it?

As something to mull over - *not* as a request to add these to the 
specification for style sheet as currently conceived, here are some of the 
other formatting attributes that the FOSI DTD includes:

<presp>     amount of space to render before element. | not currently handled 
<postsp>    amount of space to render after element.  | consistently by browsers
<indent>    left/right indent.
<boxing>    place box around element (I think Marc mentioned this).
<textbrk>   whether to break text at start/end of element, create new page etc.
<quadding>  left/right/center.

And some more exotic options:

<savetext>  save copy of text.
<usetext>   place saved text in output stream.
<enumerat>  control the behaviour of element counters i.e. section numbers, 
            list numbering etc.

Steve.

------------------------------------------------------------------------
Steven Heaney

Schlumberger Geco-Prakla
Internet: heaney@delft.sgp.slb.com
------------------------------------------------------------------------



From joe@mit.edu  Tue Oct 26 17:06:47 1993 -0400
Message-Id: <9310262106.AA06279@theodore-sturgeon.MIT.EDU>
Date: Tue, 26 Oct 93 17:06:47 -0400
From: joe@mit.edu (joe@mit.edu)
Subject: WWW meta indexes (proposal)


I can offer the GNA meta-library as a site for searching the index.  I
already have a postgres database connected to a plexus server as a
search engine.  All that is necessary is to write some perl scripts
that will do the registration semi-automatically.

I can give accounts to people interested on helping to develop this.





From wei@sting.berkeley.edu  Tue Oct 26 17:10:33 1993 -0700
Message-Id: <9310270010.AA23998@sting.Berkeley.EDU>
Date: Tue, 26 Oct 93 17:10:33 -0700
From: wei@sting.berkeley.edu (Pei Y. Wei)
Subject: FOSI

The idea was to do a quick style-hints sort of thing ASAP, 
rather than something as comphrehensive as FOSI. But I suppose
a very subset of FOSI can be that.

Personally I still much prefer the simple semi LISP'ish syntax.
But I see your points. Didn't realize several commercial SGML 
editors support it. Another argument for using SGML for stylesheets
may be that it could more easily be embedded in SGML documents.

If we go with FOSI now, someone should edit down the FOSI DTD. 
As is its got too much we can't use now.

Either way is fine with me. Let's see what others think. 

-Pei					Pei Y. Wei
					O'Reilly & Associates




From sanders@bsdi.com  Tue Oct 26 11:51:34 1993 -0500
Message-Id: <9310261651.AA04428@austin.BSDI.COM>
Date: Tue, 26 Oct 1993 11:51:34 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: WWW meta indexes (proposal) 

> After reading the draft I'm a bit confused where your proposal fits in.
Mostly just the formats of the various lines.

> If you want to have only server information (hardly usfeull IMHO) you
> wouldn't need the "Index: " line, so I assume you are also after the
> contents (URLs).
I want both, the IAFA stuff covers the server information (which is
useful for saying find all the GNN servers in TX).  I adopted
your URL index information.

--sanders



From dale@ora.com  Wed Oct 27 00:12:41 1993 -0700
Message-Id: <9310270012.ZM21727@rock.west.ora.com>
Date: Wed, 27 Oct 1993 00:12:41 -0700
From: dale@ora.com (Dale Dougherty)
Subject: Dial-up Users

I'd like to know of any efforts to expand the Web's reach by
providing greater support for serial dial-up Internet users?  More specifically, 
MacMosaic and Mosaic for Windows ought to be able to function
on systems that are not directly connected to the network.  Right
now, a SLIP/PPP connection is required to use a graphical browser; these
connections are more expensive to obtain and more difficult to install.

What can we do to enable communication over a serial line?  
It seems to me you need two things: a browser that can establish
a connection over a serial line with a net host and a process that
runs on the net host to listen for the browser's requests and act
as a gateway to the network.

This capability would allow the Web to grow enormously. 

I'd appreciate hearing from anyone who is thinking about or actually
working on this problem.

Dale

-- 
Dale Dougherty (dale@ora.com) 
Publisher, Global Network Navigator, O'Reilly & Associates, Inc.
103A Morris Street, Sebastopol, California 95472 
(707) 829-3762 (home office); 1-800-998-9938



From m.koster@nexor.co.uk  Wed Oct 27 09:11:44 1993 +0000
Message-Id: <9310270912.AA28532@dxmint.cern.ch>
Date: Wed, 27 Oct 1993 09:11:44 +0000
From: m.koster@nexor.co.uk (Martijn Koster)
Subject: Re: Dial-up Users


> [Description of why not have a dial-up browser instead of SLIP/PPP deleted]
>
> I'd appreciate hearing from anyone who is thinking about or actually
> working on this problem.

Well, this keeps coming up. The thing is, running a process on the host
requires setting things up, same as SLIP/PPP. To get error-free communication
you need a error-checking protocol, which gives you overhead, same as SLIP/PPP.
If you develop such a protocol, there won't be any implementations or
experience, unlike SLIP/PPP.

You only win a bit less overhead, but with a lot less functionality (only
WWW, nothing else), costing lot of effort. Is that worth it, keeping in mind
connections only get faster? I don't think so. If you want the full
graphical interface, images and what have you, use SLIP/PPP on a 
decent connection. If you are content with the basics over a slow line,
dial into Lynx or something.

Of course, if you do develop a dial-up browser you will instantly prove me
wrong; thousands will love you :-)

Just my 2p.

-- Martijn
__________
Internet: m.koster@nexor.co.uk
X-400: C=GB; A=Mark400; P=Nexor; O=Nexor; S=koster; I=M
X-500: c=GB@o=NEXOR@cn=Martijn Koster
WWW: http://web.nexor.co.uk/mak/mak.html



From lou@vax.ox.ac.uk  Wed Oct 27 09:48:01 1993 +0000
Message-Id: <00974A36.D34C5AB8.8176@vax.ox.ac.uk>
Date: Wed, 27 Oct 1993 09:48:01 +0000
From: lou@vax.ox.ac.uk (Lou Burnard)
Subject: FOSI/sgml stylesheets

I'd like to endorse very strongly indeed the notion of using SGML as a
notation for whatever style-sheet mechanism you eventually decide on. I
don't particularly mind whether it's a FOSI-subset, or a DSSSL
look-alike or a home-brewed dtd, but at least if it uses the SGML
formalism
(a) people can create and validate stylesheets with industry standard
software (Yes it does exist!) 
(b) people only have to learn ONE formalism
(c) integration with/conversion to other SGML-aware browsers is easy

Lou Burnard



From lou@vax.ox.ac.uk  Wed Oct 27 12:26:56 1993 +0000
Message-Id: <00974A4D.06A409E0.10591@vax.ox.ac.uk>
Date: Wed, 27 Oct 1993 12:26:56 +0000
From: lou@vax.ox.ac.uk (Lou Burnard)
Subject: fosi/sgml

I'm not sure why Terry  objects to my use of the phrase "industry
standard"  with reference to SGML software.  I agree that it would be
nice if the word "standard" could be kept to mean "Standard", but life's
not like that (as people on the Internet are constantly pointing out).
Anyway, all I wanted to remind people was that there are quite a few
generic SGML authoring and validation tools around, both commercial and
non-commercial, which means that preparing stylesheets etc. in SGML
format might be a lot less painful than preparing them in some ad hoc
formalism for which such tools don't currently exist. 

I take the point about Mosaic (etc) not *really* recognising SGML,
however. But it's not relevant to the point I was making.

Lou



From jpw@sansfoy.lib.virginia.edu  Wed Oct 27 08:23:54 1993 -0400
Message-Id: <9310271223.AA05491@sansfoy.lib.virginia.edu>
Date: Wed, 27 Oct 93 08:23:54 -0400
From: jpw@sansfoy.lib.virginia.edu (John Price-Wilkin)
Subject: sample SGMLish formatting style sheet from Lector (long)

Open Text's Lector, an X-Windows browser for tagged text, uses an sgml-ish  
display specification language.  I'm including in this an extract from the  
spec file we use for our Old English collection, and there's not as much  
variety in this as is possible with Lector, but perhaps it will give some  
inspiration in the process of creating a stylesheet language.

 # Spec file for Old English Corpus
 # Font declarations; we used the OED fonts that Open Text created because
 # of their better rendering of characters such as thorn.
 <Font>
         <Name>-oed-times-medium-r-normal--18-*</Name>
       <Family>Times</Family>
       <Type>Roman</Type>
       <Size>18</Size>
 </Font>
 <Font>
       <Name>-oed-times-medium-r-normal--14-*</Name>
       <Family>Times</Family>
       <Type>Roman</Type>
       <Size>14</Size>
 </Font>
 

 <Font>
       <Name>-oed-times-bold-r-normal--18-*</Name>
       <Family>Times</Family>
       <Type>Bold</Type>
       <Size>18</Size>
 </Font>
 <Font>
       <Name>-oed-times-bold-r-normal--14-*</Name>
       <Family>Times</Family>
       <Type>Bold</Type>
       <Size>14</Size>
 </Font>
 

 <Font>
       <Name>-oed-times-medium-i-normal--18-*</Name>
       <Family>Times</Family>
       <Type>Italic</Type>
       <Size>18</Size>
 </Font>
 <Font>
       <Name>-oed-times-medium-i-normal--14-*</Name>
       <Family>Times</Family>
       <Type>Italic</Type>
       <Size>14</Size>
 </Font>

 

 # Formats; at this point follows a series of <Spec></Spec> declarations
 # which are then rendered, under Lector, as menu options for viewing
 # the text in various ways.  I've removed all but what we call "Standard".
 # Other views typically included a shift of font to something smaller or
 # larger, a view of the tagged text, sometimes both formatted (according
 # to the rules declared in "Standard") and unformatted, and skeleton
 # views where most elements except structural headers such as chapter
 # titles are turned on.
<Spec>
       <Name>Standard</Name>
       <PrUndef>off</PrUndef>
       <PrText>on</PrText>
       <PrTag>off</PrTag>
       <Family>Times</Family>
       <Type>Roman</Type>
       <Size>18</Size>
       <Tabs>3 6 9 14 15 18 21 24 27 30 33 36 39 42 45</Tabs>
 

       # when output is fed from PatMotif to Lector, the searched-for
       # term is tagged by PatMotif with <MATCH></MATCH>; this next
       # little bit highlights the match
       <Tag>
               <Name>MATCH</Name>
               <Highlight>on</Highlight>
               <PrText>on</PrText>
       </Tag>
 

         <Tag>
                 <Name>/MATCH</Name>
                  <Highlight>off</Highlight>
          </Tag>

        # rendering entity references; in this collection, stripped
	# down references such as &t; (rather than &thorn;) are used
       <Tag><Name>t</Name><String>&254.</String><Syntax>&;</Syntax></Tag>
       <Tag><Name>T</Name><String>&222.</String><Syntax>&;</Syntax></Tag>
       <Tag><Name>A</Name><String>&198.</String><Syntax>&;</Syntax></Tag>
       <Tag><Name>a</Name><String>&230.</String><Syntax>&;</Syntax></Tag>
       <Tag><Name>amp</Name><String>&38.</String><Syntax>&;</Syntax></Tag>
       <Tag><Name>Y</Name><String>&51.</String><Syntax>&;</Syntax></Tag>
       <Tag><Name>y</Name><String>&51.</String><Syntax>&;</Syntax></Tag>
       <Tag><Name>D</Name><String>&208.</String><Syntax>&;</Syntax></Tag>
       <Tag><Name>d</Name><String>&240.</String><Syntax>&;</Syntax></Tag>
       <Tag><Name>E</Name><String>E</String><Syntax>&;</Syntax></Tag>
       <Tag><Name>e</Name><String>e</String><Syntax>&;</Syntax></Tag>

        # Generic structural and typographic information
        <Tag> <Name>Work</Name>
         <Attribute><Name>n</Name><PrVal>on</PrVal>
          <BlankLines>1</BlankLines>
          <Size>18</Size>
          </Attribute>
          <PrText>on</PrText><PrTag>off</PrTag> </Tag>
        <Tag> <Name>/Work</Name><Restore>Work</Restore></Tag>


        # Bib Stuff for title page
        <Tag><Name>extent.statement</Name><PrText>on</PrText>
          <BlankLines>0</BlankLines></Tag>
        <Tag>
        <Name>title</Name><PrText>on</PrText><PrTag>off</PrTag>
        <BlankLines>0</BlankLines></Tag>
        

        <Tag><Name>publication.statement</Name><PrText>on</PrText>
          <BlankLines>0</BlankLines></Tag>
         

        <Tag><Name>citn</Name><PrText>on</PrText>
        <BlankLines>0</BlankLines><PrTag>off</PrTag></Tag>
        <Tag><Name>/citn</Name><Restore>citn</Restore></Tag>

         <Tag><Name>reference.system</Name>
         <PrText>on</PrText><BlankLines>0</BlankLines>
         <PrTag>off</PrTag></Tag>
         <Tag> <Name>/reference.system</Name>
           <Restore>reference.system</Restore></Tag>
        

        <Tag> <Name>text.category</Name>
         <Attribute><Name>def</Name><PrVal>on</PrVal>
          <PreString>Category:  </PreString><BlankLines>1</BlankLines>
          <Size>18</Size>
          </Attribute>
          <PrText>on</PrText><PrTag>off</PrTag> </Tag>
        <Tag><Name>/text.category</Name>
	<Restore>text.category</Restore></Tag>

        <Tag> <Name>TEXT</Name>
          <PrText>on</PrText><PrTag>off</PrTag> </Tag>
        <Tag> <Name>/TEXT</Name><Restore>TEXT</Restore></Tag>
 

        <Tag> <Name>body</Name>
         <Attribute><Name>n</Name><PrVal>on</PrVal>
          <PreString>      </PreString><BlankLines>1</BlankLines>
          <Size>18</Size>
          </Attribute>
          <PrText>on</PrText><PrTag>off</PrTag> </Tag>
        <Tag> <Name>/body</Name><Restore>body</Restore></Tag>

       <Tag><Name>s</Name>
         <BlankLines>0</BlankLines>
         <Attribute><Name>n</Name><PrVal>on</PrVal>
          <PreString> </PreString><PostString>   </PostString>
          </Attribute>
        </Tag>
        <Tag><Name>/s</Name><Restore>s</Restore></Tag>

        <Tag><Name>foreign</Name><Type>Italic</Type></Tag>
        <Tag><Name>/foreign</Name><Restore>foreign</Restore></Tag>
</Spec>



From sanders@bsdi.com  Wed Oct 27 10:42:01 1993 -0500
Message-Id: <9310271542.AA01750@austin.BSDI.COM>
Date: Wed, 27 Oct 1993 10:42:01 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: WWW meta indexes (proposal) 

> but Tony Sanders wants a registration facility for
> mail-processing robots, which probably requiring a particular format
> that is not necesarrily nice for humans.

How about a Mosaic fill out form :-)

--sanders



From sanders@bsdi.com  Wed Oct 27 10:38:41 1993 -0500
Message-Id: <9310271538.AA01722@austin.BSDI.COM>
Date: Wed, 27 Oct 1993 10:38:41 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: Dial-up Users 

> on systems that are not directly connected to the network.  Right
> now, a SLIP/PPP connection is required to use a graphical browser; these
> connections are more expensive to obtain and more difficult to install.
> 
> What can we do to enable communication over a serial line?  

Doing this right would basically require reinventing SLIP and TCP/IP (you
need a reliable connection from end to end, ala tcp).  Once you have the
encapsulation protocol then all you need is to hack the CERN server to do
the translation and run it on both ends of the connection, then set
WWW_http_GATEWAY (and WWW_wais_GATEWAY, etc) to point to the local "gateway".

You don't want to hack this into the browser because then you are limiting
yourself to browsers that you have hacked.  By using a gateway every
browser that suppports WWW_http_GATEWAY (e.g., all libwww based browsers)
will work out of the box.  You can also add features like smart caching
to the local gateway (there is an effort underway to add caching to Plexus,
the prototypes are farily simple so it's not too hard to do).

--sanders



From henrich@crh.cl.msu.edu  Wed Oct 27 11:42:42 1993 -0400 (EDT)
Message-Id: <9310271542.AA27166@crh.cl.msu.edu>
Date: Wed, 27 Oct 1993 11:42:42 -0400 (EDT)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: It'd be *really* nice to

It'd be really nice to be able to specify what causes a form submit.

For example, I'd like to create a form, that uses a click on an ISMAP image to
submit the entire form.  I can think of numerous cases where being allowed to
specify what causes a submit would be mighty useful.

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                      http://rs560.msu.edu/~henrich



From marca@ncsa.uiuc.edu  Wed Oct 27 11:35:47 1993 -0700
Message-Id: <9310271835.AA29466@wintermute.ncsa.uiuc.edu>
Date: Wed, 27 Oct 93 11:35:47 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: It'd be *really* nice to

Charles Henrich writes:
> It'd be really nice to be able to specify what causes a form submit.
> 
> For example, I'd like to create a form, that uses a click on an
> ISMAP image to submit the entire form.  I can think of numerous
> cases where being allowed to specify what causes a submit would be
> mighty useful.

Actually, the case you mention (an image map in a form) is already in
the latest (so far as I know, unwritten but still agreed-upon) forms
spec.  We'll be supporting it for 2.0.

We decided to hold off on generic submit specification until later.

Marc




From raisch@internet.com  Wed Oct 27 09:27:40 1993 -0700 (PDT)
Message-Id: <Pine.3.03.9310270939.B19968-c100000@hmmm.internet.com>
Date: Wed, 27 Oct 1993 09:27:40 -0700 (PDT)
From: raisch@internet.com (Rob Raisch, The Internet Company)
Subject: Re: Dial-up Users 



On Wed, 27 Oct 1993, Tony Sanders wrote:

> > on systems that are not directly connected to the network.  Right
> > now, a SLIP/PPP connection is required to use a graphical browser; these
> > connections are more expensive to obtain and more difficult to install.
> > 
> > What can we do to enable communication over a serial line?  
> 
> Doing this right would basically require reinventing SLIP and TCP/IP (you
> need a reliable connection from end to end, ala tcp).  

Well, there's reliable and then there's *RELIABLE*

I have always thought that TCP/IP was a terrible solution to point to
point connectivity for small workstations.  It just isn't needed.  It's
large, cumbersome and wastes a lot of cycles.  Point to Point simply does
not require the same level of technology needed to get a message from one
side of the country to the other, reliably and over redundant paths, while
the bombs are falling.

Consider this model,

	- Host runs various "proxy" agents which manage TCP sessions with
	services out in the 'great wide.'

	- These proxies are simply 'stubs' which manage the connection and 
	feed the data into a communications manager.

	- The communications manager is a simple agent which manages a 
	reliable multiplexed channel back to the client.  The protocol 
	looks something like:

		[Channel Number]			1 octet
		[Packet Type & Data Length mod 2]	1 octet
		[Checksum]				2 octets
		[  ... Data ... ]			2 ... 1024 octets

	- On the client side, there is the other half of the communications
	manager.  It breaks each channel out and feeds it to a window.

	- The various windows (I've identified 12 different and useful types)
	take the data and display it.  Binary images, Gopher menus, WWW 
	browsers, etc.

	- So, each Internet service has a proxy agent which feeds data into
	a communications manager (CM.)  The CM multiplexes data over the wire
	to the client, where data if fed to independant windows (or User
	Interaction Agents.)

One of the issues here is the isolation of complexity.  The client side
handles only those issues which deal with the user, and the server deals
only with those issues which deal with the communications.

This is a simple model, extensible, and could be hacked up in a few days. 
I did it once, actually.  Would love to see someone take this on as a project.
(Marc? <grin>)

	</rr>






From joe@mit.edu  Wed Oct 27 15:20:47 1993 -0400
Message-Id: <9310271920.AA09751@theodore-sturgeon.MIT.EDU>
Date: Wed, 27 Oct 93 15:20:47 -0400
From: joe@mit.edu (joe@mit.edu)
Subject: Re: WWW meta indexes (proposal)


For those who have asked about technical details regarding the GNA
meta-library.

I'm using the Postgres object-oriented database (it's a successor to
Ingres).  The search language is something called postquel and there
is a perl-interface to the database.  I use the plexus server with
some additions to convert the WWW address to postquel commands and to
parse the response.

The big win with postgres is that searches are relatively quick and
allows some very sophisticated search terms.  Also it would be trivial
to write parsers that read in or out things into the database.

The minuses are that the record lengths are limited to 2048 bytes and
the server is somewhat buggy.  Also postquel is not a standard
language.

As for portablity, I think my system will run on any system that runs
postgres (which includes Sun's and Decstations).  I don't have any
objection to giving away the code and database as long as Global
Network Academy is giving credit for putting together the system.

As for what needs to be done..........

1) A spec needs to be written describing the fields in the database.

2) A mail robot needs to be written that parses the input format.  The
easiest way of implementing this to have a perl script that reads the
incoming file and stuffs the fields in an associative array.  It's
then trivial to take the associative array and stuff it into the
database.  Also it would be a good idea to write a procedure that
takes an associative array and converts it to index format.

It's crucial to have a mail robot handle requests semi-automatically,
because I'm overloaded right now trying to add requests by hand.

3) Some scripts need to be written to allow access of the database for
people who do not know postquel.







From montulli@stat1.cc.ukans.edu  Wed Oct 27 18:17:32 1993 CDT
Message-Id: <9310272317.AA31068@stat1.cc.ukans.edu>
Date: Wed, 27 Oct 93 18:17:32 CDT
From: montulli@stat1.cc.ukans.edu (Lou Montulli)
Subject: Pre-release of lynx ver 2.0.12

I would like to invite anyone who is interested in doing some
pre-release testing to check out /pub/lynx/prerelease/lynx2-0-12.tar.Z
on ftp2.cc.ukans.edu.

I think that I have tracked down every reported bug, but there is
nothing like a little field testing.

I expect to make an official release in a few days.

Here is most of a release anouncement.
-----------
!!!!!!!This is a pre-release anouncement!!!!!!!!!!!!!!!

Lynx Ver. 2.0.12 is now available for anonymous ftp from
 FTP2.cc.ukans.edu    as   /pub/lynx/prerelease/lynx2-0-12.tar.Z

( ftp://ftp2.cc.ukans.edu/pub/lynx/prerelease/lynx2-0-12.tar.Z )

Lynx is a distributed hypertext browser with full World Wide Web
and Gopher capibilities.  For an explanation of features and a demo, 
telnet to "kufacts.cc.ukans.edu" and login as "www".

This release of Lynx has been compiled by me on the following platforms:

 o  IBM (AIX 3.2)
 o  DEC Ultrix
 o  DEC Alpha OSF/1
 o  Sun 4
 o  NeXT (Mine is an older version of NeXTStep, but it should work 
          with newer ones too.)
 o  VMS (Multinet)

Binaries for the following platforms are available:

 o  IBM (AIX 3.2, will work with 3.1 as well)
 o  Ultrix
 o  Alpha OSF/1
 o  Sun 4
 o  VMS (Multinet)
 
A listserv list has been created for the distribution of
Lynx related information and updates.
  o  Lynx-Dev@ukanaix.cc.ukans.edu
 
Send a subscribe request to listserv@ukanaix.cc.ukans.edu to
be added to the list.  All new releases will be anounced on this
list.  Please do not send subscribe requests to the the Lynx-Dev
list directly.

    The following new features have been added:

* added VMS port fixes from Foteos Macrides.  Lynx now
  compiles and works on VMS! (bug? :)
* added preliminary level 1 forms support.
  (Parsing and user display works, but nothing else)
  I'm looking for input on the forms interface!
* local documents ending in .html can now be referenced with
  just a filename and/or path from the command line.
* Added preloaded searches to gopher URL's.  They previously
  didn't work.  This is redily apparent as preloaded CSO
  searches, which alot of people wanted. (bug?)
* The user's specified editor is now spawned for mail messages.
  If no editor is defined or if the user is anonymous, the built-in 
  lynx mail sender is used.
* added progress messages to all transfers.
  (are the gopher progress messages too numerous?)
* added -cache=# command line option to specify the number
  of WWW documents cached in memory.
* Moved many configuration options including printer setup to 
  lynx.cfg file.  The default placement of the lynx.cfg file
  will be /usr/local/lib & sys$public.  Printers can now be
  configured without recompiling!
* Removed STARTDIR variable from userdefs.h  STARTDIR is now inferred
  from the STARTFILE. (doesn't effect HTML files)
* Ported to SVR4 courtesy of Nickolay Saukh (from Russia, Wow this is
  really getting around!) 
* Ported to Irix (I think)
* National language support through LOCALE
  (instead of ISOLATIN1), protected by #ifdef LOCALE (Nickolay Saukh)


   A partial list of bugs that have been fixed

* disabled FTP connection caching to help fix multiple FTP problems
* fixed a bunch of gopher holes
* gopher lists are turned into URL's now instead of lynx
  internal format document links
* removed old hytelnet compatibility code which looked in
  multiple directories to find the correct file.  If you still
  need this capibility talk to me.
* changed all static data structures to be dynamic
  This was a pretty major change of code which may add several
  bugs. :)
* rewrote parse_links routine to make it more efficient and to
  work with dynamic structures.
* added VMS port fixes from Foteos Macrides.  Lynx now
  compiles and works on VMS!
* fixed ftp bug in WWWlib that didn't de-escape URL's before
  sending request to FTP server.
* fixed coredump bug for some files with no links.
* Fixed bug with only one link selectable out of many on the last line
  of the display.
* Uneditable documents don't get refetched. (Nickolay Saukh)



From Christopher.McRae@library.ucsf.edu  Wed Oct 27 21:39:37 1993 PDT
Message-Id: <199310280432.AA06875@library.ucsf.edu>
Date: Wed, 27 Oct 1993 21:39:37 PDT
From: Christopher.McRae@library.ucsf.edu (Christopher J. McRae)
Subject: ANNOUNCEMENT: Second SIG-Web meeting (Palo Alto, CA)


NOTE: If you have a WWW client, you may wish to read the hypertext
version of this announcment.  The URL is:
<http://www.library.ucsf.edu/www/public/SIGWEB/191193/index.html>.


Second SIG-Web meeting (Palo Alto, CA)
--------------------------------------
The first SIG-Web meeting, held 10/7/93 was a big success!  Please see
<http://www.library.ucsf.edu/www/public/SIGWEB/index.html> for
details.

The second SIG-Web meeting will be held at the Xerox Palo Alto
Research Center (PARC) November 19th, from 2-5 PM (PST).  See below for
directions.

November's meeting will focus on "success stories" of various SIG-Web
members; we'd like to hear about the network information services you're
providing, and also your success in making network information available
to your local community.  

For those who can't make it, the meeting will (most likely) be
broadcast over the Internet Multicast Backbone (MBONE). (See
<ftp://venera.isi.edu/mbone/faq.txt> for details.)

Presentations will include:

- Benay Dara-Abrams will demonstrate Silicon Valley Public Access
  Link, the community network for Santa Clara County.

- David Martin of UCSF will talk about the RedSage project, and other
  things going on at the UCSF Center for Knowledge Management.

- Mitra will talk about Gopher access to Journal Graphics, and
  providing commercial service to dial-up users.

- Steve Putz will show some World-Wide Web gateways to other
  information sources he's developed at Xerox PARC. Larry Masinter
  will demonstrate MOO-Gopher, a gopher interface from inside a mud.

- There will be an open session for people to get up and talk about
  their servers and organizations.

  If you'd like to make a presentation or give a demo, please send
  mail to mcrae@ckm.ucsf.edu, saying how much time you'd like and
  what kind of equipment you'll need.

Working Groups
  It's been suggested that we devote the last 30 minutes or so of each
  meeting split up into smaller groups. The last half-hour of this
  meeting, we'll decide which subgroups we'd like to have.

Send questions, comments, suggestions to mcrae@ckm.ucsf.edu.

Requests to be added to/deleted from the sig-web mailing list should be
sent to sig-web-request@library.ucsf.edu.

Chris
-----------------------------------------------------------------------
Christopher McRae			mail: mcrae@ckm.ucsf.edu
UCSF Center for Knowledge Management	at&t: 415/476-3577
530 Parnassus Avenue, Box 0840	 	fax: 415/476-4653
San Francisco, California 94143
-----------------------------------------------------------------------


Contact: Chris McRae
  Email: sig-web-request@library.ucsf.edu
  Phone: (415) 476-3577

   Date: Friday, November 19, 1993
   Time: 2:00 - 5:00 p.m.

Parking: Building 34 Lot, across the street from the auditorium
  Where: PARC Auditorium
	 Xerox Palo Alto Research Center (PARC)
	 3333 Coyote Hill Rd.
	 Palo Alto, CA
	(415) 812-4000

	 The PARC Auditorium is located at 3333 Coyote Hill Rd. in
	 Palo Alto. PARC is in the Stanford Research Park, between
	 Page Mill Road (west of Foothill Expressway) and Hillview
	 Avenue. The easiest way to go is to get onto Page Mill Road,
	 then turn onto Coyote Hill Road. As you drive up Coyote Hill
	 past the horse pastures, PARC is the building on the left
	 after you crest the hill. Park in the Building 34 lot across
	 the street, and enter the auditorium at the upper level of
	 the building. (The auditorium entrance is located down the
	 stairs and to the left of the main doors.)




From luotonen@ptsun00.cern.ch  Thu Oct 28 14:04:18 1993 +0100
Message-Id: <9310281304.AA16669@ptsun00.cern.ch>
Date: Thu, 28 Oct 93 14:04:18 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: "www/tcp server failing (looping), service terminated"


We have recovered the reason for info.cern.ch so often "refusing
connection".  This is not only our problem but could happen to anybody
having any daemon started very often by inetd on a Sun or a NeXT (and
maybe even on other platforms).

There is a hard-coded value in inetd allowing max 40 connections
from the same host per minute.  Fast machines can make more requests
(close to 60 per minute), which causes the inet daemon to detect this
as looping, and terminates the service for a while.

I don't yet know what browser or other program is used to cause this,
but it is obviously something that retrieves all the documents pointed
to by a given document.

In Solaris this is fixed, for SunOS 4.1.* there is a fix, e.g.

	ftp://qiclab.scn.rain.com/pub/sunos-patches/100178-08

which introduces -r command line option for inetd, e.g.:

	inetd -r 65 60

allows 65 connection per 60 seconds.

www1.cern.ch is a Sun, I have fixed it, but info.cern.ch is a NeXT --
we'll keep looking for a fix for it (anybody out there know anything
that would help??).

--
Ari Luotonen		 |
World-Wide Web Project	 |
CERN			 | phone: +41 22 767 8583
CH - 1211 Geneve 23	 | email: luotonen@dxcern.cern.ch



From terry@ora.com  Thu Oct 28 06:47:12 1993 PDT
Message-Id: <199310281347.AA02243@rock.west.ora.com>
Date: Thu, 28 Oct 1993 06:47:12 PDT
From: terry@ora.com (Terry Allen)
Subject: URN ---> URN

Re Fred Swartz's suggestion that one could construct a URN pointing
to someone else's URN, I think this would be foul play.  URNs are
to be assigned by the publisher; a pointer to a URN should be a URL.
(If needed at all; you shouldn't have to point to a URN instead
of using it directly.)

Regards,

-- 
Terry Allen  (terry@ora.com)
Editor, Digital Media Group
O'Reilly & Associates, Inc.
Sebastopol, Calif., 95472



From sanders@bsdi.com  Thu Oct 28 09:52:13 1993 -0500
Message-Id: <9310281452.AA00548@austin.BSDI.COM>
Date: Thu, 28 Oct 1993 09:52:13 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: "www/tcp server failing (looping), service terminated" 

> There is a hard-coded value in inetd allowing max 40 connections
> from the same host per minute.  Fast machines can make more requests
Yet another good reason not to run services from inetd.

> we'll keep looking for a fix for it (anybody out there know anything
> that would help??).
Add the 10 lines of code or so needed so you don't have to run from inetd.
You will get much better performance to boot.

--sanders



From bajan@bunyip.com  Thu Oct 28 10:59:36 1993 -0400
Message-Id: <9310281459.AA00719@mocha.bunyip.com>
Date: Thu, 28 Oct 1993 10:59:36 -0400
From: bajan@bunyip.com (Alan Emtage)
Subject: Bunyip Internet Directory Project

[This message is being posted to several mailing lists. My apologies for
the duplication]

Over the next several months we at Bunyip Information Systems (creators
of the archie directory system), will be running a pilot project to
assess the viability of collecting additional data cataloging information
directly from the Internet. Ultimately, this information will be made
available to the Internet community via the distribution mechanisms now
in place for the familiar archie anonymous FTP database.

One of the biggest problems currently facing the use of the wealth of
information now available on the Internet is locating the files,
documents or services that you are looking for. While archie goes some
way to addressing this problem, "cataloging" information such as contact
information, abstracts, descriptions, keywords and access policies for
the files and services are simply not available through simple filename
searches. The problem of trying to keep this cataloging information up to
date manually in such a dynamic environment is well illustrated by the
current archie Software Description Database (or "whatis" database as it
is more commonly known).

We are asking you, the anonymous FTP archive site administrators and
operators of Internet services to cooperate with us by preparing your
information for automated gathering and serving. In doing so, we believe
you will be supporting a data distribution model that is well suited to
the Internet.  Control over your content will remain with you, and the
automatic preparation of additional information services will be made
possible. The data served to the community will be updated when you
change your own files.

You need not tell us that you have these files or inform us when they
have changed: if you have asked for your anonymous FTP archive to be part
of the archie service in the past, this information will be automatically
retrieved from your archive.

Our project will use an extended version of the archie system to collect
data "templates" on anonymous FTP archives. These templates will be
automatically retrieved, collated and indexed into a form easily
searchable by users on the network. Over the period of the pilot a number
of search and retrieval techniques will be assessed to determine their
usability.

The hope is that the general user will be able to query this database and
obtain descriptive information about freely available or Public Domain
documents, images, sounds and services on the network...worldwide. In
addition to the descriptions, the templates point the user to the source
of the original data or service which may then be accessed.

By filling out and making these templates available for retrieval, you
can advertise the files and services available from your department or
institution. The templates can be used to describe

      Services
   
	The archive can offer an overall description of each the various
	Internet services offered by your organization's systems, along
	with corresponding contact information.

	This description would then indicate whether the the parent
	organization offers such services as:

	o on-line library catalogues

	o Interactive online information services such as WAIS, gopher,
	  Prospero, World Wide Web or archie

	o specialized information servers such as those providing
	  weather, geographic information, newswire feeds etc.

	o Other information services

      People

	By putting non-sensitive personal contact information into the
	templates we hope to provide the start of the first truly global
	White Pages service: the ability to locate people anywhere on the
	network.

      Documents, Datasets, Mailing List Archives, USETNET Archives,
      Software Packages, Images and other Objects

        You might wish to make available a brief description of available
	software, documents, images, sounds, video, datasets, USENET
	archives and mailing list information through the anonymous FTP
	archive.

A typical "services" template might look like this (no offense to the
Census Bureau intended :-)

Template-Type:		SERVICES
Name:			Census Bureau information server
Host-Name:		census.ispy.gov
Host-Port:		1234
Protocol:		telnet
Admin-Name:		Jay Bond
Admin-Postal:		PO Box. 42, A Street Washington DC, USA 20001
Admin-Work-Phone:	+1-202-222-3333
Admin-Work-Fax:		+1 202 444 5555
Admin-Email:		jb007@census.ispy.gov
Description:		This server provides information from the
			latest USA Census Bureau statistics (1990)
			Type "help" for more information.
Authentication:   	Once connected type your email address at
		  	the "login:" prompt. No password is
		  	required.
Registration:     	No formal registration is required
Charging-Policy:	There is no charge for the use of this service
Access-Times:		9:00 EST / 17:00 EST
Access-Policy:		This service may not be used by sites in
		  	the Republic of the VTTS
Keywords:		census, population, 1990, statistics
Last-Modified-Name:   	Miss Moneypenny
Last-Modified-Email:  	m.moneypenny@census.ispy.gov
Last-Modified-Date:   	Wed, 1 Jan 1970 12:00:00 GMT


Note that the machine on which the actual service or documents reside
need not be the same as that of the anonymous FTP archive: you may place
these templates on any anonymous FTP archive. The template contains the
date on where to locate the information itself.

The templates to be used will be those constructed by the Internet
Anonymous FTP Archives working group of the Internet Engineering Task
Force. These documents describing the templates are available as Internet
Drafts from the standard network repositories. 

They are also available from archive.cc.mcgill.ca in the pub/Network/iafa
directory. The two files are 

draft-ietf-iafa-publish-00.txt

and

draft-ietf-iafa-templates-00.txt

the templates themselves are generally extensible and you may add fields
if you do not think that the ones provided suit your particular needs.

Please do not be put off by the size of the documents: the first contains
several examples explaining and illustrating how they are filled out; the
second provides empty templates for you to use. Also, do not feel that
you are obliged to complete one of every template or even every field in
each template. We ask only that you document current practice at your
site as completely as possible. 

If you have any questions about this project or suggestions about the
templates, we would be happy to answer them. Please send mail to

	templates-info@bunyip.com

Please feel free to redistribute this message to groups you think
appropriate.


-- 
-Alan

------------------------------------------------------------------------------
Alan Emtage,				"The Left in Canada is more gauche
Bunyip Information Systems,		 than sinister"
Montreal, CANADA			 -The Economist

bajan@bunyip.com
Voice: +1 (514) 875-8611		Fax: +1 (514) 875-8134




From neuss@igd.fhg.de  Thu Oct 28 16:46:40 1993 +0100
Message-Id: <9310281546.AA00473@wildturkey.igd.fhg.de>
Date: Thu, 28 Oct 93 16:46:40 +0100
From: neuss@igd.fhg.de (neuss@igd.fhg.de)
Subject: "www/tcp server failing (looping), service terminated" 

Dear fellow Webbers,

In reply to Ari Luotonen Tony Sanders <sanders@bsdi.com> wrote:
>> There is a hard-coded value in inetd allowing max 40 connections
>> from the same host per minute.  Fast machines can make more requests
> Yet another good reason not to run services from inetd.

[munch]
> Add the 10 lines of code or so needed so you don't have to run from inetd.
> You will get much better performance to boot.
Tony is right here.. those servers that are under heavy use should not be
run from inetd, since it costs quite a lot of performance. For testing 

purposes, I prefer the inetd mechanism though, since I get a "fresh copy"
of the server software - this avoids a process becoming bigger and bigger
due to memory leaks.

Cheers, Chris



From dsr@hplb.hpl.hp.com  Thu Oct 28 16:03:03 1993 GMT
Message-Id: <9310281603.AA15751@manuel.hpl.hp.com>
Date: Thu, 28 Oct 93 16:03:03 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Second draft of HTML+ now available

I have just finished the second draft of the HTML+ discussion
document which is now available in Postscript form from:

        ftp://15.254.100.100/pub/draft-raggett-www-html-00.ps

As soon as I get a text version to meet the IETF's standard
layout requirements, I will be submitting this as an Internet
Draft, hence the funny file name above.

Please let me know ASAP if the postscript version causes problems
on 8.5x11 inch printers. So I can fix the problem before it
reaches the IETF distribution channels.

This document is for discussion, and the spec is *not* frozen.
We are limited by the need for backwards compatibility with
HTML (to provide a viable migration path), and recent work
on extensions.

Best wishes,

Dave Raggett



From jbluming@yoyo.eit.COM  Thu Oct 28 10:21:56 1993 -0700
Message-Id: <9310281721.AA03906@eit.COM>
Date: Thu, 28 Oct 1993 10:21:56 -0700
From: jbluming@yoyo.eit.COM (Jason B. Bluming)
Subject: lookie lookie, someone else just joined the party


------- Forwarded Message

Return-Path: @Xenon.Stanford.EDU,@Sunburn.Stanford.EDU:zagazeta@sumex-aim.stanford.edu
Return-Path: <@Xenon.Stanford.EDU,@Sunburn.Stanford.EDU:zagazeta@sumex-aim.stanford.edu>
Received: from Xenon.Stanford.EDU by eit.COM (4.1/SMI-4.1)
	id AA02889; Thu, 28 Oct 93 07:22:17 PDT
Received: from Sunburn.Stanford.EDU by Xenon.Stanford.EDU with SMTP (5.61+IDA/25-CS-eef) id AA07366; Thu, 28 Oct 93 07:22:16 -0700
Received: from CAMIS.Stanford.EDU by Sunburn.Stanford.EDU with SMTP (5.61+IDA/25-SUNBURN-eef) id AA28959; Thu, 28 Oct 93 07:22:12 -0700
Received: from SUMEX-Mac-96.Stanford.EDU by CAMIS.Stanford.EDU (4.1/inc-1.0)
	id AA23226; Thu, 28 Oct 93 07:15:11 PDT
Date: Thu, 28 Oct 93 07:16:57 -0800
From: Irene Zagazeta <zagazeta@sumex-aim.Stanford.EDU>
To: mis-colloquia@sumex-aim.stanford.edu
Subject: 11/4-Med.Info.Colloq.:Tom Rindfleisch-(SSRG/KSL):World-Wide Web
Message-Id: <Mailstrom.1.03.8809.8880.zagazeta@sumex-aim.stanford.edu>
Content-Type: TEXT/plain; charset=US-ASCII


***** Medical Informatics Colloquium *****


SPEAKER:  Tom Rindfleisch, Section on Medical Information
          Director of Symbolic Systems Resources Group (SSRG) 
          and Knowledge Systems Laboratory (KSL)
          

DATE      November 4th, 1993 (Thursday)
TIME:     3:00pm to 4:00pm

LOCATION: Medical School Office Building (MSOB x275)
          Stanford University School of Medicine
 
                        
********************************************************************  
TITLE:  World-Wide Web -- What, Why, & Wow?

ABSTRACT:
The exponential growth of the Internet in recent years has made it more and 
more difficult to find precisely the information needed for a particular task. 
The number of places to look has increased, the amount of material on-line at 
each place has increased, and the diversity of document types (including video 
and sound) and access schemes has increased.  Whereas good old FTP (File 
Transfer Protocol) has done yeoman service for over 20 years -- since the age 
of hackers -- and still dominates Internet traffic, several efforts to better 
integrate distributed information browsing and retrieval with modern 
human-computer interfaces have been underway in recent years.  These include 
WAIS (Wide-Area Information Service), Gopher, Archie, Veronica, and WWW 
(World-Wide Web).  Of these efforts, WWW, developed within the high-energy 
physics community, arguably has the best underlying systems design in terms of 
generality, openness, extensibility, and conceptual clarity.  WWW subsumes the 
other services mentioned above (and more) and there are even WWW client and 
server implementations available that work.

The first part of this talk will give an overview of the current state of WWW 
- -- what it does, how it works, what remains to be done, and what its 
implications might be for our work.  I will describe the three protocols that 
make up the core of WWW -- the uniform resource locating scheme (URL), the 
hypertext transfer protocol (HTTP), and the SGML-based hypertext markup 
language (HTML) -- and how WWW interfaces with other information access 
protocols and resources.  The last part of the talk will be a live demo of WWW,
including work done within the KSL to experiment with and enhance WWW for 
making information from our laboratory accessible.


------- End of Forwarded Message




From jbluming@yoyo.eit.COM  Thu Oct 28 10:29:51 1993 -0700
Message-Id: <9310281729.AA03961@eit.COM>
Date: Thu, 28 Oct 1993 10:29:51 -0700
From: jbluming@yoyo.eit.COM (Jason B. Bluming)
Subject: local copy

in /users/jbluming/papers/draft-raggett-www-html-00.ps 

-Jason
------- Forwarded Message

Return-Path: www-talk-request@dxcern.cern.ch
Return-Path: <www-talk-request@dxcern.cern.ch>
Received: from dxmint.cern.ch by eit.COM (4.1/SMI-4.1)
	id AA03753; Thu, 28 Oct 93 10:01:44 PDT
Received: from dxcern.cern.ch by dxmint.cern.ch (5.65/DEC-Ultrix/4.3)
	id AA08747; Thu, 28 Oct 1993 17:38:51 +0100
Received: by dxcern.cern.ch (5.65/DEC-Ultrix/4.3)
	id AA07655; Thu, 28 Oct 1993 17:06:36 +0100
Received: from dxmint.cern.ch by dxcern.cern.ch (5.65/DEC-Ultrix/4.3)
	id AA07650; Thu, 28 Oct 1993 17:06:33 +0100
Received: from nxoc01.cern.ch by dxmint.cern.ch (5.65/DEC-Ultrix/4.3)
	id AA27288; Thu, 28 Oct 1993 17:06:32 +0100
Received: from dxmint.cern.ch by  nxoc01.cern.ch  (NeXT-1.0 (From Sendmail 5.52)/NeXT-2.0)
	id AA12144; Thu, 28 Oct 93 16:37:08 MET
Received: from hplb.hpl.hp.com by dxmint.cern.ch (5.65/DEC-Ultrix/4.3)
	id AA27245; Thu, 28 Oct 1993 17:06:25 +0100
Received: from dragget.hpl.hp.com by hplb.hpl.hp.com; Thu, 28 Oct 93 15:53:44 GMT
Received: by manuel.hpl.hp.com
	(16.6/15.6+ISC) id AA15751; Thu, 28 Oct 93 16:03:08 GMT
From: Dave_Raggett <dsr@hplb.hpl.hp.com>
Message-Id: <9310281603.AA15751@manuel.hpl.hp.com>
Subject: Second draft of HTML+ now available
To: www-talk@nxoc01.cern.ch
Date: Thu, 28 Oct 93 16:03:03 GMT
Cc: LJJ%A1%UTRC@mrgate.utc.com
Mailer: Elm [revision: 66.36.1.1]

I have just finished the second draft of the HTML+ discussion
document which is now available in Postscript form from:

        ftp://15.254.100.100/pub/draft-raggett-www-html-00.ps

As soon as I get a text version to meet the IETF's standard
layout requirements, I will be submitting this as an Internet
Draft, hence the funny file name above.

Please let me know ASAP if the postscript version causes problems
on 8.5x11 inch printers. So I can fix the problem before it
reaches the IETF distribution channels.

This document is for discussion, and the spec is *not* frozen.
We are limited by the need for backwards compatibility with
HTML (to provide a viable migration path), and recent work
on extensions.

Best wishes,

Dave Raggett

------- End of Forwarded Message




From terry@ora.com  Thu Oct 28 10:43:46 1993 PDT
Message-Id: <199310281743.AA09169@rock.west.ora.com>
Date: Thu, 28 Oct 1993 10:43:46 PDT
From: terry@ora.com (Terry Allen)
Subject: ftp.american.edu??

Picking up on an item posted (I think) to alt.internet.services, I've tried
to construct a URL for the site ftp.american.edu (there is a "catholic"
directory I want to list in our WIC).  I can ftp to ftp.american.edu 
without difficulty, but neither 
   ftp://ftp.american.edu
nor
   ftp://ftp.american.edu/catholic
nor
   ftp://american.edu

works.  I tried replacing ftp.american.edu with the numerical address, but
no luck.  Can anyone guess what the problem (presumably with that site) is?

Thanks.


-- 
Terry Allen  (terry@ora.com)
Editor, Digital Media Group
O'Reilly & Associates, Inc.
Sebastopol, Calif., 95472



From ctrbdo%iapa@mailhost.ecn.uoknor.edu  Thu Oct 28 13:09:41 1993 CDT
Message-Id: <9310281809.AA10627@hickory.iapa>
Date: Thu, 28 Oct 93 13:09:41 CDT
From: ctrbdo%iapa@mailhost.ecn.uoknor.edu (bryan d oakley)
Subject: a general comment, a specific problem

First, the general comment:

My programming group is not connected to the internet (soon, though,
so they tell me); nevertheless, we have adopted X Mosaic as a basis
for our internal documentation on our LAN.  Since we are not on the
internet it's been a real booger (ahem) to 1: get X mosaic, and 2: get
documentation.  Since mosaic was designed to be used to browse the
internet, non-mosaic access to it's documentation is virtually nil.  I
know of one mail server which will send the HTML source for a given
URL, but that is cumbersome (and at our site rather tenuous) at best.

Is there a reason why this documentation cannot be made available for
anonymous FTP, or does such a service already exist and I am just not
aware of it?  I'm referring (obviously?) to all of the help available
via the pull-down menus, installation instructions for httpd, etc.
While the WWW project is fascinating and the tools marvelous, it's
rather cumbersome to install from scratch.  What would really make my
day would be to be able to FTP (via an external machine I have access
to) xmosaic-docs.html.tar.Z, or some such.  

Enough of that; now for the problem: 

We recently got a bunch of indigos, so I got the binary for 1.2 and
for 2.0pre4 installed to try things out.  Works like a charm.  I'm
generally not easily impressed, but this is impressive software.  I
was investigating just what it was all about, and was fascinated to see
that it could pull up a directory of source code from across our LAN
to a Sun box.  No httpd or any other special preparations.  Fresh out
of the box, as it were.  However, when I try to access a file on
another SGI box (on the same LAN) I get the standard 'document could
not be accessed' message.  Same URL, just a different machine name.
This works (or doesn't work...) both with 1.2 and 2.0pre4.

Now, I am assuming that this is some sort of permissions problem but I
don't really know where to look.  I can ftp from my machine to the
remote SGI, so I know the ftp daemon is running on the remote.  I also
assume that X Mosaic uses ftp in lieu of http when httpd is not
running or not specified.  As far as I know, no special security
measures have been installed on any machines since it's a closed
system.  

For specifics, my machine is named hobbes.  The Sun workstation is
hickory, and the other remote indigo is opus.  From hobbes, the following
URL works:

file://hickory/tmp

... but this one doesn't:

file://opus/tmp

Anyone care to comment on where I need to look to solve this problem?
Also, will installing httpd on opus (and hickory, for that matter)
solve the problem?  I'm certain I will eventually, but I want
something that will work across the network in the interim.  It's
taking me a while to get the sources and necessary documentation to do
the installation right. *sigh*

Thanks.  

---------------------------------------------------------------------
Instrument Approach Procedures Automation             DOT/FAA/AMI-230
---------------------------------------------------------------------
Bryan D. Oakley              ctrbdo%iapa@constellation.ecn.uoknor.edu
KENROB and Associates, Inc.              voice: (405) 954-7176 (work)
5909 NW Expwy Suite 209                         (405) 366-6248 (home)
Oklahoma City, Ok.  73132            



From gary@uaneuro.uah.ualberta.ca  Thu Oct 28 12:59:26 1993 -0600
Message-Id: <9310281859.AA14302@uaneuro.uah.ualberta.ca>
Date: Thu, 28 Oct 93 12:59:26 -0600
From: gary@uaneuro.uah.ualberta.ca (Gary Ritchie)
Subject: SUBSCRIBE

SUBSCRIBE



From henrich@crh.cl.msu.edu  Thu Oct 28 16:04:10 1993 -0400 (EDT)
Message-Id: <9310282004.AA00642@crh.cl.msu.edu>
Date: Thu, 28 Oct 1993 16:04:10 -0400 (EDT)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: HTML+ (Comments on latest spec)

First off, fantastic job Dave!

Okay Comments:

1) The changed attribute should follow the standard <tag> </tag> format,
scanning for </changed> should cause no more problems in code than scanning for
<changed> again.  If the end tag must not have a / in it, I would suggest
calling the tags <beginchanged> and <endchanged>

2) The <fig> and <image> tags should be rolled into one.

3) Active areas, when a ismap image is clicked on you specify that the
coordinates will be specified with ?x=X&y=Y.  I would suggest just keeping the
standard HTML format of ?x,y.

4) As stated in possible extensions, a new subtag for figures DLINE (draw line)
that follows the same conventions of the SHAPE tag.  This would give a basic
"clean" capibility for drawing over images, and can be implemented fairly
easily on the browser end.

5) The <MH> tag doesnt seem to appear explicitly in the document anywhere.  Why
the HIDDEN attribute?  And what does the browser do when that attribute doesnt
appear?

All in all though, mighty impressive Dave!  An interesting item to note, the
firstline of the abstract "This draft presents a proposal for a light
weight..."  not very lightweight anymore, the document weighs at least 2 lbs :)

-Crh
    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                      http://rs560.msu.edu/~henrich



From stumpf@informatik.tu-muenchen.de  Thu Oct 28 21:36:39 1993 +0100
Message-Id: <93Oct28.213649mesz.311357@hprbg5.informatik.tu-muenchen.de>
Date: Thu, 28 Oct 1993 21:36:39 +0100
From: stumpf@informatik.tu-muenchen.de (Markus Stumpf)
Subject: Re: WWW meta indexes (proposal)

Hello Tony et all,

the IAFA draft you mention is rather out of date
The newest one is also released as a ietf-draft and should be in
the various internet-drafts directories.

The filenames are:
	draft-ietf-iafa-howftp-00.txt
	draft-ietf-iafa-publishing-00.txt
	draft-ietf-iafa-templates-00.txt

I personally feel that in some cases they are better than the draft
Tony mentioned, in case of UR* IMHO they are a step back.
And they however contain a few errors I didn't yet find time to send
in to the appropriate mailing list.

An archive of the mailing list is at:
	ftp://archive.cc.mcgill.ca/pub/mailing-lists/iafa-archive

The mailing list is
	iafa@bunyip.com
and
	iafa-request@bunyip.com
for subscriptions.

Where to get the drafts:

Internet-Drafts are available by anonymous FTP.  Login with the	
username "anonymous" and password "guest".  After logging in,
Type "cd internet-drafts".
     "get draft-shenker-realtime-model-00.txt".
 Or 
     "get draft-shenker-realtime-model-00.ps".
 
Internet-Drafts directories are located at:	
	                                                
     o  East Coast (US)                          
        Address:  ds.internic.net (198.49.45.10)	
	                                                
     o  Pacific Rim                              
        Address:  munnari.oz.au (128.250.1.21)	
	                                                
     o  Europe                                   
        Address:  nic.nordu.net (192.36.148.17)	
	                                                

Ciao
	\Maex
-- 
______________________________________________________________________________
 Markus Stumpf                        Markus.Stumpf@Informatik.TU-Muenchen.DE 



From hgs@research.att.com  Thu Oct 28 16:42:48 1993 EDT
Message-Id: <9310282044.AA13967@dxmint.cern.ch>
Date: Thu, 28 Oct 93 16:42:48 EDT
From: hgs@research.att.com (Henning G. Schulzrinne)
Subject: HTML+ draft: table

It would be nice to have a decimal alignment option in tables. This seems
to be very much a "structural" property, so it should fit. It is one
of the more missed features in standard LaTeX tables. A generalization
would be alignment on any single character, so that the browser doesn't have
to worry about whether it's a decimal point or comma.

Henning
---
Henning Schulzrinne (hgs@research.att.com)
AT&T Bell Laboratories  (MH 2A-244)
600 Mountain Ave; Murray Hill, NJ 07974
phone: +1 908 582-2262; fax: +1 908 582-5809




From marca@ncsa.uiuc.edu  Thu Oct 28 16:13:48 1993 -0700
Message-Id: <9310282313.AA03470@wintermute.ncsa.uiuc.edu>
Date: Thu, 28 Oct 93 16:13:48 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: forwarded message from A User

Anyone bored and want to hyper-media-ize these, a la the LOC exhibits?

Cheers,
Marc

------- Start of forwarded message -------
From: A User
To: marca@ncsa.uiuc.edu
Subject: new with mosaic page addition
Date: Thu, 28 Oct 93 13:13:53 EDT

Marca,

	I'm not sure if this has been on your "What's New" page or
not, but there are some Great Images on photo1.si.edu in the images
directory. These images take you on a tour of what is at the
smithsonian Institute in Washington DC. This is an FTP site.

A
------- End of forwarded message -------




From sanders@bsdi.com  Thu Oct 28 16:54:45 1993 -0500
Message-Id: <9310282154.AA02255@austin.BSDI.COM>
Date: Thu, 28 Oct 1993 16:54:45 -0500
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: WWW meta indexes (proposal) 

> the IAFA draft you mention is rather out of date
> The newest one is also released as a ietf-draft and should be in
> the various internet-drafts directories.
Thanks for the update.

> I personally feel that in some cases they are better than the draft
> Tony mentioned, in case of UR* IMHO they are a step back.
They almost have URI's (they talk about them in the publishing doc but
they aren't in the templates).  Someone needs to set them straight on this
point.  If they adopt URI's then I think we can use their stuff and merge
the two efforts.  I hope someone does this, I can't right now.

--sanders



From jimmc%redback@eskimo.com  Thu Oct 28 15:23:37 1993 PDT
Message-Id: <9310282223.AA03486@redback.>
Date: Thu, 28 Oct 93 15:23:37 PDT
From: jimmc%redback@eskimo.com (Jim McBeath)
Subject: 

Since I am currently running XMosaic on my dial-up line without PPP or SLIP,
I thought I would put in my two cents worth.

For Unix systems, the solution Rob describes exists and is simple to use.
The 'term' package by Michael O'Reilly does pretty much what Rob
described.  It took me a few hours to understand and modify XMosaic 1.2 to use
term, and less than an hour to modify 2.0pre6.

It's actually simpler than Rob's model: term works at the TCP level,
so you just intercept the TCP socket calls in the application and redirect
them to term.  The application gets back a socket, which it then reads and
writes just as if it were connected directly.  Term does compression and
error correction (and multiplexing of requests from multiple clients),
so it's quite reliable for a point-to-point link.

I would love to have the #ifdef'ed TERM code in 2.0 so I can save
that hour on each release.  That would certainly be easier than
starting from scratch, for that 'volunteer' Rob is looking for.

Tony's idea of modifying the CERN server is interesting, but I have
no need to run any browser other than Mosaic, so modifying Mosaic
is simpler, and requires one fewer running process.  But if the local
server could do local caching, I would probably start using it.

I would rather use PPP or SLIP, but the host machine I dial in to does
not offer those services.  I pay $96/year flat rate for my account.
Accounts I found offering SLIP or PPP all charge more, plus they
have connect time charges.  That adds up real fast for someone who
likes to browse the net a lot.

Term does not require any special packages to be installed on either
machine, and can be compiled and run by any user without requiring
anything from the sys admin.  That's the advantage it has over PPP and
SLIP, which require the cooperation of the sys admin on the network host.

Lots of people have asked about running Mosaic on a Mac or under Windows
over a serial line without PPP or SLIP, but I haven't yet heard about
anyone else wanting to do that under Unix.  (Term is a Unix program, and
has so far not been ported to Mac or Windows.)  Maybe I'm the only one
in the world with a local Unix machine without SLIP or PPP :-)

-Jim McBeath
jimmc@eskimo.com


Rob Raish wrote (>):
Tony Sanders wrote (>>):

> > > on systems that are not directly connected to the network.  Right
> > > now, a SLIP/PPP connection is required to use a graphical browser; these
> > > connections are more expensive to obtain and more difficult to install.
> > > 
> > > What can we do to enable communication over a serial line?  
> > 
> > Doing this right would basically require reinventing SLIP and TCP/IP (you
> > need a reliable connection from end to end, ala tcp).  

> Consider this model,

>        - Host runs various "proxy" agents which manage TCP sessions with
>        services out in the 'great wide.'

>        - These proxies are simply 'stubs' which manage the connection and 
>        feed the data into a communications manager.

>        - The communications manager is a simple agent which manages a 
>        reliable multiplexed channel back to the client.  The protocol 
>        looks something like:

>                [Channel Number]                        1 octet
>                [Packet Type & Data Length mod 2]       1 octet
>                [Checksum]                              2 octets
>                [  ... Data ... ]                       2 ... 1024 octets

>        - On the client side, there is the other half of the communications
>        manager.  It breaks each channel out and feeds it to a window.

>        - The various windows (I've identified 12 different and useful types)
>        take the data and display it.  Binary images, Gopher menus, WWW 
>        browsers, etc.

>        - So, each Internet service has a proxy agent which feeds data into
>        a communications manager (CM.)  The CM multiplexes data over the wire
>        to the client, where data if fed to independant windows (or User
>        Interaction Agents.)

> One of the issues here is the isolation of complexity.  The client side
> handles only those issues which deal with the user, and the server deals
> only with those issues which deal with the communications.

> This is a simple model, extensible, and could be hacked up in a few days. 
> I did it once, actually.  Would love to see someone take this on as a project.
> (Marc? <grin>)

>        </rr>



From marca@ncsa.uiuc.edu  Thu Oct 28 18:01:49 1993 -0700
Message-Id: <9310290101.AA04051@wintermute.ncsa.uiuc.edu>
Date: Thu, 28 Oct 93 18:01:49 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: random wish

I have a dream that one day someone will put up a high-res
geographical map of the world linked to an ISMAP server that points to
all of the Web servers currently online...

:-)

Marc




From anthony@aaii.oz.au  Fri Oct 29 11:05:29 1993 +1000
Message-Id: <199310290106.AA14064@eden-valley.aaii.oz.AU>
Date: Fri, 29 Oct 1993 11:05:29 +1000
From: anthony@aaii.oz.au (anthony baxter)
Subject: Re: ftp.american.edu?? 

You write:
> Picking up on an item posted (I think) to alt.internet.services, I've tried
> to construct a URL for the site ftp.american.edu (there is a "catholic"
> directory I want to list in our WIC).  I can ftp to ftp.american.edu 
> without difficulty, but neither 
>    ftp://ftp.american.edu
> nor
>    ftp://ftp.american.edu/catholic
> nor
>    ftp://american.edu
> works.  I tried replacing ftp.american.edu with the numerical address, but
> no luck.  Can anyone guess what the problem (presumably with that site) is?
> 

alamein/anthony/1188 % dig ftp.american.edu hinfo

; <<>> DiG 2.0 <<>> ftp.american.edu hinfo 
;; res options: init recurs defnam dnsrch
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 6
;; flags: qr aa rd ra; Ques: 1, Ans: 1, Auth: 0, Addit: 0
;; QUESTIONS:
;;      ftp.american.edu, type = HINFO, class = IN

;; ANSWERS:
ftp.american.edu.       3600    HINFO   IBM-3090        VM/ESA

;; FROM: alamein to SERVER: default -- 192.35.59.1
;; WHEN: Fri Oct 29 10:49:00 1993
;; MSG SIZE  sent: 34  rcvd: 62


I'd say the www library cant handle ftp'ing to a VM machine. It does
look rather strange...

alamein/anthony/1189 % ftp ftp.american.edu
Connected to ftp.american.edu.
220-FTPSERVE IBM VM V2R3 at AUVM.AMERICAN.EDU, 21:01:47 EDT THURSDAY
10/28/93
220 Connection will close if idle for more than 5 minutes.
331 Send password please.
230 ANONYMOU logged in; working directory = AUSYSU:PUB.
verbose
Verbose mode off.
ftp> dir
APPC              DIR        -          -          -  3/11/93  2:43:34 -
AU                DIR        -          -          -  3/11/93  2:47:36 -
CATHOLIC          DIR        -          -          -  3/11/93  2:19:07 -
EMUSIC            DIR        -          -          -  3/11/93  3:01:18 -
LISTLOGS          DIR        -          -          -  3/11/93  0:57:34 -
NETNEWS           DIR        -          -          -  3/11/93  3:01:36 -
READ     ME       V         73         52          1  4/28/93 21:55:22 -
SERAVES           DIR        -          -          -  4/08/93 14:33:13 -


Anthony



From Steve.Heaney@delft.sgp.slb.com  Fri Oct 29 15:14:45 1993 +0100
Message-Id: <199310291414.AA02079@mordred.delft.sgp.slb.com>
Date: Fri, 29 Oct 1993 15:14:45 +0100
From: Steve.Heaney@delft.sgp.slb.com (Steve Heaney)
Subject: Re: Second draft of HTML+ now available


Dave,

Looking good.

In section 3 para 4, you pose the question "Should we support headers for which 
the level is implicitly defined by nestable section elements?".

This was included in an earlier draft (Oct 8) and IMHO the answer is yes 
... please.  You allude to the fact that this is a problem as far as 
implemetation is concerned.  Would you care to expand ?

Steve.



From henrich@crh.cl.msu.edu  Fri Oct 29 11:21:32 1993 -0400 (EDT)
Message-Id: <9310291521.AA02824@crh.cl.msu.edu>
Date: Fri, 29 Oct 1993 11:21:32 -0400 (EDT)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: HTML+ Form and Submit

Okay Ive thought about it awhile, and also based on what others have suggested
I think we should add a SUBMIT option to the input tag, as well as a &submit=
to the form query.  For example, if you have 2 images on screen, and you want a
click on only one of them to cause a submit, or an entry in a text field to
cause a submit it would look like:

<input name="image1" type=image src="image1.gif">
<input name="image2" type=image src="image2.gif" SUBMIT>
<input name="text" SUBMIT>

So when the user clicks on image1, the x,y points are remembered by the browser
(as any other input field).  When the user clicks on the second image, the
query is sent to the server as

?image1.x=X1&image1.y=Y1&image2.x=X2&image2.y=Y2&text=&submit=image2

Or when the user clicks enters in the text field we get:

?image1.x=X1&image1.y=Y1&image2.x=X2&image2.y=Y2&text=Bob&submit=text

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                      http://rs560.msu.edu/~henrich



From Steve.Heaney@delft.sgp.slb.com  Fri Oct 29 19:22:41 1993 +0100
Message-Id: <199310291822.AA02893@mordred.delft.sgp.slb.com>
Date: Fri, 29 Oct 1993 19:22:41 +0100
From: Steve.Heaney@delft.sgp.slb.com (Steve Heaney)
Subject: Accessing CSO servers via Web browsers


Anybody,

Is there any reason why I should not be able to reliably query CSO servers 
e.g. <gopher://x500.tc.umn.edu:015/2?> via any WWW browser.  NCSA Mosaic 
for X (2pre6) handles it ok, www on Unix seems to freeze as does 
NCSA Mosaic for Mac (B5).  Havn't tried Lynx yet, but that's next.

The reason I ask is that I have placed a URL in one field of my  record on 
a CSO server which, because the text seems to be returned as <pre>, is 
presented as a link when accessed using Mosaic for X.

It seemsed kinda neat so I'd like to recommend it to people if I was sure 
it was reliable.

Steve.



From marca@ncsa.uiuc.edu  Fri Oct 29 17:21:09 1993 -0700
Message-Id: <9310300021.AA02602@wintermute.ncsa.uiuc.edu>
Date: Fri, 29 Oct 93 17:21:09 -0700
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Accessing CSO servers via Web browsers

Steve Heaney writes:
> Is there any reason why I should not be able to reliably query CSO
> servers e.g. <gopher://x500.tc.umn.edu:015/2?> via any WWW browser.
> NCSA Mosaic for X (2pre6) handles it ok, www on Unix seems to freeze
> as does NCSA Mosaic for Mac (B5).  Havn't tried Lynx yet, but that's
> next.

Lou Montulli donated code to me way back when; it's no doubt in Lynx
and should be in the next Mosaic for Mac beta.

Marc




From jonm@ncsa.uiuc.edu  Sat Oct 30 10:29:04 1993 CDT
Message-Id: <9310301529.AA01164@void.ncsa.uiuc.edu>
Date: Sat, 30 Oct 93 10:29:04 CDT
From: jonm@ncsa.uiuc.edu (Jon E. Mittelhauser)
Subject: Re:  Accessing CSO servers via Web browsers

Steve Heaney writes:
> Is there any reason why I should not be able to reliably query CSO
> servers e.g. <gopher://x500.tc.umn.edu:015/2?> via any WWW browser.
> NCSA Mosaic for X (2pre6) handles it ok, www on Unix seems to freeze
> as does NCSA Mosaic for Mac (B5).  Havn't tried Lynx yet, but that's
> next.

Marca writes:

>Lou Montulli donated code to me way back when; it's no doubt in Lynx
>and should be in the next Mosaic for Mac beta.

It will also be in the next Mosaic for MS Windows beta as part of the
general improvement of the gopher interface that incorporates better
typing, icons, etc...

-Jon



From koellner@csa3.lbl.gov  Sat Oct 30 14:50:27 1993 PDT
Message-Id: <931030145027.25c06ae4@csa3.lbl.gov>
Date: Sat, 30 Oct 93 14:50:27 PDT
From: koellner@csa3.lbl.gov (Werner Koellner, LBL)
Subject: Unsubscribe

                                         LBL, Physics Division, 30-OCT-1993

    I wish to UNSUBSCRIBE from all www-... e-mail mailing lists. Please
    remove my name.

        Thank you and best regards,

                                   Werner Koellner
                                   WOKoellner@lbl.gov



From andy@ux1.cso.uiuc.edu  Sun Oct 31 01:39:20 1993 -0500
Message-Id: <199310310639.AA26127@ux1.cso.uiuc.edu>
Date: Sun, 31 Oct 1993 01:39:20 -0500
From: andy@ux1.cso.uiuc.edu (hunt andrew n)
Subject: subscribe

subscribe www-talk Andrew Hunt



From henrich@crh.cl.msu.edu  Sun Oct 31 16:16:44 1993 -0500 (EST)
Message-Id: <9310312116.AA08863@crh.cl.msu.edu>
Date: Sun, 31 Oct 1993 16:16:44 -0500 (EST)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: Quicktime -> Mpeg Converter?

Does anyone have such a beast?

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                      http://rs560.msu.edu/~henrich



From kevinh@pulua.hcc.hawaii.edu  Sun Oct 31 11:38:28 1993 HST
Message-Id: <9310312138.AA16238@pulua.hcc.Hawaii.Edu>
Date: Sun, 31 Oct 93 11:38:28 HST
From: kevinh@pulua.hcc.hawaii.edu (Kevin 'Kev' Hughes)
Subject: Re:  Quicktime -> Mpeg Converter?

> Does anyone have such a beast?

	Yes, open a URL to:

http://pulua.hcc.hawaii.edu/movies/techinfo.html

	...for pointers on where to get it and tips on using it. Good luck!

	-- Kevin



From lou@vax.ox.ac.uk  Mon Nov  1 11:26:06 1993 +0000
Message-Id: <00974E32.5ADD6860.31228@vax.ox.ac.uk>
Date: Mon, 01 Nov 1993 11:26:06 +0000
From: lou@vax.ox.ac.uk (Lou Burnard)
Subject: on change bar support in HTML+

The new spec for HTML+ (which is wonderful in many ways) proposes a
CHANGED element to mark both the beginning and end of that part of a
document which might be side-lined or red-lined or otherwise marked as
changed. It also proposes two (different) elements for passages which
are marked as having been deleted or added, as in legal texts (it says)
when for example deleted text may actually be printed with strike though
characters.

I am very happy with the idea of supporting these facilities in HTML+
but I have a few comments on the mechanisms proposed.

Of the three tags proposed, only CHANGED will allow you to deal easily
with a case where a change starts in one paragraph and ends in another.
(When this was touched on in earlier discussion here, I think someone
said flatly that as far as he/she was concerned, a correction that
spanned two paragraphs was two corrections so what was the beef?). 
Leaving aside, for the moment, the mechanism proposed to do this, I
think it's more than likely that passages to be marked as deleted or
added will span paragraphs in exactly the same way as passages to be
marked as CHANGED. Is one supposed to nest multiple occurrences of them
within a CHANGED ... CHANGED element-pair when that happens?

Secondly, one very obvious application for such elements might be for
simple version control. A browser could be instructed to display or
implement only changes relating to a particular version, for example, if
you added a VERSION attribute (or similar) on CHANGED. Maybe that's
already been proposed and rejected, but I missed the reasoning (one
objection is that it won't scale up very gracefully)


Now, as to the mechanism... Let's call the thing you want to mark a ZONE
(whether it's a zone of "stuff you wish to show as having been changed
in some unspecified way" or "stuff you wish the browser to mark as
having been deleted/added "). Current proposals are either

(a) mark the start and end of the zone with the same empty tag. The tag
marks a transition point. On one side you are outside the zone, on the
other you are inside. Only by a sequential scan of the context can a
browser tell where you are. If you do a hyper-leap into the middle of
the zone you won't have the faintest idea that you're in it.

(b) a variant on the above in which you mark the start of the zone with
a ZONE_START and the end with a ZONE_END tag. Again, if you land in the
middle you're in trouble, but now at least when you find a ZONE_* tag
you know which direction to look to find out what's happening. I'm not
sure whether this is worth the extra confusion.

In either case, to find the "other" one, you can use the SGML id/idref
mechanism. Each ZONE tag has an ID attribute, the value of which must be
unique within the document, and either a STARTS or an ENDS attribute,
the value of which is the same as the ID value on its 'partner'. Thus:

.... <zone id=z1 ends=z2> 
         this is inside a zone 
     <zone id=z2 starts=z1> this is outside  

The value for whichever of starts/ends is not specified is understood to
be identical with the value for ID. 

It should be stressed that this is all rather flakey from the SGML point
of view. An SGML parser won't help you beyond checking that there does
is exist somewhere a zone with the ID you supply on a a starts/ends
attribute. An SGML application won't recognize  the stuff within
a zone as a meaningful element. 

Lou Burnard



From bert@let.rug.nl  Mon Nov  1 15:54:05 1993 +0100 (MET)
Message-Id: <9311011453.AA09750@freya.let.rug.nl>
Date: Mon, 1 Nov 1993 15:54:05 +0100 (MET)
From: bert@let.rug.nl (Bert Bos)
Subject: Comments on HTML+ discussion document (long)

I've taken the weekend to delve into the new HTML+ specification. Here
are my comments.

The HTML+ draft is a good example of a balance between a vision of the
future and a realistic, implementable plan. Compared to HyTime -- to
which it has become more similar with this generation -- it is clear
that the former wants to cover everything that may become possible in
the future, while HTML+ goes no further than the technology of next
year (which is already impressive enough!)

When designing this year's HTML, one should nevertheless keep an open
eye for the things that may be added in the years after. Keeping the
door open for (future) HyTime compatibility seems a healthy approach
to me. A few of the comments below refer to HyTime in this manner.



3. Headers
   -------

ad "nestable sections"

    Keeping explicit, context-independent header-levels will make the
    browser simpler. But we can express the structure of a document
    with sections as well, by assuming an (omittable) element
    enclosing every header and the subsequent text:

	<!ELEMENT SECTION1 O O (H1, %bodytext ?, SECTION2*)>
	<!ELEMENT SECTION2 O O (H2, %bodytext ?, SECTION3*)>
	etc.

    This will make it illegal to skip a level, which is essential if
    some browser or printer driver wants to number the headings. It
    also allows a link to be made to an entire SECTION, instead of to
    header only.



4. Paragraphs
   ---------

ad "HTML+ formally doesn't require you to wrap text up as paragraphs"

    This may be true conceptually, but the to the software this is
    less easy. It would be better to require all text to be wrapped up
    as something. In other words, if untagged text follows a header, a
    P tag is assumed:

	<!ELEMENT P O O (L | %text)+>
	<!ENTITY % bodytext "(%block | %lists | %paras)>
	<!ELEMENT SECTION1 O O (H1, %bodytext ?, SECTION2)>
	etc.

    When PCDATA is encountered after a H1, H@, etc, a P tag is
    automatically inserted. NB. to make this acceptable to a
    validating SGML parser, some trickery with SHORTREFs is needed, in
    order to skip unwanted blank space, but that can be done (I tried)
    and it doesn't affect the browser.



5.2. Hypertext links
     ---------------

ad "HREF"

    Why not take one further step and make HTML+ HyTime compliant? It
    involves adding one more element to the DTD and a number of
    attributes that will not show up, since they all get default
    values:

	<!ATTLIST A
	   -- Anchor attributes --
	   id ID #IMPLIED
	   rel CDATA #IMPLIED
	   ... etc.
	   -- Extra for HyTime --
	   ref ID #REQUIRED			-- link to NOTLOC element --
	   -- Required for HyTime --
	   HyTime NAME #FIXED "clink"
	   HyNames CDATA #FIXED "target linkends"
	>
	<!ELEMENT notloc - - CDATA>
	<!ATTLIST notloc
	    id IDREF #REQUIRED			-- link to A element --
	    notation NOTATION #FIXED "WWW"
	>

    (To make this complete, there should also be a declaration
    <!NOTATION WWW... somewhere in the DTD.) It doesn't matter where
    in the document the NOTLOC element is inserted, it could be inside
    the A element, at the top or end of the document, as long as there
    is a NOTLOC for every A. Using any authoring tool (e.g., the
    html-mode for Emacs) generating the NOTLOC and the ID to bind
    NOTLOC and A together should be automatic.

    In fact HTML+ already works with this indirection partially, in
    the LINK idref attribute.

ad "TYPE", "SIZE", and "METHODS"

    It is already noted in the text, but it should also be stressed in
    the user interface of any browser that uses these attributes:
    don't trust these attributes!



5.6. Logical emphasis
     ---------------

ad "Q"

    The browser should insert quotation marks, such  as `to be' or "to
    be", or whatever style of quoting is preferred.

ad "CITE"

    The browser should display this as (Festinger...) or [Festinger],
    or whatever style is preferred. CITE is meant for use in running
    text, not in a bibliography.

ad "ACRONYM"

    A browser might use small caps instead of the full-size caps.



5.7. Extending the set of logical roles
     ----------------------------------

ad "isn't meant to apply retroactively"

    [Great idea, this RENDER element!] The best place for RENDER
    elements is therefore at the top of the document. It is an empty
    element, there is no </RENDER>.

    The comma-separated list of styles is probably better changed to a
    blank-separated list, as is customary in SGML, I believe.

	<!ATTLIST RENDER
	    tag CDATA #REQUIRED		-- Why was this #IMPLIED? --
	    style CDATA #IMPLIED
	>



5.9. Images
     ------

ad "text flowing around the image"

    While this may look nice for an image at the start of a a
    paragraph, it isn't so nice for images anywhere else. It is also
    difficult to implement. Better not require this. Instead, require
    that an image *never* overlaps with text.

ad "IMAGE"

    The footnote that recommends the IMAGE element over IMG should be
    promoted to a normal sentence. (And why not drop the ALT
    attribute of IMG altogether?)

ad "SEETHRU"

    This is a nice feature, that can make displays much more
    attractive, but it will always be dependent on the format of the
    image. For XPM, no such attribute is needed; for 256-color images
    it can be an RGB or HSV value in X format; for true-color images
    it has to be a color range or approximate color.

ad "multipart/mixed"

    How can the browser recognize which part of the multipart message
    corresponds to a given URL? (But maybe this paragraph should be
    moved to the HTTP definition anyway.)



5.11. Conditional text
      ----------------

    The normal SGML method would be to use `marked sections:'

	... text before the marked section...
	<![ %online [ ... text that only appears when on-line... ]]>
	... more general text...
	<![ %printer [ ... text that only appears on the printer... ]]>

    %online and %printer are entities, that have the values:

	<!ENTITY % online "INCLUDE">
	<!ENTITY % printer "IGNORE">

    for the browser, and the other way round for the printer.



6.1. Longer quotations
     -----------------

ad footnote 1 "quote by name"

    This is certainly useful. It allows one to automatically show the
    latest version of something, without having to change the document
    itself (cf. Windows DDE). It works for IMAGEs, so why not for
    text? But it should not be a function of the QUOTE element. Better
    to define TXT and TEXT (analogous to IMG and IMAGE).

    Maybe we want to quote not a complete document, but only a certain
    element, identified with an ID attribute. This might yield a P or
    a TABLE, or L, etc.



6.4. Notes and admonishments
     -----------------------

ad "ROLE attribute"

    In the absence of a SRC attribute (And I strongly recommend
    writers to omit it for all but the exceptional types of notes),
    the ROLE attribute should determine the rendering of the note and
    the note icon. The value of the ROLE attribute should therefore
    not be printed (it is not a word, but a type). The following list
    of predefined ROLEs should be recognized by browsers:

	note	- (no icon)
	warning	- exclamation mark, or triangular traffic sign
	error	- stop traffic sign
	info	- circled "i"
	tip	- index finger pointing up



7.3. Plain lists
     -----------

    Plain lists are sufficiently different from bulleted lists to
    warrant an element of their own. I would suggest dropping the
    PLAIN attribute and only use DIR instead.



9. Tables
   ------

    The TB element has been omitted from the description. Also, it is
    used but not defined in the DTD.



11. Literal text
    ------------

ad "TAB"

    Instead of the width of the capital M, use the "em". When the font
    has no em defined, the width of the M or something similar could
    be used instead.



14.1. HTMLPLUS
     --------

    Official versions of HTML+ should be mentioned in the SGML
    declaration, but the attributes of the HTMLPLUS tag could be used
    to notify the browser of extra requirements or hints, that do not
    affect the DTD. FORMS=off is such a requirement: a browser must
    comply. An example of a hint could be LANG=NL, telling the browser
    to apply Dutch formatting conventions as much as possible. (It
    becomes the default for all other LANG attributes.)



14.4. ISINDEX
     -------

ad "the search field always visible"

    This is mentioned in 2.2, but it might be stressed here again.
    This is what makes ISINDEX different from INPUT. A good example of
    the use of ISINDEX is as a sort of command line. Maybe ISINDEX
    should therefore be called something different, like ISINPUT or
    HASCLI.



14.7. Links
      -----

ad "UseIndex"

    The UseIndex attribute implies that there is an index and gives
    its URL, but does it also mean that the current document is
    "searchable"? Maybe the browser should show a different prompt
    from the one used for ISINDEX.



15. Large documents
    ---------------

ad "implicit links"

    The table of contents concept is an instance of a more abstract
    concept, that of independent links. What is described here is
    essentially a method for adding hyperlinks to documents that don't
    have them. So why not make it more general. Example:

	<ILINK from="http://mach.ine/doc1#id1"
	       to="http://mach.ine/doc2#id2" -- hyperlink between elements -->
	<ILINK from="http://mach.ine/doc1"
	       to="http://mach.ine/doc2"
	       role="next" -- hyperlink between documents -->

    (Or better yet, use the indirection of HyTime.)

ad "WWW-link"

    This is similar in concept to the REL=subdocument idea, but it
    works completely differently. It should be in a numbered section
    of its own.



Appendix I
----------

    HTMLPLUS could be defined as just

	<!ELEMENT HTMLPLUS O O (HEAD, BODY)>

    So many elements have the three attributes ID, LANG and INDEX,
    that it might be clearer to put them in an entity.

ad "OL"

    Why isn't a list defined as:

	<!ELEMENT (OL|UL) - - (LI*)>
	...
	<!ELEMENT LI - O (%block|%lists|%paras)*>

    i.e., a list consists of nothing but list items, but a list item may
    contain more than just text.

ad "A"

    The INDEX attribute is missing? Why is SIZES specified as NAMES,
    when only numbers are allowed?

ad "character entities"

    The list of character entities should be referred to by name:

	<!ENTITY %Latin1 PUBLIC ...>
	%Latin1

    This allows an SGML application to substitute a different file,
    e.g., one that maps entities to LaTeX macros.



Appendix III
------------

    There should have been some documentation on how this code is
    used.

ad "for (i = 0; pgon[i][X]..."

    Typically a C programmer! First use an index and only then check
    if it is valid to do so. No Pascal programmer would do it like
    this. Better to write:

	pgon[MAXVERTS-1][X] = -1;    /* Ensure termination */
	for (numverts = 0; pgon[numverts][X] != -1; numverts++) ;

    Not only is it safer, it is also slightly faster.

ad "p = (double*) pgon + 1"

    Please don't use this style in example code! Replace this by p = 0
    and replace every use of p by pgon[p][Y], etc.



Miscellaneous comments
-----------------------

At the moment, there is only one annotation server for the whole of
WWW. Clearly, this is not a long term solution. The load should be
distributed. I can see two solutions:

1) an algorithm in the browser computes the annotation server to
contact given a URL (a hashing functions or the `nearest domain'.)

2) every document specifies its own annotation server, in a LINK
element:

    <LINK role=Annotations href="http://hoohoo.ncsa.uiuc.edu:8001/">


--
                     _________________________________
                    / _   Bert Bos <bert@let.rug.nl>  |
           ()       |/ \  Alfa-informatica,           |
            \       |\_/  Rijksuniversiteit Groningen |
             \_____/|     Postbus 716                 |
                    |     9700 AS GRONINGEN           |
                    |     Nederland                   |
                    \_________________________________|



From uunet!ctrbdo%iapa@dxmint.cern.ch  Mon Nov  1 11:31:52 1993 CST
Message-Id: <9311011731.AA12019@hickory.iapa>
Date: Mon, 1 Nov 93 11:31:52 CST
From: uunet!ctrbdo%iapa@dxmint.cern.ch (bryan d oakley)
Subject: viewing source code with embedded links

I am wanting to be able to view source code using Mosaic such that the
code remains in it's existing non-wrapped state, but with links being
properly rendered (ie: as if a <PRE> preceded each file).  Now, I
don't want to have to add a <PRE> to each file so I'm wondering what
is the best way to accomplish this.  

The problem I am trying to solve falls somewhere between the domains
of literate programming and the World Wide Web.  The ultimate goal is
to have hypertexified source code that a maintenance programmer could
browse via Mosaic, with the ability to jump to specifications, test
documents and so on.  Ultimately I think it would be nice to have
available a source code / HTML 'pretty-printer', which would take the
source code and allow comments to be wrapped and rendered in a
different font, perhaps tag variables with <VAR>, and so on.

So, the question is, what's the best way to proceed?  At this point,
since I've just recently installed NCSA httpd (version 1.whatever),
I'm assuming that I could create a script in htbin, though I'm not
sure how I would use it.  Ideally I would like the URL
'http://server/src/main.f' to execute my script causing main.f to be
found and tagged, then displayed in Mosaic.  If that URL won't work,
is there one that will?  I don't want the user to have to enter the
name of the source file in an <ISINDEX> document.

Perhaps someone is already working on such a beast?  If not, I could
use some fairly specific hints.  I'm new to administrating httpd and
Mosaic, so the knowledge base is low.  I'm not on the internet so
sound advice would be more appreciated than a pointer to an URL
(though I can surf the 'net via my delphi account from home when I
have to, so URLs would be appreciated as well).

Thanks.


---------------------------------------------------------------------
Instrument Approach Procedures Automation             DOT/FAA/AMI-230
---------------------------------------------------------------------
Bryan D. Oakley              ctrbdo%iapa@constellation.ecn.uoknor.edu
KENROB and Associates, Inc.              voice: (405) 954-7176 (work)
5909 NW Expwy Suite 209                         (405) 366-6248 (home)
Oklahoma City, Ok.  73132            



From davis@dri.cornell.edu  Mon Nov  1 15:35:21 1993 -0500
Message-Id: <199311012035.AA02830@willow.tc.cornell.edu>
Date: Mon, 1 Nov 1993 15:35:21 -0500
From: davis@dri.cornell.edu (Jim Davis)
Subject: comments on HTML+ discussion document

First of all congratulations to Dave for excellent work.  Don't be
fooled by this email, as it contains only my complaints and
disagreements; the praise and delight are to be understood implicitly!

My main comment in that HTML+ is too big.  It is beginning to resemble
PL/I (am I the only one old enough to remember this language) or
Common Lisp.  Do we really need all these features, and more
important, will the browser implementors actually put them all in?
The thing about WWW is that it's very very easy to make a simple
server but it's getting to be harder and harder to make full client.

1) Re 5.2 Hypertext links.  Why not drop TYPE, SIZE, and METHODS?  As
you say, there's no guarentee they will be accurate.  We're just
asking for trouble by putting them in the language.  Yes, it would be
nice if the browser could tell me ahead of time what is at the other
end of the link but given a choice between inaccurate info and no info
I'll prefer no info.  If we put these in the language, there will be
times when it is wrong and it screws someone; What's more, eventually
some clever person will demand that we build some mechanism for
guarenteeing that they stay up to date.  If you really need this info
before transfering, isn't that what the HEAD method is for?

2) 5.11 Conditional Text.  I appreciate the problem, having
run into it myself, but this is not the right answer.  The general
problem is that different rendering is required for a printed (dead)
document and for an online (live one).  HTML+ seems to have several
different solutions for the problem.  There's the conditional text
and also the PRINT attribute.  I would prefer to keep *both* out of
the language until a clean proposal comes in that unifies all.

I dislike conditional text because:
 1) there's no guarentee that people will use it in parallel ways i.e.
to provide equivalent info for online or printing cases.  There's no
guarentee the two sides will stay consistent.
 2) If you are going to have conditional text might as well generalize
it to include arbitrary boolean tests.  I can imagine browsers that
are neither printing not screens, e.g audio browsers.  
 3) I can  also imagine smarter printing programs that might want
to look at the anchor to determine the proper way to print it.

3) Re 56.4 notes and admonishments

I agree with Bert Bos, the ROLE in NOTE should be a type, and not
printed.  Als je kan maar het Engels gebruiken.  ("Otherwise, you can
only use the english language.")

4) Re 8.1 Active areas:

you have the origin in the upper left corner (good) but the last draft
of HTTP I saw has the origin (for SPACEJUMP) in the lower left.  We
are asking for trouble here.

5) 13 Indexing

I don't understand why this is even in the HTML spec.  I can certainly
appreciate that document authors might want to define index hits when
writing documents, but this index info has no semantics to the
browser, so why should it be in there?

Does the definition of HTML allow me to put any arbitary stuff I want
inside a tag, e.g. can I write

<h3 ID="z23" shoe-size=19 rent="4+dollars">

If so, then I can put the "index info" in there in the same way?

6> 14.2 HEAD and BODY.

Are these mandatory?  or optional?  

7) Re 14.7 LINK.  It's not clear to me what a browser should do
with links like REL=Previous, since a user (client) can arrive
by many paths at a given node.  I would be upset if I clicked
on "Back" and landed not at the previous (historical) node but
rather the one that some author thought was previous.

8) Typos: 

  p2 extra space after apostrophe in "document' s text"
  p 4 missing space "level one header.Header"

best wishes



From robm@ncsa.uiuc.edu  Mon Nov  1 15:46:52 1993 -0600
Message-Id: <9311012146.AA02213@void.ncsa.uiuc.edu>
Date: Mon, 1 Nov 1993 15:46:52 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: viewing source code with embedded links

/*
 * viewing source code with embedded links  by bryan d oakley (uunet!ctrbdo%iapa@dxmint.cern.ch)
 *    written on Nov  1, 11:31am.
 *
 * I am wanting to be able to view source code using Mosaic such that the
 * code remains in it's existing non-wrapped state, but with links being
 * properly rendered (ie: as if a <PRE> preceded each file).  Now, I
 * don't want to have to add a <PRE> to each file so I'm wondering what
 * is the best way to accomplish this.  
 * 
 * The problem I am trying to solve falls somewhere between the domains
 * of literate programming and the World Wide Web.  The ultimate goal is
 * to have hypertexified source code that a maintenance programmer could
 * browse via Mosaic, with the ability to jump to specifications, test
 * documents and so on.  Ultimately I think it would be nice to have
 * available a source code / HTML 'pretty-printer', which would take the
 * source code and allow comments to be wrapped and rendered in a
 * different font, perhaps tag variables with <VAR>, and so on.
 * 
 * So, the question is, what's the best way to proceed?  At this point,
 * since I've just recently installed NCSA httpd (version 1.whatever),
 * I'm assuming that I could create a script in htbin, though I'm not
 * sure how I would use it.  Ideally I would like the URL
 * 'http://server/src/main.f' to execute my script causing main.f to be
 * found and tagged, then displayed in Mosaic.  If that URL won't work,
 * is there one that will?  I don't want the user to have to enter the
 * name of the source file in an <ISINDEX> document.

Currently, there isn't any way to do this under NCSA httpd. What you can do
for now is write a short htbin script which takes as the first argument the
name of the source file and spits back something of type text/html
containing a <PRE> at the beginning. Such a script could be as simple as:

--cut
#!/bin/sh

echo Content-type: text/html
echo

echo "<PRE>"
cat $1
echo "</PRE>"

--cut

Note that this doesn't work for files with weird characters like spaces or
ampersands et. al., but you get the idea.

The way you'd access this is

http://your.server/htbin/src?/your/source/path/file.f

You can add HREFs to documents with question marks in them, and you can Open
URL in mosaic with the question mark in there and it will send it on to the
server.

We are planning to add the capability to have a script which looks like a
directory in the path name but is in actuality a file. I.e. if you were to
do:

http://your.server/htbin/src/your/source/path/file.f

The server would parse the URL, figure out that /htbin/src is actually a
server script, and execute it like

/htbin/src /your/source/path/file.f

 * Perhaps someone is already working on such a beast?  If not, I could
 * use some fairly specific hints.  I'm new to administrating httpd and
 * Mosaic, so the knowledge base is low.  I'm not on the internet so
 * sound advice would be more appreciated than a pointer to an URL
 * (though I can surf the 'net via my delphi account from home when I
 * have to, so URLs would be appreciated as well).
 */

Hope this helps
--Rob



From sanders@bsdi.com  Mon Nov  1 16:51:49 1993 -0600
Message-Id: <9311012251.AA07578@austin.BSDI.COM>
Date: Mon, 01 Nov 1993 16:51:49 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: comments on HTML+ discussion document 

> 7) Re 14.7 LINK.  It's not clear to me what a browser should do
> with links like REL=Previous, since a user (client) can arrive
> by many paths at a given node.  I would be upset if I clicked
> on "Back" and landed not at the previous (historical) node but
> rather the one that some author thought was previous.

In addition to the logical structure built from the navigation history
HTML allows the author to define explicit relationships for organizing
large colletions of material.  It's is up to the browser to present this
to the user in a clear and consistant way.  For example, one might opt to
represent this information graphically (maybe this is a bit much,
but you get the idea):

         Previous
             \
              \
               Back
              / \
Preceding    /   \           
        \   /     Next      See also:
         \ /                  Table of Contents
 Parent--CUR--Child           Document History
         / \                  Previous Version
        /   \                 Glossary
 Forward     Following        Index

There are three navigation modes mixed in here.  Back/Forward (like
NCSA Mosaic), Previous/Back/Next (like Midas), and then the explicit
navigation tags (Preceding/Following and Parent/Child, plus the
see also's).

Or you can do what is currently done, ignore it completely (sigh).

There is more information about link relationships at:
    http://info.cern.ch/hypertext/WWW/MarkUp/Relationships.html

--sanders



From terry@ora.com  Mon Nov  1 15:11:46 1993 PST
Message-Id: <199311012311.AA14039@rock.west.ora.com>
Date: Mon, 1 Nov 1993 15:11:46 PST
From: terry@ora.com (Terry Allen)
Subject: HTML+ and HyTime

Bert Bos proposes making HTML+ HyTime-compliant by complicating
the syntax of the A element.  There is absolutely no need to 
do this, as it has no practical effect whatsoever; it will only
turn off users, many of them naive about SGML.

When HyTime tools are available it will be soon enough to thing
about changing this well designed presentation DTD to work with
them.  Until then, as people are struggling to get into HTML,
let along HTML+, let's leave the A element as it is.

Further on Mr Bos's comments:

Text flow.  This is indeed difficult to implement, and may 
require more info than HTML+ demands, but it part of what 
people expect from a good renderer.  

Conditional text.  Marked sections are Bad, because they leave
no seam in the ESIS.  One might well want to output a marked
section but indicate that it's been marked; or to output two
alternate versions of something.  Better to use a version 
attribute in an element than this poorly designed function of
SGML.

Plain lists.  Are only unmarked bulletted lists.  There is no
reason in the world to make another element for them.

Tab.  Em is indeed a better choice than capital M, and is 
traditional.  The font doesn't have to define an em, though---
it ought to be equal to the width of lowercase m, or be 
entirely fixed.

But I'm sure we all welcome Mr Bos's comments; don't let me
dissuade you from making more of them, Bert!

Regards,

-- 
Terry Allen  (terry@ora.com)
Editor, Digital Media Group
O'Reilly & Associates, Inc.
Sebastopol, Calif., 95472



From john@math.nwu.edu  Mon Nov  1 17:31:40 1993 -0600 (CST)
Message-Id: <9311012331.AA07908@hopf.math.nwu.edu>
Date: Mon, 1 Nov 1993 17:31:40 -0600 (CST)
From: john@math.nwu.edu (John Franks)
Subject: Wais2html


I've been working on WAIS index support for the gn gopher/http server.
As a by-product I wrote a short program which may be of use to people
using other servers to allow them to use WAIS indexes.  It's nothing
fancy and hasn't been well tested but might be a start for someone
wanting to implement WAIS indexing.

Available from  ftp://ftp.acns.nwu.edu/pub/gn/wais2html.tar.Z

Here's the README:

Wais2html is a small C program which is linked WAIS libraries.  It
is run with arguments including a WAIS index name and search terms
and it produces on stdout an html document containing a list of 
URL's to the files which contain a match for the search terms.  The
intent is that this can be used with an http server to provide <INDEX>
html documents which will search a collection of files indexed with
WAIS.  It only works with full text indexes of a collection of files,
i.e. there is no support for things like mail or news format where
a single message, as opposed to a whole file is considered a document.
This would be easy to add, but requires cooperation from the server
to return only part of a file.  

WARNING: This is a quick effort with almost no testing done.  There
is no support -- you're on your own.


Here is what you need to do.

1. Get the WAIS software.  You can use either freeWAIS from
	ftp://ftp.cnidr.org/pub/NIDR.tools/freeWAIS-0.202.tar
or
	ftp://ftp.bio.indiana.edu/util/wais/iubio-wais-8b5-d.tar.Z
and build WAIS per the instructions.


2. In the wais2html src directory make symbolic links to the directories
"bin" and "ir" in the main WAIS source directory.


3. Run make in the wais2html directory, producing the wais2html binary.


4. Index your files.  This is done with the program "waisindex" which
in the bin subdirectory of the main WAIS source directory.  I suggest
doing this by making a directory, say "waisindex" in which the index
files will reside. Then cd to that directory and use the command
	waisindex -t filename /complete/path/to/files...
or
	waisindex -t first_line /complete/path/to/files...
where "files..." is replaced by a list of all the files you want to
index.  The difference in these two commands is that the html document
which wais2html will produce will refer to the matching documents
either by the name of the file containing a match or by the the first
line of the contents of the file containing a match.  Note that in
the first form the argument is literally the string "filename"; that
string is not replaced with the name of a file.

[This step will be different if your server will run chrooted, because
the complete path of the files are embedded in the index.  I haven't
tried it, but it should work to do the indexing chrooted,
i.e. /etc/chroot newroot waisindex]


5. Test your set up with this index by running the command 
	wais2html index root_dir title host port words...
where root_dir is the root relative to which your server calculates
URLs, host is your host name, index is "/path/to/waisindex/index",
title is a quoted string for the title of the html document and
words...  is a list of search terms.  Note that the "index" argument
is slightly strange.  It is the path to the waisindex directory you
created with "/index" tacked on.  There is no file by this name but
a bunch of files of the form index.*.


6. If all works well set up your server to handle an INDEX query by
running the program wais2html with arguments as in step 5 and so it
returns the document this program produces on stdout.




From hotsand!ellson  Mon Nov  1 19:35:54 1993 EST
Message-Id: <9311020035.AA16320@hotsand.dacsand>
Date: Mon, 1 Nov 93 19:35:54 EST
From: hotsand!ellson (John Ellson)
Subject: Re: comments on HTML+ discussion document

> From: Tony Sanders <sanders@bsdi.com>

> to the user in a clear and consistant way.  For example, one might opt to
> represent this information graphically (maybe this is a bit much,
> but you get the idea):
> 
>          Previous
>              \
>               \
>                Back
>               / \
> Preceding    /   \           
>         \   /     Next      See also:
>          \ /                  Table of Contents
>  Parent--CUR--Child           Document History
>          / \                  Previous Version
>         /   \                 Glossary
>  Forward     Following        Index
> 

This is great!  Could we please have an array of buttons like this in
future browsers?

One problem with putting "standard" links like this in the document
itself is that they are forever scrolling off the page and are never
there when you want them.  (Same comment applies to the search field
in xmosaic).  Do you always read to the end of a page before turning
to the next?

Questions:  
  - When would "Following" be a different document than "Next"?
  (or is "Following" just pagedown in the current document?)
  - Maybe "Child" isn't needed?  Firstly there is rarely one child and
  secondly the hypertext links in the body are the links to the children.

  How about:	Home     | Back    | PgUp      TableOfContents
		---------+---------+------     ListOfFigures
		Previous | Reload  | Next      Glossary
		---------+---------+------     Index
		Parent   | Forward | PgDn      DocumentInfo

John Ellson
AT&T Bell Labs
Holmdel, NJ



From sanders@bsdi.com  Mon Nov  1 19:57:29 1993 -0600
Message-Id: <9311020157.AA08140@austin.BSDI.COM>
Date: Mon, 01 Nov 1993 19:57:29 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: comments on HTML+ discussion document 

> Questions:  
>   - When would "Following" be a different document than "Next"?
>   (or is "Following" just pagedown in the current document?)

"Following" is an explictly named document (by the author) using <LINK
REL="Precedes" HREF="..."> whereas "Next" is a logical beast based on the
users own navigation history.  There are three different navigation models
at work here:

#1  History Navigation (per NCSA Mosaic): Back/Forward
    These simply take you forward and back in your history

#2  Logicial Navigation (per Midas): Next/Previous
    The info.cern.ch info explains it as:
	When the current node is one of several nodes linked to the back
	node, go to the next of those nodes. Leave the Back node unchanged.
	Modify the history to remove the current node and replace it with
	the "next" (new current) node.
    Basically, you build a list of all the destination links in a
    document in the same order they appear.  The users selects one,
    you go to it.  The user selects "Next", so you go to the "Back"
    document and having remembered which link the user just selected you
    pick the "next" one in the list.  Sounds complicated but it's
    actually pretty simple (and useful).

#3  Explicit Navigation (per nobody yet):  Parent/Child/Preceding/Following
    These are simply the REL/REV types of Subdocument and Precedes
    Parent/Child are used for defining the structure of a document set
    (like a hierarchical outline).  Preceding/Following are for traversing
    information in a linear fashion defined by the author (for reading a
    book).

For more information about navigational techniques see
    http://info.cern.ch/hypertext/WWW/DesignIssues/Navigation.html

Maybe this UI will work, I was trying to express the relationships with
my diagram but that might be overly complicated.  I like your table layout
though Pgup/Pgdown don't quite seem to fit.  Maybe we need icons.  The
corners navigate the explicit Subdocument and Precedes links.

             	Up       | Back    | Preceding
 		---------+---------+-----------
 		Previous | Home    | Next 
 		---------+---------+-----------
 		Down     | Forward | Following 


The important thing is that browsers do *something* so we can start
playing around and seeing what works and what doesn't.

--sanders



From hotsand!ellson  Mon Nov  1 22:44:18 1993 EST
Message-Id: <9311020344.AA17692@hotsand.dacsand>
Date: Mon, 1 Nov 93 22:44:18 EST
From: hotsand!ellson (John Ellson)
Subject: Re: comments on HTML+ discussion document

> Maybe this UI will work, I was trying to express the relationships with
> my diagram but that might be overly complicated.  I like your table layout
> though Pgup/Pgdown don't quite seem to fit.  Maybe we need icons.  The
> corners navigate the explicit Subdocument and Precedes links.
> 
>              	Up       | Back    | Preceding
>  		---------+---------+-----------
>  		Previous | Home    | Next 
>  		---------+---------+-----------
>  		Down     | Forward | Following 
> 

I was trying to chose something that aligned with the cursor keys on
my keyboard in the expectation that people will want to map them as
shortcuts.  My keypad has the following, is this fairly standard?

          Home   |    ^    |   PgUp
	---------+---------+-----------
	   <     |         |    >
        ---------+---------+-----------
	  End    |    v    |   PgDn

Back, Forward, Previous, Next, seem to map well,  but I think that Home
in the center would be confusing (at least on this keypad) which was
why I proposed "Reload" in the center.

My keypad also has "-", "+", and Enter which would be great for
stepping through the hyperlinks in the body of the document and then
selecting one with the Enter key.

A certain overworked person ;-)  suggested that it would be nice if 
we could do this from the server side, instead of reinventing the 
browser.  Seems like a good idea except that I think we need a couple of hooks.

Firstly I think we need a non-scrolled region of the browser 
that can be defined by HTML text in the <head> of the document; 
with normal scrolled text being defined in the <body>.

Secondly, the behaviors of these buttons must still be provided by
the browser.  All we can do in the html document is to attach a user
specified icon or anchor to a specific behavior (and perhaps enable
or disable the behavior).  

Perhaps we should think about the HTML+ issues first?  

How about the following:

    <control home> ... </control>
    <control back> ... </control>
    <control forward> ... </control>
    <control reload> ... </control>

    <control next=(url)> ... </control>
    <control previous=(url)> ... </control>
    <control following=(url)> ... </control>
    <control preceding=(url)> ... </control>

I've probably got the syntax all messed up.  How would this fit with
the LINK directive?

John Ellson
AT&T Bell Labs



From marca@ncsa.uiuc.edu  Mon Nov  1 22:15:36 1993 -0800
Message-Id: <9311020615.AA02673@wintermute.ncsa.uiuc.edu>
Date: Mon, 1 Nov 93 22:15:36 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: comments on HTML+ discussion document

Jim Davis writes:
> My main comment in that HTML+ is too big.  It is beginning to
> resemble PL/I (am I the only one old enough to remember this
> language) or Common Lisp.  Do we really need all these features, and
> more important, will the browser implementors actually put them all
> in?  The thing about WWW is that it's very very easy to make a
> simple server but it's getting to be harder and harder to make full
> client.

Funny that Jim makes these comments today -- I was going to send out a
note tonight to make much the same point.  We've had some time to mull
over HTML+ now, and to look at the progress of WWW software
development, and it is becoming apparent that HTML+ -- even after
months of revisions -- does noticeably suffer from "second system
syndrome": it just tries to do too much.  I think we need to prune
some things out to make it really manageable.

Justifications:

If we do this, and the things we prune turn out to be very necessary
in the long term, then they will be back in HTML++.  If it turns out
they're not -- i.e., if lack of tables does not turn out to actually
be a showstopper for anyone who wants to use HTML+ as a delivery
format -- then this will be apparent also and save us from having them
burden down this markup language.

If we do *not* prune some of these things, we are indeed making it
prohibitive to build browsers.  It may very well be the end of next
year before Mosaic across platforms fully implements HTML+ as it
stands, and we've got a comparatively huge development effort.  Is
that level of complexity the foundation we want to build WWW on in the
long term?

More and more I think the most important thing for us to do at this
point is to enable as many *applications* as possible.  Fill-out forms
clearly do this, for example.  Conversely, I think we have to let the
finer points of document formatting take a back seat -- the problem
domain is much bigger, and we do have to face the fact that anyone who
is going to use WWW is going to do so for its special capabilities
(distributed hypermedia, fill-out forms, etc.) and not its document
formatting capabilities (for which PostScript, PDF, TeX, etc. are
always going to be better suited, no matter how hard we work in the
context of an effort like WWW).

Like Jim, I don't want to sound negative -- I do think HTML+ is a big
step forward -- but I think we need to tackle these issues now in
order to make sure it's successful and relevant.

> 1) Re 5.2 Hypertext links.  Why not drop TYPE, SIZE, and METHODS?  As
> you say, there's no guarentee they will be accurate.  We're just
> asking for trouble by putting them in the language.  Yes, it would be
> nice if the browser could tell me ahead of time what is at the other
> end of the link but given a choice between inaccurate info and no info
> I'll prefer no info.  If we put these in the language, there will be
> times when it is wrong and it screws someone; What's more, eventually
> some clever person will demand that we build some mechanism for
> guarenteeing that they stay up to date.  

Agreed.  I'm also ready to say let's scrap TITLE and PRINT -- I don't
think they add enough real functionality to a generic browser to
justify their existence.

> 2) 5.11 Conditional Text.  I appreciate the problem, having
> run into it myself, but this is not the right answer.  The general
> problem is that different rendering is required for a printed (dead)
> document and for an online (live one).  HTML+ seems to have several
> different solutions for the problem.  There's the conditional text
> and also the PRINT attribute.  I would prefer to keep *both* out of
> the language until a clean proposal comes in that unifies all.

Agreed.

> 3) Re 56.4 notes and admonishments
> 
> I agree with Bert Bos, the ROLE in NOTE should be a type, and not
> printed.

Yup -- it's easy to put the "<b>NOTE:</b>" in by hand; it makes little
sense to have it in the language.

> 4) Re 8.1 Active areas:
> 
> you have the origin in the upper left corner (good) but the last draft
> of HTTP I saw has the origin (for SPACEJUMP) in the lower left.  We
> are asking for trouble here.

Yup -- let's standardize across all these various different methods by
specifying the same thing with what we're already doing (ISMAP --
upper left).

> 5) 13 Indexing
> 
> I don't understand why this is even in the HTML spec.  I can certainly
> appreciate that document authors might want to define index hits when
> writing documents, but this index info has no semantics to the
> browser, so why should it be in there?

Agreed.

> 6> 14.2 HEAD and BODY.
> 
> Are these mandatory?  or optional?  

I've never been clear on the point of those -- there doesn't seem to
be any point in time where they'd be useful.  I must be missing
something...

More comments from reading over the spec today:

intro page: Use of "light weight" seems incorrect :-).

            Should standardize throughout on the term "hypermedia",
            and not use "hypertext".

page 1: Should be "Uniform Resource Locator", "Uniform Resource Name".

        Strike "for the nearest available copy" -- not relevant, and
        not the only (or main) purpose of URNs.

        "The latter being designed" should be "The latter was
        designed".

        Strike "It is hoped that HTML+ will be useful for information
        exchange via email and network news as well as HTTP" -- there
        is already no reason HTML should be considered HTTP-specific.

page 2: Kill "freely accessible" -- not relevant.

        "World Web" should be "World Wide Web".

        "HTML+ documents consists of" should be "HTML+ documents
        consist of".

page 3: This whole "HTML+ provides a means for authors to specify such
        paths either explicitly via declarations at the beginning of
        the node or implicitly according to the context in which a
        given node is reached.  Another possibility is for servers to
        send such information independently, e.g. as MIME message
        headers" is overkill.  Why should there be two distinct
        methods to accomplish the same thing?  In any case, the latter
        sentence should be tossed out of the HTML+ spec as irrelevant.
        
        "You can also provide a search field that is always present
        (and can't be scrolled away)" is a browser issue and not in
        the scope of a markup language spec.

page 4: Strike "(preferably centered)".

        Strike "flush left".

        Strike "WYSIWYG editors should automatically generate
        identifiers.  In this case, they should provide a point and
        click mechanism for defining links so that authors don't need
        to deal explicitly with identifier names."  Also strike
        sentence after that -- shouldn't be a part of the markup spec
        and in fact exposes a weakness that we don't want to deal with
        yet (like I've said before: there will never be a marker where
        you really need one, regardless of how many you stick in
        there).  Also strike following paragraph.

page 5: "you may wish to switch off word wrap with WRAP=OFF" seems to
        come out of left field.  In any case, do we really want that?
        Isn't that what PRE/LIT is for?

        Footnote: What is "H" (as opposed to "H1 to H6")?

page 6: Is &quot; really necessary?

        Where did the "Q" tag come from?

page 7: What is "<!ENTITY ...> %ISOcyr1;" stuff?  Is it intended to be
        in a DTD or in a HTML+ document?  If the latter, we don't
        normally use "%" as a prefix for anything.  I suggest we just
        toss it out altogether, in any case -- if we need to do
        languages, let's use MIME.

page 8: Kill <U> -- underlining is too convenient, obvious, and
        popular a representation method for hyperlinks; many browsers
        will have to ignore it anyway.

        Why superscript and subscript?  If we don't do math (see
        below), what applications require them?  They would be quite a
        bit of work to implement, and many browsers wouldn't be able
        to.

page 10: "may overwrite previous lines of text???  What???

        Footnote is kinda confusing.

page 11: Omit SEETHRU paragraph.

        "bigpic.giff" should be "bigpic.gif"

        Clear up ambiguity introduced by saying that some servers can
        handle drags.

        Kill final paragraph in section (about "asking HTTP servers to
        include images with the HTML+ document as a MIME multipart
        message") -- it's far from clear that this will be implemented
        in any near term.

page 12: Axe conditional text section.

        Kill <L> -- it's really kinda pointless, because of <BR>.

        Another mention of WRAP=OFF that doesn't seem to need to be
        there.

page 13: Kill suggestion in footnote 1.

page 18: Clarify to leave ISMAP as "?x,y" since it's already in place.

page 19: Kill second paragraph of section 8.3 altogether.

        Kill tables -- they add a lot of complexity to the
        requirements for a conforming browser while not provide enough
        capabilities to think that they'll keep a potential
        application from being show-stopped by their absence.  Both
        inlined images and PRE sections will be "good enough"
        substitutes in most cases.

page 22: Let's use a separate METHOD attribute to keep things
        nonconfusing.

        Kill <htmlplus forms=off> paragraph.

        Do we *really* (I mean *really*) need the MH stuff?

page 23: TYPE's default should be clarified to be a single-line text
        entry area.

        Instances of TYPE=IMAGEMAP should be TYPE=IMAGE throughout.

        Istances of MAX should be MAXLENGTH.

page 28: Kill math stuff altogether.  It belongs elsewhere -- we can't
        do enough of it to be competitive with existing, used systems
        and so we should punt -- at least for now.  Again, this is one
        of those things that can reappear in HTML++ if it turns out
        it's really needed -- but let's keep it out of the base
        spec.

page 31: Kill htmlplus tag.

        ISINDEX spec should specify encoding method beyond just
        space-to-plus.

page 32: I still think NEXTID should be nuked from the spec -- let it
        be used by particular editors WITHIN A COMMENT if necessary,
        but it has nothing to do with the markup language.

page 47: Appendix II is way overkill.  Any text-based browsers
        wouldn't be able to do anything with almost all of the
        symbols, and graphics-based browsers typically would need a
        *lot* of complex special-case rendering code.  Let's let the
        normal (albeit slow) progress of system character sets solve
        this problem correctly.

Cheers,
Marc




From henrich@crh.cl.msu.edu  Mon Nov  1 23:33:01 1993 -0500 (EST)
Message-Id: <9311020433.AA12531@crh.cl.msu.edu>
Date: Mon, 1 Nov 1993 23:33:01 -0500 (EST)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: Tables and HTML+

I agree that HTML+ probably should be scaled back abit (Especially the math
markup) I think that the table HTML should be in the spec.  It is fairly well
thought out.  If at the moment no browser implements it, fine.  But if in the
future someone wants to, they at least have a guidline to go by, instead of
coming up with something on their own...

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                      http://rs560.msu.edu/~henrich



From alanb@ncsa.uiuc.edu  Tue Nov  2 02:18:22 1993 CST
Message-Id: <9311020818.AA12577@void.ncsa.uiuc.edu>
Date: Tue, 2 Nov 93 02:18:22 CST
From: alanb@ncsa.uiuc.edu (Alan Braverman)
Subject: X Play Gizmo


X Play Gizmo 1.0 is now available at ftp.ncsa.uiuc.edu in the
/Mosaic/misc/xplaygizmo directory. 

X Play Gizmo is intended to be used as a Mosaic external viewer for sounds or
movies.  It pops up a small control panel from which the user can start and
stop playing of the sound or movie (with the sound or movie player of his/her
choice).  After installing X Play Gizmo, sound and movie files may be played
multiple times, and saved locally, without multiple retrievals.

See xplaygizmo.readme (in the distribution tar file) for instructions on
compiling, command-line flags, and using xplaygizmo with NCSA Mosaic for X.

Precompiled executables for Sun and SGI are available.


Alan Braverman
Software Development Group
National Center for Supercomputing Applications
alanb@ncsa.uiuc.edu



From marca@ncsa.uiuc.edu  Tue Nov  2 03:28:03 1993 -0800
Message-Id: <9311021128.AA03902@wintermute.ncsa.uiuc.edu>
Date: Tue, 2 Nov 93 03:28:03 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: NCSA Mosaic for X 2.0 prerelease 7 available

Ladies and gentlemen, another in the long series of moments you've all
been waiting for...

...ftp.ncsa.uiuc.edu in /Mosaic/prerelease.  Source, plus binaries for
Sun, IBM, SGI.

This prerelease is another step on the road to 2.0.  With luck, the
real 2.0 release will be next week.

There are no known crash conditions, other than a few obscure
system-related problems (e.g. crash in XtKeysymToKeycodeList) that we
can't find ways to work around.  If this prerelease crashes on you for
any reason, please report the crash with a full dbx stack traceback.

On the upside -- transparent uncompression is back.

BTW, thanks MUCH to all the prerelease testers who have sent in
feedback and bug reports -- your help is (as with 1.x) making 2.0 into
a vastly better product than it could otherwise be.

If you make this prerelease available to normal users, please make
sure they understand that it is not a full, stable release and that it
is bound to have a few problems and instabilities.

Changes and additions in this prerelease include:

 o Smart inlined image caching. Resource imageCacheSize can be
   set to the maximum image cache size of your choice (in kbytes;
   default 2048) -- command line option -ics also does this. 
    o All of the images in a given document will be (temporarily)
      cached while on that page regardless of the value of 
      imageCacheSize. (This is a feature :-). 
    o Cache flushes "least recently viewed". 
 o Added TYPE="image" to forms support (see testcase). 
 o Added interruptible reads. All data loads should now be completely
   interruptible (from end of DNS lookup to beginning of in-widget
   document formatting), except for certain stages of a direct WAIS
   query. 
 o Added "mosaic-internal-present" magic viewer to cause arbitrary
   MIME types to be presented to the user using Mosaic's normal
   plaintext display mechanism. Added many default mappings for
   things like troff and TeX documents to this magic viewer. 
 o Made additional fixes to HTTP code for very small inlined images
   -- testcases here and here. 
 o Transparent uncompression is back (but not recommended, for
   cross-platform compatibility). 
    o X resources uncompressCommand and 
      gunzipCommand still control uncompression commands. 
    o You should upgrade to gzip version 1.2.4 if you're not already
      there, as the new default for X resource gunzipCommand is
      "gunzip -n -f", which requires a recent version of gzip. 
    o Mosaic will not transparently uncompress anything coming
      across a HTTP/1.0 connection, under any circumstances, yet. 
    o Mosaic will not transparently uncompress anything
      transferred in binary transfer mode, but will transparently
      uncompress files typed such that they get saved directly to
      disk (e.g. application/octet-stream, and any
      MIME type mapped to magic viewer
      "mosaic-internal-dump"). 
 o Partially removed smart FTP interface -- will be restored at some
   point in the future when I have more time to work on it. In the
   meantime, it caused too many problems with too many servers. 
 o Added "Reload Images" menu option to explicitly flush images on
   current page and reload the entire thing. 
 o Added horrible hack to allow (slow, but working) transactions with
   way-old HTTP0 servers. 
 o Made handling of screwed-up HTTP/1.0 MIME header sets more
   robust. 
 o Proper password entry dialog for authentication support. 
 o Added last resolved host info caching to help performance with slow,
   confused, or misconfigured DNS servers. 
 o Most temporary files weren't going into specified TMPDIR -- fixed. 
 o Fixed bug in handling of Gopher titles with 8-bit characters (testcase 
   here -- this image). 
 o Fixed bugs in issuing Gopher queries -- punctuation in queries, etc.
   should work now. 
 o Better handling if temporary disk space runs out (still not a good
   thing to allow to happen, though). 
 o Better socket handling (sockets should always be closed by the time
   an external viewer is started now, so they don't leak until the viewer
   exits). 
 o Fixed bug in handling HTTP/1.0 redirection for inlined images and
   reloading. 
 o Fixed bug in following symlinks to absolutely specified files on FTP
   servers. 
 o Fixed minor and intermittent scrollbar management bug. 
 o Fixed another coredump opportunity in GIF reading code. 
 o Fixed another coredump opportunity in FTP icon code (testcase
   file://ftp.uwp.edu/pub/music/lyrics/b/beatles -- can't read it because
   the FTP server is highly nonstandard, but at least now it doesn't dump
   core). 
 o Fixed coredump opportunity in mailcap-parsing code. 
 o Fixed handling of some Gopher directories (e.g. 
   gopher://calypso.oit.unc.edu/11/sunsite.d). 
 o Fixed coredump when using HREF instead of SRC with IMG. 
 o Color stuff -- start at http://nearnet.gnn.com/mkt/mkt.intro.html
   with correct colors and middle-button the resource directory, close
   new window, repeat as necessary, occasionally pressing 'R' (refresh)
   in the original window -- you'll see the colors in the newly opened
   window look incorrect (in 1.2 also). Fixed! 
 o Fixed interruptible I/O weirdness on some System V systems. 
 o Cleaned up generation of Gopher titles. 
 o Changed default player for all audio files from showaudio to sfplay
   for SGIs to avoid various problems. 
 o Problem in SELECT's coming over Gopher -- %0D's at end of lines
   don't get clipped out -- testcase 
   gopher://gopher.saintjoe.edu/0/search/archieplex.html -- fixed. 
 o Fixed glitch with PostScript code. 
 o Made small change to FTP code to cooperate with various FTP
   servers better (testcase here). 
 o Fixed coredump when pressing Reset button in form with password
   entry field. 
 o Fixed socket leaking problems in FTP, WAIS, and beyond -- sockets
   should never again be leaked by Mosaic; if you can confirm this is
   happening, please let us know (and provide evidence, testcase
   sequences, and netstat readouts). 
 o Added recognition of Gopher+ image, sound, and movie types --
   still no guarantee they'll be handled properly, as Gopher+ does typing
   a little differently and we don't provide full support for Gopher+
   anyway. 
 o Fixed problem if temporary local copy of HDF file goes away
   unexpectedly. Also better handling of temporary local files -- 
   however, beware that if you use Mosaic's HDF viewing support, you
   should clean up your temporary directory space on a fairly regular
   basis, as Mosaic does not always know when to clean it up for you
   (for various reasons -- Mosaic should always clean up local copies of
   other types of data files though). 
 o Fixed longstanding security glitch in Gopher support (Marc VH will
   recognize this). 
 o News support tweaked. 
 o More performance enhancements -- go Quantify! 
 o Added some portability fixes. 
 o Lots of little cleanups and fixes. 

Comments and feedback much appreciated -- however, beware: THIS IS
UNSUPPORTED CODE.  If you want stability, get Mosaic 1.2
(ftp.ncsa.uiuc.edu, /Mosaic/xmosaic-binaries and
/Mosaic/xmosaic-source).

Cheers,
Marc

--
Marc Andreessen
Software Development Group
National Center for Supercomputing Applications
marca@ncsa.uiuc.edu (MIME welcomed here)




From lou@vax.ox.ac.uk  Tue Nov  2 10:03:19 1993 +0000
Message-Id: <00974EEF.F5074A38.14175@vax.ox.ac.uk>
Date: Tue, 02 Nov 1993 10:03:19 +0000
From: lou@vax.ox.ac.uk (Lou Burnard)
Subject: navigation

No browser currently supports parent-child-sibling type navigation,
because HTML doesn't make it easy to support such structures. HTML+, with
its containerized paragraphs and hierarchic sections, is a great leap
forward in that direction, so I hope very much that this kind of
facility will soon start to appear. When you're implementing it chaps,
please don't forget that it would be useful to say not just 'get me the
nth child' but 'get me the nth child which is a FOO',. For example:
- go to the next child <changed> tag
- go to the <H1> of which this paragraph (somewhere inside a H4) is the
  direct descendant
- go to the next <h2> inside this <H1>

Lou B





From hoesel@chem.rug.nl  Tue Nov  2 14:43:02 1993 +0100 (MET)
Message-Id: <9311021343.AA02170@Xtreme>
Date: Tue, 2 Nov 1993 14:43:02 +0100 (MET)
From: hoesel@chem.rug.nl (frans van hoesel)
Subject: pre 7 does not compile

Hi marc,

the new prerelease has a minor problem which shows up during compilation on
a SGI machine:
        cc -g      -I.. -I../libXmx -I../libwww-2.09a -c globalhist.c
accom: Error: globalhist.c, line 749: Type mismatch in prototypes,   pointer to const  void  versus   pointer to pointer to struct
            sizeof (cached_cd_array[0]), mo_sort_cd_for_qsort);
       ------------------------------------------------------^

I'm sending this to www-talk as well, so you don't get a lot of these mail
messages.

ps. why don't you use -lc_s on a sgi machine, you do use all the other
shared libraries? Or perhaps you do use it, but it is not in the makefile.

- frans





From terry@ora.com  Tue Nov  2 07:01:59 1993 PST
Message-Id: <199311021501.AA22963@rock.west.ora.com>
Date: Tue, 2 Nov 1993 07:01:59 PST
From: terry@ora.com (Terry Allen)
Subject: Please Tables in HTML+

I can do just about everything I need to in HTML for the 
documents I'm currently trying to put up, except for tables.
PRE is a poor substitute for proper tables, and Table is
the biggest advance HTML+ offers me over HTML.  

I agree we could defer much of what's in the current draft,
but please let's keep Tables in.  I wish they'd go away,
but they won't.

Marc A deprecates underlining and the HTMLPLUS tag.  Underlining
is essential for representing edited or modified text; browsers
simply need a way to distinguish underlined text from hot 
underlined text.  The HTMLPLUS tag, if the begin tag is made
inomissible, will be a precious indication of what DTD a document
corresponds to.  I really think it should be retained.

Regards,

-- 
Terry Allen  (terry@ora.com)
Editor, Digital Media Group
O'Reilly & Associates, Inc.
Sebastopol, Calif., 95472



From cheung@eplrx7.es.dupont.com  Tue Nov  2 10:15:10 1993 EST
Message-Id: <9311021515.AA10330@eplrx7.es.duPont.com>
Date: Tue, 2 Nov 93 10:15:10 EST
From: cheung@eplrx7.es.dupont.com (Bryan Cheung)
Subject: Proper client interpretation of <pre>blah</pre>

I have noticed some differences in the way that w3 clients interpret the
<pre>blah</pre> clause. It seems that some X,Mac-mosaic, and Cello
ALWAYS insert a newline after <pre>blah</pre>, whereas Lynx does not.
What is the proper behavior?

  I encounter the problem in the scenario described below. I welcome
any and all advice on better HTML techniques -- I am a beginner.

I am trying to set up a table of the form:

   Column1           Column2          Column3
   ===========================================
   Value11           Value12          Value13
   Value21           Value22          Value23
   Value31           Value32          Value33
   ...
   Valuen1           Valuen2          Valuen3
   ===========================================

Generated by

   Column1           Column2          Column3
   ===========================================
   <inc srv "/here/row1.html">
   <inc srv "/there/row2.html">
   ...
   <inc srv "/there/rown.html">
   ===========================================

Where each "rown.html" can be included in multiple tables, and looks like:

   <pre>Valuen1           Valuen2          Valuen3</pre>

and contains *NO* newlines.  Note that many of the ValuenX values may
be hypertext links.

In XMosaic, Mac-mosaic (NCSA), and Cello, the display resulting from
the above setup is:

   Column1           Column2          Column3
   ===========================================
   Value11           Value12          Value13

   Value21           Value22          Value23

   Value31           Value32          Value33

   ...

   Valuen1           Valuen2          Valuen3

   ===========================================

In Lynx I get:

   Column1           Column2          Column3
   ===========================================
   Value11           Value12          Value13
   Value21           Value22          Value23
   Value31 Value32 Value33                     <--strange collapsed white space
   Value41           Value42          Value43
   Value51           Value52          Value53
   ...
   Valuen1           Valuen2          Valuen3
   ===========================================

Any clues or help is greatly apreciated.


                              -- Bryan Cheung
                                 cheung@eplrx7.es.dupont.com





From terry@ora.com  Tue Nov  2 07:53:32 1993 PST
Message-Id: <199311021553.AA29836@rock.west.ora.com>
Date: Tue, 2 Nov 1993 07:53:32 PST
From: terry@ora.com (Terry Allen)
Subject: Re: Please Tables in HTML+

It's simple.  My docs have lots of tables, and tables are common
in other people's docs.  It's a common problem, not to be evaded
on the argument that WWW can't do everything.  

-- 
Terry Allen  (terry@ora.com)
Editor, Digital Media Group
O'Reilly & Associates, Inc.
Sebastopol, Calif., 95472



From cheung@eplrx7.es.dupont.com  Tue Nov  2 11:34:21 1993 EST
Message-Id: <9311021634.AA11351@eplrx7.es.duPont.com>
Date: Tue, 2 Nov 93 11:34:21 EST
From: cheung@eplrx7.es.dupont.com (Bryan Cheung)
Subject: Re: Proper client interpretation of <pre>blah</pre>

Just a quick additional note - TABS are not used in any of the html
files. All spacing within <pre>blah</pre> is done with literal spaces.

                              -- Bryan Cheung
                                 cheung@eplrx7.es.dupont.com





From marca@ncsa.uiuc.edu  Tue Nov  2 10:51:02 1993 -0800
Message-Id: <9311021851.AA04792@wintermute.ncsa.uiuc.edu>
Date: Tue, 2 Nov 93 10:51:02 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Re: Please Tables in HTML+

Terry Allen writes:
> It's simple.  My docs have lots of tables, and tables are common
> in other people's docs.  It's a common problem, not to be evaded
> on the argument that WWW can't do everything.  

Terry, there are *lots* of common problems.  The resources required to
solve them all simply aren't present.  Neither Jim nor I are trying to
torpedo your efforts by suggesting that tables aren't important, but
at the same time I think that "tables are common" isn't a sufficient
standalone argument to justify the complexity they introduce.

Marc




From weber@eit.COM  Tue Nov  2 09:07:22 1993 PST
Message-Id: <9311021707.AA08344@eit.COM>
Date: Tue, 2 Nov 93 09:07:22 PST
From: weber@eit.COM (Jay C. Weber)
Subject: Re: Please Tables in HTML+


Yeah, in my experience tables are the most anticipated feature of
HTML+ implementations, next to forms.

The advent of forms implementations has even stepped up interest in
tables, since people tend to design forms in two dimensions.

Also, a MAJOR upcoming application of Web software is for online catalogs,
where table support is key.

We'd be glad to work on tables in xmosaic, if NCSA is willing to integrate
our code, and before long port to [wm]mosaic.

Jay Weber
EIT



From tom@fatty.law.cornell.edu  Tue Nov  2 12:36:00 1993 -0500 (EST)
Message-Id: <9311021736.AA26473@fatty.law.cornell.edu>
Date: Tue, 2 Nov 1993 12:36:00 -0500 (EST)
From: tom@fatty.law.cornell.edu (Thomas R. Bruce)
Subject: HTML+ discussion doc and Marc's comments

Folks:

If Marc and team are expressing reservations about the sheer size of
the spec and its implementation, imagine my feelings on the subject as
a solo developer.

A  spec of this complexity guarantees one of two things:
that there will be diversity of browsers, with great unevenness of
capabilities among them, or that there will be no diversity of
browsers.  Browser development under HTML as it is _now_ is just this
side of economically unfeasible for all except nationally-funded
operations like NCSA, and I think they may be finding it a bit of a
stretch also.

Browser development under HTML+ as it stands would be effectively
restricted to NCSA if anyone wanted it done in less than a year by
noncommercial developers -- longer if I'm reading Marc's estimate of
cross-platform development time correctly -- and to those others who
could attract the necessary funding.  That's not a pretty prospect in
the dreary Nineties.  

Now, there are obviously those for whom a single Web browser would be
a good thing -- mostly information providers such as ORA who are
constrained to provide technical support for access to their goods;
it's easier to support one cross-platform product than a diverse
population of them.

Obviously I've got some strong and frankly ambivalent feelings about
the matter.  I've got some time and effort in this, and it would be
wrenching to say the least if I came to view the next logical step in
the development of Cello as permanently out of reach. It may also be
that I've just been answering too much support mail lately; I start to
see every communication as meaning, "We want the MOON and we want it
NOW and what's the MATTER with YOU?".  But a bit of realism wouldn't
hurt, and I think Marc's put his finger on it well.

Regards,
Tb.
-- 
+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+
|  Thomas R. Bruce                           trb2@cornell.edu |
|  Research Associate                                         |
|  Cornell Law School                     Voice: 607-255-1221 |
|  Myron Taylor Hall                        FAX: 607-255-7193 |
|  Ithaca, NY 14853                                           |
+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+



From wmperry@strawberry.ucs.indiana.edu  Tue Nov  2 13:55:57 1993 -0500
Message-Id: <15153.752266557@strawberry.ucs.indiana.edu>
Date: Tue, 02 Nov 1993 13:55:57 -0500
From: wmperry@strawberry.ucs.indiana.edu (William M. Perry)
Subject: Re: Please Tables in HTML+ 

In response to your message dated: Tue, 02 Nov 1993 10:51:02 PST
>Terry Allen writes:
>> It's simple.  My docs have lots of tables, and tables are common
>> in other people's docs.  It's a common problem, not to be evaded
>> on the argument that WWW can't do everything.  
>
>Terry, there are *lots* of common problems.  The resources required to
>solve them all simply aren't present.  Neither Jim nor I are trying to
>torpedo your efforts by suggesting that tables aren't important, but
>at the same time I think that "tables are common" isn't a sufficient
>standalone argument to justify the complexity they introduce.

  Hear hear. :) I think tables would be difficult to parse correctly.
Especially when you have links in the <TD> elements.  When do you fill
the paragraphs within them?  I think using a <PRE> segment would work
just as well in 99 out of 100 cases.  And in that 100th case, HTML
isn't going to be the best way to present the document anyway - it
should use postscript or PDF or whatever the latest and greatest full
blown presentation language is at the time.  If we simply must have
tables, how about specifying them a little more at the start?
Something like <TABLE COLS="5" WIDTH="15">, with width being optional,
and defaulting to (Screen Width / COLS)?  And the vertical argument to
TH is going to be a bear.  (Where one headers takes up two vertical
slots)

  When I grabbed the new HTML+ specification and saw all the nice
things in there, I thought 'Hey, this will be great to write it', then
I thought 'God this is going to be a pain to implement'.  Especially
that bit about Math Presentation.  I don't think it would be a good
idea to have the executables bloated by the TeX math code.  People who
want to do math-related documents will be more comfortable with TeX,
and limited by HTML+.  Either an IMG tag to a gif image or a hyperlink
to the dvi file would be better.

   HTML+ is getting too far away from `a light weight delivery format
for browsing and querying [...] HTML+ embodies a pageless model making
it suitable for efficient rendering on a wide range of display types,
for example, VT100 terminals, X11 Workstations [...]`  It will be
almost impossible to do the math markup on a vt100, and seems like it
would be difficult even in Xwindows.  This is akin to the desire for
'sliders' and 'knobs' for forms support - yes, it would be nice, BUT
not everyone could use them.  There are DVI viewers for almost every
system out there, as well as postscript, and eventually PDF (if adobe
doesn't sue too much).

   I for one feel the Xmosaic binary is large enough as it is - I
don't think we need TeX-like math support in it to bloat it anymore.
(Marc - no offense - its Motif's fault :)

   Hope I didn't ramble too much...

   On to another subject from the HTML+ specification - what happened
to the <EM B> tag?  I thought this was better than the <RENDER> hints
that we can put in the documents.  But, if the author is going to have
to put the RENDER attribute in anyway, why wouldn't he just use the
attribute he is saying is equivalent to begin with?  Did something
just get cut & pasted away by accident, or was it excised on purpose?

   -Bill P.




From marca@ncsa.uiuc.edu  Tue Nov  2 15:21:33 1993 -0800
Message-Id: <9311022321.AA05846@wintermute.ncsa.uiuc.edu>
Date: Tue, 2 Nov 93 15:21:33 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: navigation

Lou Burnard writes:
> No browser currently supports parent-child-sibling type navigation,
> because HTML doesn't make it easy to support such structures. 

Actually, no.  They don't support it because it's not very high on the
list of things people are screaming at the browser writers about
(despite its recurring presence on this mailing list, it's not a
showstopper).

Marc




From marca@ncsa.uiuc.edu  Tue Nov  2 17:45:32 1993 -0800
Message-Id: <9311030145.AA06269@wintermute.ncsa.uiuc.edu>
Date: Tue, 2 Nov 93 17:45:32 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: in the news

I thought people on this list might like to see this... "Internet" was
of course Mosaic :-).

Marc

------- Start of forwarded message -------
Following is an article from the Champaign-Urbana "News-Gazette,"
10-27-93, p. B6. 

"Internet" Computer Network Unveiled

By ANNE COOK, News-Gazette Staff Writer

CHAMPAIGN -- Busey Bank Chairman Ed Scharlau today unveiled "Internet"
computer technology that puts the area instantly in touch with the
world.  "We're opening up a new entrance to Champaign Urbana on the
electronic highway," Scharlau told about 1,000 business and academic
leaders at his semi-annual economic seminar at the University of
Illinois Assembly Hall.

"Millions can access it by computer and get impressions about our
cities," he said.  "The railroads opened up the west, and electronic
highways will open up the world to a new frontier. Whole industries
will be destroyed, new ones born and productivity will leap."
University of Illinois supercomputing center director Larry Smarr has
championed the Internet cause locally, and has been joined by leaders
of Champaign County civic organizations who formed an "Infostructure"
committee last year to promote the program.

Internet began as a scientific network linking universities and
research facilities, but it's grown to a system that links 50
countries.  Scharlau said more than 20 million people use the system
and more than 100 million people are likely to do so in five years.
"From your home in a few years you will receive and send your mail,
make a phone or video call, send a fax, read your favorite magazine,
watch a movie," he said. "Kids will do research for school projects,
and they'll have electronic pen pals."  He demonstrated the
possibilities by calling on Ul Chancellor Michael Aiken to call up
from Honolulu Community College reference material about dinosaurs.
     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Lee O'Neill and Mike Henneman, co-chairmen of the Infostructure
Committee, showed off other system capabilities, O'Neill reviewing a
local business directory compiled especially for the occasion and
Henneman renewing his subscription to The News-Gazette electronically.
"This demonstration hopefully helped you understand how Champaign
County can become a 21st century community," Scharlau said. "In turn,
this tremendous new entranceway to our community should attract
innovative 21st century business and create millions of fans for the
county."

He said some indicators suggest the area economy continues to be
healthier than average, citing a study by Restaurant Business that
suggests Champaign-Urbana and Honolulu have more in common than
Internet.

The survey measured people's propensity to eat out. A score greater
than 100 indicated a greater-than-average propensity.
"Champaign-Urbana was the highest of all cities with a score of 204,"
Scharlau said. "Honolulu was next with 196. That's a combination of
having a major university here and tourism and visitors."  Among the
national statistics he cited:

* Inflation rates have averaged 2.5 percent so far in 1993 and are
  expected to average 3.5 percent next year.

* Interest rates for a 30-year Treasury bond that were 7.6 percent a
  year ago are now about 5.9 percent.

Among the local economic projections he made:

* Retail sales are expected to increase only slightly but sales in
  Rantoul and Urbana have held up well and a slump in those two cities
  may have bottomed out in 1992.

* Real estate sales in Champaign County may reach a record $196
  million in 1993 with 1,949 closed deals, but the average selling
  price seems likely to drop from about $77,000 in 1992 to $72,000
  this year.

* Agricultural output seems likely to drop about $1 million from last year.

Scharlau noted that Champaign-Urbana's educational opportunities, as
well as its restaurant activity, received national prominence.  "The
UI's C-U campus was ranked as the best buy in the Midwest by Money
Guide magazine," he said.  "In Money magazine, where C-U was rated 293
out of 300 communities, another article about finances said, send your
kid to the UI. That's one of our best assets."
------- End of forwarded message -------




From dsr@hplb.hpl.hp.com  Wed Nov  3 10:35:43 1993 GMT
Message-Id: <9311031035.AA10363@manuel.hpl.hp.com>
Date: Wed, 3 Nov 93 10:35:43 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: Please Tables in HTML+

Come on guys, parsing tables is really quite easy and is wanted by
lots of people.

Bill P. writes:

> I think tables would be difficult to parse correctly. Especially
> when you have links in the <TD> elements.  When do you fill the
> paragraphs within them?

The pre-pass through the table needs to establish minimum and maximum
width requirements. This is simply a matter of the length of the longest
word, and the total length of the all the words plus spaces. You don't
need to be accurate on the latter, just to deal well with short lines.
The pre-pass can ignore <A> and </A> altogether!

Once you have chosen the column widths, displaying the cell contents is
just like normal, only the left and right margins are set for the current
cell. You display each cell, one at a time, going as far as is needed
(stopping at the bottom of the window or end of the cell which ever is
sooner). VT100 browsers will find it easier if they keep a screen image.

As soon as I get some time free from dealing with email on the HTML+ I-D
and coming with with revisions to the spec, I will get down to revamping my
X Windows browser to cope with tables etc. HTML+ is really quite simple, and
needn't require huge code sizes. The spec seems huge, but this is due to the
need to give plenty of examples. The TEI spec by contrast comes to around one
foot thick of paper!

Math markup is needed, and can be processed without undue complexity.
I included a preliminary proposal as a means to encourage discussion by
mathematicians and other people as to just what is needed and how to
find an elegant balance suitable for the web.

Bill P. also writes:

>   On to another subject from the HTML+ specification - what happened
> to the <EM B> tag?  I thought this was better than the <RENDER> hints
> that we can put in the documents.  But, if the author is going to have
> to put the RENDER attribute in anyway, why wouldn't he just use the
> attribute he is saying is equivalent to begin with?  Did something
> just get cut & pasted away by accident, or was it excised on purpose?

Yes, the generic <EM atts> mechanism was removed on purpose:

    o   I received a lot of flak on this mechanism

    o   HTML+ was repositioned as a superset of HTML to encourage
        evolutionary extensions of browsers

    o   The RENDER mechanism allows you to specify the intended
        rendering once whereas the older EM mechanism needed the
        same hints to be repeated time and time again

    o   The new approach provides a possible path for future
        extensions with richer rendering hints if desired

Dave Raggett (sporting a brand new flak jacket :)



From dsr@hplb.hpl.hp.com  Wed Nov  3 14:40:48 1993 GMT
Message-Id: <9311031440.AA13952@manuel.hpl.hp.com>
Date: Wed, 3 Nov 93 14:40:48 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: Please Tables in HTML+

Terry Allen writes:

> Dave, would you be willing to cut down the present HTML+ DTD,
> call the smaller version HTML+, and save the present HTML+ DTD
> as HTML++ (or HTML3, or something)?  so long as there's a spec,
> that's all I want.

I propose we define the compliance of browsers with HTML+ in terms
of a sequence of levels:

    Level 0     Plain old HTML with HR and BR etc.

    Level 1     Level 0 + new presentation tags, e.g. strikethru

    Level 2     Level 1 + new paragraph and list styles, e.g. <note>

    Level 3     Level 2 + fill-out forms and figures <IMAGE> and <FIG>

    Level 4     Level 3 + tables, and support for standard LINKs

    Level 5     Level 4 + math

This takes the pressure off browser writers and gives them staged goals.
Documents could indicate their level in the HTMLPLUS element. We can argue
precisely what is and what isn't in each level on www-talk. I will then
document this in a revision to the HTML+ Internet Draft.

Dave Raggett




From dsr@hplb.hpl.hp.com  Wed Nov  3 14:59:03 1993 GMT
Message-Id: <9311031459.AA13965@manuel.hpl.hp.com>
Date: Wed, 3 Nov 93 14:59:03 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: Second draft of HTML+ now available

I have tweaked the postscript version of the new HTML+ discussion
document which should now (fingers crossed) come out ok on Letter
and A4 paper sizes.

        ftp://15.254.100.100/pub/draft-raggett-www-html-00.ps

The plain text version is now available:

        ftp://15.254.100.100/pub/draft-raggett-www-html-00.txt

The DTD is also available on its own:

        ftp://15.254.100.100/pub/htmlplus.dtd.txt

The first two have now been submitted to the IETF for circulation.

New versions of the discussion document will have names like

        draft-raggett-www-html-01.ps and -02.ps, -03.ps etc.

Dave Raggett



From henrich@crh.cl.msu.edu  Wed Nov  3 10:19:53 1993 -0500 (EST)
Message-Id: <9311031519.AA16227@crh.cl.msu.edu>
Date: Wed, 3 Nov 1993 10:19:53 -0500 (EST)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: Re: Please Tables in HTML+

> I propose we define the compliance of browsers with HTML+ in terms
> of a sequence of levels:
>
> This takes the pressure off browser writers and gives them staged goals.
> Documents could indicate their level in the HTMLPLUS element. We can argue
> precisely what is and what isn't in each level on www-talk. I will then
> document this in a revision to the HTML+ Internet Draft.

Thats a good idea, I second the motion.

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                      http://rs560.msu.edu/~henrich



From wade@cs.utk.edu  Wed Nov  3 10:46:52 1993 -0500
Message-Id: <9311031546.AA18608@galoob.cs.utk.edu>
Date: Wed, 03 Nov 1993 10:46:52 -0500
From: wade@cs.utk.edu (Reed Wade)
Subject: Re: Please Tables in HTML+ 


>I propose we define the compliance of browsers with HTML+ in terms
>of a sequence of levels:
>
>    Level 0     Plain old HTML with HR and BR etc.

[ stuff deleted ]

>    Level 5     Level 4 + math
>
>This takes the pressure off browser writers and gives them staged goals.
>Documents could indicate their level in the HTMLPLUS element. We can argue
>precisely what is and what isn't in each level on www-talk. I will then
>document this in a revision to the HTML+ Internet Draft.

I'm all for identifying functional differences in browsers for sanity's
sake. It would be a big win for everybody.

Actually tho, I'd prefer somthing a little more discontinuous. Math
is very important for our browser, tables less so. Math support will
likely be the first thing I add from html+. (Unless Math wont work
correctly without the other levels of functionality.)

Would it be reasonable to describe sets of functionality rather than
levels?

Reed Wade
wade@cs.utk.edu




From dsr@hplb.hpl.hp.com  Wed Nov  3 16:11:00 1993 GMT
Message-Id: <9311031611.AA14208@manuel.hpl.hp.com>
Date: Wed, 3 Nov 93 16:11:00 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: HTML+ Form and Submit

Charles Henrich writes:

> Okay Ive thought about it awhile, and also based on what others have
> suggested I think we should add a SUBMIT option to the input tag, as well as
> a &submit= to the form query.  For example, if you have 2 images on screen,
> and you want a click on only one of them to cause a submit, or an entry in a
> text field to cause a submit it would look like:

> <input name="image1" type=image src="image1.gif">
> <input name="image2" type=image src="image2.gif" SUBMIT>
> <input name="text" SUBMIT>

Well, this was my original suggestion, but it would cause problems:

    o   users confused by unexpected and slow network access

    o   just how should browsers decide when to submit for
        text and numeric fields (easy for radio buttons)?

The explicit submit button avoids these issues. A possible middle course
is to add a simple constraint language for forms, but this will have to
wait until we have more experience ...

Dave



From dsr@hplb.hpl.hp.com  Wed Nov  3 16:20:23 1993 GMT
Message-Id: <9311031620.AA14220@manuel.hpl.hp.com>
Date: Wed, 3 Nov 93 16:20:23 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: Second draft of HTML+ now available

Josh Osborne comments:

> Speaking of migration paths, if we could define "subsets" of HTML+ and
> MIME types for them we could phase-in HTML+ by providing HTML & HTML+
> pages for things and letting the HTTP server & client decide which to
> fetch...

Sounds good to me. We could use a parameter on the content type, e.g.

        Content-Type: text/html; level=2

Where level=0 (the default) is plain old HTML.

Thanks for the other comments. I will fix things up for the next revision
to the discussion document.

Dave



From henrich@crh.cl.msu.edu  Wed Nov  3 11:16:48 1993 -0500 (EST)
Message-Id: <9311031616.AA16458@crh.cl.msu.edu>
Date: Wed, 3 Nov 1993 11:16:48 -0500 (EST)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: Re: HTML+ Form and Submit

>     o   users confused by unexpected and slow network access

Thats *not* a valid issue.  If the form writer creates a stupid form, so be it,
but we need the rope.  Like in C, make plenty of rope for the author to hang
themselves, but it also gives the author great flexibility in doing innovative
things.

>     o   just how should browsers decide when to submit for
>         text and numeric fields (easy for radio buttons)?

Good question, my gut reaction is when the press return it submits.

> The explicit submit button avoids these issues. A possible middle course
> is to add a simple constraint language for forms, but this will have to
> wait until we have more experience ...

We cant get more experience until we have the options :)

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                      http://rs560.msu.edu/~henrich



From hotsand!rhb  Wed Nov  3 11:38:37 1993 EST
Message-Id: <9311031638.AA27137@hotsand.dacsand>
Date: Wed, 3 Nov 93 11:38:37 EST
From: hotsand!rhb (Rich Brandwein)
Subject: Re: in the news


Check out the front page on today's New York Times business section.
They talk about NCSA/WWW and the MTV server among other things...

Rich



From timbl@www3.cern.ch  Wed Nov  3 17:50:23 1993 +0100
Message-Id: <9311031650.AA02001@www3.cern.ch>
Date: Wed, 3 Nov 93 17:50:23 +0100
From: timbl@www3.cern.ch (Tim Berners-Lee)
Subject: First URI meeting notes


Simon Spero suggested I post a summary of the URI working
group discussion to these lists.

This is mostly going to be about how and why things are not being  
agreed. I was not physically at the meeting but was watching
and listening and occasionally interrupting over the MBONE.

Comments in [square brackets] are mine.
-------------------------------------------------------------

Eric Huizer started (as IESG member and one of the 3 Area Directors
related to the URI work) by giving suggetions. These were basically

a. Very important spec for future: should not make sacrifices for
  current installed base.
b. URL document is almost not quite at consensus.
c. URN is not but should not hold up URL
d. Consensus is not achieved with a vote, chairs must get it somehow,
   on the net, not necessarily in the meeting room.
e. Chairs should prevent newcomer questions from slowing progress.
f. IESG needs a Functional Specification to explain what the
   URL spec should do  so that they have something to hold it up
   against. Without that
  Eric as AD would stop it consensus or no.
 

 [I wondered whether (e) could be applied to (f)  ;-)) ]


Alan Emtage explained that a bar-bof of 5-6 people had a consistent
view of what Eric's document should say, viz:-

URLs	1. Pointers for dereferencing
	2. Transient
	3. machine consumable
	4. transport-friendly
	
URLs	Location independent
	Persistent
	Human Transcribable
	Transport friendly
	Machine consumable

URCs	Identification, metainfo.
	HUMAN consumable and also machine consumable.
	Transport friendly
	URL & URN caching.

[if 4 points is a functional spec]

John Kunze was a member of the group, which was only trying to
figure out how to make progress.  The group introduced a new field.
[seriously, they did.].  This was a URL spec version number
to be quoted in each URL, like

	url:1:ftp://info.cern.ch/pub


 The group needed now to "define the entire UR* area,
including describing resolution services which they would come
up with." [This worried me]

Marshal Rose as IESG member wondered who string up, with a WG
taking 18 months on a 12 page document.  He has something
funny on the backof his Tshirt which wasn't multicast.

Larry Masinter pointed out that 1. above wasn't a god definition, as
you can't really be rdereference a telnet: or mailto: URL.
[Agree. Better to talk about object model, with retrieval
not being the only possible action on an object]

There was a lot of discussion of terms. There was a lot of
voting by making noise, some of which I attempted to
join in with over the net.

Steve Putz [intelligently] pointed out that URLs could be
defined as those name spaces which are defined by a direct
mappoing onto protocols.  Cliff Lynch confusingly
suggested that URLs should be as indendent of protocol
as possible. [I hope he meant URN in which case I agree]

Dave Crocker asked that the group consider three real problem  
scenarios.  [This to me emphasises that IETF ancients and
newcomers were in the same boat in that they needed the scene
setting and the foundations of what wee are talking about defined.]

Larry compared URLs to MIME external body parts and noted  
differences.

At this point it became more difficult to take notes and I stopped.
By the end of the meeting, Jim Fulton had volunteered to write
a requirements spec for the URL document.

[Now I am going to put down some of this functional spec myself.
Watch this space.]

Tim




From timbl@www3.cern.ch  Wed Nov  3 18:04:28 1993 +0100
Message-Id: <9311031704.AA02012@www3.cern.ch>
Date: Wed, 3 Nov 93 18:04:28 +0100
From: timbl@www3.cern.ch (Tim Berners-Lee)
Subject: What URIs are and are not.



Let me put down the *original* functional spec for URIs.
I fear that some people have gotten away from the original
requirement, and wanted to start designing things.

Listen good if you are a newcomer to the list or on the
IESG ;-)

There are many protocols on the net which imply a data model
which can be mapped onto some concept of "objects" and
addresses/names/identifiers/locators for those objects.

 Examples:	Protocol	Objects
		FTP		Directories
				Files
		SMTP		mail addresses
				mail messages
		NNTP		newsgroups
				articles
		HTTP		objects
		Gopher		menus
				documents
		DNS		hosts
				Mail eXchanges
		...

There will be many more future examples.

The characteristics of the objects and the properties of the
names.addresses/identifiers/locators vary and are defined by:-

	a. The protocol specification
	b. The way the protocol is actually used
	c. The conventions which are used by people
	
 (Example:  a.The FTP RFC implies that a directory object may contain  
files,
 in defining that NLST on a directory returns a list of files.
 b.The protocol is in fact often used using only A and I
 modes, and with the user/pass pair being "anonymous" and
 a mail address.  c. A convention is that ftp.x.x.x host names
 are not changed very often, but can change
  Hence the properties of 

 	ftp://info.cern.ch/pub/www
 are that it contains files, maybe listed by anonymous
 ftp to info.cern.ch, the files may change, but lifetimes
 will be of the order of year for directories.)
 

 There is for each protocol an implicit name/address/identifier
 space for the n/a/i s in th implicit data model.

I am trying to get across the great variety of schemes.

What you can do with an address/name/identifier depends also
on who and where you are and what facilities you have.  So
it is difficult to define.  (This is why I don't feel that the
URL/URN taxonomy debate has given us much).

HOWEVER, it is still extremely useful to have the concept of
the universal set of all identifier/name/addresses in all
schemes.
It is also useful to have a syntax for writing down the value

One cannot deny that it is useful, because WWW *uses* it.  This
is *not* to say that the WWW installed base prevents any bugs
in the URL spec from being fixed, but it is an existence proof
of the need.

The syntax for the universal set was called, in WWW, the URI
syntax, for Universal Resource Identifier.  The WG changed
"Universal" to "Uniform", but in doing so lost the important
significance of the Universality: that fact that, if you create
a name space, whatever its properties, I can give it a name
and map its syntax into acceptable UDI syntax.

Note that attepmts to make URIs a subset of another
name space are of couse possible but pointless by
definition.

The URI working group pointed out very sensibly that a
system of more persistent names was necessary.

Unfortunately, and this was the *big mistake*, we then
set about a taxonomy of all name spaces, to divide them into
URLs (of which they had several) and URNs (of which they used
none as no lookup method existed), and worse, to extend the
taxonomy to new schemes not yet invented,

I had hoped that a distributed persistwent name lookup
service would arise, but it didn't.  What did happen was
that great world-designing started and never finished.

Anyway, all existing schems have been called URLs, and
URN is a reserved name.

Since, there have been long discussion about, for example, whether
a news article id is a URL or a URN.  The IIIR community is trying
to retrofit a top-down design onto all existing systems. This
is foolish because

	1.	If you retrofit a design onto existing practice
		to make it clean you have to lie about existing
		practice.
	
	2.	To do a top-down design in this area won't work.
		We have to progress by a sequence of brilliant
		independent ideas.
		
	3.	If you manage to categorize all the existing schemes
		into a taxonomy you will only end up restricting the
		future dschemes into yoru current mind set.

What SHOULD we be doing?  Valid things to define and, therefore,
argue over are:

	1.	Interpretation of the implicit data model.
		For example, my interpretaion of the FTP model
		was that you browse directories, and the filenames
		are the names, and the files the addresses.
		The data type is guessed from the filename.
		This was my laying of a formal model onto the FTP
		protocol which didn't dedfine one.
		Others take the view that one doesn't browse a
		directory, one gets an address from a mail message,
		and there is information th the filename (etc)
		to tell you which transfer type to use.
		
		Obviously both are valid mappings, we need to chose
		and maybe use both.
		
	2.	Design of new data models. This is valid for HTTP
		and for URNs.
		
	3.	The mapping of names in the model onto a concrete
		string syntax. Malinly a question aof character sets,
		and settled, thank you.
		
The URL document talked about "requirements" on names
and addresses in different schemes. That was a mistake. It should
have talked about "characteristics" of names in different models.
We can only document these characteristics for current protocols,
we can't define them.  What we can do though is invent new schemes,
and in particular the fabled URN scheme.
Discussion of the relative merits of characteristics is
outside the bounds of the URL document.

In summary, the URL document

	- defines a Universal syntax for ANY past or future
	  names/addresses/identifiers

	- defines a spoecific mapping of name spaces
	  implicit in existing protocols into URI space.

The URIs defined for existing protocols are known as URLs
and they have the property that they map directly onto a
single protocol in each case.

If the URI WG wants to define something other than URIs
as defined above (and I hope in the document) then they
should first decide what to do with URIs.

Tim Berners-Lee
CERN




From dsr@hplb.hpl.hp.com  Wed Nov  3 17:36:22 1993 GMT
Message-Id: <9311031736.AA14430@manuel.hpl.hp.com>
Date: Wed, 3 Nov 93 17:36:22 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: Please Tables in HTML+

> I'm all for identifying functional differences in browsers for sanity's
> sake. It would be a big win for everybody.

Yes, I feel this is getting quite urgent.

> Actually tho, I'd prefer somthing a little more discontinuous. Math
> is very important for our browser, tables less so. Math support will
> likely be the first thing I add from html+. (Unless Math wont work
> correctly without the other levels of functionality.)

The math stuff needs superscripts and subscripts but little else.

> Would it be reasonable to describe sets of functionality rather than levels?

What would you suggest?

Perhaps we should start by surveying coverage on current browsers.

Dave Raggett



From timbl@www3.cern.ch  Wed Nov  3 18:42:46 1993 +0100
Message-Id: <9311031742.AA02351@www3.cern.ch>
Date: Wed, 3 Nov 93 18:42:46 +0100
From: timbl@www3.cern.ch (Tim Berners-Lee)
Subject: URN: criticism, point and protocol.



I have one criticism of the current URN document,
one philosophical note and one
suggestion for an implementation of a real DNS scheme.
_____________________________________________________
Fit the first

The criticism is that the hierarchical design is 

essentially (fiddley bits omitted)

	<hierarchical authority> : <opaque string>
	
This looks nice but could be better.  Let's assume for
now that the hierarchical authority has some divider like /
so we could have something like

 IANA / EDU / MIT / LCS / AMANDA : UHFGUHDWPUDEHESYSTSHKJS
	
but more likely it would be more like (internally in fact)

 IANA / EDU /MIT / LCS / AMANDA : NOTES / 1993 / JAN / GRUNDGE4
	
Now I am concerened that one might want to move the colon
around,. In fact I'll give the game away by telling you that
I am going to propose that the / and the : be merged.  But
I haven't yet, so read on.

Looking atthe above example, can you really determine
where you would want to define a "naming authority"
and where an "opaque string"?  Should MIT, or MIT/LCS,
or MIT/LCS/AMANDA* be the naming authority?
What happens when LCS splits into 126 parts, which
group into 6 subdivisions, all of which want to be
a naming authority? And then collapses back into one?

So much for the problem. The answer is clear. Look
at domain names. In particular, look at MX records
and mail addresses. Suppsoe (which I don't)
I have a mail address of

	timbl@as.cn.cern.ch

You can't tell and don't want to know where the MX record
is -- is the authority cern.ch or cn.cern.ch? It doesn't
matter and it can change. 


Look at what Carl and  Marshall have done with DNS and phone numbers
to see the flexibility which this gives.

So,

I propose that the / and the : be merged into one
form of visible hierarchical structure.

There. I proposed it, as I promoised.  I submit that
otherwise the URN scheme imposes too much structure and will  
overconstrain future implementations -- in short, it will be broken.

We end up with a URN being (in essence, fiddly bits omitted)
	peices	::	void
		|	piece delimiter pieces
just like everything else.

	
__________________________________________________
Fit the second.

What protocol should we DEFINE to implement URNs?

None.  Any URN name space which is linked to one protocol
is broken, and is more of a URL.
___________________________________________________
Fit the third
How we could implement one real protocol to actually try it out?

Use DNS for the top level of the hierarchy using the MX record
kludge. (That is, that you can ask for appropriate MX
records for a given DNS name even if the DNS name does not exist
in the hierarchy).

One possibility is to add an IX record. This I am told
would mean recompiling all DNS.  It would be nice because
it would allow the existing domians to contain information just
like they contain mail addresses and hosts.

The second possibility is actually to use MX records in
a separate tree, like to find document

	aaa1.notes.sept.timbl.as.cn.cern.ch

you would look for an MX record for

	aaa1.notes.sept.timbl.as.cn.cern.ch.ix

This is actually doable experimentally now.

What you would get back would be a bunch of [I|M]X
record pointing to whois++ or http or z39.99
servers which would handle what you want.

In time, recommmendations could be made as to the protocols
to be used, whwreas during experimentation more than one
protocol could be used.

If an MX record is returned with a URI for a resolution
service whose URL scheme you don't recognise, you
don't crash, you just ignore it, mitra.

Note:

	1.	There is nothing to stop someone making
		a better protocol than the IX method, and
		nothing to stop both running together,
		and nothing to stop one being
		later decided on by the market or the
		IESG. And nothing to stop a transition scheme
		to a new better one later in 2056.

	2.	The same applies to the second level retrieval
		protocol, defined by the URL in the IX
		record.
		
	3.	The naming authority need not correspond
		to the same level in the tree as the IX record --
		the management and allocation of names are
		independent functions. As someone said recently.
		
(Much though it is convenient to have just one protocol,
it is essential to be *able* to have two.  At each level.)

Will someone please implement this?   :-)
Whatddya think?

	Tim Berners-Lee
	CERN


____________________________________________________________
*Parts of the name are all ficticious and any resemblance
to any person organization, domain, byte etc alive or dead is  
entirely coincidental.




From kevinh@pulua.hcc.hawaii.edu  Wed Nov  3 10:25:54 1993 HST
Message-Id: <9311032025.AA10184@pulua.hcc.Hawaii.Edu>
Date: Wed, 3 Nov 93 10:25:54 HST
From: kevinh@pulua.hcc.hawaii.edu (Kevin 'Kev' Hughes)
Subject: Announcing getsites 1.4, a Web log analyzer


	*getsites* is a small C program that will produce detailed, concise,
weekly, or daily reports from your Web server. Here's the details:

	* Works with CERN, NCSA, Plexus, and gn log files.
	* All reports are in the same consistent format.
	* All reports include server name and type, GMT and local date,
          total requests last 7 days, unique hosts last 7 days,
	  total unique hosts, number of HTML and non-HTML requests,
          and total number of requests.
	* Detailed report includes IP addresses and host name,
          number of host requests, and last access date.
	* Weekly and daily reports are in vertical bar-chart format,
	  with number of requests for each week or day.
	* You can choose to ignore numerical addresses beginning with
          a certain string.
	* getsites can take standard input, so you can pipe stuff to it.
	* getsites can use a previous full getsites report to lookup
          addresses both ways (this really speeds things up).

	You can find out more at:

http://pulua.hcc.hawaii.edu/files/getsites.html

	Or just grab the source at:

http://pulua.hcc.hawaii.edu/files/getsites.14.c

	Enjoy!

	-- Kevin

--
Kevin Hughes
kevinh@pulua.hcc.hawaii.edu
Honolulu Community College WWW site maintainer



From dduchier@csi.uottawa.ca  Wed Nov  3 19:52:39 1993 -0500
Message-Id: <9311040052.AA17630@csi.UOttawa.CA>
Date: Wed, 3 Nov 93 19:52:39 -0500
From: dduchier@csi.uottawa.ca (Denys Duchier)
Subject: HTML+, tables, math, lists

I use HTML and xmosaic as a delivery mechanism for lecture notes and I
should like to encourage developers not to give up too soon on some of
the fancier bits in the HTML+ proposal.

1. I dearly miss tables.  I'd rather have a less ambitious table
   mechanism than none at all.  For example, I could easily do without
   the "row spanning" capability; I would be happy to supply the width
   of a text cell (or column) in, say, em units; etc...

2. I am desperate for some simple math capability, e.g. subscripts,
   superscripts, fractions, sums, ... I wish more symbols were made
   available, e.g. math symbols and greek letters; also `prime' -- I
   really miss that one a lot.

3. I _really_need_ control over the labeling of items in a list.  The
   HTML+ proposal suggests that LI should have a SRC attribute.  While
   this is a good idea, in the vast majority of cases, I simply want
   to supply a string to use as the label (e.g. "2b.i").  Could we
   please give LI an N attribute wich could be used to specify an
   explicit label, e.g. <LI N="2b.i">.  [I think TEI also suggests a
   LABEL element that can serve as an alternative way of specifying an
   item's label].

--Denys



From kevinh@pulua.hcc.hawaii.edu  Wed Nov  3 15:51:42 1993 HST
Message-Id: <9311040151.AA18202@pulua.hcc.Hawaii.Edu>
Date: Wed, 3 Nov 93 15:51:42 HST
From: kevinh@pulua.hcc.hawaii.edu (Kevin 'Kev' Hughes)
Subject: Re:  in the news

> and they'll have electronic pen pals."  He demonstrated the
> possibilities by calling on Ul Chancellor Michael Aiken to call up
> from Honolulu Community College reference material about dinosaurs.
>      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

	Weird, I never thought it would be used at an economic seminar...?

	-- Kevin

--
Kevin Hughes
kevinh@pulua.hcc.hawaii.edu
Honolulu Community College WWW site maintainer



From kevinh@pulua.hcc.hawaii.edu  Wed Nov  3 16:03:58 1993 HST
Message-Id: <9311040203.AA18490@pulua.hcc.Hawaii.Edu>
Date: Wed, 3 Nov 93 16:03:58 HST
From: kevinh@pulua.hcc.hawaii.edu (Kevin 'Kev' Hughes)
Subject: Announcing getsites 1.5, a Web log analyzer

> 	*getsites* is a small C program that will produce detailed, concise,
> weekly, or daily reports from your Web server. Here's the details...

	Version 1.5 fixes a Plexus parsing problem and has one or two
minor tweaks (thought I would fix them right away). You can get it from:

http://pulua.hcc.hawaii.edu/files/getsites.15.c

	Enjoy!

	-- Kevin

--
Kevin Hughes
kevinh@pulua.hcc.hawaii.edu
Honolulu Community College WWW site maintainer



From kurlanda@informatik.uni-frankfurt.de  Thu Nov  4 11:11:08 1993 MEZ
Message-Id: <9311041011.AA27362@hysteria.rbi.informatik.uni-frankfurt.de>
Date: Thu, 4 Nov 93 11:11:08 MEZ
From: kurlanda@informatik.uni-frankfurt.de (kurlanda@informatik.uni-frankfurt.de)
Subject: WWW based Library Catalog

Hello,

we are trying to put the catalog of our institutes library on our WWW-Server.
This is not only a service to our students or institute members, but
would increase the acceptance of our WWW-server as the main electronic
information media by a large amount.

Here is my question:
Putting the titles, and later the fact if the book is lent or not,
from the librarians software to ascii and then into the
html-format is easy enough. The question is how to part the mass of
data into reasonable pieces and indexing it, so
that our students can retrieve the status of a particular book or
the titles of some papers matching a searchpattern. Do you know of an
existing solution for such a problem? It would be nice of you to mail
me an address or tip. Thank you in advance.

-- 
Jens Kurlanda 	  (Raum:014b)			J.W.Goethe Universitaet Frakfurt
Tel:069 798 8378				Robert-Mayer-Strasse 11-15
Email: kurlanda@rbi.informatik.uni-frankfurt.de D-60549 Frankfurt (Germany)

			



From luotonen@ptsun00.cern.ch  Thu Nov  4 11:37:37 1993 +0100
Message-Id: <9311041037.AA13286@ptsun03.cern.ch>
Date: Thu, 4 Nov 93 11:37:37 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: CERN httpd 2.13 and libwww 2.13 released


CERN-httpd 2.13 and libwww 2.13 released.

	*****************************************************
	**                                                 **
	**          Everybody using CERN-httpd:            **
	**                                                 **
	**             IT IS TIME TO UPGRADE!              **
	**                                                 **
	*****************************************************

ftp://info.cern.ch/pub/www/src/*_2.13.tar.Z

httpd 2.13:
	* Server Script support (/htbin-URLs); compatible with
	  that of NCSA's (including redirection), but
	    - no need for scripts to translate escaped
	      special characters
	    - full AA support for scripts as any documents
	    - scripts can seem to have a "directory structure"
	* all known AA bugs fixed:
	    - broken fail rule
	    - setuid() looks up nobody correctly; and
	      doesn't refuse to run even if it fails
	* other additions:
	    - full filename suffix recognition (e.g. fixes
	      "cannot convert application/octet-stream to
	       www/present" with inlined .xbm images),
	      defaults are always used, and can be overridden
	      from the rule file
	    - understands Accept: */*
	    - more tolerant of bad requests
	    - checks that the third argument in HTTP1 request
	      is really "HTTP/1.0" and not just garbage (bad
	      HTTP0 request)

libwww 2.13:
	* single HTPromptUsernameAndPassword() to enable
	  a single authentication dialog box in GUIs
	* fix: connection not opened before authentication
	  information prompted

--
Ari Luotonen		 |
World-Wide Web Project	 |
CERN			 | phone: +41 22 767 8583
CH - 1211 Geneve 23	 | email: luotonen@dxcern.cern.ch



From W.vanLeeuwen@nikhef.nl  Thu Nov  4 12:38:37 1993 +0100
Message-Id: <9311041138.MA27961@nikhefh.nikhef.nl>
Date: Thu, 4 Nov 1993 12:38:37 +0100
From: W.vanLeeuwen@nikhef.nl (Willem van Leeuwen)
Subject: Re: WWW based Library Catalog

You may try the NIKHEF solution.

URL: http://www.nikhef.nl/www/pub/default/library.html

Mail me if you want more details.

Best regards,

Willem van Leeuwen



From bert@let.rug.nl  Thu Nov  4 17:04:29 1993 +0100 (MET)
Message-Id: <9311041604.AA04186@freya.let.rug.nl>
Date: Thu, 4 Nov 1993 17:04:29 +0100 (MET)
From: bert@let.rug.nl (Bert Bos)
Subject: HTML+ -- dropping & adding features

The discussion on HTML+ seems to concentrate on which elements to
remove and which to add. There are three main arguments:

1) a large spec would be very difficult to implement
2) elements once added cannot be removed again
3) HTML is for presentation only, not for writing or archiving

(1) and (2) are valid reasons for being careful, and for taking the
development one step at a time. However, (1) has to be addressed
someday, because eventually we want to add more features, don't we?

(3) Is a stance that appeals to me, but it leaves a few questions. If
HTML is for presentation, what does one use for writing and storing
documents?

In fact, I've been writing docs in a superset of HTML+, and converting
them to plain HTML+ afterwards.  This allows using all the facilities
of SGML, such as shortrefs, shorttags, entities, and subdocs, while
keeping the hypertext version simple. The richer source doc can also
be used for other things, such as converting to LaTeX. My `authoring
system,' if it deserves the name, consists of just Emacs, sgmls, and
make.

Could this be the solution? Maybe. But not until there are more
authoring tools available. And it postpones solutions for non-latin
alphabets (like Dave's ISOcyr1 example) to some time in the future.

In more detail, what are the things people want to drop or add?

Drop:
a) Anchor attributes TYPE, SIZE & METHODS (handled by the
   protocol instead?) TITLE & PRINT also have limited use.
b) Conditional text. seems to introduce as many problems as it solves.
c) INDEX attributes. No function in browser. See (3) and comments above.
d) Several LINK REL types. `Guided tours' (Previous & Next) cannot be
   specified in the docs. A doc could be part of several tours! 
e) Document type subset (the top part that looks like <!DOCTYPE
   HTMLPLUS [...]>). Not needed if entities, subdocs, etc. are left out.
f) Text flow around images. Maybe just keep the special case of an
   image at the very start of a P?
g) In spite of Terry Allen's comments, I'm still of the opinion that a
   DIRectory across the page is different from a bulleted list. The
   latter is meant to be read, the former is for reference only. But
   anyway some redundant items can be dropped from the spec.
h) Q. The quote is useful for writers, but little is lost when the
   hypertext contains explicit `'.
i) WRAP attribute seems unnecessary in view of LIT
j) SEETHRU. Still too unsettled, Maybe we should wait until we have a
   better idea of what we want or don't want in the way of inline
   image display (alpha-channels? rotatable 3D?, inlined movies?)
k) L seems to be covered sufficiently by LIT, BR (for layout) and P
   (for the ID attribute).
l) `Quote by name' suggestion. Let's stick to simple hyperlinks for
   the moment. If needed we can let the server deal with it.
m) NEXTID. Might be useful for authoring, but is meaningless to the
   browser.
n) CITE, PERSON & ABBREV. Just like Q and INDEX= it is good to have
   something like this when writing, but for presentation literal
   parentheses resp. nothing might be good enough.

Don't drop:
a) HEAD and BODY. They allow the HEAD or the BODY to be retrieved
   independently, using simple SGML tools. They don't have to be in
   the doc, as long as they are in the DTD.
b) TABLES. They can't be too hard to implement, can they? Would it be
   easier without the ROWSPAN?
c) SUB & SUP. If only to keep people from using ugly IMGs instead.

To drop or not to drop?
a) U. As Marc Andreesen said, underlining is often used for indicating
   links. On the other hand, it is a common decoration in
   typewriter-style text.
b) LANG attributes. Can influence hyphenation, layout, quoting (`' ""
   ,,'' <<>>), font-selection (e.g., smaller caps for German), and
   probably other things. Do we need that yet?
c) MH. What are the arguments pro & can for this?
d) MATH. I would love to have this, but it might be a burden on the
   implementors.
e) `Document clusters' (LINK REL types such as UseIndex, Contents,
   UseGlossary, Bookmark, Parent) change the way the Web is viewed: no
   longer a flat system, but hierarchical collections of typed docs.

Add:
a) A LABEL attribute on the LI element, to override the default bullet
   with some text (as suggested by Terry Allen)



Bert
-- 
                     _________________________________
                    / _   Bert Bos <bert@let.rug.nl>  |
           ()       |/ \  Alfa-informatica,           |
            \       |\_/  Rijksuniversiteit Groningen |
             \_____/|     Postbus 716                 |
                    |     9700 AS GRONINGEN           |
                    |     Nederland                   |
                    \_________________________________|



From W.vanLeeuwen@nikhef.nl  Thu Nov  4 17:12:08 1993 +0100
Message-Id: <9311041612.RA13584@nikhefh.nikhef.nl>
Date: Thu, 4 Nov 1993 17:12:08 +0100
From: W.vanLeeuwen@nikhef.nl (Willem van Leeuwen)
Subject: WWW based library

The very first draft of a description how the NIKHEF WWW based library
server works can be found at URL:

	http://www.nikhef.nl/www/pub/default/doc/www_based_library.html

Please keep asking if the information is not good enough.

NOTE: The latest and greatest prereleases of Xmosaic cause trouble to our
      server, which is a rather old version of the CERN httpd.
      You may use the production version of Xmosaic or the linemode browser.

Best regards,

Willem van Leeuwen



From timbl@www3.cern.ch  Thu Nov  4 17:34:41 1993 +0100
Message-Id: <9311041634.AA05009@www3.cern.ch>
Date: Thu, 4 Nov 93 17:34:41 +0100
From: timbl@www3.cern.ch (Tim Berners-Lee)
Subject: Web and Mail integration: a few key connections.


There are currently two worlds in the IETF which ought to collide:
the multimedia information access world, epitomized by the WWW
architecture, and the RFC822+MIME world of mail.  Sorry about the
hastily scribbled nature of this note about tying it all together.
I send it to the entire IETF list because there has been
criticism in the past that ideas have not been aired widely enough.

 	Background
 	==========
	
The Web is the world of information accessible instantly on request.
WWW uses Uniform Resource Identifiers (URIs, see URL ID) to unify  
many protocols, but it
also has its own protocol (HHTP, ID coming out) which
has features needed for a clean and complete system.

URIs are sometimes divided into URLs (Locators) which
refer to the use of a particular protocol for aceess,
and URNs (names) which don't.  Lots of URLs are defined,
no URNs.

RFC822 is basic Internet mail, and MIME describes how
multimedia can be represented for mail.

HTTP is a request/response stateless internet-style
protocol, which transmits objects around as MIME
messages (except allowing binary transport).

HTTP has a bunch of headers for metainformation
in addition to the MIME ones. These are "URC" information
in terminology of the URI working group.

WWW defines one (soon two) SGML document types
for sending around basic hypertext (+graphics).
The first, "HTML", explicitly uses URIs of other
objects in hypertext links. (See HTML ID)

There has been some discussion recently about how to
send SGML documents along with DTDs and oetr things
which they reference in MIME messages. (see SGML-MIME ID).
SGML documents refer to external entities
as either "PUBLIC", in which case a special "Formal
Public Identifier" (FPI) space is used and everyone
is supposed o know what's in it, or "SYSTEM" in which
case the significance is purely local.

	Proposals
	=========
	
My suggestions for tying this all togther are:

1. In an Internet context, the SGML "SYSTEM" identifiers
   should be conventionally URIs.  As there are URIs
   which refer to a local file system, this does not
   rule out refering to local files too.

2. The FPI space should be registered as a URN.

3. Some space inside FPI space should be found for
   the URN tree as well.
 

4.  For the case of mail transport, both message-id values
   (identifeirs of mail messages) and content-ids
   (identifiers of parts of a multpart MIME message)
    should be registered as URNs.  They will of course
    only be dereferencable by people who have been
    sent the relevant mail, but that is fine.
    

    Now we have URI schemes
    

    	fpi:
	cid:
	mid:

5.  The convention is adopted that when a multipart/related
    document is sent, that the first part is consuleted for
    information about the relationships.
    

    HTML allows links to be made and also allows
    the relationships to be given between parts.
    

6.   The metainformation headers in HTTP should be
    adopted as the URC format for the URI working group,
    with suitable discussion and additions. 

    

    This will allow, using the Link: header which
    is isomorphous to the HTML <LINK> element,
    relationships to be defined between non-HTML
    pars of a MIME multipart/related document.

7.   HTTP should be specified to include support
     for MIME multipart/related, to solve the problem
     of servers which like to send a document with all
     its included graphics in one respone.
     

     Acceptance of multipart/related could be made
     mandatory or subject to the
     		Accept: multipart/related
     header in the HTTP request.


I think that's everything.


	References for working documents and discussion lists:
	==========
	
URI, URL:
 ftp://ftp.internic.net/internet-drafts/draft-ietf-uri-url-01.ps
 mailto:uri-request@bunyip.com

HTML:
 ftp://ftp.internic.net/internet-drafts/draft-ietf-iiir-html-01.ps
 mailto:www-talk-request@info.cern.ch

HTTP:
  ftp://info.cern.ch/pub/www/doc/http-spec.ps
  mailto:www-talk-request@info.cern.ch

SGML-MIME:
  ftp://ftp.internic.net/internet-drafts/draft-ietf-mime-sgml-00.txt 

  mailto: ietf-822-request@dimacs.rutgers.edu

All .ps postscript files have plainascii .txt equivalents.
All documents may be retrieved by URL by sending a message
with a line "send " followed by the URL to robot@info.cern.ch

Please send comments to specific lists only where you can!

Tim Berners-Lee
CERN



From henrich@crh.cl.msu.edu  Thu Nov  4 13:23:42 1993 -0500 (EST)
Message-Id: <9311041823.AA19687@crh.cl.msu.edu>
Date: Thu, 4 Nov 1993 13:23:42 -0500 (EST)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: Forms submission

Ack, I *really* *really* want to be able to submit on multiple field entries.
For example, im trying to build a form for my interactive weather map (for
which now you entry a semi-cryptic "isindex" query).  There are two basic
options, Show a station report, or show a surface map or both.  However, if the
user is requesting show a surface map, they have to fill out a bunch more
information.  I dont want to have to have a full page of "fill this out only if
your are requesting the surface map".  It'd be SO much nicer that when they
click on the "Show surface map" radio button, the form re-appears, this time
with all the additional information that is needed.

Who do I have to appease to get this?  What offerings to the gods must I
make? :)

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                      http://rs560.msu.edu/~henrich



From marc@library.ucsf.edu  Thu Nov  4 10:56:07 1993 -0800
Message-Id: <199311041856.AA26036@library.ucsf.edu>
Date: Thu, 4 Nov 1993 10:56:07 -0800
From: marc@library.ucsf.edu (Marc Salomon)
Subject: Forms submission - buttons

Hello-

First off, I would like to give an accolade to the ncsa team for their fine work
on forms.  Good job.

From what I gather from the documentation, there is a single ACTION associated
with each FORM.  This means that every <INPUT TYPE="SUBMIT"> button, no matter
what it's label, does the same thing.  We need to add some method of 
determining, in the case where we have multiple <INPUT TYPE="SUBMIT"> buttons,
how did I get here?  Joel Richardson mentioned this in his message of 10 Oct,
but that was before 2.0.5.

Would it be possible to include an attribute to the <INPUT TYPE="SUBMIT"> tag
that would encode the value of the button in the URL that would still be 
built by <FORM ACTION={URL prefix}>?

The way it is now:

<input type="reset" VALUE="CLEAR">
<input type="submit" VALUE="SEARCH">
<input type="submit" VALUE="DEFINE">
<input type="submit" VALUE="REFINE">
<input type="submit" VALUE="BROWSE"> 

Hitting each type="submit" button does the same thing.  The VALUE does not get
encoded into the URL.

I would like to see something akin to:

<input type="reset" VALUE="CLEAR">
<input type="submit" name="search" VALUE="SEARCH">
<input type="submit" name="define" VALUE="DEFINE">
<input type="submit" name="refine" VALUE="REFINE">
<input type="submit" name="browse" VALUE="BROWSE"> 

with an URL encoding scheme some variant of:

action+submit_name?name=value&name=value . . .

-marc
marc@ckm.ucsf.edu
//////////////////////////////////////////////////////////////////////////////
// Marc Salomon                                  e-mail: marc@ckm.ucsf.edu  \\ 
\\ Software Engineer                                                        //
// Innovative Software Systems Group             phone:  415.476.9541       \\
\\ UCSF Center for Knowledge Management                                     //
// 530 Parnassus SF, CA 94134-0840               fax:    415.476.4653       \\
\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\



From marca@ncsa.uiuc.edu  Thu Nov  4 13:39:00 1993 -0800
Message-Id: <9311042139.AA13246@wintermute.ncsa.uiuc.edu>
Date: Thu, 4 Nov 93 13:39:00 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Forms submission

Charles Henrich writes:
> Ack, I *really* *really* want to be able to submit on multiple field
> entries.  For example, im trying to build a form for my interactive
> weather map (for which now you entry a semi-cryptic "isindex"
> query).  There are two basic options, Show a station report, or show
> a surface map or both.  However, if the user is requesting show a
> surface map, they have to fill out a bunch more information.  I dont
> want to have to have a full page of "fill this out only if your are
> requesting the surface map".  It'd be SO much nicer that when they
> click on the "Show surface map" radio button, the form re-appears,
> this time with all the additional information that is needed.
> 
> Who do I have to appease to get this?  What offerings to the gods
> must I make? :)

For now, go with either the "fill this out only if you want the
surface map" or separate forms, and we'll revisit it in a couple of
months... we really need to stabilize the first cut now, and get some
stable software out there.

Cheers,
Marc




From robm@ncsa.uiuc.edu  Thu Nov  4 17:09:56 1993 -0600
Message-Id: <9311042309.AA24458@void.ncsa.uiuc.edu>
Date: Thu, 4 Nov 1993 17:09:56 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CERN httpd 2.13 and libwww 2.13 released

/*
 * CERN httpd 2.13 and libwww 2.13 released  by Ari Luotonen (luotonen@ptsun00.cern.ch)
 *    written on Nov  4, 11:37am.
 *

[...]

 * httpd 2.13:
 * 	* Server Script support (/htbin-URLs); compatible with
 * 	  that of NCSA's (including redirection), but
 * 	    - no need for scripts to translate escaped
 * 	      special characters

Is this considered a feature? If you look, ours does an unescape_url and a
plus_to_space on the args before they're sent. The problem is that a lot of
scripts end up re-assembling what the server sent them. In addition to that,
if a script has an argument that is an & but encoded as %xx, and the server
decodes it and sends it to the script, the form decoding scripts will become
hosed.

So, the next release of NCSA httpd will not do any decoding of the
arguments, and will send them all as argv[1], and support programs and code
will be provided for scripts to do this themselves. That way, forms scripts
can split on & instead of +, et al.

 * 	    - full AA support for scripts as any documents
 * 	    - scripts can seem to have a "directory structure"
 */


--Rob



From montulli@stat1.cc.ukans.edu  Thu Nov  4 17:54:19 1993 CST
Message-Id: <9311042354.AA35711@stat1.cc.ukans.edu>
Date: Thu, 4 Nov 93 17:54:19 CST
From: montulli@stat1.cc.ukans.edu (Lou Montulli)
Subject: Lynx 2.0.12 now available!

Lynx Ver. 2.0.12 is now available for anonymous ftp from
 FTP2.cc.ukans.edu    as   /pub/lynx/lynx2-0-12.tar.Z

( ftp://ftp2.cc.ukans.edu/pub/lynx/lynx2-0-12.tar.Z )

Lynx is a distributed hypertext browser with full World Wide Web
and Gopher capibilities.  For an explanation of features and a demo, 
telnet to "kufacts.cc.ukans.edu" and login as "www".

This release of Lynx has been compiled by me on the following platforms:

 o  IBM (AIX 3.2)
 o  DEC Ultrix
 o  DEC Alpha OSF/1
 o  Sun 4
 o  NeXT (Mine is an older version of NeXTStep, but it should work 
          with newer ones too.)
 o  VMS (Multinet)

This release is rumored to compile on the following platforms:
 o  HP-UX (snake)
 o  Solaris 2
 o  SVR4
 o  VMS (UCX)
 o  LINUX
 o  SGI 
 o  SUN 3
 o  AIX 3.1
 o  NeXTStep 3.x

Binaries for the following platforms are available:

 o  IBM (AIX 3.2, will work with 3.1 as well)
 o  Ultrix
 o  Alpha OSF/1
 o  Sun 4
 o  VMS (Multinet)
 
A listserv list has been created for the distribution of
Lynx related information and updates.
  o  Lynx-Dev@ukanaix.cc.ukans.edu
 
Send a subscribe request to listserv@ukanaix.cc.ukans.edu to
be added to the list.  All new releases will be anounced on this
list.  Please do not send subscribe requests to the the Lynx-Dev
list directly.

    The following new features have been added:

* added preliminary level 1 forms support.
  (Parsing and user display works, but nothing else)
  I'm looking for input on the forms interface!
* interuptable I/O added.  Hit the 'a' key for "abort" during
  transfers.  Its a little flakey right now during connections,
  but it works most of the time :)  
* local HTML documents ending in .html can now be referenced with
  just a filename and/or path from the command line.
* Added preloaded searches to gopher URL's.  They previously
  didn't work.  This is readily apparent as preloaded CSO
  searches, which alot of people wanted. (bug?)
* added descriptive subject lines to files mailed from lynx
* added "X-within-URL" mail header line to specify which
  URL from which files, comments, and mailto links are sent from.
* The user's specified editor is now spawned for mail messages.
  If no editor is defined or if the user is anonymous, the built-in 
  lynx mail sender is used.
* added progress messages to all transfers.
* added -cache=# command line option to specify the number
  of WWW documents cached in memory.
* added VMS port fixes from Foteos Macrides.  Lynx now
  compiles and works on VMS! (bug?)
* Moved many configuration options including printer setup to 
  lynx.cfg file.  The default placement of the lynx.cfg file
  will be /usr/local/lib & sys$public.  Printers can now be
  configured without recompiling!
* Removed STARTDIR variable from userdefs.h  STARTDIR is now inferred
  from the STARTFILE. (doesn't effect HTML files)
* Ported to SVR4 courtesy of Nickolay Saukh (from Russia, Wow this is
  really getting around!) 
* Uneditable documents don't get refetched. (Nickolay Saukh)
* National language support through LOCALE
  (instead of ISOLATIN1), protected by #ifdef LOCALE (Nickolay Saukh)


   A partial list of bugs that have been fixed

* disabled FTP connection caching to help fix multiple FTP problems
* fixed a bunch of gopher holes
* gopher lists are turned into URL's now instead of lynx
  internal format document links
* removed old hytelnet compatibility code which looked in
  multiple directories to find the correct file.  If you still
  need this capibility talk to me.
* changed all static data structures to be dynamic
  This was a pretty major change of code which may add several
  bugs. :)
* rewrote parse_links routine to make it more efficient and to
  work with dynamic structures.
* added VMS port fixes from Foteos Macrides.  Lynx now
  compiles and works on VMS!
* fixed ftp bug in WWWlib that didn't de-escape URL's before
  sending request to FTP server.
* fixed coredump bug for some files with no links.
* Fixed bug with only one link selectable out of many on the last line
  of the display.

:lou
-- 
  **************************************************************************
  *           T H E   U N I V E R S I T Y   O F   K A N S A S              *
  *         Lou  MONTULLI @ Ukanaix.cc.ukans.edu                           *
  *                         Kuhub.cc.ukans.edu      ACS Computing Services *
  *     913/864-0436        Ukanvax.bitnet             Lawrence, KS 66044  *
  *             UNIX! Cool! I know that!  Jurassic Park - The Movie        *
  **************************************************************************



From marca@ncsa.uiuc.edu  Thu Nov  4 19:57:43 1993 -0800
Message-Id: <9311050357.AA14769@wintermute.ncsa.uiuc.edu>
Date: Thu, 4 Nov 93 19:57:43 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: continuing solaris networking problems

2.0 prerelease 7 has source-level fixes for the problems many people
saw in pre6 in the network connection code (the new interruptible I/O
code) on Solaris and other SVR4 systems.

HOWEVER, if you run a stock pre7 Sun binary (e.g. the ones we
distribute) on a Solaris system, you will not see the effect of the
fixes, since the stock Sun binaries are naturally not compiled with
SVR4 defined and therefore the fixes don't have any effect.

So, a few questions and comments...

(a) Can someone try compiling pre7 under Solaris and let us know if
    it's working OK?
(b) Is Sun shipping Motif with Solaris yet?  (I guess 2.2 is the
    latest that's out there...)  If not, when's it going to start?
(c) Any suggestions on how we should handle this for the 2.0 release
    next week?  We don't have a spare Sun to run Solaris on and have
    no desire whatsoever to run Solaris on any of our in-use Suns (it
    would be impossible).

Cheers,
Marc




From robm@ncsa.uiuc.edu  Fri Nov  5 04:30:00 1993 -0600
Message-Id: <9311051030.AA04490@void.ncsa.uiuc.edu>
Date: Fri, 5 Nov 1993 04:30:00 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CERN httpd 2.13 and libwww 2.13 released

/*
 * Re: CERN httpd 2.13 and libwww 2.13 released  by Charles Henrich (henrich@crh.cl.msu.edu)
 *    written on Nov  4,  7:59pm.
 *
 * > Is this considered a feature? If you look, ours does an unescape_url and
 * > a plus_to_space on the args before they're sent. The problem is that a
 * > lot of

Actually, what I wrote above is wrong. The server only does plus-to-space
conversion.

 * Yes, wish NCSA's server did it too! :)
 */

Such a setup makes it impossible to implement forms which have ampersands in
their value or name fields.

--Rob



From len.hatfield@vt.edu  Fri Nov  5 11:40:11 1993 -0500
Message-Id: <9311051636.AA25691@dxmint.cern.ch>
Date: Fri, 5 Nov 1993 11:40:11 -0500
From: len.hatfield@vt.edu (Len Hatfield)
Subject: serial client for WWW?

Folks:

        This is probably a dumb question, but here goes: is there any way
to get to a WWW server from a serially connected Macintosh?  I'm giving a
demonstration of tools of interest to faculty in the humanities at a remote
college; I'm told they have only a serial network connecting their Macs to
a central server, which in turn probably has telnet capabilities to the
rest of the Internet.  Suggestions would be welcome. 

                                                                           
    ...Len 





From peveritt@pandora.ncts.navy.mil  Fri Nov  5 08:56:59 1993 +0600
Message-Id: <9311051456.AA00958@voltaire.ncts.navy.mil>
Date: Fri, 5 Nov 1993 08:56:59 +0600
From: peveritt@pandora.ncts.navy.mil (Paul Everitt)
Subject: Re: continuing solaris networking problems


> From: marca@ncsa.uiuc.edu (Marc Andreessen)
> To: www-talk@nxoc01.cern.ch
> Cc: ebina@ncsa.uiuc.edu
> Subject: continuing solaris networking problems
> 
> 2.0 prerelease 7 has source-level fixes for the problems many people
> saw in pre6 in the network connection code (the new interruptible I/O
> code) on Solaris and other SVR4 systems.
> 
> HOWEVER, if you run a stock pre7 Sun binary (e.g. the ones we
> distribute) on a Solaris system, you will not see the effect of the
> fixes, since the stock Sun binaries are naturally not compiled with
> SVR4 defined and therefore the fixes don't have any effect.
> 

Yes, true, true.

> So, a few questions and comments...
> 
> (a) Can someone try compiling pre7 under Solaris and let us know if
>     it's working OK?

There is someone out there that has been keeping currentbinaries  with 
the prereleases, although I will not drop the name to protect the 
innocent :-)

> (b) Is Sun shipping Motif with Solaris yet?  (I guess 2.2 is the
>     latest that's out there...)  If not, when's it going to start?

No Motif with Solaris 2.3 (released from Sun Micro on Nov 3).  Solaris
2.4 (spring) is the schedule.

> (c) Any suggestions on how we should handle this for the 2.0 release
>     next week?  We don't have a spare Sun to run Solaris on and have
>     no desire whatsoever to run Solaris on any of our in-use Suns (it
>     would be impossible).
> 
> Cheers,
> Marc
> 
> 



From tom@fatty.law.cornell.edu  Fri Nov  5 13:52:49 1993 -0500 (EST)
Message-Id: <9311051852.AA15440@fatty.law.cornell.edu>
Date: Fri, 5 Nov 1993 13:52:49 -0500 (EST)
From: tom@fatty.law.cornell.edu (Thomas R. Bruce)
Subject: Oh, yes, one other thing...

Cellists:

I neglected to mention a quasi-new-feature in the release
announcement.  It may break a lot, but let's see if it does...

Cello now incorporates a "peek mode", which is intended to deal with
the ever-growing problem of Gopher Bloat -- 1 zillion K files placed
on Gopher servers by people who don't know better.  If you hold down
the CTRL key while clicking on a Gopher or HTTP link, only the first 4
K of the file will be retrieved and shown.  You can then use
File/Reload document to get the full version if it proves interesting.

This makes no attempt to deal with things like incomplete anchors or
selector strings, so it may have some interesting effects... we'll
make it sophisticated later.

Tb.
-- 
+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+
|  Thomas R. Bruce                           trb2@cornell.edu |
|  Research Associate                                         |
|  Cornell Law School                     Voice: 607-255-1221 |
|  Myron Taylor Hall                        FAX: 607-255-7193 |
|  Ithaca, NY 14853                                           |
+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+



From terry@ora.com  Fri Nov  5 16:45:30 1993 PST
Message-Id: <199311060045.AA04697@rock.west.ora.com>
Date: Fri, 5 Nov 1993 16:45:30 PST
From: terry@ora.com (Terry Allen)
Subject: SP or emsp

One of the items in the HTML+ spec that would really help WWW typographers
is the SP element, which might alternately be specified as ISO 8879
Publishing Entities &emsp;.  Do browser developers have any preference
on this point, and would this em-space element or entity be easy
to implement?

Dave, did you intend something different by SP than &emsp; or &ensp;?

As an example of where it would be useful, I'd like to remove the 
dashes in the top-level TOC of the online Whole Internet Catalog,
which are there now to get some separation between the in-line hotlinks
(design suggestions welcome).

Regards,

-- 
Terry Allen  (terry@ora.com)
Editor, Digital Media Group
O'Reilly & Associates, Inc.
Sebastopol, Calif., 95472



From totic@milton.cs.uiuc.edu  Fri Nov  5 19:33:40 1993 CST
Message-Id: <199311060133.AA08044@milton.cs.uiuc.edu>
Date: Fri, 5 Nov 93 19:33:40 CST
From: totic@milton.cs.uiuc.edu (Aleksandar Totic)
Subject: Re: serial client for WWW?

>         This is probably a dumb question, but here goes: is there any way
> to get to a WWW server from a serially connected Macintosh?  I'm giving a
> demonstration of tools of interest to faculty in the humanities at a remote
> college; I'm told they have only a serial network connecting their Macs to
> a central server, which in turn probably has telnet capabilities to the
> rest of the Internet.  Suggestions would be welcome. 

I do not know of a way, without using SLIP, or ARA. We are toying with
the idea of porting 'term', a UNIX utility, but have not looked into
it in any detail. Volunteers?

Aleks
-- 
Aleksandar Totic      - lead MacMosaic programmer -        atotic@ncsa.uiuc.edu
Software Development Group      National Center for Supercomputing Applications



From kevinh@pulua.hcc.hawaii.edu  Fri Nov  5 17:41:54 1993 HST
Message-Id: <9311060341.AA09738@pulua.hcc.Hawaii.Edu>
Date: Fri, 5 Nov 93 17:41:54 HST
From: kevinh@pulua.hcc.hawaii.edu (Kevin 'Kev' Hughes)
Subject: getsites 1.6 is out


        *getsites* is a small C program that will produce detailed, concise,
weekly, or daily reports from your Web server. Here's the details:

        * Works with CERN, NCSA, Plexus, and GN log files.
        * All reports are in the same consistent format.
        * All reports include server name and type, GMT and local date,
          total requests last 7 days, unique hosts last 7 days,
          total unique hosts, number of HTML and non-HTML requests,
          total number of requests, and date coverage.
        * Detailed report includes IP addresses and host name,
          number of host requests, and last access date.
        * Weekly and daily reports are in vertical bar-chart format,
          with number of requests for each week or day.
        * You can choose to ignore numerical addresses beginning with
          a certain string.
        * getsites can take standard input, so you can pipe stuff to it.
        * getsites can use a previous full getsites report to lookup
          addresses both ways (this really speeds things up).

	Problems of getsites hanging or spewing out megabytes of endless junk
(sorry about that) should be fixed, along with the major #include file
related problems! System-V specific time functions have been removed and
rewritten in ANSI C, so hopefully you'll be able to compile this
thing just about anywhere.
	An great improvement in speed has been made, particularly for those
analyzing logs with lots of host names. GN users can specify (in a #define)
whether they want to log Gopher as well as HTML accesses.
	Triple thanks to those who contributed patches and suggestions,
who know who you are.

        You can find out more at:

http://pulua.hcc.hawaii.edu/files/getsites.html

        Or just grab the source at:

http://pulua.hcc.hawaii.edu/files/getsites.16.c

        Enjoy!

        -- Kevin

--
Kevin Hughes
kevinh@pulua.hcc.hawaii.edu
Honolulu Community College WWW site maintainer



From montulli@stat1.cc.ukans.edu  Fri Nov  5 22:12:12 1993 CST
Message-Id: <9311060412.AA28969@stat1.cc.ukans.edu>
Date: Fri, 5 Nov 93 22:12:12 CST
From: montulli@stat1.cc.ukans.edu (Lou Montulli)
Subject: Re: SP or emsp

> 
> One of the items in the HTML+ spec that would really help WWW typographers
> is the SP element, which might alternately be specified as ISO 8879
> Publishing Entities &emsp;.  Do browser developers have any preference
> on this point, and would this em-space element or entity be easy
> to implement?
> 
> Dave, did you intend something different by SP than &emsp; or &ensp;?
> 
> As an example of where it would be useful, I'd like to remove the 
> dashes in the top-level TOC of the online Whole Internet Catalog,
> which are there now to get some separation between the in-line hotlinks
> (design suggestions welcome).
> 
I had thought we were going to have &emsp and &ensp.  But I
don't really care since I will be implementing them the same :)

:lou
-- 
  **************************************************************************
  *           T H E   U N I V E R S I T Y   O F   K A N S A S              *
  *         Lou  MONTULLI @ Ukanaix.cc.ukans.edu                           *
  *                         Kuhub.cc.ukans.edu      ACS Computing Services *
  *     913/864-0436        Ukanvax.bitnet             Lawrence, KS 66044  *
  *             UNIX! Cool! I know that!  Jurassic Park - The Movie        *
  **************************************************************************



From Gisle.Aas@nr.no  Sat Nov  6 15:41:02 1993 +0100
Message-Id: <9311061441.AA10292@holt>
Date: Sat, 6 Nov 93 15:41:02 +0100
From: Gisle.Aas@nr.no (Gisle.Aas@nr.no)
Subject: suffix.pl and other utilities for Plexus

This is some of the utilities that I use with the Plexus 3.0j server.
You might also want to take a look at:

   http://www.nr.no/demo/gateways.html.


-------------------------------------------------------------------
#!/bin/sh
# This is a shell archive (produced by shar 3.49)
# To extract the files from this archive, save it to a file, remove
# everything above the "!/bin/sh" line above, and type "sh file_name".
#
# made 11/06/1993 13:42 UTC by aas@holt
# Source directory /nr/holt/u3/aas/HTTP
#
# existing files will NOT be overwritten unless -c is specified
#
# This shar contains:
# length  mode       name
# ------ ---------- ------------------------------------------
#   2702 -rw-r--r-- suffix.pl
#    849 -rw-r--r-- sh.pl
#    795 -rw-r--r-- inc.pl
#   1374 -rw-r--r-- nr-access.pl
#    114 -rw-r--r-- nr-access.conf
#
# ============= suffix.pl ==============
if test -f 'suffix.pl' -a X"$1" != X"-c"; then
	echo 'x - skipping suffix.pl (File already exists)'
else
echo 'x - extracting suffix.pl (Text)'
sed 's/^X//' << 'SHAR_EOF' > 'suffix.pl' &&
# suffix.pl
#
# $Id: suffix.pl,v 1.5 1993/11/06 13:41:30 aas Exp $
#
# Author: Gisle Aas, Norsk Regnesentral, Oslo
#
# This package enables the server to return different version of a
# document depending on the domain where the client is. We use this
# package for serving Norwegian sites with Norwegian replies while all
# other sites get replies in English.
#
# When activated this package reads the file "domain.suffix" where it
# expects to find a mapping from various domain names to suffixes that
# the files should have. For instance a domain.suffix file that looks
# like this:
#
#    .nr.no		nynorsk
#    .no		bokmaal
#    .se		swedish
#
# And an HTTP client that runs on nora.nr.no and asks for
# http:/gisle.html makes the server return the first that exist
# of the following documents:
#
#     gisle.nynorsk.html
#     gisle.bokmaal.html
#     gisle.html
X
X
package suffix;
X
$configFile = "/local/www/etc/domain.suffix";
&parseConfig;
X
sub do {
X    local($path,$query) = @_;
X    # query is not used
X    &do("index.html",$query) unless length $path;
X    -d $path && &main'error('forbidden',
X		          "You are not allowed to read direcotries like \"$path\"");
X    local($af, $port, $inetaddr) = unpack($main'sockaddr, $main'peeraddr);
X    local($name) = &main'hostname($inetaddr);
X
X    local($suffix) = &findSuffix($name);
X    local($file) = &retrieve($path, $suffix);
X    
X    &main'error('internal_error', "This should not happen, $name!");
}
X
X
sub retrieve {
X    local($p, $suf) = @_;
X    local($s, $f);
X
X    local($dir, $file);
X    local($i) = rindex($p, '/');
X    $dir = substr($p, 0, $i);
X    $dir = "." unless length $dir;
X    $file = substr($p, $i + 1);
X
X    for $s (split(":", $suf)) {
X	$f = $dir . "/" . &makeFilename($file, $s);
X	if (-f $f) { &main'retrieve($f); exit }
X        #print "Can't locate '$f'<p>\n";
X    }
X    &main'retrieve($path);
X    exit;
}
X
sub makeFilename
{
X    local($file, $ekstra) = @_;
X    $file .= ".$ekstra" unless $file =~ s/\.([^.]+$)/.$ekstra.$1/;
X    return $file;
}
X
sub parseConfig
{
X    local($x, $y);
X    open(C, $configFile) || return;
X    while (<C>) {
X	s/#.*//; # remove comments
X	s/^\s+//;
X	s/\s+$//;
X	next if /^$/;
X	($x, $y) = split(" ", $_);
X	$x =~ s/^\.//;
X	$y =~ s/^\.//;
X	$y =~ s/://g;
X	$domSuffix{$x} = $y;
X	#print "Domain $x prefeers suffix $y<p>\n";
X    }
X    close(C);
}
X
sub findSuffix
{
X    local($n, $dom, $nn, $suffix);
X    $nn = $_[0];
X
X    $dom = "";
X    for $n (reverse split(/\./, $nn)) {
X	$dom = ".$dom" if length $dom;
X	$dom = "$n$dom";
X	if (defined $domSuffix{$dom}) {
X	    $suffix = ":$suffix" if length $suffix;
X	    $suffix = "$domSuffix{$dom}$suffix"
X	    }
X	#print "$dom, $suffix<p>";
X    }
X    return $suffix;
}
1;
SHAR_EOF
chmod 0644 suffix.pl ||
echo 'restore of suffix.pl failed'
Wc_c="`wc -c < 'suffix.pl'`"
test 2702 -eq "$Wc_c" ||
	echo 'suffix.pl: original size 2702, current size' "$Wc_c"
fi
# ============= sh.pl ==============
if test -f 'sh.pl' -a X"$1" != X"-c"; then
	echo 'x - skipping sh.pl (File already exists)'
else
echo 'x - extracting sh.pl (Text)'
sed 's/^X//' << 'SHAR_EOF' > 'sh.pl' &&
# $Id: sh.pl,v 1.1 1993/11/06 13:27:10 aas Exp $
X
# This package is used for starting local applications by clicking on
# hypertext links.  Just make a link to /sh/script or /sh?command and
# a document that is feed to the shell is returned.  Put the following
# line in the .mailcap file:
#
#     application/x-sh; sh -f %s
#
# Author: Gisle Aas, Norsk Regnesentral, Oslo
X
X
package sh;
X
sub do
{
X    local($rest, $query) = @_;
X    
X    if (-f "sh/$rest") {
X	&main'MIME_header('ok', 'application/x-sh');
X        &main'raw_file("sh/$rest");
X        return;
X    }
X    if ($rest eq "" && $query ne "") {
X	&main'MIME_header('ok', 'application/x-sh');
X        $query =~ s/\+/ /g;
X        $query =~ s/%([\da-f][\da-f])/sprintf("%c",hex($1))/egi;
X        print "$query\n";
X        return;       
X    }
X    &main'error('not_found', "No script found")
}
X
1;
SHAR_EOF
chmod 0644 sh.pl ||
echo 'restore of sh.pl failed'
Wc_c="`wc -c < 'sh.pl'`"
test 849 -eq "$Wc_c" ||
	echo 'sh.pl: original size 849, current size' "$Wc_c"
fi
# ============= inc.pl ==============
if test -f 'inc.pl' -a X"$1" != X"-c"; then
	echo 'x - skipping inc.pl (File already exists)'
else
echo 'x - extracting inc.pl (Text)'
sed 's/^X//' << 'SHAR_EOF' > 'inc.pl' &&
# inc.pl - inplements the <inc cmd="cmd"> tag for hacked-html text
#
# $Id: inc.pl,v 1.1 1993/11/06 13:36:11 aas Exp $
#
# Autor: Gisle Aas, Norsk Regnesentral, Oslo
X
package inc;
X
&init;
sub init
{
X    $main'ext{'hacked-html'} = 'text/hacked-html';
X    $main'trans{'text/hacked-html'} = "text/html:inc'html";
}
X
sub html
{
X    # this is a translation filter
X    while (<STDIN>) {
X	s/<inc\s+([^>]*)>/&inc($1)/ige;
X	print;
X    }
}
X
sub inc
{
X    local($_) = $_[0];
X    return scalar(`$1`)                      if /^cmd="([^"]+)"/i;
X    return "<pre>\n".scalar(`$1`)."</pre>\n" if /^precmd="([^"]+)"/i;
X    return eval "$1"                         if /^perl="([^"]+)"/i;
X    return scalar(`cat $1`)                  if /^file="([^"]+)"/i;
X    return "<em>&lt;inc $1&gt; not understood</em>";
}
1;
SHAR_EOF
chmod 0644 inc.pl ||
echo 'restore of inc.pl failed'
Wc_c="`wc -c < 'inc.pl'`"
test 795 -eq "$Wc_c" ||
	echo 'inc.pl: original size 795, current size' "$Wc_c"
fi
# ============= nr-access.pl ==============
if test -f 'nr-access.pl' -a X"$1" != X"-c"; then
	echo 'x - skipping nr-access.pl (File already exists)'
else
echo 'x - extracting nr-access.pl (Text)'
sed 's/^X//' << 'SHAR_EOF' > 'nr-access.pl' &&
#
# access-filter.pl -- Disallow access to certain paths
#
# access-filter.pl,v 1.3 1993/10/05 20:50:29 sanders Exp
#
# by Tony Sanders <sanders@bsdi.com>, Oct 1993
# extended (and renamed) by Gisle Aas <aas@nr.no>, Oct 1993
#
# Read a configuration file and disallow certain paths/domain combinations
# Requires configuration.
X
sub access {
X    local($fromfd, $peeraddr, $action, $path, $version) = @_;
X    local($af, $port, $inetaddr) = unpack($main'sockaddr, $peeraddr);
X    local($host) = &main'hostname($inetaddr);
X
X    local($line, $op, $path_pat, $domain_pat);
X    foreach $line (@access_filter'lines) {
X       ($op, $path_pat, $domain_pat) = split(' ', $line);
X       if (($path =~ $path_pat) && ($host =~ $domain_pat)) {
X          &main'error('forbidden', "$action $path invalid") if $op eq "DENY";
X          last;
X       }
X    }
}
X
package access_filter;
X
&access_filter'config($main'plexus{'nr-access-config'});
X
sub config {
X    &main'debug("config $_[0]");
X    local($config) = shift || die "access-filter: no config file\n";
X    local($path,$domain);
X    @lines = ();
X    &main'open("access_filter'CONFIG", $config) || die "$config: $!";
X    while (<CONFIG>) {
X        if (/^\s*(ALLOW|DENY)\s+\/?(\S+)\s*(\S*)/) {
X	    $path = &main'globpat($2);
X            $domain = &main'globpat($3);
X	    push(@lines, "$1 $path $domain");
X	}
X    }
X    close(CONFIG);
}
X
1;
SHAR_EOF
chmod 0644 nr-access.pl ||
echo 'restore of nr-access.pl failed'
Wc_c="`wc -c < 'nr-access.pl'`"
test 1374 -eq "$Wc_c" ||
	echo 'nr-access.pl: original size 1374, current size' "$Wc_c"
fi
# ============= nr-access.conf ==============
if test -f 'nr-access.conf' -a X"$1" != X"-c"; then
	echo 'x - skipping nr-access.conf (File already exists)'
else
echo 'x - extracting nr-access.conf (Text)'
sed 's/^X//' << 'SHAR_EOF' > 'nr-access.conf' &&
# OP	PATH		DOMAIN
X
ALLOW	/private*	*.nr.no
DENY	/private*	*
X
DENY 	/hidden*	*
X
ALLOW	/op2*		*.nr.no
DENY	/op2*		*
SHAR_EOF
chmod 0644 nr-access.conf ||
echo 'restore of nr-access.conf failed'
Wc_c="`wc -c < 'nr-access.conf'`"
test 114 -eq "$Wc_c" ||
	echo 'nr-access.conf: original size 114, current size' "$Wc_c"
fi
exit 0



From peveritt@pandora.ncts.navy.mil  Sat Nov  6 11:37:38 1993 +0600
Message-Id: <9311061737.AA00365@voltaire.ncts.navy.mil>
Date: Sat, 6 Nov 1993 11:37:38 +0600
From: peveritt@pandora.ncts.navy.mil (Paul Everitt)
Subject: Anyone using IADS for authoring?


Hey sportsfans.  I have become sick of writing HTML by hand.  I
know there is talk of writing an HTML editor, but these things
take time.  At one point, I had managed to get tkWWW working on
my Solaris machine (compiled it on SunOS 4.x), only to find
that tkWWW was always about 5 features behind.

I downloaded the Windoze IADS package discussed in comp.text.sgml.
Looks pretty slick.  Anybody using it to write their HTML?  Is
there a DTD that is even close to HTML+?

I know that IADS will not be able to verify the existance of links,
but hey, you get what you pay for.

Comments??

Paul.Everitt@ncts.navy.mil



From NED%INNOSOFT.BITNET@cearn.bitnet  Sun Nov  7 15:14:07 1993 -0800 (PST)
Message-Id: <01H51FBPA57K9BVGZP@INNOSOFT.COM>
Date: Sun, 07 Nov 1993 15:14:07 -0800 (PST)
From: NED%INNOSOFT.BITNET@cearn.bitnet (Ned Freed)
Subject: Re: Web and Mail integration: a few key connections.

> There has been some discussion recently about how to
> send SGML documents along with DTDs and oetr things
> which they reference in MIME messages. (see SGML-MIME ID).
> SGML documents refer to external entities
> as either "PUBLIC", in which case a special "Formal
> Public Identifier" (FPI) space is used and everyone
> is supposed o know what's in it, or "SYSTEM" in which
> case the significance is purely local.

My understanding is that there's one level of indirection implicit in SGML
to begin with. Specifically, the actual documents references things by
names which are then bound to actual objects by the DTD.

> 1. In an Internet context, the SGML "SYSTEM" identifiers
>    should be conventionally URIs.  As there are URIs
>    which refer to a local file system, this does not
>    rule out refering to local files too.

This sounds like a good idea to me.

> 2. The FPI space should be registered as a URN.

As I understand it, the FPI space has a lot in common with several other things
in OSI. Specifically, while it does provide a convenient space for public
usage, the lack of any authoritative registration process makes it very
difficult for things to really interoperate. (Many other aspects of OSI have
similar problems, such as BP15 OID usage, FTAM file formats, and so on.)

Given that this is a fair representation of the current situation, I think
having the Internet provide such a process would be a wonderful thing. In
addition, if that process can be piggybacked on top of some existing or
soon-to-exist scheme like URNs, so much the better.

> 3. Some space inside FPI space should be found for
>    the URN tree as well.

I'm not sure how you'd do this in any authoritative way. Any SGML experts (I'm
certainly nothing of the kind) care to comment?

> 4.  For the case of mail transport, both message-id values
>     (identifeirs of mail messages) and content-ids
>     (identifiers of parts of a multpart MIME message)
>     should be registered as URNs.  They will of course
>     only be dereferencable by people who have been
>     sent the relevant mail, but that is fine.

Are these really URNs? Aren't they actually URIs since the access method is
implicit in the name?

> 5.  The convention is adopted that when a multipart/related
>     document is sent, that the first part is consuleted for
>     information about the relationships.

Expect to see some documents clarifying the handling of multipart MIME
objects in the near future.

> 7.   HTTP should be specified to include support
>      for MIME multipart/related, to solve the problem
>      of servers which like to send a document with all
>      its included graphics in one respone.

Interesting idea. I like it.

I think we also need some kind of message subtype in MIME that does things
similar to message/external-body but resolves URIs and/or URNs. I don't see
this as being something that can be just another access-type under
message/external-body because of the semantics peculiar to the HTTP way of
resolving URIs (specifically, that the content-type is selected by the server
in response to what the client indicates it can handle).

                                Ned



From hotsand!rhb  Sun Nov  7 18:51:44 1993 EST
Message-Id: <9311072351.AA10154@hotsand.dacsand>
Date: Sun, 7 Nov 93 18:51:44 EST
From: hotsand!rhb (Rich Brandwein)
Subject: xmosaic command line arg for geometry

Is there an xmosaic command line arg for geometry?  I've tried the
typical xterm arg, which don't seem to work and I can't find reference
to it in any of the documentation.  

Rich



From alanb@ncsa.uiuc.edu  Sun Nov  7 18:22:34 1993 CST
Message-Id: <9311080022.AA20092@void.ncsa.uiuc.edu>
Date: Sun, 7 Nov 93 18:22:34 CST
From: alanb@ncsa.uiuc.edu (Alan Braverman)
Subject: xmosaic command line arg for geometry

rhb@hotsand.att.com writes:
> Is there an xmosaic command line arg for geometry?  I've tried the
> typical xterm arg, which don't seem to work and I can't find reference
> to it in any of the documentation.  
> 
> Rich

The standard -geometry only affects the invisible top level widget which
manages the rest of Mosaic's windows.  

The developers are planning on adding some X resources to make up for it, but
so far there is no way.


--
Alan Braverman
Software Development Group
National Center for Supercomputing Applications
alanb@ncsa.uiuc.edu



From moore@cs.utk.edu  Sun Nov  7 20:49:51 1993 -0500
Message-Id: <9311080149.AA11656@thud.cs.utk.edu>
Date: Sun, 07 Nov 1993 20:49:51 -0500
From: moore@cs.utk.edu (Keith Moore)
Subject: Re: Web and Mail integration: a few key connections. 

Ned writes...

> I think we also need some kind of message subtype in MIME that does things
> similar to message/external-body but resolves URIs and/or URNs. I don't see
> this as being something that can be just another access-type under
> message/external-body because of the semantics peculiar to the HTTP way of
> resolving URIs (specifically, that the content-type is selected by the 
> server in response to what the client indicates it can handle).

There is a need for a URN-like thing that can be absoultely tied to a
particular format of an object.  Without such a URN there is no way to
cache/replicate objects correctly. 

This doesn't preclude HTTP (or gopher, or whatever) from doing "conversion"
from a primary format to another format on behalf of the client.

A properly designed URN/URL system would not prevent use of MIME's
message/external-body with URNs, though it might not allow conversion
on-the-fly in this case.

Keith



From mcarthur@fit.qut.edu.au  Mon Nov  8 12:26:41 1993 EST
Message-Id: <199311080226.MAA06949@fitmail.fit.qut.edu.au>
Date: Mon, 8 Nov 93 12:26:41 EST
From: mcarthur@fit.qut.edu.au (Mr Robert McArthur)
Subject: NSCA <inc srv...> ?

I seem to have a problem getting the <inc srv "|date"> working on
NCSA 1.0a3.1.  I have a small document which really just prints the
current date...or should.  I have tried "|/bin/date" as well.  Since it
gives date as an example on hoohoo of this inc srv, its just possible I
have a conceptual error in my implementation:-), rather than a bug.

Thanks,
Robert
<http://sleet.fit.qut.edu.au:8001/first_page.html>

or, for the source,

<HEAD>
<TITLE>Queensland University of Technology</TITLE>
</HEAD>
<BODY>
<h1>Queensland University of Technology</h1>
<h1>Faculty of Information Systems</h1>
<h1>Experimental WWW Server</h1>

The time and date in Brisbane, Australia at the moment 
is <inc srv "|date">.

<p>Thanks!
Bye
</BODY>





From marca@ncsa.uiuc.edu  Sun Nov  7 21:14:34 1993 -0800
Message-Id: <9311080514.AA26326@wintermute.ncsa.uiuc.edu>
Date: Sun, 7 Nov 93 21:14:34 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: NCSA Mosaic for X 2.0 prerelease 8 available

Ladies and gentlemen, next to last in the long series of moments we've
all been waiting for...

...ftp.ncsa.uiuc.edu in /Mosaic/prerelease.  Source, plus binaries for
Sun, IBM, SGI.

This prerelease should be the final step on the road to 2.0.  With
luck, the real 2.0 release will be in a day or two.  Please stress the
prerelease out and report any serious problems to us ASAP.

There are no known crash conditions, other than a few obscure
system-related problems (e.g. crash in XtKeysymToKeycodeList) that we
can't find ways to work around.  If this prerelease crashes on you for
any reason, please report the crash with a full dbx stack traceback.

As before, thanks MUCH to all the prerelease testers who have sent in
feedback and bug reports -- your help is making 2.0 into a vastly
better product than it could otherwise be.

If you make this prerelease available to normal users, please make
sure they understand that it is not a full, stable release and that it
may have a few problems and instabilities.

Changes and additions in this prerelease include:

 o Renamed executable 'Mosaic' and application class name 'Mosaic'. User
   X resources and system app defaults files should be updated as necessary. 
 o Implemented FORM METHOD="POST" with optional 
   ENCTYPE="application/x-www-form-urlencoded". 
 o Implemented TEXTAREA as described in the current (11/2) HTML+ spec. 
 o Fixed bugs with image caching (particularly with very small image cache
   sizes) and multiple open windows. 
 o Scrolled lists with nothing selected now return nothing. 
 o Fixed coredump opportunity in GUI part of authentication code (Marc's
   fault, not Ari's). 
 o Fixed glitch with spinning icon and deferred image loading. 
 o Quotes (") in OPTIONs now work. 
 o Radio buttons no longer allowed to be "none of many" (document writers
   should make one of the buttons checked by default -- if you think you
   want to allow "none of many" behavior, just throw in a "none of the
   above" radio button). 
 o Image input elements whose images are deferred no longer have a
   hyperlink available in the deferred image icon. 
 o Fixed glitch with exploding Gopher/FTP icons in some cases. 
 o Force allowShellResize to false on Mosaic shell windows to avoid some
   stupid window manager bugs. 
 o "I have noticed that Mosaic 2.0pre6 does not properly scroll horizontally
   when a preformatted <PRE> declared document is wider than the
   window." Also gopher://gopher.ora.com/00/ordering/online.ordering.
   Fixed! 
 o Fixed coredump opportunity when temporary directory (TMPDIR) is
   unusable. 
 o Fixed coredump opportunities when interrupting NNTP connects and
   reads and when including inlined images in news articles (yikes). 
 o Fixed bad PostScript output of documents with titles with embedded
   newlines. 
 o Fixed problems in PostScript code on DEC Alphas (hopefully). 
 o Fixed another coredump opportunity in GIF reading code. 
 o Fixed glitch in simplying URLs like 'http://blargh.blah.:8001/'. 
 o Password entry fields in forms now obey the MAXLENGTH attribute. 
 o Changed default DEC Ultrix and Alpha audio player to "aplay" (c.f.
   AudioFile). 
 o Tried to make handling of HTTP network writes more elegant, in case
   some HTTP0 server really confuses things. 
 o Additional performance optimizations in HTML widget. 
 o New colorful spinning globe icon. 
 o Final interface tweaks, according to the advice of our user interface and
   visual design expert. 
 o Fixed compilation glitches on a couple different platforms. 
 o A few miscellaneous minor cleanups. 

Comments and feedback much appreciated -- however, remember: THIS IS
UNSUPPORTED CODE.

Cheers,
Marc

--
Marc Andreessen
Software Development Group
National Center for Supercomputing Applications
marca@ncsa.uiuc.edu (MIME welcomed here)




From marca@ncsa.uiuc.edu  Sun Nov  7 21:42:04 1993 -0800
Message-Id: <9311080542.AA26423@wintermute.ncsa.uiuc.edu>
Date: Sun, 7 Nov 93 21:42:04 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: re: NCSA Mosaic for X 2.0 prerelease 8 available

BTW, an English-language description of Mosaic version 2.0 is now
available as Help on Version:

http://www.ncsa.uiuc.edu/SDG/Software/Mosaic/Docs/help-on-version-2.0.html

This will be serving as a substitute for real 2.0 docs until they
arrive.

Cheers,
Marc




From henrich@crh.cl.msu.edu  Sun Nov  7 23:15:30 1993 -0500 (EST)
Message-Id: <9311080415.AA28114@crh.cl.msu.edu>
Date: Sun, 7 Nov 1993 23:15:30 -0500 (EST)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: Mosaic p8

*SLICK* logo!  Way better than the spinning S, two thumbs up, sweet!

-Cfh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                      http://rs560.msu.edu/~henrich



From peveritt@pandora.ncts.navy.mil  Sun Nov  7 22:20:39 1993 +0600
Message-Id: <9311080420.AA03418@voltaire.ncts.navy.mil>
Date: Sun, 7 Nov 1993 22:20:39 +0600
From: peveritt@pandora.ncts.navy.mil (Paul Everitt)
Subject: re: NCSA Mosaic for X 2.0 prerelease 8 available


Howdy neighbors.  Anybody wanna put a binary for Solaris 2.x 
up for adoption?   Please*3e20!!

Paul.Everitt@ncts.navy.mil



From mcarthur@fit.qut.edu.au  Mon Nov  8 14:44:30 1993 EST
Message-Id: <199311080444.OAA10010@fitmail.fit.qut.edu.au>
Date: Mon, 8 Nov 93 14:44:30 EST
From: mcarthur@fit.qut.edu.au (Mr Robert McArthur)
Subject: NCSA <inc srv...> update, still not ok

With a number of other people trying it from outside my domain, I find
that I get the message
	date: unknown option(s)
[or was it "invalid option"?]
Anyway, I have tried 'ls' and 'uname', all returning this exact phrase...
help...

Robert



From jim@grimaldi.rutgers.edu  Mon Nov  8 00:09:17 1993 EST
Message-Id: <CMM-RU.1.3.752735357.jim@grimaldi.rutgers.edu>
Date: Mon, 8 Nov 93 0:09:17 EST
From: jim@grimaldi.rutgers.edu (Jim Martin)
Subject: re: NCSA Mosaic for X 2.0 prerelease 8 available

> 
> Howdy neighbors.  Anybody wanna put a binary for Solaris 2.x 
> up for adoption?   Please*3e20!!
> 

	Well, I'm running pre8 (and everything else back to 1.2) under
solaris 2.2 and (currently) 2.3 just fine. It will blather quite a bit
on startup if your system doesn't match the ones at NCSA, but that can
all be safely ignored. Good luck!
								Jim


	Jim Martin			Internet: jim@noc.rutgers.edu
	Network Services		UUCP: {backbone}!rutgers!jim
	Rutgers University		Phone: (908) 932-3719



From peveritt@pandora.ncts.navy.mil  Sun Nov  7 23:15:29 1993 +0600
Message-Id: <9311080515.AA03559@voltaire.ncts.navy.mil>
Date: Sun, 7 Nov 1993 23:15:29 +0600
From: peveritt@pandora.ncts.navy.mil (Paul Everitt)
Subject: re: NCSA Mosaic for X 2.0 prerelease 8 available

Jim--

Are you using the binary for sun4, or did you compile your own?
I have the sun4 binary running in BCP, but since pre4 the networking
stuff has been broken.  The CERN people found the bug.  If you
take the source and compile it yourself, it works, but I don't
have Motif, so damn.

Or, maybe you are not having the same problem as us, which would
make me say huh?, because there are other people with the same 
symptom.  Mosaic does a DNS lookup, connects, and returns the
"Info server not ..." msg.  However, it works on my local machine's
httpd daemon.

I.e. did you compile it yourself, or grap the sun4 binary from 
NCSA?

Paul


> From jim@grimaldi.rutgers.edu Sun Nov  7 23:11 CST 1993
> Date: Mon, 8 Nov 93 0:09:17 EST
> From: Jim Martin <jim@grimaldi.rutgers.edu>
> To: peveritt@pandora.ncts.navy.mil (Paul Everitt)
> Cc: www-talk@nxoc01.cern.ch
> Subject: re: NCSA Mosaic for X 2.0 prerelease 8 available
> 
> > 
> > Howdy neighbors.  Anybody wanna put a binary for Solaris 2.x 
> > up for adoption?   Please*3e20!!
> > 
> 
> 	Well, I'm running pre8 (and everything else back to 1.2) under
> solaris 2.2 and (currently) 2.3 just fine. It will blather quite a bit
> on startup if your system doesn't match the ones at NCSA, but that can
> all be safely ignored. Good luck!
> 								Jim
> 
> 
> 	Jim Martin			Internet: jim@noc.rutgers.edu
> 	Network Services		UUCP: {backbone}!rutgers!jim
> 	Rutgers University		Phone: (908) 932-3719
> 



From robm@ncsa.uiuc.edu  Mon Nov  8 00:17:36 1993 -0600
Message-Id: <9311080617.AA26342@void.ncsa.uiuc.edu>
Date: Mon, 8 Nov 1993 00:17:36 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: NCSA <inc srv...> update, still not ok

/*
 * NCSA <inc srv...> update, still not ok  by Mr Robert McArthur (mcarthur@fit.qut.edu.au)
 *    written on Nov  8,  2:44pm.
 *
 * With a number of other people trying it from outside my domain, I find
 * that I get the message
 * 	date: unknown option(s)
 * [or was it "invalid option"?]
 * Anyway, I have tried 'ls' and 'uname', all returning this exact phrase...
 * help...
 * 
 * Robert
 */

What kind of system are you doing this on? Also, does the server log
anything in error_log when this happens?

--Rob



From dsr@hplb.hpl.hp.com  Mon Nov  8 10:56:21 1993 GMT
Message-Id: <9311081056.AA04404@manuel.hpl.hp.com>
Date: Mon, 8 Nov 93 10:56:21 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: Forms submission

> Ack, I *really* *really* want to be able to submit on multiple field entries.
> For example, im trying to build a form for my interactive weather map (for
> which now you entry a semi-cryptic "isindex" query).  There are two basic
> options, Show a station report, or show a surface map or both.  However, if
> the user is requesting show a surface map, they have to fill out a bunch
> more information.  I dont want to have to have a full page of "fill this out
> only if your are requesting the surface map".  It'd be SO much nicer that
> when they click on the "Show surface map" radio button, the form re-appears,
> this time with all the additional information that is needed.

Fear not! I will include this capability in the next revision to the HTML+
internet draft, which I hope to produce in the near future.

Dave



From timbl@www3.cern.ch  Mon Nov  8 12:03:19 1993 +0100
Message-Id: <9311081103.AA07661@www3.cern.ch>
Date: Mon, 8 Nov 93 12:03:19 +0100
From: timbl@www3.cern.ch (Tim Berners-Lee)
Subject: Re: Web and Mail integration: a few key connections. 


>There is a need for a URN-like thing that can be absoultely tied to  
a
>particular format of an object.  Without such a URN there is no way  
to
>cache/replicate objects correctly. 


(URN-like thing =~ "URI", the generic identifier)

The HTTP spec has, in the object metainfo, a URI: header.
It specifies a URI for the object.
The "vary=" parameter of this header specifies whether the
URI refers to the exact binary pattern, or whether it can
refer to "variants" of language, content-type or version.
(These are the only variants curerntly explicit, one can
imagine others)
Caching systems obviously use this information intelligently
to know whether they have a copy verbatim of an object or a copy of
one instance of a generic object.

Tim



From decoux@moulon.inra.fr  Mon Nov  8 12:48:08 1993 +0100
Message-Id: <9311081148.AA15985@moulon.moulon.inra.fr>
Date: Mon, 8 Nov 93 12:48:08 +0100
From: decoux@moulon.inra.fr (ts)
Subject: Oracle and <FORM>


 Oracle and <FORM>
 =================

 If you want to update a database, try 

  "http://moulon.inra.fr/oracle/A/update/table?action=tables"

 or retrieve "http://moulon.inra.fr/" and select "update the database".

 To update the database, you must have :
  - a client 1.0 which accept <FORM>
  - an username : scott
  - a password : tiger

 With (scott,tiger) you can retrieve, update and add rows, you need another
(username, password) to delete rows or put a lock.

 More explanations are given in :
  "http://moulon.inra.fr/update_eng.html" (english version)

  ou
  
  "http://moulon.inra.fr/update.html" (version francaise)


Guy Decoux




From dsr@hplb.hpl.hp.com  Mon Nov  8 12:16:48 1993 GMT
Message-Id: <9311081216.AA05130@manuel.hpl.hp.com>
Date: Mon, 8 Nov 93 12:16:48 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: SP or emsp

> I had thought we were going to have &emsp and &ensp.  But I
> don't really care since I will be implementing them the same :)

I would recommend you to map &ensp; to a single space and &emsp; to
two spaces. The main thing is that these spaces *are not collapsed*
unlike the normal treatment of whitespace in SGML documents.

This means don't map them to spaces at too low a level or your browser
will be unable to treat them differently from normal whitespace.

Dave



From dolesa@smtp-gw.spawar.navy.mil  Mon Nov  8 08:24:31 1993 EDT
Message-Id: <9310087527.AA752775871@smtp-gw.spawar.navy.mil>
Date: Mon, 08 Nov 93 08:24:31 EDT
From: dolesa@smtp-gw.spawar.navy.mil (Andre Doles)
Subject: NCSA Mosaic for NeXT


I'm totally confused.  I get xmosaic-1.2-NeXT.Z and can uncompress it, but it 
ends up a text file.  What in the world do I have to do to make this program 
work under NeXT???  If it were Tar.Z'd, I might be able to do something with 
it.  How should I handle this file???  Help appreciated.

                                    Andre' Doles
                                    Space & Naval Warfare Systems Command HQ



From roeber@axcrnb.cern.ch  Mon Nov  8 16:32:54 1993 +0100
Message-Id: <9311081532.AA26949@dxmint.cern.ch>
Date: Mon, 8 Nov 1993 16:32:54 +0100
From: roeber@axcrnb.cern.ch (Frederick G.M. Roeber)
Subject: Partial gatewaying

I'm setting up a corner of the web on a firewalled network.  Any host (almost) 
at CERN can be accessed directly; all else must go via a gateway.  
Unfortunately, the usual WWW_access_GATEWAY redirection is an all-or-nothing 
deal.  I can't just set things up so everything goes via the gateway, because 
one server will be operationally critical (containing all the on-line docs for 
running LEP and SPS), and its access should be kept as simple (and reliable) as 
possible.  (Even redirection wouldn't be very nice.)

My first thought was to hack HTAccess.c to check the hostname against an 
environment variable (set to ".cern.ch") to decide whether or not to use the 
WWW_access_GATEWAY variables.  Another way would be to edit HTAccess.c to skip 
the gatewaying when the host is "localhost," NFS-mount the critical stuff, and 
use file:.  Any other ideas?

Frederick.



From henrich@crh.cl.msu.edu  Mon Nov  8 10:46:46 1993 -0500 (EST)
Message-Id: <9311081546.AA29439@crh.cl.msu.edu>
Date: Mon, 8 Nov 1993 10:46:46 -0500 (EST)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: HTML -> ASCII?

Anyone have such a tool?

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                      http://rs560.msu.edu/~henrich



From Erik.Huizer@surfnet.nl  Mon Nov  8 17:12:08 1993 +0100
Message-Id: <9311081612.AA07519@survival.surfnet.nl>
Date: Mon, 08 Nov 93 17:12:08 +0100
From: Erik.Huizer@surfnet.nl (Erik Huizer)
Subject: Re: What URIs are and are not.


> Listen good if you are a newcomer to the list or on the
> IESG ;-)


This is the second sneer of this sort, and I start to dislike it. I hope
that the IESG (i.e. my) intervention has been positive and has been helpfull
to get the URI WG back up to speed. If not I suggest you either lodge a
formal complaint to the IESG, or back off.

I also like to argue that although I have not read all mail to this list,
nor attended all meetings of the group that my level of involvement is
sufficient to have an overview of what is happening and what has been
discussed before.

Furthermore, my name is written with a k rather than a c.

Erik



From dgd@cs.bu.edu  Mon Nov  8 14:03:55 1993 -0500
Message-Id: <9311081903.AA04963@csd.bu.edu>
Date: Mon, 8 Nov 93 14:03:55 -0500
From: dgd@cs.bu.edu (David Durand)
Subject: Re: Web and Mail integration: a few key connections.


   This is in reply to Ned Freed's comments on UR* and ISO FPIs. I've
been involved w/ SGML one way or another for a long time now so I can
at least clear up the factual questions, I think. The Formal Public
Indentifier (FPI) is addressing the "URN" problem of naming content
(with the identity/data format issues to be resolved by the publisher
not the naming formats).
Ned wrote in response to (timbl?)
>> SGML documents refer to external entities
>> as either "PUBLIC", in which case a special "Formal
>> Public Identifier" (FPI) space is used and everyone
>> is supposed o know what's in it, or "SYSTEM" in which
>> case the significance is purely local.

>My understanding is that there's one level of indirection implicit in SGML
>to begin with. Specifically, the actual documents references things by
>names which are then bound to actual objects by the DTD.

Documents reference things by the use of "entities" which are defined
in the DTD to resolve to either FPIs which are presumed known, or by
system strings. My quibble here is that both system string -> object
mappings and the FPI-> object mapping are in the SGML processor and
are external to both the document and the DTD. Any method of resolution
satisfactory to the users is OK.

Then we have this proposal:
>> 1. In an Internet context, the SGML "SYSTEM" identifiers
>>    should be conventionally URIs.  As there are URIs
>>    which refer to a local file system, this does not
>>    rule out refering to local files too.

>This sounds like a good idea to me.
  Actually a bad idea. Since URIs are standard, they should be formal
identifiers: SYSTEM strings are _defined_ to be the place for
non-portable names in SGML. Assuming a particular format for SYSTEM
identifiers is guranteed not to work for existing documents, and
allows conforming SGML software to ignore SYSTEM identifiers at
will. Names which have a standard resolution method should use formal
identifiers.

   This seems related to a following point:

>> 2. The FPI space should be registered as a URN.

>As I understand it, the FPI space has a lot in common with several other things
>in OSI. Specifically, while it does provide a convenient space for public
>usage, the lack of any authoritative registration process makes it very
>difficult for things to really interoperate. (Many other aspects of OSI have
>similar problems, such as BP15 OID usage, FTAM file formats, and so on.)
>
>Given that this is a fair representation of the current situation, I think
>having the Internet provide such a process would be a wonderful thing. In
>addition, if that process can be piggybacked on top of some existing or
>soon-to-exist scheme like URNs, so much the better.

The FPI space should be registered as a URN, and this can be done
pretty easily. Going the other direction is a bat trickier. The
objection Ned raises is based on a common misconception, since the ISO
registeation authority does not yet exist. However, the ISBN is an
accepted sub-domain for registration. So all one needs to do to create
a public FPI is have an ISBN publisher number and then make up a
subdomain. SRI or the government, for instance, could thus create a
proper inclusion of URN into FPI space tomorrow. However, the worst
wart on ISO 1090 (the FPI spec) is a length limitation to roughly 120
characters, so until this changes, many URN's are unlikely to fit into
the available space.

I don't have ISO 8879 (SGML) or ISO 1090 (FPI) in my hands at the
moment so I can't tell you what my view of an ideal solution would be,
but this kind of inter-standard coordination is pretty important. SGML
is the only contender for a non-presentational document language, and
would thus be important even without its increasing commercial
use.

    -- David Durand
    Boston University Computer Science



From waterbug@epims1.gsfc.nasa.gov  Mon Nov  8 21:40:23 1993 EST
Message-Id: <9311090240.AA14771@epims1.gsfc.nasa.gov>
Date: Mon, 8 Nov 93 21:40:23 EST
From: waterbug@epims1.gsfc.nasa.gov (Steve Waterbury)
Subject: Re: NCSA Mosaic for X 2.0 prerelease 8 available


Marc, 

Prerelease 8 is great ... ESPECIALLY the spinning globe.  Gee, hours of fun!  A 
tiny nit:  the image of the globe is a little bit dark on my machine ... 
does anyone else have that?  (I know -- what an ungrateful lout I am!  Really!)  
Frabjous!  

Now THIS will REALLY impress the suits in the front office!  (Hah -- you think 
I'm kidding!)  

:-)

Steve Waterbury.



From dale@ora.com  Mon Nov  8 23:29:32 1993 -0800
Message-Id: <9311082329.ZM11417@rock.west.ora.com>
Date: Mon, 8 Nov 1993 23:29:32 -0800
From: dale@ora.com (Dale Dougherty)
Subject: Re: HTML -> ASCII?

The simplest approach is a sed script that removes HTML tags,
that is, anything between a pair of angle brackets.

s/<.[^>]*>//g


You can obviously build more complicated scripts in sed, awk or perl.
The above script will strip out link information because HREF 
is an attribute inside the tag.   

Such seat-of-the-pants conversions depend on how consistent the 
HTML coding is.  This is by no means a general solution.

-- 
Dale Dougherty (dale@ora.com) 
Publisher, Global Network Navigator, O'Reilly & Associates, Inc.
103A Morris Street, Sebastopol, California 95472 
(707) 829-3762 (home office); 1-800-998-9938



From timbl@www3.cern.ch  Tue Nov  9 11:28:48 1993 +0100
Message-Id: <9311091028.AA08692@www3.cern.ch>
Date: Tue, 9 Nov 93 11:28:48 +0100
From: timbl@www3.cern.ch (Tim Berners-Lee)
Subject: Re: What URIs are and are not.


>Date: Mon, 08 Nov 93 17:12:08 +0100
>From: "Erik Huizer (SURFnet BV)" <Erik.Huizer@surfnet.nl>

>> Listen good if you are a newcomer to the list or on the
>> IESG ;-)
>
>This is the second sneer of this sort, and I start to dislike it.

Snmeer not intended. (I must brush up my smiley technique.)
Sorry, Erik, I realised too late I had said something similar
-- also with a big wink -- in an earlier message.

Nor a complaint.  Obviously there is not enough background
requirements spec in the document.  Anyone, (IESG members included)
comming with a broader outlook is going to want to know what the
URI WG thinks it is talking about.  There is maybe an image of
a "newcomer" as a spotty kid who's just found out about the IETF
and come along to experience it -- not true in general for the URI WG
as most are people with great experience coming in from related
 fields as the URI field has some bearing on the other bits.

I hope
>that the IESG (i.e. my) intervention has been positive and has been  
helpfull
>to get the URI WG back up to speed.

Your comments about the document are important.
If the document is only comprehensible given a
historical knowledge of the WG's wandering concept set, then it's no
use to anybody.  I felt that was probably because I had been shy of
putting in the aims of the document.   Was the rest of my
message any use at setting the objectives? Should some of that
go into the document itself?

IESG involvement with "a WG which takes 18 months over 12 pages"
is also appropriate.

>I also like to argue that although I have not read all mail to this  
list,
>nor attended all meetings of the group that my level of involvement  
is
>sufficient to have an overview of what is happening and what has  
been
>discussed before.

Perhaps you could point out specifically where the URI
spec fails to state its objectives.

>Furthermore, my name is written with a k rather than a c.

Please excuse me!
Tin

>Erik




From Erik.Huizer@surfnet.nl  Tue Nov  9 12:17:31 1993 +0100
Message-Id: <9311091117.AA08143@survival.surfnet.nl>
Date: Tue, 09 Nov 93 12:17:31 +0100
From: Erik.Huizer@surfnet.nl (Erik Huizer)
Subject: Re: What URIs are and are not.

Tim,

> Your comments about the document are important.
> If the document is only comprehensible given a
> historical knowledge of the WG's wandering concept set, then it's no
> use to anybody.  I felt that was probably because I had been shy of
> putting in the aims of the document.   Was the rest of my
> message any use at setting the objectives? Should some of that
> go into the document itself?

> Perhaps you could point out specifically where the URI
> spec fails to state its objectives.

I saw the draft spec that Jim Fulton managed to write up during some
bar-bofs at the IETF. I think that looks pretty good and contains the
essential points from your earlier posting. I assume Jim will send it to
this list shortly. look at it and see if you can live with it.

Thanks,
Erik




From qq15@liverpool.ac.uk  Tue Nov  9 11:48:04 1993 GMT
Message-Id: <9311091148.AA14734@chad3-14.liv.ac.uk>
Date: Tue, 9 Nov 93 11:48:04 GMT
From: qq15@liverpool.ac.uk (Pete)
Subject: Re: NCSA Mosaic for X 2.0 prerelease 8 available

> Prerelease 8 is great ... ESPECIALLY the spinning globe.  Gee, hours of fun!  A 
> tiny nit:  the image of the globe is a little bit dark on my machine ... 
> does anyone else have that?  (I know -- what an ungrateful lout I am!  Really!)  

It's fine on my Sun IPX - and yes I can sit and watch it for hours!

I'm really looking forward to the release of 2.0 - that's when I plan
to launch our WWW service on our user population.

Pete



From neuss@igd.fhg.de  Tue Nov  9 14:14:52 1993 +0100
Message-Id: <9311091314.AA00965@wildturkey.igd.fhg.de>
Date: Tue, 9 Nov 93 14:14:52 +0100
From: neuss@igd.fhg.de (neuss@igd.fhg.de)
Subject: Re: HTML -> ASCII?

Dear fellow Webbers,

dale@ora.com (Dale Dougherty) wrote:
> The simplest approach is a sed script that removes HTML tags,
> that is, anything between a pair of angle brackets.
> s/<.[^>]*>//g

Yip.. but that does not always work.. e.g. you can have brackets commented
out with "<!--", or inside a <LISTING> foo </LISTING>. Some of us
out here (and that includes me, I'm working on an indexing tool) need
to strip out HTML commands. Ari Loutonen from CERN has proposed using
the command line browser for this purpose, but something smaller would 

be preferable...

Does something like this exist? 

Cheers, Chris





From luotonen@ptsun00.cern.ch  Tue Nov  9 10:39:42 1993 +0100
Message-Id: <9311090939.AA24209@ptsun03.cern.ch>
Date: Tue, 9 Nov 93 10:39:42 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: Clicks inside a polygon


   Cheers People,

Is there a public domain implementation of resolving if a point
is inside or outside of a polygon such that it could be part of
the CERN daemon distribution.  [Does someone get the code for this
a while back from Robert Cailliau -- he's in the US and I can't
ask from him directly.]

If there is none, can someone point me to the theory of it?

PS. Rob:  I pass a form request to a script already parsed
in CERN daemon, e.g.:

	/htbin/script/first/argument?name1=value1&name2=value2

is called as:

	.../script /first/argument name1= value1 name2= value2

You can always detect if the first arg is present by checking if
arg count is odd or even (besides, you probably know it anyway for
a given script).  All the unescaping can be done before the script
call.

Thanks,

                     \\\\Ari Luotonen//////
                      \\\\WWW Person//////
                       \\\\\\/\\\\\//////
                        \\\\//\\\\//////
                         \\////\\//////
                          \/\/\/\/\/\/




From KLENSIN@infoods.mit.edu  Tue Nov  9 08:18:41 1993 -0500 (EST)
Message-Id: <752851121.120215.KLENSIN@INFOODS.UNU.EDU>
Date: Tue, 09 Nov 1993 08:18:41 -0500 (EST)
From: KLENSIN@infoods.mit.edu (John C Klensin)
Subject: Re: What URIs are and are not.

Tim,
   In the hope that adding another AD to this discussion will clarify,
rather than further muddy the waters, let me try to briefly summarize
what I (we) said in Houston.

To advance the URL document, we  are going to need  a clear statement of
what the WG intends it to be used for, ideally stated in terms of
functional requirements.  My personal preference is that we end up  with
two documents, so that the functional requirements/rationale  can remain
very stable while the URL doc evolves as it passes along the standards
track.  But that is just a preference; the WG should do what it thinks
best.  

I expect that this document will be somewhat different than it would
have been a year or 18 months ago: we've all learned things from the
last months of discussions and examination of different requirements.

   john



From marca@ncsa.uiuc.edu  Sun Nov  7 21:14:34 1993 -0800
Message-Id: <9311091650.AA08722@jmullins.Stanford.EDU>
Date: Sun, 7 Nov 93 21:14:34 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: NCSA Mosaic for X 2.0 prerelease 8 available

Ladies and gentlemen, next to last in the long series of moments we've
all been waiting for...

...ftp.ncsa.uiuc.edu in /Mosaic/prerelease.  Source, plus binaries for
Sun, IBM, SGI.

This prerelease should be the final step on the road to 2.0.  With
luck, the real 2.0 release will be in a day or two.  Please stress the
prerelease out and report any serious problems to us ASAP.

There are no known crash conditions, other than a few obscure
system-related problems (e.g. crash in XtKeysymToKeycodeList) that we
can't find ways to work around.  If this prerelease crashes on you for
any reason, please report the crash with a full dbx stack traceback.

As before, thanks MUCH to all the prerelease testers who have sent in
feedback and bug reports -- your help is making 2.0 into a vastly
better product than it could otherwise be.

If you make this prerelease available to normal users, please make
sure they understand that it is not a full, stable release and that it
may have a few problems and instabilities.

Changes and additions in this prerelease include:

 o Renamed executable 'Mosaic' and application class name 'Mosaic'. User
   X resources and system app defaults files should be updated as necessary.
 o Implemented FORM METHOD="POST" with optional
   ENCTYPE="application/x-www-form-urlencoded".
 o Implemented TEXTAREA as described in the current (11/2) HTML+ spec.
 o Fixed bugs with image caching (particularly with very small image cache
   sizes) and multiple open windows.
 o Scrolled lists with nothing selected now return nothing.
 o Fixed coredump opportunity in GUI part of authentication code (Marc's
   fault, not Ari's).
 o Fixed glitch with spinning icon and deferred image loading.
 o Quotes (") in OPTIONs now work.
 o Radio buttons no longer allowed to be "none of many" (document writers
   should make one of the buttons checked by default -- if you think you
   want to allow "none of many" behavior, just throw in a "none of the
   above" radio button).
 o Image input elements whose images are deferred no longer have a
   hyperlink available in the deferred image icon.
 o Fixed glitch with exploding Gopher/FTP icons in some cases.
 o Force allowShellResize to false on Mosaic shell windows to avoid some
   stupid window manager bugs.
 o "I have noticed that Mosaic 2.0pre6 does not properly scroll horizontally
   when a preformatted <PRE> declared document is wider than the
   window." Also gopher://gopher.ora.com/00/ordering/online.ordering.
   Fixed!
 o Fixed coredump opportunity when temporary directory (TMPDIR) is
   unusable.
 o Fixed coredump opportunities when interrupting NNTP connects and
   reads and when including inlined images in news articles (yikes).
 o Fixed bad PostScript output of documents with titles with embedded
   newlines.
 o Fixed problems in PostScript code on DEC Alphas (hopefully).
 o Fixed another coredump opportunity in GIF reading code.
 o Fixed glitch in simplying URLs like 'http://blargh.blah.:8001/'.
 o Password entry fields in forms now obey the MAXLENGTH attribute.
 o Changed default DEC Ultrix and Alpha audio player to "aplay" (c.f.
   AudioFile).
 o Tried to make handling of HTTP network writes more elegant, in case
   some HTTP0 server really confuses things.
 o Additional performance optimizations in HTML widget.
 o New colorful spinning globe icon.
 o Final interface tweaks, according to the advice of our user interface and
   visual design expert.
 o Fixed compilation glitches on a couple different platforms.
 o A few miscellaneous minor cleanups.

Comments and feedback much appreciated -- however, remember: THIS IS
UNSUPPORTED CODE.

Cheers,
Marc

--
Marc Andreessen
Software Development Group
National Center for Supercomputing Applications
marca@ncsa.uiuc.edu (MIME welcomed here)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
--
Marc Andreessen
Software Development Group
National Center for Supercomputing Applications
marca@ncsa.uiuc.edu (MIME welcomed here)





From masinter@parc.xerox.com  Tue Nov  9 15:08:44 1993 PST
Message-Id: <93Nov9.150852pst.2795@golden.parc.xerox.com>
Date: Tue, 9 Nov 1993 15:08:44 PST
From: masinter@parc.xerox.com (Larry Masinter)
Subject: Re: Web and Mail integration: a few key connections. 

On web and mail integration:

Perhaps we could extend what Mime is using for 'content-type' to a
more general 'resource type'; some kinds of resources are actual files
with a given format, but other things that we want are URLs for
interactive services which will have a type of 'telnet/3270' vs
'telnet/vt220', or multicast audio and video channels.

I was puzzling how to 'type' these things as long as they were
supposed to fit within 'content-type', until I realized that
content-type could be considered just a subset of a more general case.




From mitra@path.net  Tue Nov  9 15:34:17 1993 PDT
Message-Id: <9311091534.aa12932@pandora.sf.ca.us>
Date: Tue, 9 Nov 1993 15:34:17 PDT
From: mitra@path.net (Mitra)
Subject: Re: Web and Mail integration: a few key connections.

I believe that some of these sorts of thgings (e.g. telnet) are 
registered by the gopehr folks


- Mitra



From minh@wits.uow.edu.au  Wed Nov 10 12:00:43 1993 EST
Message-Id: <9311100100.AA01597@wits.uow.edu.au>
Date: Wed, 10 Nov 93 12:00:43 EST
From: minh@wits.uow.edu.au (Minh Luu)
Subject: add





From moore@cs.utk.edu  Tue Nov  9 20:03:14 1993 -0500
Message-Id: <9311100103.AA17803@thud.cs.utk.edu>
Date: Tue, 09 Nov 1993 20:03:14 -0500
From: moore@cs.utk.edu (Keith Moore)
Subject: Re: Web and Mail integration: a few key connections. 

> On web and mail integration:
> 
> Perhaps we could extend what Mime is using for 'content-type' to a
> more general 'resource type'; some kinds of resources are actual files
> with a given format, but other things that we want are URLs for
> interactive services which will have a type of 'telnet/3270' vs
> 'telnet/vt220', or multicast audio and video channels.

I think that's appropriate, so long as we know how to draw the line between
the MIME types that can be carried in mail and those that don't.

Maybe the distinction (at the top-level) is interactive vs. non-interactive.

So:

interactive-text/telnet; TERM=vt220
interactive-text/tn3270 (this really is a different protocol)
interactive-text/rlogin
interactive-text/x25pad
interactive-text/lat
interactive-text/cterm
interactive-text/dialup; PN="+1.615.555.1212"
interactive-audio/vat
interactive-video/nv  (but the names should describe protocols, not
                       specific tools)

Remember, the main reason for the top-level MIME type is to give gateways an
clue as to whether than discard, convert, or retain the content.  If
gateways are willing to do protocol translations across network boundaries
the distinction might somehow still be useful.

Keith



From mitra@path.net  Tue Nov  9 21:16:25 1993 PDT
Message-Id: <9311092116.aa05072@pandora.sf.ca.us>
Date: Tue, 9 Nov 1993 21:16:25 PDT
From: mitra@path.net (Mitra)
Subject: New list IETF-TYPES@SERVER.PATH.NET

As requested at the IETF meeting in Houston, a new list has been created 
for discussion of any issues related to Content-Types as used in 
both IIIR and MIME applications. 

This is intended to provide a single place that people interested in
Content-Types can interact, rather than the multiple places, and 
duplicated email that we are getting at the moment. 

To subscribe, send a one line message 


SUBSCRIBE IETF-TYPES Your Name

to listserv@server.path.net,  if you want to receive copies of your own 
submissions then also send a one-liner

SET IETF-TYPES MAIL ACK

The mailing list is gatewayed locally to news, if you want to receive it that
way please contact me by email.

- Mitra



From mueller@sc.zib-berlin.de  Wed Nov 10 08:51:29 1993 +0100
Message-Id: <9311100751.AA03339@ave.ZIB-Berlin.DE>
Date: Wed, 10 Nov 93 08:51:29 +0100
From: mueller@sc.zib-berlin.de (Peter Mueller)
Subject: Re: NCSA Mosaic for X 2.0 prerelease 8 available

Can't find ftp.ncsa.uiuc.edu:/Mosaic/prerelease ... Maybe I'm too
tired yet, but I think, there's no prerelease subdir.

Regards,

Peter



From W.vanLeeuwen@nikhef.nl  Wed Nov 10 10:25:43 1993 +0100
Message-Id: <9311100925.KA22388@nikhefh.nikhef.nl>
Date: Wed, 10 Nov 1993 10:25:43 +0100
From: W.vanLeeuwen@nikhef.nl (Willem van Leeuwen)
Subject: Problem with httpd 2.13

On Nov 4 luotonen@ptsun00.cern.ch (Ari Luotonen wrote:

| CERN-httpd 2.13 and libwww 2.13 released.
| 
|         *****************************************************
|         **                                                 **
|         **          Everybody using CERN-httpd:            **
|         **                                                 **
|         **             IT IS TIME TO UPGRADE!              **
|         **                                                 **
|         *****************************************************
| 

I therefore installed the latest versions of the linemode browser and
the daemon from the following files:
	WWWDaemon_2.13.tar
	WWWLibrary_2.13.tar
	WWWLineMode_2.12.tar

I installed the daemon on a test machine: nic.nikhef.nl.

The following script demonstrates what happens.
The old and new linemode browser can access a html file via httpd when
the old server is used, not when the new server is used.
In that case I get Error 500.

Script started on Tue Nov  9 14:00:24 1993
warning: could not update utmp entry
[nic] #[23] a
=========================================================================
old browser old daemon
=========================================================================
HTBrowse: default_default is file://nic/sd3/user/a03/bin/default.html, Initial page is http://nic.nikhef.nl/user/a03/www/default/NikhefGuide.html
New anchor 245b8 has hash 48 and address `http://nic.nikhef.nl/user/a03/www/default/NikhefGuide.html'
HTAccess: loading document http://nic.nikhef.nl/user/a03/www/default/NikhefGuide.html
HTTPAccess: Direct access for http://nic.nikhef.nl/user/a03/www/default/NikhefGuide.html
TCP: Parsed address as port 80, IP address 192.16.199.49
HTTP connected, socket 4
HTTP writing command `GET /user/a03/www/default/NikhefGuide.html
' to socket 4
SGML: Start <DOCUMENT>
Unknown tag header
SGML: Start <TITLE>
SGML: End   </TITLE>
Unknown end tag </header>
Unknown tag body
SGML: Start <H1>
HTML: Change to style Heading1

SGML: End   </H1>
SGML: Start <P>
HTML: Change to style Normal
FORMAT IS `%79.79s%s
'
                                                             NIKHEF Information
                               WELCOME TO NIKHEF

SGML: Start <P>
   The NIKHEF WWW server has been moved from nic.nikhef.nl to www.nikhef.nl.

SGML: Start <A>
new Anchor 258f8 named `' is child of 245b8
New anchor 25b70 has hash 32 and address `http://nikhefh.nikhef.nl/www/pub/default/NikhefGuide.html'
Linking anchor 258f8 to anchor 25b70
SGML: End   </A>
SGML: Start <P>
   Click here [1] to access the NIKHEF information on the new server.

SGML: Start <P>
   Please change the NIKHEF address into

SGML: Start <P>
   http://www.nikhef.nl/www/pub/default/NikhefGuide.html

SGML: Start <ADDRESS>
SGML: Start <A>
new Anchor 25cc8 named `' is child of 245b8
New anchor 25c38 has hash 52 and address `http://nikhefh.nikhef.nl/www/pub/default/Phone.html?leeuwen'
Linking anchor 25cc8 to anchor 25c38
HTML: Change to style Address
SGML: End   </A>
SGML: End   </ADDRESS>
Unknown end tag </body>
SGML: End   </DOCUMENT>
HTML: Change to style Normal
                                                        webmaster@nikhef.nl [2]


     [End]







HTTP: close socket 4.
HTAccess: `http://nic.nikhef.nl/user/a03/www/default/NikhefGuide.html' has been accessed.
1-2, Quit, or Help: h


WWW LineMode Browser version 1.4 (WWWLib 1.1a)   COMMANDS AVAILABLE

You are reading
 "NIKHEF Information"
whose address is
  http://nic.nikhef.nl/user/a03/www/default/NikhefGuide.html

  List            List the references from this document.
  <number>        Select a referenced document by number (from 1 to 2).
  Go address      Go to document of given [relative] address
  PRInt           Print text of this document. *
  ! command       Execute shell command without leaving.
  > file          Save the text of this document in a file. *
  >> file         Append the text of this document to a file. *
  | command       Pipe this document to a shell command. *
  CD directory    Change local working directory.
* Prefix these commands with "Source " to use raw source.

  Verbose         Switch to non-verbose mode.
  Help            Display this page.
  Manual          Jump to the online manual for this program
  Quit            Leave the www program.

1-2, Quit, or Help: q
=========================================================================
new browser old daemon
=========================================================================

 Calling new version of www

New anchor 63a28 has hash 48 and address `http://nic.nikhef.nl/user/a03/www/default/NikhefGuide.html'
HTAccess: loading document http://nic.nikhef.nl/user/a03/www/default/NikhefGuide.html
HTTPAccess: Direct access for http://nic.nikhef.nl/user/a03/www/default/NikhefGuide.html
TCP: Parsed address as port 80, IP address 192.16.199.49
Composing Authorization for nic.nikhef.nl:80/user/a03/www/default/NikhefGuide.html
HTAASetup_lookup: No template matched `user/a03/www/default/NikhefGuide.html' (so probably not protected)
HTTP: Not sending authorization (yet)
HTTP connected, socket 4
HTTP Tx: GET /user/a03/www/default/NikhefGuide.html HTTP/1.0
Accept: www/source q=0.300
Accept: www/unknown q=0.300
Accept: application/octet-stream q=0.100
Accept: text/plain
Accept: text/html
Accept: image/jpeg
Accept: image/x-tiff
Accept: image/gif
Accept: application/postscript
User-Agent:  CERN-LineMode/2.12  libwww/2.13


HTTP: read returned 50 bytes.
HTTP: Rx: Document address invalid or access not authorised
HTTP: close socket 4 to retry with HTTP0
Composing Authorization for nic.nikhef.nl:80/user/a03/www/default/NikhefGuide.html
HTAASetup_lookup: No template matched `user/a03/www/default/NikhefGuide.html' (so probably not protected)
HTTP: Not sending authorization (yet)
HTTP connected, socket 4
HTTP Tx: GET /user/a03/www/default/NikhefGuide.html


HTTP: read returned 533 bytes.
HTTP: Rx: <header>
HTFormat: Constructing stream stack for text/html to www/present
SGML: *** Unknown element header
SGML: Start <TITLE>
SGML: End   </TITLE>
Unknown end tag </header>
SGML: Start <BODY>
SGML: Start <H1>
HTML: Change to style Heading1
SGML: End   </H1>
SGML: Start <P>
HTML: Change to style Normal
                                                             NIKHEF Information
                               WELCOME TO NIKHEF

SGML: Start <P>
   The NIKHEF WWW server has been moved from nic.nikhef.nl to www.nikhef.nl.

SGML: Start <A>
new Anchor 659c8 named `' is child of 63a28
New anchor 61d60 has hash 32 and address `http://nikhefh.nikhef.nl/www/pub/default/NikhefGuide.html'
Linking anchor 659c8 to anchor 61d60
SGML: End   </A>
SGML: Start <P>
   Click here [1] to access the NIKHEF information on the new server.

SGML: Start <P>
   Please change the NIKHEF address into

SGML: Start <P>
   http://www.nikhef.nl/www/pub/default/NikhefGuide.html

SGML: Start <ADDRESS>
SGML: Start <A>
new Anchor 61ee8 named `' is child of 63a28
New anchor 61a20 has hash 52 and address `http://nikhefh.nikhef.nl/www/pub/default/Phone.html?leeuwen'
Linking anchor 61ee8 to anchor 61a20
HTML: Change to style Address
SGML: End   </A>
SGML: End   </ADDRESS>
SGML: End   </BODY>
HTML: Change to style Normal
                                                        webmaster@nikhef.nl [2]


     [End]








HTTP: close socket 4.
HTAccess: `http://nic.nikhef.nl/user/a03/www/default/NikhefGuide.html' has been accessed.
1-2, Up, Quit, or Help: h


WWW LineMode Browser version 2.12 (WWWLib 2.13)   COMMANDS AVAILABLE

You are reading
 "NIKHEF Information"
whose address is
  http://nic.nikhef.nl/user/a03/www/default/NikhefGuide.html

  Top             Return to the first page of the document.
  Up              Move up one page within the document
  List            List the references from this document.
  <number>        Select a referenced document by number (from 1 to 2).
  Go address      Go to document of given [relative] address
  PRInt           Print text of this document. *
  ! command       Execute shell command without leaving.
  > file          Save the text of this document in a file. *
  >> file         Append the text of this document to a file. *
  | command       Pipe this document to a shell command. *
  CD directory    Change local working directory.
* Prefix these commands with "Source " to use raw source.

  Verbose         Switch to non-verbose mode.
  Help            Display this page.
  Manual          Jump to the online manual for this program
  Quit            Leave the www program.

1-2, Up, Quit, or Help: q
=========================================================================
old browser new daemon
=========================================================================
HTBrowse: default_default is file://nic/sd3/user/a03/bin/default.html, Initial page is http://nic.nikhef.nl/user/a03/www/default/NikhefGuide.html
New anchor 245b8 has hash 48 and address `http://nic.nikhef.nl/user/a03/www/default/NikhefGuide.html'
HTAccess: loading document http://nic.nikhef.nl/user/a03/www/default/NikhefGuide.html
HTTPAccess: Direct access for http://nic.nikhef.nl/user/a03/www/default/NikhefGuide.html
TCP: Parsed address as port 80, IP address 192.16.199.49
HTTP connected, socket 4
HTTP writing command `GET /user/a03/www/default/NikhefGuide.html
' to socket 4
SGML: Start <DOCUMENT>
Unknown tag BODY
SGML: Start <H1>
HTML: Change to style Heading1

SGML: End   </H1>
HTML: Change to style Normal
                                   ERROR 500

Unknown end tag </BODY>
SGML: End   </DOCUMENT>
   Unable to access document.
     [End]


















HTTP: close socket 4.
HTAccess: `http://nic.nikhef.nl/user/a03/www/default/NikhefGuide.html' has been accessed.

=========================================================================
new browser new daemon
=========================================================================

 Calling new version of www

New anchor 63a28 has hash 48 and address `http://nic.nikhef.nl/user/a03/www/default/NikhefGuide.html'
HTAccess: loading document http://nic.nikhef.nl/user/a03/www/default/NikhefGuide.html
HTTPAccess: Direct access for http://nic.nikhef.nl/user/a03/www/default/NikhefGuide.html
TCP: Parsed address as port 80, IP address 192.16.199.49
Composing Authorization for nic.nikhef.nl:80/user/a03/www/default/NikhefGuide.html
HTAASetup_lookup: No template matched `user/a03/www/default/NikhefGuide.html' (so probably not protected)
HTTP: Not sending authorization (yet)
HTTP connected, socket 4
HTTP Tx: GET /user/a03/www/default/NikhefGuide.html HTTP/1.0
Accept: www/source q=0.300
Accept: www/unknown q=0.300
Accept: application/octet-stream q=0.100
Accept: text/plain
Accept: text/html
Accept: image/jpeg
Accept: image/x-tiff
Accept: image/gif
Accept: application/postscript
User-Agent:  CERN-LineMode/2.12  libwww/2.13

HTTP: read returned 152 bytes.
HTTP: Rx: HTTP/1.0 500 Unable to access document.
WWW Alert:  HTTP server at nic.nikhef.nl replies:
HTTP/1.0 500 Unable to access document.
HTTP: close socket 4.
HTAccess: Can't access `http://nic.nikhef.nl/user/a03/www/default/NikhefGuide.html'
WWW Alert:  Unable to access document.

WWW: Can't access `http://nic.nikhef.nl/user/a03/www/default/NikhefGuide.html'
[nic] #[24] exit
script done on Tue Nov  9 14:00:45 1993

I probably do something terribly wrong, any suggestion is welcome.

Willem van Leeuwen



From CSP1DWD@mvs.oac.ucla.edu  Wed Nov 10 04:48:00 1993 PST
Message-Id: <9311101248.AA28670@dxmint.cern.ch>
Date: Wed, 10 Nov 93 04:48 PST
From: CSP1DWD@mvs.oac.ucla.edu (Denis DeLaRoca)
Subject: Re: Re: NCSA Mosaic for X 2.0 prerelease 8 available

>  Can't find ftp.ncsa.uiuc.edu:/Mosaic/prerelease ... Maybe I'm too
>  tired yet, but I think, there's no prerelease subdir.

Apparently, Mosaic 2.0 is now out (see the README file), thus the
pre-release directory is gone... Yeah for the 2.0 release!!!

-- Denis




From kny@tekla.fi  Wed Nov 10 15:09:31 1993 +0200
Message-Id: <9311101309.AA10267@kit.tekla.fi>
Date: Wed, 10 Nov 93 15:09:31 +0200
From: kny@tekla.fi (Kim Nyberg)
Subject: fork-execvp-kludge for xmosaic (2.0 pre 8)

Still missing the completely non-blocking i/o of erwise (RIP) I
decided to make a really ugly (DON'T try this at home kids) quick'n
dirty hack for xmosaic to simulate the erwise behaviour. When using
the middle button to open up a new window (following the new url)
the patched xmosaic forks off a new process and does an execvp
restarting itself with the new url as an argument.

Note that you have to remove Marc's #ifdef PRERELEASE in gui.c in
order to get xmosaic to load the requested url. The name of the binary
is hardcoded as "xmosaic", please change if needed.

Kim

Ps. Marc, feel free to include the patch in the next release, tho I
understand if you wont include it (it really is a dirty hack, but it made
xmosaic more useable for me)

Ps2. Of course I'm waiting for non-blocking multiple loads ... >:)

-- cut here --
*** gui.c~	Tue Nov  9 12:19:57 1993
--- gui.c	Wed Nov 10 14:11:58 1993
***************
*** 495,507 ****
        if (strncmp (url, "telnet:", 7) && strncmp (url, "tn3270:", 7) &&
            strncmp (url, "rlogin:", 7))
          {
            /* Not a telnet anchor. */
  
!           /* Open the window (generating a new cached_url). */
!           mo_open_another_window (win, url, reftext, target);
  
!           /* Now redisplay this window. */
!           mo_redisplay_window (win);
          }
        else
          /* Just do mo_load_window_text go get the xterm forked off. */
--- 495,522 ----
        if (strncmp (url, "telnet:", 7) && strncmp (url, "tn3270:", 7) &&
            strncmp (url, "rlogin:", 7))
          {
+ 	  int pid;
            /* Not a telnet anchor. */
  
! 	  pid = fork();
! 	  if (pid == (-1))
! 	  {
! 	      /* Open the window (generating a new cached_url). */
! 	      mo_open_another_window (win, url, reftext, target);
  
! 	      /* Now redisplay this window. */
! 	      mo_redisplay_window (win);
! 	  }
! 	  else
! 	      if (!pid)
! 	      {
! 		  char *argv[3];
! 
! 		  argv[0] = "xmosaic";
! 		  argv[1] = url;
! 		  argv[2] = NULL;
! 		  execvp("xmosaic", argv);
! 	      }
          }
        else
          /* Just do mo_load_window_text go get the xterm forked off. */
-- cut here --



From marca@ncsa.uiuc.edu  Wed Nov 10 00:24:12 1993 -0800
Message-Id: <9311100824.AA01715@wintermute.ncsa.uiuc.edu>
Date: Wed, 10 Nov 93 00:24:12 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: NCSA Mosaic for X 2.0 available

Ladies and gentlemen, start your engines...

NCSA Mosaic for X 2.0 is now available.

...ftp.ncsa.uiuc.edu in /Mosaic:

  o Source in /Mosaic/Mosaic-source.

  o Binaries for SunOS 4.1.3, Solaris (yup) 2.3, AIX 3.2, IRIX 4.x,
    DEC Alpha (OSF/1), DEC Ultrix, and HP/UX 9.x (700-series) in
    /Mosaic/Mosaic-binaries.

Thanks MUCH to all the prerelease testers who sent us feedback and bug
reports -- your help made 2.0 into a vastly better product than it
would otherwise have been and will no doubt continue to improve Mosaic
throughout 2.x's lifespan.

If you have any comments, questions, or problems with Mosaic 2.0,
please send mail to mosaic-x@ncsa.uiuc.edu.  Also please drop us a
note if you enjoy using Mosaic or if you are using it in any
interesting projects or applications -- we love to hear from our
users!

The remainder of this message is a text copy of 2.0's "Help on
Version" and summarizes important changes and new features in 2.0.

------------------------------------------------------------------------------
The online version of this document is:
http://www.ncsa.uiuc.edu/SDG/Software/Mosaic/Docs/help-on-version-2.0.html

Introduction to NCSA Mosaic for X 2.0
*************************************

This document is intended to serve as an introduction to NCSA Mosaic for
the X Window System version 2.0. It covers new features in version 2.0, and
changes from version 1.2, that will affect most users of Mosaic. 

For more information on any of the details in this document, please feel free
to send mail to mosaic-x@ncsa.uiuc.edu (or, alternately, to the World
Wide Web mailing list www-talk@info.cern.ch or the Usenet newsgroup 
comp.infosystems.www). 

Status Of Documentation For 2.0
===============================

We are currently writing real Mosaic 2.0 documentation; it isn't yet
available, for which we apologize. In the meantime, this document should at
least help current users of Mosaic 1.2 upgrade to 2.0 without too much pain. 

Potential Problems
==================

This section is an up-front listing of how Mosaic 2.0 is different than
Mosaic 1.2 in ways that may cause apparent trouble to existing 1.2 users. 

 o The Mosaic executable has been renamed Mosaic, and the new class
   name for Mosaic is, predictably, Mosaic. Existing Mosaic 1.2 X
   resources and application defaults files should be modified to match. 

 o The method by which you customize the viewers Mosaic uses for
   various datatypes (e.g. MPEG movies or PostScript documents) has 
   completely changed. 

   First, the multimedia X resources (e.g. gifViewerCommand) used
   by Mosaic 1.2 are totally ignored by Mosaic 2.0. (Trust me, this is
   really a good thing.) 

   Second, you now have complete control over the types of data
   Mosaic can understand and what it does with each type, as well as the
   file extensions that correspond to each type (when communicating
   with a HTTP0 or FTP server). 

   Third, Mosaic now uses the MIME typing mechanism for naming
   data types (e.g., the MIME type for a GIF image is image/gif).
   This provides a substantial amount of interoperability with the
   present and future of multimedia email on the Internet, but will
   require a little readjustment on the part of users who are used to
   simply calling GIF files "type GIF", etc. 

   For more information on these issues, see: 

    o Information on mapping MIME types to external viewers. 
    o Information on mapping file extensions to MIME types. 

 o Mosaic 2.0 speaks the HTTP/1.0 protocol, while Mosaic 1.2 spoke
   the pre-HTTP/1.0 protocol commonly referred to as "HTTP0" or
   "HTTP/0.9". 

   This means that Mosaic 2.0 sends more complex queries to HTTP
   servers than Mosaic 1.2 did. If you are running a fairly recent HTTP0
   server (e.g. NCSA httpd 0.5), this should not be a problem -- the new
   protocol is backward compatible, and Mosaic will go to great lengths
   to make sure it interacts with the HTTP0 server correctly. 

   However, some old HTTP servers (anything pre-1993) will break
   completely when sent a HTTP/1.0 query, and Mosaic 2.0 won't be
   able to make things work. Such servers are actually in violation of
   the final HTTP0 protocol specification and should at least be
   upgraded to conform to that specification, if not HTTP/1.0. 

 o HTTP/1.0 servers are by now (November 1993) fairly widespread,
   and many sites are using them without even realizing that they are
   HTTP/1.0 servers, because they also talk HTTP0 to clients (like
   Mosaic 1.2) that only talk HTTP0. 

   It is important to realize that HTTP/1.0 mandates server-side typing
   of files. This means that the server must recognize, for example, that
   the file extension ".gif" means that the file is a GIF image (i.e.,
   MIME type image/gif), and must communicate this information
   to the client within the HTTP/1.0 retrieval process. HTTP/1.0 clients
   like Mosaic 2.0 will not look at file extensions to determine file types
   when talking to HTTP/1.0 servers -- if the server gets the type
   wrong, the client will not look at the suffix to try to figure out the
   right type. 

   This means that if all of a sudden a file that Mosaic 1.2 always
   handled as an HTML document is handled by Mosaic 2.0 as if it is a
   binary data file, and the file is being served off an HTTP/1.0 server,
   the server is (almost surely) at fault for not informing the client of
   the correct type. 

   Related issue: Transparent uncompression is currently never done
   when talking to a HTTP/1.0 server. This will be fixed in a
   maintenance release. We do however discourage reliance on
   transparent uncompression in general, as clients on other platforms
   (e.g. NCSA Mosaic for the Mac & Windows) generally can't
   uncompress files compressed using the standard Unix methods (
   compress and gzip). 

   (Note to the skeptical: server-side typing is actually a powerful
   feature of HTTP/1.0, despite any migration problems it may cause.
   Also note that Mosaic 2.0 will still do file extension typing when
   talking to HTTP0 servers, so you can always continue to run a
   HTTP0 server in conjunction with Mosaic 2.0 if you prefer
   client-side typing.) 

 o Mosaic 2.0 does not have the hardcoded Documents and Manuals
   menus that were in Mosaic 1.2. They were removed for a number of
   reasons too boring to go into here. If, however, you find yourself
   "lost in cyberspace" because of the loss of those hardcoded menus,
   choose the "Internet Starting Points" entry in Mosaic 2.0's 
   Navigate menu -- Mosaic will fetch a document from NCSA that
   contains the contents of Mosaic 1.2's hardcoded menus in HTML
   form. 

   Also see the new "Internet Resources Meta-Index", also under
   Mosaic 2.0's Navigate menu, for an alternate set of Internet
   starting points perhaps more suitable to the task of locating any
   specific piece of information on the network. 

New Features In Mosaic 2.0
==========================

OK, this is the fun part. What will Mosaic 2.0 do for you? 

 o Completely interruptible I/O. At any point in a data transfer process
   (hostname lookups and certain stages of direct WAIS queries
   excepted), you can click on the icon in the upper right corner of the
   window to stop the current network action. 

 o Fill-out forms. As per the current HTML+ spec, documents can
   specify interactive fill-out forms -- with input elements including
   text entry areas, toggle buttons, selection lists, popup menus, etc. --
   and Mosaic will instantiate such fill-out forms as sets of Motif
   widgets embedded inside the documents. 

   This provides a way to provide arbitrarily sophisticated front-end
   interfaces to databases and search engines, as well as other network
   services -- e.g., ordering pizzas. 

   See details on fill-out forms. 

 o Authentication. Thanks to Ari Luotonen at CERN, Mosaic can now
   communicate properly with HTTP/1.0 servers that demand user
   authentication before accessing information -- the user is presented
   with an opportunity to enter a username and password to authenticate
   herself to the remote server. 

   Currently, the "BASIC" authentication scheme is supported, which
   provides for encoded (not cleartext, but not encrypted) transmission
   of password data across the network. This provides a level of security
   at least as secure as, e.g., telnet. 

   Once a user is authenticated on a particular server, Mosaic is smart
   about caching and reusing the authentication information in
   subsequent transactions with the same server in the same session --
   the user will be informed at any time the cached authentication fails
   and will be provided with the opportunity to enter a new username
   and password again. 

   See the CERN authentication overview for more information. 

 o Direct WAIS access. Mosaic can now talk directly to WAIS servers
   without needing to go through an intermediate gateway. This also
   means: 

    o Mosaic can cleanly retrieve and properly handle binary data
      (images, audio, video, etc.) as well as HTML documents from
      WAIS servers. Mosaic 2.0's normal customization
      mechanisms can be used to customize what happens when
      various types of binary data are accessed from WAIS servers. 
    o Mosaic natively supports freeWAIS's ability to tie together
      multiple data files with different formats under a single
      umbrella (e.g. as a result of a query across text, the user may
      be presented with her choice of text, image, or audio). 

   Examples of direct WAIS access: 

    o Direct access to CNIDR WAIS directory of servers. 
    o Direct access to InterNIC RFC WAIS server. 
    o A search on the term "MIME" in the InterNIC RFC WAIS
      server. 
    o RFC 1437 from the InterNIC RFC WAIS server. 

 o Full format/viewer/extension customizability, including the ability
   to allow local shell scripts to be launched from hyperlinks. 

   For more information, see: 

    o Information on mapping MIME types to external viewers. 
    o Information on mapping file extensions to MIME types. 
    o Information on allowing shell scripts to be executed via
      hyperlinks. 

 o Native viewing of HDF and netCDF scientific data files. Here are
   some examples: 

    o An HDF file of a galactic jet. 
    o A complex HDF file containing lots of different data
      elements, including hyperlinks within annotations. 
    o A netCDF file. 
    o An image of NCSA Director Larry Smarr. 
    o A huge (5+ megabytes) HDF file of satellite weather image
      and associated metadata. 

   Note: since it is possible for Mosaic 2.0 to be compiled without
   native HDF/netCDF viewing support, your particular copy may not
   be able to view the above examples. 

 o URL redirection. This means that a server can return, instead of a
   document, a pointer to a document anywhere on the Internet. When
   this happens, Mosaic will transparently attempt to fetch the new
   document. 

   Among other things, this enables clean graphical distributed
   information space mapping -- a single image map can have hotspots
   corresponding to information resources scattered throughout various
   information servers across the Internet, and the user can jump to any
   of those resources with a single mouse click. 

   For an example of URL redirection in conjunction with image
   mapping, see the experimental Internet Resources Metamap. 

 o Inlined image caching, including customizability of the amount of
   memory Mosaic will use to cache inlined images (default is 2048
   kilobytes). 

   Use the command line flag -ics or the X resource 
   imageCacheSize to set the size of the image cache in kilobytes. 

 o Delayed image loading, for users with slow network connections.
   Use the -dil command line option or set the delayImageLoads
   X resource to True to enable delayed image loading by default; it can
   be controlled on a per-window basis from Mosaic's Options
   menu. 

 o HTTP/1.0 support. In addition to enabling things like fill-out forms
   support, redirection, and authentication, this means that Mosaic can
   talk with the new breed of sophisticated HTTP/1.0 servers being
   deployed on the network to the fullest extent of their -- and
   Mosaic's -- ability. 

   See also the CERN HTTP/1.0 spec. 

 o Better hypermedia document display capabilities: 

    o Documents can be arbitrarily long now. 
    o Normal document text is formatted to the width of the visible
      window, not the width of the widest element (e.g. sections of
      preformatted text) in the document. 
    o Support for <BR> (line break) and <HR> (horizontal rule)
      tags. 
    o Sophisticated support for inlining Motif widgets into
      documents, which enables the fill-out forms support
      described above. 
    o Performance speedups. 

 o URL canonicalization -- a fancy way of saying that Mosaic strips
   redundant or useless information (like capital letters in hostnames,
   ":80" in HTTP queries and ":70" in Gopher queries, and trailing dots
   in hostnames) out of all URLs it accesses. This makes the global
   history tracking much more consistent by improving the odds that
   two slightly different URLs that point to the same document are
   recognized as identical by Mosaic. 

 o Improved system resource management -- many memory and socket
   leaks were fixed. Due to these fixes and the inlined image caching
   mentioned above, Mosaic should not be terribly hard on your system
   even if you use it for a long time now. 

 o Better PostScript output, including output of color inlined images. 

 o Cute little icons in Gopher and FTP interfaces. 

 o Enhanced remote control features, including ability to scroll through
   documents from shell scripts and cleanly fire off external viewers
   (e.g. images and audio). 

 o Mouse tracking -- see the URL for the hyperlink under the pointer. 

 o Menu item File->Refresh Current provides a convenient
   way to restore proper inlined image colors in a given window if the
   colors have been previously stolen for another window's inlined
   images -- keyboard accelerator (with pointer inside the scrolled
   document viewing window) is Capital-R. 

 o Configurable Documents menu, for local site configuration. 

 o Full compile-time customizability of home page, docs directory, and
   all other hardcoded URLs for sites without direct Internet access. 

 o Lots and lots of bug fixes and minor functionality and performance
   improvements. 

More Information
================

You may wish to look over an exhaustive list of technical changes that took
place during the development of Mosaic version 2.0. 

To take full advantage of Mosaic 2.0's capabilities, you should run a very
smart HTTP/1.0 server. We recommend NCSA httpd. If you prefer a
Perl-based server, try Plexus. Other options are CERN httpd and GN. 

mosaic-x@ncsa.uiuc.edu
------------------------------------------------------------------------------

Cheers,
Marc & Eric

--
Marc Andreessen & Eric Bina
Software Development Group
National Center for Supercomputing Applications
marca@ncsa.uiuc.edu & ebina@ncsa.uiuc.edu




From marca@ncsa.uiuc.edu  Wed Nov 10 04:01:39 1993 -0800
Message-Id: <9311101201.AA02513@wintermute.ncsa.uiuc.edu>
Date: Wed, 10 Nov 93 04:01:39 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: NCSA Mosaic for X 2.0 available

[This is a resend; NCSA experienced severe power and network problems
through early this morning, which seem to all be fixed now.]

Ladies and gentlemen, start your engines...

NCSA Mosaic for X 2.0 is now available.

...ftp.ncsa.uiuc.edu in /Mosaic:

  o Source in /Mosaic/Mosaic-source.

  o Binaries for SunOS 4.1.3, Solaris (yup) 2.3, AIX 3.2, IRIX 4.x,
    DEC Alpha (OSF/1), DEC Ultrix, and HP/UX 9.x (700-series) in
    /Mosaic/Mosaic-binaries.

Thanks MUCH to all the prerelease testers who sent us feedback and bug
reports -- your help made 2.0 into a vastly better product than it
would otherwise have been and will no doubt continue to improve Mosaic
throughout 2.x's lifespan.

If you have any comments, questions, or problems with Mosaic 2.0,
please send mail to mosaic-x@ncsa.uiuc.edu.  Also please drop us a
note if you enjoy using Mosaic or if you are using it in any
interesting projects or applications -- we love to hear from our
users!

The remainder of this message is a text copy of 2.0's "Help on
Version" and summarizes important changes and new features in 2.0.

------------------------------------------------------------------------------
The online version of this document is:
http://www.ncsa.uiuc.edu/SDG/Software/Mosaic/Docs/help-on-version-2.0.html

Introduction to NCSA Mosaic for X 2.0
*************************************

This document is intended to serve as an introduction to NCSA Mosaic for
the X Window System version 2.0. It covers new features in version 2.0, and
changes from version 1.2, that will affect most users of Mosaic. 

For more information on any of the details in this document, please feel free
to send mail to mosaic-x@ncsa.uiuc.edu (or, alternately, to the World
Wide Web mailing list www-talk@info.cern.ch or the Usenet newsgroup 
comp.infosystems.www). 

Status Of Documentation For 2.0
===============================

We are currently writing real Mosaic 2.0 documentation; it isn't yet
available, for which we apologize. In the meantime, this document should at
least help current users of Mosaic 1.2 upgrade to 2.0 without too much pain. 

Potential Problems
==================

This section is an up-front listing of how Mosaic 2.0 is different than
Mosaic 1.2 in ways that may cause apparent trouble to existing 1.2 users. 

 o The Mosaic executable has been renamed Mosaic, and the new class
   name for Mosaic is, predictably, Mosaic. Existing Mosaic 1.2 X
   resources and application defaults files should be modified to match. 

 o The method by which you customize the viewers Mosaic uses for
   various datatypes (e.g. MPEG movies or PostScript documents) has 
   completely changed. 

   First, the multimedia X resources (e.g. gifViewerCommand) used
   by Mosaic 1.2 are totally ignored by Mosaic 2.0. (Trust me, this is
   really a good thing.) 

   Second, you now have complete control over the types of data
   Mosaic can understand and what it does with each type, as well as the
   file extensions that correspond to each type (when communicating
   with a HTTP0 or FTP server). 

   Third, Mosaic now uses the MIME typing mechanism for naming
   data types (e.g., the MIME type for a GIF image is image/gif).
   This provides a substantial amount of interoperability with the
   present and future of multimedia email on the Internet, but will
   require a little readjustment on the part of users who are used to
   simply calling GIF files "type GIF", etc. 

   For more information on these issues, see: 

    o Information on mapping MIME types to external viewers. 
    o Information on mapping file extensions to MIME types. 

 o Mosaic 2.0 speaks the HTTP/1.0 protocol, while Mosaic 1.2 spoke
   the pre-HTTP/1.0 protocol commonly referred to as "HTTP0" or
   "HTTP/0.9". 

   This means that Mosaic 2.0 sends more complex queries to HTTP
   servers than Mosaic 1.2 did. If you are running a fairly recent HTTP0
   server (e.g. NCSA httpd 0.5), this should not be a problem -- the new
   protocol is backward compatible, and Mosaic will go to great lengths
   to make sure it interacts with the HTTP0 server correctly. 

   However, some old HTTP servers (anything pre-1993) will break
   completely when sent a HTTP/1.0 query, and Mosaic 2.0 won't be
   able to make things work. Such servers are actually in violation of
   the final HTTP0 protocol specification and should at least be
   upgraded to conform to that specification, if not HTTP/1.0. 

 o HTTP/1.0 servers are by now (November 1993) fairly widespread,
   and many sites are using them without even realizing that they are
   HTTP/1.0 servers, because they also talk HTTP0 to clients (like
   Mosaic 1.2) that only talk HTTP0. 

   It is important to realize that HTTP/1.0 mandates server-side typing
   of files. This means that the server must recognize, for example, that
   the file extension ".gif" means that the file is a GIF image (i.e.,
   MIME type image/gif), and must communicate this information
   to the client within the HTTP/1.0 retrieval process. HTTP/1.0 clients
   like Mosaic 2.0 will not look at file extensions to determine file types
   when talking to HTTP/1.0 servers -- if the server gets the type
   wrong, the client will not look at the suffix to try to figure out the
   right type. 

   This means that if all of a sudden a file that Mosaic 1.2 always
   handled as an HTML document is handled by Mosaic 2.0 as if it is a
   binary data file, and the file is being served off an HTTP/1.0 server,
   the server is (almost surely) at fault for not informing the client of
   the correct type. 

   Related issue: Transparent uncompression is currently never done
   when talking to a HTTP/1.0 server. This will be fixed in a
   maintenance release. We do however discourage reliance on
   transparent uncompression in general, as clients on other platforms
   (e.g. NCSA Mosaic for the Mac & Windows) generally can't
   uncompress files compressed using the standard Unix methods (
   compress and gzip). 

   (Note to the skeptical: server-side typing is actually a powerful
   feature of HTTP/1.0, despite any migration problems it may cause.
   Also note that Mosaic 2.0 will still do file extension typing when
   talking to HTTP0 servers, so you can always continue to run a
   HTTP0 server in conjunction with Mosaic 2.0 if you prefer
   client-side typing.) 

 o Mosaic 2.0 does not have the hardcoded Documents and Manuals
   menus that were in Mosaic 1.2. They were removed for a number of
   reasons too boring to go into here. If, however, you find yourself
   "lost in cyberspace" because of the loss of those hardcoded menus,
   choose the "Internet Starting Points" entry in Mosaic 2.0's 
   Navigate menu -- Mosaic will fetch a document from NCSA that
   contains the contents of Mosaic 1.2's hardcoded menus in HTML
   form. 

   Also see the new "Internet Resources Meta-Index", also under
   Mosaic 2.0's Navigate menu, for an alternate set of Internet
   starting points perhaps more suitable to the task of locating any
   specific piece of information on the network. 

New Features In Mosaic 2.0
==========================

OK, this is the fun part. What will Mosaic 2.0 do for you? 

 o Completely interruptible I/O. At any point in a data transfer process
   (hostname lookups and certain stages of direct WAIS queries
   excepted), you can click on the icon in the upper right corner of the
   window to stop the current network action. 

 o Fill-out forms. As per the current HTML+ spec, documents can
   specify interactive fill-out forms -- with input elements including
   text entry areas, toggle buttons, selection lists, popup menus, etc. --
   and Mosaic will instantiate such fill-out forms as sets of Motif
   widgets embedded inside the documents. 

   This provides a way to provide arbitrarily sophisticated front-end
   interfaces to databases and search engines, as well as other network
   services -- e.g., ordering pizzas. 

   See details on fill-out forms. 

 o Authentication. Thanks to Ari Luotonen at CERN, Mosaic can now
   communicate properly with HTTP/1.0 servers that demand user
   authentication before accessing information -- the user is presented
   with an opportunity to enter a username and password to authenticate
   herself to the remote server. 

   Currently, the "BASIC" authentication scheme is supported, which
   provides for encoded (not cleartext, but not encrypted) transmission
   of password data across the network. This provides a level of security
   at least as secure as, e.g., telnet. 

   Once a user is authenticated on a particular server, Mosaic is smart
   about caching and reusing the authentication information in
   subsequent transactions with the same server in the same session --
   the user will be informed at any time the cached authentication fails
   and will be provided with the opportunity to enter a new username
   and password again. 

   See the CERN authentication overview for more information. 

 o Direct WAIS access. Mosaic can now talk directly to WAIS servers
   without needing to go through an intermediate gateway. This also
   means: 

    o Mosaic can cleanly retrieve and properly handle binary data
      (images, audio, video, etc.) as well as HTML documents from
      WAIS servers. Mosaic 2.0's normal customization
      mechanisms can be used to customize what happens when
      various types of binary data are accessed from WAIS servers. 
    o Mosaic natively supports freeWAIS's ability to tie together
      multiple data files with different formats under a single
      umbrella (e.g. as a result of a query across text, the user may
      be presented with her choice of text, image, or audio). 

   Examples of direct WAIS access: 

    o Direct access to CNIDR WAIS directory of servers. 
    o Direct access to InterNIC RFC WAIS server. 
    o A search on the term "MIME" in the InterNIC RFC WAIS
      server. 
    o RFC 1437 from the InterNIC RFC WAIS server. 

 o Full format/viewer/extension customizability, including the ability
   to allow local shell scripts to be launched from hyperlinks. 

   For more information, see: 

    o Information on mapping MIME types to external viewers. 
    o Information on mapping file extensions to MIME types. 
    o Information on allowing shell scripts to be executed via
      hyperlinks. 

 o Native viewing of HDF and netCDF scientific data files. Here are
   some examples: 

    o An HDF file of a galactic jet. 
    o A complex HDF file containing lots of different data
      elements, including hyperlinks within annotations. 
    o A netCDF file. 
    o An image of NCSA Director Larry Smarr. 
    o A huge (5+ megabytes) HDF file of satellite weather image
      and associated metadata. 

   Note: since it is possible for Mosaic 2.0 to be compiled without
   native HDF/netCDF viewing support, your particular copy may not
   be able to view the above examples. 

 o URL redirection. This means that a server can return, instead of a
   document, a pointer to a document anywhere on the Internet. When
   this happens, Mosaic will transparently attempt to fetch the new
   document. 

   Among other things, this enables clean graphical distributed
   information space mapping -- a single image map can have hotspots
   corresponding to information resources scattered throughout various
   information servers across the Internet, and the user can jump to any
   of those resources with a single mouse click. 

   For an example of URL redirection in conjunction with image
   mapping, see the experimental Internet Resources Metamap. 

 o Inlined image caching, including customizability of the amount of
   memory Mosaic will use to cache inlined images (default is 2048
   kilobytes). 

   Use the command line flag -ics or the X resource 
   imageCacheSize to set the size of the image cache in kilobytes. 

 o Delayed image loading, for users with slow network connections.
   Use the -dil command line option or set the delayImageLoads
   X resource to True to enable delayed image loading by default; it can
   be controlled on a per-window basis from Mosaic's Options
   menu. 

 o HTTP/1.0 support. In addition to enabling things like fill-out forms
   support, redirection, and authentication, this means that Mosaic can
   talk with the new breed of sophisticated HTTP/1.0 servers being
   deployed on the network to the fullest extent of their -- and
   Mosaic's -- ability. 

   See also the CERN HTTP/1.0 spec. 

 o Better hypermedia document display capabilities: 

    o Documents can be arbitrarily long now. 
    o Normal document text is formatted to the width of the visible
      window, not the width of the widest element (e.g. sections of
      preformatted text) in the document. 
    o Support for <BR> (line break) and <HR> (horizontal rule)
      tags. 
    o Sophisticated support for inlining Motif widgets into
      documents, which enables the fill-out forms support
      described above. 
    o Performance speedups. 

 o URL canonicalization -- a fancy way of saying that Mosaic strips
   redundant or useless information (like capital letters in hostnames,
   ":80" in HTTP queries and ":70" in Gopher queries, and trailing dots
   in hostnames) out of all URLs it accesses. This makes the global
   history tracking much more consistent by improving the odds that
   two slightly different URLs that point to the same document are
   recognized as identical by Mosaic. 

 o Improved system resource management -- many memory and socket
   leaks were fixed. Due to these fixes and the inlined image caching
   mentioned above, Mosaic should not be terribly hard on your system
   even if you use it for a long time now. 

 o Better PostScript output, including output of color inlined images. 

 o Cute little icons in Gopher and FTP interfaces. 

 o Enhanced remote control features, including ability to scroll through
   documents from shell scripts and cleanly fire off external viewers
   (e.g. images and audio). 

 o Mouse tracking -- see the URL for the hyperlink under the pointer. 

 o Menu item File->Refresh Current provides a convenient
   way to restore proper inlined image colors in a given window if the
   colors have been previously stolen for another window's inlined
   images -- keyboard accelerator (with pointer inside the scrolled
   document viewing window) is Capital-R. 

 o Configurable Documents menu, for local site configuration. 

 o Full compile-time customizability of home page, docs directory, and
   all other hardcoded URLs for sites without direct Internet access. 

 o Lots and lots of bug fixes and minor functionality and performance
   improvements. 

More Information
================

You may wish to look over an exhaustive list of technical changes that took
place during the development of Mosaic version 2.0. 

To take full advantage of Mosaic 2.0's capabilities, you should run a very
smart HTTP/1.0 server. We recommend NCSA httpd. If you prefer a
Perl-based server, try Plexus. Other options are CERN httpd and GN. 

mosaic-x@ncsa.uiuc.edu
------------------------------------------------------------------------------

Cheers,
Marc & Eric

--
Marc Andreessen & Eric Bina
Software Development Group
National Center for Supercomputing Applications
marca@ncsa.uiuc.edu & ebina@ncsa.uiuc.edu




From brian@eit.COM  Wed Nov 10 11:07:11 1993 PST
Message-Id: <9311101107.ZM4334@eitech.com>
Date: Wed, 10 Nov 93 11:07:11 PST
From: brian@eit.COM (Brian Smithson)
Subject: Re: xmosaic command line arg for geometry

On Nov 7,  6:51pm, rhb@hotsand.att.com wrote:
> Subject: xmosaic command line arg for geometry
> Is there an xmosaic command line arg for geometry?  I've tried the
> typical xterm arg, which don't seem to work and I can't find reference
> to it in any of the documentation.  
> 
> Rich
>-- End of excerpt from rhb@hotsand.att.com

Just last weekend, I had a desperate need to control geometry for a
self-running demo on Monday :-).  I tried just about everything, and
found a way to do it.

In app-defaults, or .Xdefaults, or (as I did) merged into xrdb, set the
following X resource:

XMosaic*geometry: WxH+X+Y

where W, H, X, and Y are the usual parameters for a -geometry command line
argument.

-- 
-Brian Smithson                                             brian@eit.com
 Enterprise Integration Technologies                      +1 415 617 8009
 459 Hamilton Avenue, Palo Alto, CA 94301 USA         FAX +1 415 617 8019



From wmperry@indiana.edu  Wed Nov 10 16:20:00 1993 +0000
Message-Id: <2943.752948400@tartarus.uwa.edu.au>
Date: Wed, 10 Nov 1993 16:20:00 +0000
From: wmperry@indiana.edu (William M. Perry,,855-2896,331-9062)
Subject: Xmosaic 2.0 for linux?

Any kind soul out there feel like compiling a Mosaic 2.0 binary for
linux?  It would be greatly appreciated. :)

Just wondering,
   Bill P.



From marca@ncsa.uiuc.edu  Thu Nov 11 00:38:54 1993 -0800
Message-Id: <9311110838.AA07211@wintermute.ncsa.uiuc.edu>
Date: Thu, 11 Nov 93 00:38:54 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: notes on 2.0 binaries

Please read the following, particularly re Solaris and IBM binaries.
Feedback on whether Mosaic-ibm-static even works on non-AIX 3.2.4
systems would be greatly appreciated.

Cheers,
Marc

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Summary of availability and features of NCSA-supplied Mosaic 2.0 binaries
-------------------------------------------------------------------------

ftp://ftp.ncsa.uiuc.edu/Mosaic/Mosaic-binaries

  -rwxr-xr-x  1 11811    wsstaff    756381 Nov 10 05:44 Mosaic-alpha.Z
  -rwxr-xr-x  1 11811    wsstaff   1995413 Nov 10 05:44 Mosaic-dec.Z
  -rwxr-xr-x  1 11811    wsstaff   1719076 Nov 10 05:44 Mosaic-hp700.Z
  -rwxr-xr-x  1 11811    wsstaff   1859677 Nov 11 06:30 Mosaic-ibm-static.Z
  -rwxr-xr-x  1 11811    wsstaff   2924967 Nov 10 05:45 Mosaic-ibm.Z
  -rwxr-xr-x  1 11811    wsstaff   1442979 Nov 10 06:00 Mosaic-sgi.Z
  -rwxr-xr-x  1 11811    1         1502779 Nov 10 18:52 Mosaic-solaris.Z
  -rwxr-xr-x  1 11811    wsstaff   2606677 Nov 10 05:45 Mosaic-sun-lresolv.Z
  -rwxr-xr-x  1 11811    wsstaff   2589890 Nov 10 05:46 Mosaic-sun.Z

Mosaic-alpha:           DEC Alpha, OSF/1 version 1.3.
                        No DTM, no HDF, no native WAIS.
Mosaic-dec:             DEC MIPS, Ultrix 4.0.
                        DTM, HDF, no native WAIS.
Mosaic-hp700:           HP 9000/730, HP-UX 9.01.
                        No DTM, HDF, no native WAIS.
Mosaic-ibm:             IBM RS/6000, AIX 3.2.4, X11R5.
                        DTM, HDF, native WAIS.
Mosaic-ibm-static:      IBM RS/6000, AIX 3.2.4, linked static.
                        DTM, HDF, native WAIS.
                        NOTE: This binary is an experiment; please
                              give it a shot if the normal Mosaic-ibm
                              doesn't work on your system and let us
                              know how it goes.  There seem to be
                              spurious error messages printed in the
                              shell window when this binary is run;
                              they don't seem to affect the program's
                              functionality.
                              Also note that this binary is the only
                              one not compiled with debugging enabled,
                              as the debugging binary was over 11
                              megabytes.
Mosaic-sgi:             SGI IRIX 4.0.x.
                        DTM, HDF, native WAIS.
Mosaic-solaris:         Sun Solaris 2.3.
                        No DTM, no HDF, no native WAIS.
                        NOTE: You may need to set the environment
                              variable XKEYSYMDB to point to the 
                              XKeysymDB file on your system when
                              running this binary.
Mosaic-sun-lresolv:     Sun SunOS 4.1.3, linked to system libresolv.a.
                        DTM, HDF, native WAIS.
Mosaic-sun:             Sun SunOS 4.1.3.
                        DTM, HDF, native WAIS.
                        NOTE: If Mosaic-sun does not work on your
                              particular system, you should try
                              Mosaic-sun-lresolv instead (unless you
                              are running Solaris; then you should run
                              Mosaic-solaris).

All Mosaic binaries -- except Mosaic-ibm-static -- are compiled with
debugging (-g) enabled, so users can send us a core traceback if a
coredump should happen to occur.  If you wish, you may strip the
binaries; however, you will then be unable to help us if something
goes wrong, and we may not be able to fix any bugs you encounter.

Note that it is relatively straightforward to compile Mosaic yourself
on, in particular, SGI, IBM, and DEC Alpha systems as shipped by the
respective vendors.

Note further that we may stop distributing any of these binaries at
any time.

mosaic-x@ncsa.uiuc.edu

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~




From decoux@moulon.inra.fr  Thu Nov 11 09:28:31 1993 +0100
Message-Id: <9311110828.AA04063@moulon.moulon.inra.fr>
Date: Thu, 11 Nov 93 09:28:31 +0100
From: decoux@moulon.inra.fr (ts)
Subject: NCSA Mosaic for X 2.0 available


> For Method = POST
> 
> The contents of the form are encoded exactly as with the GET method (above), but
> rather than appending them to the URL specified by the form's ACTION attribute as a
> query, the contents are sent in a data block as part of the POST operation. The 
> ACTION attribute (if any) is the URL to which the data block is POSTed. 
> 
> 

 Why not, like SMTP, terminate the message with a '.'

 Thanks for this release,

Guy Decoux




From jfg@infodesign.ch  Thu Nov 11 01:27:48 1993 +0100
Message-Id: <9311110027.AA00660@infodesign.ch>
Date: Thu, 11 Nov 93 01:27:48 +0100
From: jfg@infodesign.ch (Jean-Francois Groff)
Subject: Re: Clicks inside a polygon

>>> On Tue, November 9, Ari Luotonen said:
 > 
 > Is there a public domain implementation of resolving if a point
 > is inside or outside of a polygon such that it could be part of
 > the CERN daemon distribution.

  Here is the algorithm used by PostScript, which is to my knowledge
the best combination of reliability and ease of coding :

  From the point to test, draw a line in any direction. Count the
times the path of the shape crosses this line. Add 1 each time the
path crosses your line from left to right, substract 1 each time it
crosses it from right to left. If the result is non-zero, the point is
inside the path. If a path segment happens to be tangent or colinear
to your test line, change the direction of that line and try again.

  This algorithm works for any kind of shape, not just polygons, and
even if the drawing path crosses itself (e.g. when you draw a 5-branch
star in one stroke with just five lines). With doughnut-like shapes,
points inside the doughnut hole are considered outside the doughnut
iff the interior path is drawn in the opposite direction of the
exterior path. For more details, read the Postscript Reference Manual
(a.k.a. Red Book), second edition, section 4.5.2. "Filling".

  In the case of polygons, I can implement it for you if you like, as
I already have routines to check line intersections.

  Till later...

	Jean-Francois




From sanders@bsdi.com  Thu Nov 11 10:29:35 1993 -0600
Message-Id: <9311111629.AA06620@austin.BSDI.COM>
Date: Thu, 11 Nov 1993 10:29:35 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: NCSA Mosaic for X 2.0 available 

marca talks about:
> > For Method = POST
Guy writes:
>  Why not, like SMTP, terminate the message with a '.'

That would mean no real binary data.  We don't want HTTP to be as crippled
as mail transport agents.

--sanders



From dcmartin@library.ucsf.edu  Thu Nov 11 11:29:06 1993 PST
Message-Id: <199311111929.AA01798@library.ucsf.edu>
Date: Thu, 11 Nov 1993 11:29:06 PST
From: dcmartin@library.ucsf.edu (David C. Martin)
Subject: Re: notes on 2.0 binaries 

The source code for Mosaic 2.0 is also available on ftp.library.ucsf.edu
in pub/NCSA.  Please feel free to access this copy to alleviate some
burden on ftp.ncsa.uiuc.edu.

dcm



From cheung@eplrx7.es.dupont.com  Thu Nov 11 18:39:17 1993 EST
Message-Id: <9311112339.AA13719@eplrx7.es.duPont.com>
Date: Thu, 11 Nov 93 18:39:17 EST
From: cheung@eplrx7.es.dupont.com (Bryan Cheung)
Subject: Socially correct URLs for archived RFCs

    I am considering writing a program to automagically hypertexify RFC 1540,
which is the listing/description of all the Internet official protocol 
standards. If I were to make URL references to all the other RFCs discussed
in RFC 1540 so that they pointed to Internet anonymous FTP sites which
archive RFCs, which site(s) should I refer to??? Any volunteers?? Has 
anyone already done this??
    On another note, once the above task has been completed, does anyone
want to volunteer to house the beast?? Depending on the complexity of the
problem I may just decide to hypertexify the RFC index, but the same questions
apply.
            Any and all comments are appreciated,
                      

                              -- Bryan Cheung
                                 cheung@eplrx7.es.dupont.com





From kevinh@pulua.hcc.hawaii.edu  Thu Nov 11 14:09:34 1993 HST
Message-Id: <9311120009.AA08128@pulua.hcc.Hawaii.Edu>
Date: Thu, 11 Nov 93 14:09:34 HST
From: kevinh@pulua.hcc.hawaii.edu (Kevin 'Kev' Hughes)
Subject: Re: Clicks inside a polygon

> Is there a public domain implementation of resolving if a point
> is inside or outside of a polygon such that it could be part of
> the CERN daemon distribution.

	Look at the function that does that at

http://pulua.hcc.hawaii.edu/files/mapper.c

	...or ask Dave Raggett, I believe he's tacking that code at the
end of the HTML+ DTD in an appendix. The function was worked on by a man
who does some heavy computer graphics work - he's analyzed many such functions,
and this one has proven itself to be one of the best. It has been featured
in the online "Raytracing News", and it is publicly distributable.
	And one nice thing is, you don't need anything above integer math
for it.

	-- Kevin



From peveritt@pandora.ncts.navy.mil  Thu Nov 11 18:53:54 1993 +0600
Message-Id: <9311120053.AA05706@voltaire.ncts.navy.mil>
Date: Thu, 11 Nov 1993 18:53:54 +0600
From: peveritt@pandora.ncts.navy.mil (Paul Everitt)
Subject: Re: field "METHOD" in "<FORM>"


Guy--

I saw your email a while back.  I am *VERY* interested in using
HTML+ forms as a front end to Sybase.  I am trying to explain it
to my Sybase programmer, but I'm not sure what is involved.  What
is it on the server side that you are using to pass your data
from the form to the database?

--Paul


 Hello,

 I want to update a database, and to do it I need a new field "METHOD" in
the tag "<FORM>". Example :

  - <FORM ACTION="table name"> to retrieve a row (default value "GET")
  - <FORM METHOD="PUT" ACTION="table name"> to update a row
  - <FORM METHOD="POST" ACTION="table name"> to add a row
  - <FORM METHOD="DELETE" ACTION="table name"> to delete a row

 Any other ideas ?

 Thanks,

Guy Decoux



From romig@cis.ohio-state.edu  Fri Nov 12 00:08:56 1993 -0500
Message-Id: <9311120508.AA00868@allosaur.cis.ohio-state.edu>
Date: Fri, 12 Nov 93 00:08:56 -0500
From: romig@cis.ohio-state.edu (Steve Romig)
Subject: Socially correct URLs for archived RFCs

We've already written some scripts that convert rfcs, iens, faqs,
emacs info and man pages to html - see
ftp.cis.ohio-state.edu:/pub/www/cis.tar.Z for the code.  The servers
are running on www.cis.ohio-state.edu - I'm in the process of
converting everything to be http/1.0 compliant (all done but waisgate)
and am moving things to a different server (which will become
www.cis.ohio-state.edu when I am done), so its a bit flaky at the
moment.

See
http://www.cis.ohio-state.edu:80/hypertext/information/information.html
for pointers to these things (and more).  Note that if you are using a
client that uses http/1.0, keyword searches through our waisgate won't
work yet.  Sigh...

--- Steve
 



From romig@cis.ohio-state.edu  Fri Nov 12 00:11:52 1993 -0500
Message-Id: <9311120511.AA00876@allosaur.cis.ohio-state.edu>
Date: Fri, 12 Nov 93 00:11:52 -0500
From: romig@cis.ohio-state.edu (Steve Romig)
Subject: Socially correct URLs for archived RFCs

Blast, just noticed that our rfc archive is out of date, and doesn't
include 1540.  I'll have to fix that also...

--- Steve



From decoux@moulon.inra.fr  Fri Nov 12 06:30:43 1993 +0100
Message-Id: <9311120530.AA10415@moulon.moulon.inra.fr>
Date: Fri, 12 Nov 93 06:30:43 +0100
From: decoux@moulon.inra.fr (ts)
Subject: field "METHOD" in "<FORM>"


> I saw your email a while back.  I am *VERY* interested in using
> HTML+ forms as a front end to Sybase.  I am trying to explain it
> to my Sybase programmer, but I'm not sure what is involved.  What
> is it on the server side that you are using to pass your data
> from the form to the database?

 Hello,

 I use Oracle Precompilers.

 Example :

 When server receive :

/oracle/A/update/PROJETS?action=update&selection=ROWID%3D%27000002BF.0000.0003%27&PROJET=P145&TYPE=type+P1

 C program is something like this :

  putenv("ORACLE_SID=A");
  putenv("ORACLE_HOME=/usr/local/oracle");
  EXEC SQL CONNECT :username IDENTIFIED BY :password;
  strcpy(tmp,"UPDATE PROJETS SET (PROJET='P145',TYPE='type P1') WHERE ROWID='000002BF.0000.0003'");
  EXEC SQL EXECUTE IMMEDIATE :tmp;
  EXEC SQL COMMIT WORK RELEASE;


 Actually, it is a beta test version. When all is well, I put the complete
source of this interface on "moulon.inra.fr" in directory "/pub/www-oracle"

Guy Decoux



From sanders@bsdi.com  Thu Nov 11 23:48:35 1993 -0600
Message-Id: <9311120548.AA10216@austin.BSDI.COM>
Date: Thu, 11 Nov 1993 23:48:35 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: httpd scripts for WAIS queries. 

In comp.infosystems.www I mused over the fact that we need a unified format
for all servers to pass data to external gateway code so all servers
(Plexus, NCSA, CERN at least) could share then (there is hope that Plexus
gateways will soon/eventually be easy to use with NCSA's /htbin stuff).

George Phillips asked in email (spuring me to complete my thoughts :-):
> Anyhow, do you have a list of information the main plexus code
> determines?  If so, maybe we can propose a option standard for
> external servers.

You need to deal with methods like POST that have contents in addition to
the HTTP/1.0 headers.  My suggestion is to pass most information to the
script via STDIN due to command line length limitations (alternatively we
could stuff it in a file and pass a pointer but that seems like a bad idea
for a number of reasons).  However, some things are best passed via
the command line for ease of use.

So here is a summary of the values you need access to (obviously, not
all scripts need all of these):
    Protocol		; http (gopher, etc)
    Method		; GET/PUT/POST/...
    URL			; split into various pieces include the query part
    Version		; HTTP/0.9 or HTTP/1.0
    Port		; port number this request came in (for multiport)
    Peeraddr		; ip address/hostname of requesting host
    Authuser		; special case of request header, may be anonymous
                        ; this is the username of the authenticate user
    Content-type	; another special case of request header

    Request Headers	; probably passed via stdin
    Content		; if any -- probably passed via stdin

So we could go with:

    STDIN:
        Request headers followed by blank line (the standard mail header)
        Content
    Command line:
        command -p protocol -m method -u url/path -v version -i port
                -a peeraddr -n username -c content-type

Another issue is who outputs what information (e.g., who writes the HTTP/1.0
header).  I vote that the gateway should be responsible for all output.
The reason for this is that it is then very easy for the server to step
in the middle and perform special processing (like format conversion),
without any special cases needed in the gateway code.

Further down the road perhaps we need to "type" the external code so
we can have internal conversions to various types/versions of them.
For example, we already have the /htbin standard, so the server could
continue to support existing /htbin scripts.  The above could become
/htbin_plus or something.  This way we can evolve the standards as
requirements change and not break anything along the way.

Comments/suggestions welcome.

This document is online:
    http://www.bsdi.com/HTTP:TNG/ext-gateway.txt

--sanders



From Lars-Gunnar.Olsson@data.slu.se  Fri Nov 12 13:19:34 1993 +0100
Message-Id: <199311121219.AA13255@pinus.slu.se>
Date: Fri, 12 Nov 1993 13:19:34 +0100
From: Lars-Gunnar.Olsson@data.slu.se (Lars-Gunnar Olsson)
Subject: Re: notes on 2.0 binaries 

For those of you who are trying to get from Europe you are welcome to get it
from ftp.sunet.se under /pub/www/Mosaic instead (this goes for the Mac and PC
versions as well).

/L-G



From kchang@ncsa.uiuc.edu  Fri Nov 12 10:28:18 1993 CST
Message-Id: <9311121628.AA27380@landrew.ncsa.uiuc.edu>
Date: Fri, 12 Nov 93 10:28:18 CST
From: kchang@ncsa.uiuc.edu (Kenneth Chang)
Subject: Rendering <KBD>

On a somewhat less technical issue, I wanted to recommend to browser
authors that, when possible, <KBD> be rendered in the bold version of the
monospace font. This would be immensely helpful for those us who write
manuals and who write stuff like

At the login prompt, enter ``anonymous'' and your e-mail address for
the password:
<p>
<pre>
220 zaphod FTP server
Name (ftp:user): <kbd>anonymous</kbd>
Password:<kbd>user@computer</kbd>
</pre>

Putting user input in bold helps distinguish it from screen output (i.e.
sytem prompts, status messages, etc.)

--ken chang
  NCSA Publications





From guenther.fischer@hrz.tu-chemnitz.de  Fri Nov 12 18:26:41 1993 +0100 (MET)
Message-Id: <9311121726.AA05941@flash1.hrz.tu-chemnitz.de>
Date: Fri, 12 Nov 1993 18:26:41 +0100 (MET)
From: guenther.fischer@hrz.tu-chemnitz.de (Guenther Fischer)
Subject: I want have "Last-modified:" in HTTP/1.0 headers

Hi,
I've set up a simple cache server based on Tony Sanders plexus 3.0.

I'll give this work to a student to make it better - my own time slices
for such a work are too small.

To do this right I need some informations from "real" servers.

 - Tony has give me the Last-Modified: header line, but I need this from
   other servers too - please HELP
 - Tony has give me the HEAD command - it'a a small work in the server
   and better than do GET and break the connection

On the client side I need the WWW_html_gateway definition like in Mosaic -
I hope other clients have th same feature.

What I've done till now:

- I only cache HTTP/1.0 servers and I configure a server list to cache.
  For other servers it works as a put throught gateway.
- I also can configure types of documents to cache.
- I count using for caching algorithsm

What we will do next:

Server:

- reGET documents after a resonable time (configurable for types - I think
  gifs have another TTL than htmls ...

  (here I need the Last-modified: - Please - I think it's more than the Date:
  all HTTP/1.0 servers give me. HEAD would help)

  So we could:
	if ( TimeToLive is "OUT" )  # after 1 day or so ...
		&reGET(...) unless &HEAD_is_uptodate();
	&wrap_from_cache();	

Tool to clean the cache:

- walk throught the cache and decide to
	- hold or (HEAD says up to date)
	- reget or (HEAD says out of date)
	- remove from cache. (documents with small usage)

  Do this at a nice time (night or weekend or ...)

SERVER-IMPLEMENTORS! give me the needed information.

	~Guenther
-- 
Name:      Guenther Fischer
Institute: TU Chemnitz, Universitaetsrechenzentrum
Phone:     0371 668 361
mail:      fischer@hrz.tu-chemnitz.de



From robm@ncsa.uiuc.edu  Fri Nov 12 13:02:25 1993 -0600
Message-Id: <9311121902.AA20950@void.ncsa.uiuc.edu>
Date: Fri, 12 Nov 1993 13:02:25 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: I want have "Last-modified:" in HTTP/1.0 headers

/*
 * I want have "Last-modified:" in HTTP/1.0 headers  by Guenther Fischer (guenther.fischer@hrz.tu-chemnitz.de)
 *    written on Nov 12,  6:26pm.

[...]

 *  - Tony has give me the Last-Modified: header line, but I need this from
 *    other servers too - please HELP
 *  - Tony has give me the HEAD command - it'a a small work in the server
 *    and better than do GET and break the connection

It's in the forthcoming release of NCSA httpd.

 * SERVER-IMPLEMENTORS! give me the needed information.
 */

NCSA httpd will be returning content-length, content-type, and last-modified
where applicable. 

--Rob



From putz@parc.xerox.com  Fri Nov 12 11:40:01 1993 PST
Message-Id: <93Nov12.114016pst.2445@spoggles.parc.xerox.com>
Date: Fri, 12 Nov 1993 11:40:01 PST
From: putz@parc.xerox.com (Steve Putz)
Subject: Re: I want have "Last-modified:" in HTTP/1.0 headers

Guenther,

Beware of HTTP servers that are really *gateways* to information you
may not want to cache.  I have two such servers:

	http://pubweb.parc.xerox.com/map
and
	http://web2.xerox.com/digitrad

Both are front ends to large databases where it makes little sense to
cache.  However both servers also have a small and fairly static
hierarchy of HTML documents as well, under:

	http://pubweb.parc.xerox.com/hypertext
and
	http://web2.xerox.com/docs

Can your cache server be configured to know the difference?

Note that my servers have not yet been upgraded to HTTP/1.0, but they
will be eventually.

Steve Putz
Xerox PARC
 



From reinpost@info.win.tue.nl  Fri Nov 12 21:08:32 1993 MET
Message-Id: <199311122008.VAA09219@wsinis10.info.win.tue.nl>
Date: Fri, 12 Nov 93 21:08:32 MET
From: reinpost@info.win.tue.nl (Reinier Post)
Subject: Re: I want have "Last-modified:" in HTTP/1.0 headers

You (Guenther Fischer) write:
>
>Hi,
>I've set up a simple cache server based on Tony Sanders plexus 3.0.

Great!

(If only our security man would allow us to run perl on a WWW port ...)

Mine is very VERY simple and still contains bugs, but it is sufficient for
grabbing part of WWW to give a demo on a standalone machine, which is
its main reason of existence.  It is in C and works with of NCSA httpd.

-- 
Reinier Post						 reinpost@win.tue.nl
a.k.a. <A HREF="http://www.win.tue.nl/cs/is/reinpost/reinier.E.html">me</A>



From sanders@bsdi.com  Fri Nov 12 14:31:08 1993 -0600
Message-Id: <9311122031.AA12623@austin.BSDI.COM>
Date: Fri, 12 Nov 1993 14:31:08 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: I want have "Last-modified:" in HTTP/1.0 headers 

Reinier Post's message:
> (If only our security man would allow us to run perl on a WWW port ...)

That's funny since perl code is generally much more secure than C code.
It doesn't have any of the stupid problems like fingerd did for the
internet worm.

--sanders



From mvanheyn@cs.indiana.edu  Fri Nov 12 15:43:33 1993 -0500
Message-Id: <5654.753137013@frilled.cs.indiana.edu>
Date: Fri, 12 Nov 1993 15:43:33 -0500
From: mvanheyn@cs.indiana.edu (Marc VanHeyningen)
Subject: Re: I want have "Last-modified:" in HTTP/1.0 headers 

Thus wrote: Steve Putz
>Guenther,
>
>Beware of HTTP servers that are really *gateways* to information you
>may not want to cache.  I have two such servers:
>
>	http://pubweb.parc.xerox.com/map
>and
>	http://web2.xerox.com/digitrad
>
>Both are front ends to large databases where it makes little sense to
>cache.  However both servers also have a small and fairly static
>hierarchy of HTML documents as well, under:
>
>	http://pubweb.parc.xerox.com/hypertext
>and
>	http://web2.xerox.com/docs
>
>Can your cache server be configured to know the difference?

Short of having every example of a gateway coded in, how could a cache
server possibly tell the difference?

Rhetorical question.  Answer:  The Expires: header.  It's the
responsibility of the server to make available an indication of how
long that information will remain "current".

- Marc
--
Marc VanHeyningen  mvanheyn@cs.indiana.edu  MIME, RIPEM & HTTP spoken here



From sanders@bsdi.com  Fri Nov 12 14:53:44 1993 -0600
Message-Id: <199311122053.OAA12776@austin.BSDI.COM>
Date: Fri, 12 Nov 1993 14:53:44 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: I want have "Last-modified:" in HTTP/1.0 headers 

> Beware of HTTP servers that are really *gateways* to information you
> may not want to cache.  I have two such servers:
The way to solve this is to #1 run an HTTP/1.0 server and #2
define a mechanism so that the client/gateway can know this,
perhaps using the already defined Expires: header.  At any rate,
it's the job of the server to contain this information.

That said, I see no reason not to cache at least the map server.
If it's not used much the cache should expire rapidly.

--sanders



From putz@parc.xerox.com  Fri Nov 12 13:39:16 1993 PST
Message-Id: <93Nov12.133922pst.2445@spoggles.parc.xerox.com>
Date: Fri, 12 Nov 1993 13:39:16 PST
From: putz@parc.xerox.com (Steve Putz)
Subject: Re: I want have "Last-modified:" in HTTP/1.0 headers

Marc VanHeyningen <mvanheyn@cs.indiana.edu> wrote:
>
> Short of having every example of a gateway coded in, how could a cache
> server possibly tell the difference?
> 
> Rhetorical question.  Answer:  The Expires: header.  It's the
> responsibility of the server to make available an indication of how
> long that information will remain "current".

Is that what we want "Exipres" to mean?   In both my examples, the
information from the gateways does not expire or become obsolete.
Rather I was suggesting that the likelyhood of a cache hit can be small
because the virtual information space is so large.

For example, users will rarely click on the exact same latitude and
longitude in the map viewer, and the cost of caching the resulting GIF
image is high.  On the other hand if someone widely publishes a URL for
a particular map, caching makes sense.

My point is that choosing caching strategies becomes more difficult as
the information space gets richer.  The Expires: header does not really
solve the problem.

Steve Putz
Xerox PARC



From WIGGINS@msu.edu  Fri Nov 12 16:48:31 1993 EST
Message-Id: <9311122152.AA05157@dxmint.cern.ch>
Date: Fri, 12 Nov 93 16:48:31 EST
From: WIGGINS@msu.edu (Rich Wiggins)
Subject: Turning off a sound that you've started

Back in March, when Tim Berners-Lee gave me a tour of the wonders of the
Web, one of the few nits I could pick was that he was able to start
playing audio documents from MSU's Voice Library, but we had to hunt
around manually for the process in order to stop the sound.

Do newer releases of Mosaic have a way to stop playing of an audio
document that's been started? Or if Mosaic doesn't have the ability to
kill a sound process it's spawned, is there a sound player for the Sun
that'll pop up a dialog box to let us stop the sound when we want to? We
have a demo coming up next week, and this might be a reason for doing a
Gopher demo on a Next instead of a Web demo on a Sun -- we want smooth
mouse control, not PSes and Kills in this demo.

/Rich Wiggins, CWIS Coordinator, Michigan State U



From stumpf@informatik.tu-muenchen.de  Fri Nov 12 22:55:57 1993 +0100
Message-Id: <93Nov12.225610mesz.311351@hprbg5.informatik.tu-muenchen.de>
Date: Fri, 12 Nov 1993 22:55:57 +0100
From: stumpf@informatik.tu-muenchen.de (Markus Stumpf)
Subject: I want a SIMPLE gateway

Hi,

currently libwww has some gateway code (back in, it was completely
broken in libwww9a (the version xmosaic2.0 and lynx use).
Why does it have to be as sophisticated as it is?
All the clients have e.g. gopher and html parsing capabilities.
Can we have a simple gateway code (maybe with a compile switch) that
does nothing else as to first send a line with the address and port to
a gateway server, this opens a connection to the specified host, sends
everything else the client sended and returns all the destination server
sended. This would make it really easy to write kinda firewall server.
(yes, I know of the socks package, but I don't want to enable every
 "nonstandard" gopher, http port in the world).
The line could be e.g. a partial URL like
    http://some.univ.edu:80/

Oh, and it would be nice to be able to specify "local domains" and
addresses that don't require gatewaying on the client side.

I'd looked at the code, but it's more than a "quick hack", so before
spending lots of hours learning about the internas of libwww I'd thought
I first ask the people familiar with the code whether they'll do it :-)

Have a nice weekend
	\Maex
-- 
______________________________________________________________________________
 Markus Stumpf                        Markus.Stumpf@Informatik.TU-Muenchen.DE 



From mvanheyn@cs.indiana.edu  Fri Nov 12 17:13:20 1993 -0500
Message-Id: <6057.753142400@frilled.cs.indiana.edu>
Date: Fri, 12 Nov 1993 17:13:20 -0500
From: mvanheyn@cs.indiana.edu (Marc VanHeyningen)
Subject: Re: I want have "Last-modified:" in HTTP/1.0 headers 

Thus wrote: Steve Putz
>Marc VanHeyningen <mvanheyn@cs.indiana.edu> wrote:
>> Short of having every example of a gateway coded in, how could a cache
>> server possibly tell the difference?
>> 
>> Rhetorical question.  Answer:  The Expires: header.  It's the
>> responsibility of the server to make available an indication of how
>> long that information will remain "current".
>
>Is that what we want "Exipres" to mean?   In both my examples, the
>information from the gateways does not expire or become obsolete.
>Rather I was suggesting that the likelyhood of a cache hit can be small
>because the virtual information space is so large.
>
>For example, users will rarely click on the exact same latitude and
>longitude in the map viewer, and the cost of caching the resulting GIF
>image is high.  On the other hand if someone widely publishes a URL for
>a particular map, caching makes sense.
>
>My point is that choosing caching strategies becomes more difficult as
>the information space gets richer.  The Expires: header does not really
>solve the problem.

Ok, I see more what you mean.  Presumably such information which is
large and not frequently requested (like never after the first time)
won't be cached very long by any reasonable caching strategy.

A minor optimization might be to skip caching the results of applying
the SPACEJUMP method.  For that matter, POST and CHECKIN/OUT and
pretty much any method other than GET probably shouldn't be cached,
and naturally documents requiring authorization to access shouldn't be
cached (unless the authorization is global to anyone with access to
that cache, maybe.)  That solves much of the problem.  There are still
domains (most any search in which arbitrary keywords may be specified)
in which hits are less likely; a smart cache might not cache (or
expire faster) any URL which is a search (i.e. has a ? in it.)  Hits
can still happen, though; for instance, my CS Tech Report index got a
whole lot of queries for the sample searches specified in the Mosaic
demo document, and caching those could have been a win for some
locations.

- Marc
--
Marc VanHeyningen  mvanheyn@cs.indiana.edu  MIME, RIPEM & HTTP spoken here



From waterbug@epims1.gsfc.nasa.gov  Fri Nov 12 19:33:45 1993 EST
Message-Id: <9311130033.AA17735@epims1.gsfc.nasa.gov>
Date: Fri, 12 Nov 93 19:33:45 EST
From: waterbug@epims1.gsfc.nasa.gov (Steve Waterbury)
Subject: Re: Turning off a sound that you've started


Rich Wiggins writes:

> ... Or if Mosaic doesn't have the ability to
> kill a sound process it's spawned, is there a sound player for the Sun
> that'll pop up a dialog box to let us stop the sound when we want to? 

In fact, I have been having Mosaic call the sound player in the Sun 
Xview deskset ($OPENWINHOME/bin/audiotool) to play sounds, and it's 
probably just what you want.  (You can also "see" when the sound is 
finished, replay it, etc.)  All you have to do is change the Mosaic 
X resource XMosaic*audioPlayerCommand from showaudio to audiotool 
(with the appropriate path, of course).  

I have to admit, I haven't set up showaudio on my machine, so it was 
actually out of laziness that I was using the built-in Sun tool ... 
it's nice for the control, but has the somewhat annoying behavior 
that a new instance of the audiotool pops up every time you play a 
sound, even if there is already an audiotool running -- it would be 
great if the one that was already running could be detected and used 
for any succeeding sounds!  Perhaps this could be done with Sun's 
"Tool Talk" or something ... oh well, not high on _my_ to-do list! :-)  

Then again, the trouble with the audiotool is that it's a Sun 
proprietary thing ... I wonder if there is a PD tool along the same 
lines? 

Steve Waterbury
NASA/GSFC



From hitoaki@mahler.ntt.jp  Sat Nov 13 12:54:56 1993 +0900
Message-Id: <9311130355.AA24595@mahler.ntt.jp>
Date: Sat, 13 Nov 1993 12:54:56 +0900
From: hitoaki@mahler.ntt.jp (Hitoaki Sakamoto)
Subject: Re: notes on 2.0 binaries 


  The Mosaic 2.0 is also available on www.ntt.jp in
/networking/WWW/Web.

-hitoaki
  



From /S=muenkel/OU=tnt/@uni-hannover.de  Sat Nov 13 16:28:35 1993 +0100
Message-Id: <9311131528.AA15268@helios.tnt.uni-hannover.de>
Date: Sat, 13 Nov 1993 16:28:35 +0100
From: /S=muenkel/OU=tnt/@uni-hannover.de ()
Subject: ANNOUNCING: New html menus for the lemacs

Hallo,

I've written a new version (2.0) of my extensions to the html-mode from Marc
Andreessen for the Lucid Emacs (lemacs). The name of the package is
	hm--html-menus-2.0.tar.gz
You can find it on the following ftp server:
	info.cern.ch in /pub/www/contrib
	sunsite.unc.edu in /pub/Linux/apps/editors/emacs/
	ftp.rrzn.uni-hannover.de in /pub/unix/editors/lemacs/contrib

The package provides functions to insert the following html-commands in html-
pages:
1. Anchors:
	Html link, Info link, Gopher link, File link, 
	Ftp link, News link, Mail link, Wais link,
	Proggate link, Local Proggate link, General link,
	Link target
2. Frame elements:
	Full html frame with html, head, body, title, header and signature
	elements or only the single elments
3. Structure elements:
	Menu or list item, Menu, Unordered list, Ordered list, Directory list,
	Description list, Description title, Description entry, New Paragraph
4. for preformated text:
	Without links, With links, Blockquote, Listing
5. Formatting:
	Bold, Italic, Underline, Typewriter,
	Emphasized, Strong, Code, Sample, Keyboard, Variable, Definition,
	Citation, HTML Comment
6. Inlined Image:
	Bottom aligned, Top aligned

If it makes sense, the functions worked also on selected regions. Therefore 
I've used the same menu items and the same keystrokes. So you don't need to
learn different menus or keys for similar functions.
You can choose the popup menus between an expert menu, an novice menu and
the menu from Marc Andreessen interactive.
With the pulldown menu, you can do the following things:
- select the pulldown menu
- change the highlighting of html tags
- quotify hrefs
- reload the config files
- load html templates from a template directory (one template is included
  in the package)
- preview html documents with the xmosaic
- preview html documents with the w3 package for the lemacs

You can configure the html mode with a special configuration file for your site
and with another file specific for a user.

The html is under developement and therefore also this package is under
developement. So, if you have any ideas to extend the package, feel free to
email them to muenkel@tnt.uni-hannover.de.


Heiko



From marca@ncsa.uiuc.edu  Sat Nov 13 17:08:14 1993 -0800
Message-Id: <9311140108.AA14573@wintermute.ncsa.uiuc.edu>
Date: Sat, 13 Nov 93 17:08:14 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Re: Turning off a sound that you've started

Steve Waterbury writes:
> 
> Rich Wiggins writes:
> 
> > ... Or if Mosaic doesn't have the ability to
> > kill a sound process it's spawned, is there a sound player for the Sun
> > that'll pop up a dialog box to let us stop the sound when we want to? 
> 
> In fact, I have been having Mosaic call the sound player in the Sun 
> Xview deskset ($OPENWINHOME/bin/audiotool) to play sounds, and it's 
> probably just what you want.  (You can also "see" when the sound is 
> finished, replay it, etc.)  All you have to do is change the Mosaic 
> X resource XMosaic*audioPlayerCommand from showaudio to audiotool 
> (with the appropriate path, of course).  
> 
> I have to admit, I haven't set up showaudio on my machine, so it was 
> actually out of laziness that I was using the built-in Sun tool ... 
> it's nice for the control, but has the somewhat annoying behavior 
> that a new instance of the audiotool pops up every time you play a 
> sound, even if there is already an audiotool running -- it would be 
> great if the one that was already running could be detected and used 
> for any succeeding sounds!  Perhaps this could be done with Sun's 
> "Tool Talk" or something ... oh well, not high on _my_ to-do list! :-)  
> 
> Then again, the trouble with the audiotool is that it's a Sun 
> proprietary thing ... I wonder if there is a PD tool along the same 
> lines? 

Try 'xplaygizmo', ftp.ncsa.uiuc.edu (if you can get through :-),
/Mosaic/misc.  It was built to provide a simple GUI for external
viewers, like sound players.

Marc




From roeber@vxcrna.cern.ch  Sun Nov 14 00:44:25 1993 +0100
Message-Id: <9311132344.AA23694@dxmint.cern.ch>
Date: Sun, 14 Nov 1993 00:44:25 +0100
From: roeber@vxcrna.cern.ch (Frederick G.M. Roeber)
Subject: Re: I want a SIMPLE gateway

>currently libwww has some gateway code (back in, it was completely
>broken in libwww9a (the version xmosaic2.0 and lynx use).
>Why does it have to be as sophisticated as it is?
>Can we have a simple gateway code [...]
>Oh, and it would be nice to be able to specify "local domains" and
>addresses that don't require gatewaying on the client side.

Speaking of the devil, that's just what I came in today to do.
I'm using a simple gateway Dave Ragget wrote, which just takes one line
in the form of "host:port" or "host:port user:password," opens that
connection if authorized, and glues the two sockets together.  It doesn't
care what the protocol is; http, ftp, gopher, or most important for me:
wais and http0.  (I tried the CERN httpd as a gateway, it choked on
wais and http0.)

I hacked HTTCP.c (Mosaic's version; sorry CN) so that the HTDoConnect
call detects if the connect failed due to ENETUNREACH, EHOSTUNREACH, etc.
If it did, then it recurses to connect to the gateway machine.  If the
gateway open works, and the gateway responds positively, then HTDoConnect
returns as if everything worked first time.

This now works.

The gateway can return an "unauthorized" message if you're not on a legit
network, and didn't specify a good username:password.  This response is
caught, so once I figure out the HTAA* code, I think I should be able to
hook in the authorization request popup.  Then, supposedly, the first
time you use the gateway from an unauthorized network you'd get prompted 
for a username:password; after that, "it just works."  If I understand it.

I've more cleaning up to do, particularly involving default ports, but
hopefully in a day or two I'll have some diffs to offer up.

Cheers,
Frederick.



From marca@ncsa.uiuc.edu  Sat Nov 13 17:08:14 1993 -0800
Message-Id: <9311140108.AA14573@wintermute.ncsa.uiuc.edu>
Date: Sat, 13 Nov 93 17:08:14 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Re: Turning off a sound that you've started

Steve Waterbury writes:
> 
> Rich Wiggins writes:
> 
> > ... Or if Mosaic doesn't have the ability to
> > kill a sound process it's spawned, is there a sound player for the Sun
> > that'll pop up a dialog box to let us stop the sound when we want to? 
> 
> In fact, I have been having Mosaic call the sound player in the Sun 
> Xview deskset ($OPENWINHOME/bin/audiotool) to play sounds, and it's 
> probably just what you want.  (You can also "see" when the sound is 
> finished, replay it, etc.)  All you have to do is change the Mosaic 
> X resource XMosaic*audioPlayerCommand from showaudio to audiotool 
> (with the appropriate path, of course).  
> 
> I have to admit, I haven't set up showaudio on my machine, so it was 
> actually out of laziness that I was using the built-in Sun tool ... 
> it's nice for the control, but has the somewhat annoying behavior 
> that a new instance of the audiotool pops up every time you play a 
> sound, even if there is already an audiotool running -- it would be 
> great if the one that was already running could be detected and used 
> for any succeeding sounds!  Perhaps this could be done with Sun's 
> "Tool Talk" or something ... oh well, not high on _my_ to-do list! :-)  
> 
> Then again, the trouble with the audiotool is that it's a Sun 
> proprietary thing ... I wonder if there is a PD tool along the same 
> lines? 

Try 'xplaygizmo', ftp.ncsa.uiuc.edu (if you can get through :-),
/Mosaic/misc.  It was built to provide a simple GUI for external
viewers, like sound players.

Marc




From robm@ncsa.uiuc.edu  Sun Nov 14 05:10:08 1993 -0600
Message-Id: <9311141110.AA08594@void.ncsa.uiuc.edu>
Date: Sun, 14 Nov 1993 05:10:08 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: NCSA httpd 1.0a4 released


NCSA httpd 1.0a4 is finally released. It is available from ftp.ncsa.uiuc.edu
in /Web/ncsa_httpd. If all goes well with this release, and no major bugs
are reported, this will become the official (non-alpha) NCSA httpd 1.0 (and
we can finally get shorter version numbers).

NCSA httpd 1.0a4 has some remarkable changes. There are too many to detail
here, and the online docs are already written. If you don't have network
access, a .tar file of the online documentation is now being provided with
new releases of httpd.

Quickly, though, features added include user authentication, an improved
image mapping script with circles and polygons, and POST scripts. There are
many other changes, improvements, and bug fixes.

The online documentation at http://hoohoo.ncsa.uiuc.edu/ has been vastly
improved, even if you are upgrading I would suggest reading it all the way
through. It was difficult to get a clear grasp of what was happening in the
old docs, the new docs may prove enlightening.

If you are running httpd 1.0a3 and its ilk, especially if you are using
the access control features, I'd strongly suggest upgrading.

If you are using a version of httpd earlier than that, PLEASE upgrade,
since those versions of httpd have harmful bugs that confuse HTTP/1.0
clients.

--Rob




From decoux@moulon.inra.fr  Sun Nov 14 14:41:24 1993 +0100
Message-Id: <9311141341.AA10658@moulon.moulon.inra.fr>
Date: Sun, 14 Nov 93 14:41:24 +0100
From: decoux@moulon.inra.fr (ts)
Subject: Oracle and <FORM>



 Oracle and <FORM>
 =================

 Files for WWWDaemon 2.13 are in 
	ftp://moulon.inra.fr/pub/www-oracle/example.tar.Z

 This is not a beta version, nor a prerelease but JUST an EXAMPLE. It must
be seriously tested (and debugged) and actually I can't do it.

 I don't want to make a Perl version. I prefer wait DBPerl (middle 94).

 Implement :
 ---------

  * method GET, PUT, POST, DELETE, SHOWMETHOD, CHECKIN and CHECKOUT

For method PUT and POST : it must be work even if the client only send
modified columns and not the whole form.

  * <FORM METHOD="POST"> only for Oracle.
 I don't like it : actually my server receive "POST" and execute GET, PUT,
POST ... 
 
 I prefer receive a header line "X-keyword: (atend)" (or any other line) to
signal me that the keyword follow header lines.

 Don't implement :
 ---------------

  * <TEXTAREA> : I've no idea how to add it.

  Example :

 ____________________________________________________________

table example (
   url varchar(255) not null,
   comment varchar(255) not null
)
 ____________________________________________________________

 column with tag <TEXTAREA> is ... ???

  * RAW column : if you have a raw column in a table, you must create a
view without this raw column and give access to the view.
 It is not a BUG, I don't like raw column.



  The future release must have the tag <MH HIDDEN>.
  I prefer send :

 ------------------------------------------------------------
 <FORM>
 <MH HIDDEN>
 X-oracle: rowid='000000000000', lock=wwwAAAa6578
 </MH>
 ...
 ------------------------------------------------------------

 rather than, like actually :

 ------------------------------------------------------------
 <FORM>
 <SELECT NAME="rowid" <OPTION>'000000000000'</SELECT>
 <SELECT NAME="lock" <OPTION>wwwAAAa6578</SELECT>
 ...
 ------------------------------------------------------------


 Documentation is :
  http://moulon.inra.fr/update.html

 Demo is :
  http://moulon.inra.fr/oracle/A/update/table?action=tables

Guy Decoux





From sanders@bsdi.com  Sun Nov 14 10:51:21 1993 -0600
Message-Id: <199311141651.KAA22444@austin.BSDI.COM>
Date: Sun, 14 Nov 1993 10:51:21 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: Oracle and <FORM> 

decoux@moulon.inra.fr writes:
>  <FORM>
>  <MH HIDDEN>
>  X-oracle: rowid='000000000000', lock=wwwAAAa6578
>  </MH>
You can also accomplish the same thing by putting the information
in the ACTION:
    <FORM ACTION="http://server/rowid='00000000000'/lock=wwwAAAa6578/">

--sanders



From robm@ncsa.uiuc.edu  Sun Nov 14 19:24:47 1993 -0600
Message-Id: <9311150124.AA12742@void.ncsa.uiuc.edu>
Date: Sun, 14 Nov 1993 19:24:47 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Server Scripts


It has been brought to my attention that many gateway writers are waiting to
announce or release their gateways for fear that the script interface will
change again and their scripts will not work. While I view the changes to
the script interface in 1.0a4 as minor, and easily fixed, this is still a
valid complaint.

So, let me emphasize something and make a promise. 

First, the "a" in NCSA httpd version numbers is still there because I
consider the software alpha software.  We're still working with the scripts
interface (and other aspects of the server) and trying to make it as
powerful as possible. 

With that in mind, I'll make this promise. *Whatever script interface is in the
official NCSA httpd 1.0 will stay there.* If you have scripts which you
don't want to rewrite many times, you may wish to stay with NCSA httpd
1.0a3.2. I will try to make 1.0's release as speedy as possible (within 2
weeks I hope). At that point, if any changes are made to the scrip
interface, they will be backward compatible.

So, I'd like to open up the discussion of what should be in the script
interface to the script writers. Attached is a number of suggestions which
have been brought up and which I am considering supporting in the finalized
script interface. As always, we welcome your ideas and comments.

--Rob


>From robm Sun Nov 14 18:41:06 1993
From: robm@void (Rob McCool)
Date: Sun, 14 Nov 1993 18:41:06 -0600
In-Reply-To: George Phillips <phillips@cs.ubc.ca>
       "script support" (Nov 14,  4:18pm)
X-Mailer: Mail User's Shell (7.2.5 10/14/92)
To: George Phillips <phillips@cs.ubc.ca>, <httpd@ncsa.uiuc.edu>
Subject: Re: script support
Cc: sanders@bsdi.com
Status: OR

/*
 * script support  by George Phillips (phillips@cs.ubc.ca)
 *    written on Nov 14,  4:18pm.
 *
 * I was just playing with the script support in 1.0a4 and discovered
 * a few minor but troublesome problems with the interface.  Here
 * they are with some useful (I hope) suggested solutions:
 * 
 * Problem:  Script can only return "Content-Type:" and "Location:".
 * Effect:  Script cannot send an HTTP/1.0 header like "Content-Length",
 * and it cannot report errors with HTTP/1.0 codes.
 * Possible Solution(s):  Allow the script to "take-over" header output,
 * perhaps by detecting "HTTP/1.0 nnn" response string.  Or have a
 * configuration option that indicates a script wishes to do it all.
 * Either way, you may want to provide the server indentification as
 * an environment variable (SERVER_ID?) so that the script can do a proper
 * Server: header.  If the script can take over completely, it will
 * need to know the protocol version (PROTOCOL environment variable?).

This is something Tony brought up, too, perhaps I'll make a new field to
tell the server to pass the header as-is. Env. variables with the server
name and protcol are a good idea.

 * Problem:  Script cannot return absolute URLs that reference itself.
 * Effect:  Script installation may require hardcoding information on
 * how the server knows to run it (i.e., it knows it's called /htbin/foo).
 * Possible Solution(s):  Make all the script writers code in that
 * information or provide an environment variable (SCRIPT_PATH?).
 * The latter is preferable and allows the script to say things
 * like "$SERVER_NAME$SCRIPT_PATH/go/here" when a relative URL
 * is too cumbersome to emit.

Perhaps, then, a $SCRIPT_NAME env. variable? I call it name since it is a
translated name, not a path name.

 * Problem:  No way to distinguish "/htbin/prog?/foo" and "/htbin/prog/foo".
 * Effect:  User input could confuse the script.
 * Possible Solution(s):  Always force two script arguments when a search
 * request has been detected so you get:
 *      URL		#args	args
 *   /htbin/prog		0
 *   /htbin/prog/foo	1	"/foo"
 *   /htbin/prog?foo	2	"" "foo"
 *   /htbin/prog/bar?foo	2	"/bar" "foo"

I wondered about this one myself. I chose the method I did because I wanted
to make the transition between the new and old interfaces a little less
painful.

 * Problem:  Cannot use Alias mechanism to point to a script.
 * Effect: "Alias /foo /htbin/prog" gives you the script source of "prog"
 * instead of running "prog".
 * Possible Solution(s):  Fix it in the code :-).  I view this problem
 * as pretty minor.  A nice feature if the solution is simple.

Use ScriptAlias instead. That's what it's there for.

 * Problem:  Script has no way of knowing what server is running it.
 * Effect:  Hard to change script interface without breaking old scripts
 * and servers.  Also hard to write gateway scripts that are easily portable
 * between different servers.
 * Possible Solution(s):  Drop in an environment variable like GATEWAY_PROTO.
 * Script can key on that to figure out what the arguments mean, etc. No big
 * deal now, but will make completely generic drop-into-your-server scripts
 * easier to write.

I'm hoping to get a semi-ideal script interface into the official 1.0
release, and then not change it at all.

 * No showstoppers here, but it would really be nice to be rid of the
 * prog?foo" vs. "prog?/foo" ambiguity.  The rest are liveable if
 * inconvenient.  Just say the word and I'll code up some fixes -- I'm
 * quite eager to have the ability to publish some of my gateway code
 * without having to publish my server along with it.
 */

Most likely, I will pursue these changes, and barring any other huge bugs,
the interface we come out with will be 1.0 and won't change.

--Rob




From leddo@minnie.cs.su.oz.au  Mon Nov 15 18:37:48 1993 +1100 (EST)
Message-Id: <9311150738.AA12300@dxmint.cern.ch>
Date: Mon, 15 Nov 1993 18:37:48 +1100 (EST)
From: leddo@minnie.cs.su.oz.au (Michael Francis Ledwidge)
Subject: The Written Word


	I would like to announce a new WWW site. 

	Rather than bore you with the entire spiel - here is a quote from
	the opening node.

	`While development continues on making the World-Wide Web more
sophisticated (HTML double-plus-good) efforts should be made to put
this technology to other uses - some more relevant to the arts than to
the sciences.'

	URL: http://minnie.cs.su.oz.au/writ/start.html

	I hope to hear from some of you.

					Cheers
						Michael Ledwidge
						leddo@minnie.cs.su.oz.au






From terry@ora.com  Mon Nov 15 13:04:29 1993 PST
Message-Id: <199311152104.AA19862@rock.west.ora.com>
Date: Mon, 15 Nov 1993 13:04:29 PST
From: terry@ora.com (Terry Allen)
Subject: Mosaic2.0 and ISINDEX

Mosaic2.0's treatment of the ISINDEX tag is now in violation of the HTML+ DTD.
According to the DTD, the tag is allowed only in HEAD---that is, it's metainformation
about the doc, and was thus properly implemented in the frame of 1.2.

Now Mosaic renders a search field in the document wherever the tag appears:
if it appears properly in HEAD, the search field is at the top of the doc,
but if it appears improperly elsewhere, the field is still rendered.  

If browser developers won't stick to the DTD, there's no point in having one.

Regards,

-- 
Terry Allen  (terry@ora.com)
Editor, Digital Media Group
O'Reilly & Associates, Inc.
Sebastopol, Calif., 95472



From Nathan.Torkington@vuw.ac.nz  Tue Nov 16 13:40:44 1993 +1300
Message-Id: <199311160040.AA11756@kauri.vuw.ac.nz>
Date: Tue, 16 Nov 1993 13:40:44 +1300
From: Nathan.Torkington@vuw.ac.nz (Nathan Torkington)
Subject: Banjo tablature archive

Ok, the doors are open.  If you know how to use the World Wide Web,
point your browsers at
	http://www.vuw.ac.nz/who/Nathan.Torkington/banjo/tab/home.html
for the (currently small) tablature archive.

If you don't have Internet access, send e-mail to
	listserv@info.cern.ch
with
	HELP
in the body of the message, to find out about receiving World Wide Web
files via e-mail (the command you will need to use to do this is
SEND).

If you do have Internet access, telnet to info.cern.ch (no password is
needed) and, once presented with the first page of text, type
	g http://www.vuw.ac.nz/who/Nathan.Torkington/banjo/tab/home.html
and press Return.

To find out more about the World Wide Web, read the Usenet newsgroup
comp.infosystems.www (a copy of the Frequently Asked Questions list
should be able to be read there) or if you can't read Usenet news,
send mail to me (Nathan.Torkington@vuw.ac.nz).

Currently the contents are:

Bach

Musette in D Major
   Transcribed by Nathan Torkington. 
Toccata and Fugue in D Minor (BWV 565)
   Transcribed by Nathan Torkington. Incomplete. 

Mozart

Turkish March (from Piano Sonata #11 in A)
   Transcribed by Nathan Torkington. 

Bluegrass

Salt Creek
   Original break by Nathan Torkington. 
Differential Hampster/Pig in a Pen
   Original tune by Nathan Torkington. Suspiciously similar to ``Pig
   in a Pen'', I am told. ;-) 

Jazz

Jekyll and Hyde
   Bela Fleck tune, transcribed by Nathan Torkington. 
Monkey See
   Bela Fleck tune, transcribed by Nathan Torkington. 

Exercises

Scales
   Nathan Torkington. 

Cheers;

Nat



From phillips@cs.ubc.ca  Mon Nov 15 17:57:00 1993 -0800
Message-Id: <6836*phillips@cs.ubc.ca>
Date: 15 Nov 93 17:57 -0800
From: phillips@cs.ubc.ca (George Phillips)
Subject: browser execution

I've implemented and have been using a URL scheme which makes
a WWW browser execute local programs.  I'm planning on making this
code available to others.  I am quite familiar with what current
browsers and servers can do and I feel that a "local execution"
URL serves a useful purpose.

I realize that others (everybody? :-) disagree with such a URL
scheme, but let me present my current mechanism for discussion.
If you're against it, then let your guiding principle in the
discussion be "If they're gonna do it, at least make them do
it as reasonably and safely as possible.".

Here's how it works.  I have a new URL scheme called "x-exec".
A typical x-exec: URL looks like:

	x-exec://program/all/the/rest

"program" is the name of the program to execute.  The name is % escaped
so it may contain "/"s or other odd characters.  The browser de-escapes
the name and then checks a compiled-in and an environment specified
list of directories.  "program" must appear in one of the
directories or be listed explictly before it can be executed.  If it
satisfies that test, "program" is run with "/all/the/rest" as a single
argument.  The output of the program will look like an HTTP/1.0
response with status codes and MIME headers.  A provision in the
browser to recognize raw HTML would be a nice but unnecessary feature.

There are a few things to note here.  The default action of such
a patch will be to do nothing.  Only if the installer puts something
on the internal list or if the user creates their list can anything
be executed.  The list specification depends on the operating system.
On UNIX, an environment variable with colon-separated directories
(WWW_PATH? WWW_EXECPATH) is likely.  DOS applications may choose a
similar option but with ";" as a separator.  Program execution
must be done carefully -- use pipe(), fork() and exec() rather
than popen() or system().

My current implementation passes the rest of the URL as a single
argument.  I recommend that the program be executed in the same
way as an external gateway script under NCSA's HTTPD -- the problems
both mechanisms face are extremely similar.

I hope we can hammer out the details on how this should be done,
if it must.



From robm@ncsa.uiuc.edu  Mon Nov 15 21:11:49 1993 -0600
Message-Id: <9311160311.AA11675@void.ncsa.uiuc.edu>
Date: Mon, 15 Nov 1993 21:11:49 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: NCSA httpd 1.0a5 

Well, my week is ruined.

NCSA httpd 1.0a5 is now released. It's a bug fix for 1.0a4. 

When fixing a bug in the inetd code, I broke the standalone code which
changed the user id to the one dictated in the configuration file.

THE NET EFFECT OF THIS IS HTTPD IS ALWAYS RUNNING AS ROOT. THIS IS BAD.

If you downloaded 1.0a4, I have made a "bin" directory full of binaries so
that you can plug in the new binary. Included at the end of this message and
in that directory is a source patch for those of you compiling from source.

Obviously, I feel terrible about this unexcusable oversight, and I can only
ask you to bear with us until 1.0. If you have already upgraded to 1.0a4,
PLEASE APPLY THIS PATCH OR GET A NEW BINARY.

Begging your forgiveness
--Rob

*** httpd_1.0a4/src/httpd.h	Sun Nov 14 03:12:19 1993
--- httpd_1.0a5/src/httpd.h	Mon Nov 15 19:59:06 1993
***************
*** 169,175 ****
  
  /* ------------------------------ error types ------------------------------ */
  
! #define SERVER_VERSION "NCSA/1.0a4"
  #define SERVER_PROTOCOL "HTTP/1.0"
  #define SERVER_SUPPORT "httpd@ncsa.uiuc.edu"
  
--- 169,175 ----
  
  /* ------------------------------ error types ------------------------------ */
  
! #define SERVER_VERSION "NCSA/1.0a5"
  #define SERVER_PROTOCOL "HTTP/1.0"
  #define SERVER_SUPPORT "httpd@ncsa.uiuc.edu"
  
*** httpd_1.0a4/src/httpd.c	Sun Nov 14 03:12:18 1993
--- httpd_1.0a5/src/httpd.c	Mon Nov 15 20:38:28 1993
***************
*** 154,165 ****
              }
              log_error("socket error: accept failed");
          }
          if((pid = fork()) == -1)
              log_error("unable to fork new process");
          else if(!pid) {
!             /* we do this here so that logs can be opened as root */
!             setuid(user_id);
!             setgid(group_id);
              close(0);
              close(1);
              dup2(csd,0);
--- 154,189 ----
              }
              log_error("socket error: accept failed");
          }
+ 	/* we do this here so that logs can be opened as root */
          if((pid = fork()) == -1)
              log_error("unable to fork new process");
          else if(!pid) {
! 	    struct passwd* pwent;
! 
!             /* Only effective if we're running as root */
!             if(!getuid()) {
!                 /* Now, make absolutely certain we don't have any privileges
!                  * except those mentioned in the configuration file. */
!                 if ((pwent = getpwuid(user_id)) == NULL) {
!                     log_error("couldn't determine user name from uid");
!                     exit(-1);
!                 }
!                 /* Reset `groups' attribute. */
!                 if (initgroups(pwent->pw_name, group_id) == -1) {
!                     log_error("unable to setgroups");
!                     exit(-1);
!                 }
!                 /* Note the order, first setgid() and then setuid(), it
!                  * wouldn't work the other way around. */
!                 if (setgid(group_id) == -1) {
!                     log_error("unable change gid");
!                     exit(-1);
!                 }
!                 if (setuid(user_id) == -1) {
!                     log_error("unable change uid");
!                     exit(-1);
!                 }
!             }
              close(0);
              close(1);
              dup2(csd,0);
***************
*** 170,178 ****
              fclose(stdout);
              exit(0);
          }
!         close(csd);
      }
- }
  
  extern char *optarg;
  extern int optind;
--- 194,202 ----
              fclose(stdout);
              exit(0);
          }
!             close(csd);
!         }
      }
  
  extern char *optarg;
  extern int optind;
***************
*** 195,207 ****
      read_config();
      open_logs();
      get_local_host();
-     user_id = getuid();
-     group_id = getgid();
  
      set_env_vars();
      if(standalone)
          standalone_main();
      else {
          port = get_portnum(fileno(stdout),stdout);
          process_request(stdin,stdout);
      }
--- 219,231 ----
      read_config();
      open_logs();
      get_local_host();
  
      set_env_vars();
      if(standalone)
          standalone_main();
      else {
+         user_id = getuid();
+         group_id = getgid();
          port = get_portnum(fileno(stdout),stdout);
          process_request(stdin,stdout);
      }




From twyan@lynx.cs.usfca.edu  Mon Nov 15 19:42:11 1993 -0800
Message-Id: <9311160342.AA28251@lynx.cs.usfca.edu>
Date: Mon, 15 Nov 1993 19:42:11 -0800
From: twyan@lynx.cs.usfca.edu (Tommy Yan)
Subject: ADD


add me to the subscription list



From rex@joyce.cs.su.oz.au  Tue Nov 16 14:48:14 1993 +1100
Message-Id: <9311160349.AA14270@dxmint.cern.ch>
Date: Tue, 16 Nov 1993 14:48:14 +1100
From: rex@joyce.cs.su.oz.au (Rex Monty di Bona)
Subject: Please remove erict@minnie.cs.su.oz.au from these mailing lists

    Subject: Undelivered mail returned from basser.cs.su.oz.au
    
    *******************************************************************************
    MAIL SENT TO: erict@minnie.cs.su.oz.au
    RETURNED FROM: basser.cs.su.oz.au
    MESSAGE ID WAS: 3gu2Ms-yt+u2LX
    
    Failure explanation follows :-
    Could not send to erict: destination unknown
    *******************************************************************************
    
    Received: from dxmint.cern.ch (insecurely) by joyce.cs.su.OZ.AU;
    	Tue, 16 Nov 1993 14:15:40 +1100
    Received: from nxoc01.cern.ch by dxmint.cern.ch (5.65/DEC-Ultrix/4.3)
    	id AA08964; Tue, 16 Nov 1993 04:14:51 +0100
    Received: by  nxoc01.cern.ch  (NeXT-1.0 (From Sendmail 5.52)/NeXT-2.0)
    	id AA21690; Tue, 16 Nov 93 03:43:31 MET
    Received: from dxmint.cern.ch by  nxoc01.cern.ch  (NeXT-1.0 (From Sendmail 5.52)/NeXT-2.0)
    	id AA21686; Tue, 16 Nov 93 03:43:29 MET
    Received: from newton.ncsa.uiuc.edu by dxmint.cern.ch (5.65/DEC-Ultrix/4.3)
    	id AA08899; Tue, 16 Nov 1993 04:13:43 +0100
    Received: from void.ncsa.uiuc.edu by newton.ncsa.uiuc.edu with SMTP id AA16301
      (5.65a/IDA-1.4.2 for www-talk@nxoc01.cern.ch); Mon, 15 Nov 93 21:13:37 -0600
    Return-Path: <robm@ncsa.uiuc.edu>
    Received: by void.ncsa.uiuc.edu (4.1/NCSA-4.1)
    	id AA11675; Mon, 15 Nov 93 21:11:50 CST
    Message-Id: <9311160311.AA11675@void.ncsa.uiuc.edu>
    From: robm@ncsa.uiuc.edu (Rob McCool)
    Date: Mon, 15 Nov 1993 21:11:49 -0600
    X-Mailer: Mail User's Shell (7.2.5 10/14/92)
    To: www-talk@nxoc01.cern.ch, www-announce@nxoc01.cern.ch, ejk@uiuc.edu,
            ekatz@ncsa.uiuc.edu, httpd@ncsa.uiuc.edu
    Subject: NCSA httpd 1.0a5 
    
    Well, my week is ruined.
    
    NCSA httpd 1.0a5 is now released. It's a bug fix for 1.0a4. 
    
    When fixing a bug in the inetd code, I broke the standalone code which
    changed the user id to the one dictated in the configuration file.
    
    THE NET EFFECT OF THIS IS HTTPD IS ALWAYS RUNNING AS ROOT. THIS IS BAD.
    
    If you downloaded 1.0a4, I have made a "bin" directory full of binaries so
    that you can plug in the new binary. Included at the end of this message and
    in that directory is a source patch for those of you compiling from source.
    
    Obviously, I feel terrible about this unexcusable oversight, and I can only
    ask you to bear with us until 1.0. If you have already upgraded to 1.0a4,
    PLEASE APPLY THIS PATCH OR GET A NEW BINARY.
    
    Begging your forgiveness
    --Rob




From marca@ncsa.uiuc.edu  Mon Nov 15 23:15:16 1993 -0800
Message-Id: <9311160715.AA20386@wintermute.ncsa.uiuc.edu>
Date: Mon, 15 Nov 93 23:15:16 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Mosaic2.0 and ISINDEX

Terry Allen writes:
> Mosaic2.0's treatment of the ISINDEX tag is now in violation of the
> HTML+ DTD.  According to the DTD, the tag is allowed only in
> HEAD---that is, it's metainformation about the doc, and was thus
> properly implemented in the frame of 1.2.
> 
> Now Mosaic renders a search field in the document wherever the tag
> appears: if it appears properly in HEAD, the search field is at the
> top of the doc, but if it appears improperly elsewhere, the field is
> still rendered.
> 
> If browser developers won't stick to the DTD, there's no point in
> having one.

Your documents are not conforming to the DTD.

Marc




From rik@rdt.monash.edu.au  Tue Nov 16 18:15:16 1993 +1100
Message-Id: <199311160715.SAA13630@daneel.rdt.monash.edu.au>
Date: Tue, 16 Nov 93 18:15:16 +1100
From: rik@rdt.monash.edu.au (Rik Harris)
Subject: Re: Mosaic2.0 and ISINDEX 

Terry Allen writes:
> Mosaic2.0's treatment of the ISINDEX tag is now in violation of the
> HTML+ DTD.  According to the DTD, the tag is allowed only in
> HEAD---that is, it's metainformation about the doc, and was thus
> properly implemented in the frame of 1.2.
> 
> Now Mosaic renders a search field in the document wherever the tag
> appears: if it appears properly in HEAD, the search field is at the
> top of the doc, but if it appears improperly elsewhere, the field is
> still rendered.
> 
> If browser developers won't stick to the DTD, there's no point in
> having one.

I seem to recognise this argument from a few months ago.  I believe what came
out of it then was something like:

- browsers should follow the DTD and render DTD-compliant documents correctly
- browser behaviour for documents that do not conform to the DTD is undefined
- browser implementers should be allowed to interpret non-conformant
  documents loosely so they can provide something that still looks OK
- authors should NOT use the browser as a DTD conformance testing tool

My own comments:

Marc and the NCSA team have done a great job implementing the HTML and HTML+
stuff.  Mosaic was one of the first (if not _the_ first) to implement forms,
and allow people to actually try this stuff out before HTML+ is set in stone.
If you want to bash Mosaic, I didn't notice your browser...If you don't want
SGML in w3, then don't blame it on Mosaic.

rik.
--
Rik Harris - rik.harris@fcit.monash.edu.au
+61 3 560-3265 (AH & ans.mach)      +61 3 565-3227 (BH)
Department of Robotics and Digital Technology, FCIT, Clayton Campus,
Monash University, Australia   http://www.vifp.monash.edu.au/people/rik.html




From marca@ncsa.uiuc.edu  Tue Nov 16 01:42:51 1993 -0800
Message-Id: <9311160942.AA20716@wintermute.ncsa.uiuc.edu>
Date: Tue, 16 Nov 93 01:42:51 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Mosaic2.0 and ISINDEX

Actually, I don't think my response was sufficient.  Let's step
through this in more detail.

> Terry Allen writes:
> > Mosaic2.0's treatment of the ISINDEX tag is now in violation of the
> > HTML+ DTD.  

A DTD is, by definition, a document type definition, not a display
technology specification.

A display technology cannot be in violation of a DTD -- by definition,
only a document can be in violation of a DTD.

A display technology that does not properly handle all documents that
conform to a given DTD is broken with respect to that DTD and cannot
claim that it properly handles all documents that conform to that DTD.

Mosaic 2.0 properly handles documents that conform to the HTML DTD
(whatever it happens to be today, and with the caveat that this, as
usual, holds only until someone can provide us with a testcase to the
contrary) and also properly handles documents that include forms as
specified in the latest HTML+ DTD (which may not be out yet, but we've
been coordinating with the DTD author, so there should be no problems
there).

> > According to the DTD, the tag is allowed only in HEAD---that is,
> > it's metainformation about the doc, 

OK so far -- but to be clear, let's nail down that "the tag is allowed
only in HEAD" applies to *documents* (which it, obviously, does).

> > and was thus properly implemented in the frame of 1.2.

Not accurate.  You are, in my opinion, attempting to force a given
display technology method to suit your particular preferences by
claiming a violation in our particular method of handling (presenting)
a part the document spec, which is by definition not reasonable due to
the separation of markup and presentation inherent in our approach.

> > Now Mosaic renders a search field in the document wherever the tag
> > appears: if it appears properly in HEAD, the search field is at the
> > top of the doc, 

The document conforms to the DTD, and Mosaic handles it properly.

> > but if it appears improperly elsewhere, the field is still
> > rendered.

The document does NOT conform to the DTD and Mosaic does as best it
can in the name of robustness.  The document should be fixed.

> > If browser developers won't stick to the DTD, there's no point in
> > having one.

Makes no sense.  We properly handle all documents that conform to the
DTD.

Could be reworded quite reasonably as: "If document writers won't
stick to the DTD, there's no point in having one."

..........

I think it's safe to say that the root problem here is that you are
unhappy with how Mosaic 2.0 handles ISINDEX.  There are several
previously-stated reasons why we now do what we do in 2.0...

------------------------------------------------------------------------------
 o Consistent approach to query mechanisms inside Mosaic. 
 o Allow code and interface complexity to be reduced. 
 o A few nasty problems were hitting the "popup text entry field"
   approach attempted for prerelease 2; notably, lots of unavoidable
   flashing when field popped up and down and intermittent but crippling
   Motif geometry management problem. This change removes those
   problems. 
 o Everyone wants the ability to enter a query (and the corresponding
   widgets) to be present only when the document is actually an ISINDEX
   document; this provides that very cleanly. 
 o This solves existing problem of when to retain contents of search field
   -- since search field now exists on a per-document basis, this is very
   clean. 
 o Encourage experimentation with fill-out forms by presenting an
   example for existing query engines. 
------------------------------------------------------------------------------

The primary problem that keeps me from simply putting in an option to
make you happy is the third one in the list above; after hours of
experimentation I couldn't get Motif to do what I wanted without
hitting intermittent bugs that ended up making the program unusable on
some systems.

Marc




From phillips@cs.ubc.ca  Mon Nov 16 01:13:00 1993 -0800
Message-Id: <6845*phillips@cs.ubc.ca>
Date: 16 Nov 93  1:13 -0800
From: phillips@cs.ubc.ca (George Phillips)
Subject: Mosaic2.0 and ISINDEX

Marc says:
>I think it's safe to say that the root problem here is that you are
>unhappy with how Mosaic 2.0 handles ISINDEX.  There are several
>previously-stated reasons why we now do what we do in 2.0...

I think what Mosaic 2.0 does with <ISINDEX> is reasonable, but it
does force a tough choice on the document provider who must either:

1) Obey the DTD and put <ISINDEX> in the <HEAD> and live with the
   search field being right at the top of the document.
2) Make the document non-compliant to the DTD and put <ISINDEX>
   where you wish to see the input field in Mosaic 2.0.

If you're a bit fast and loose (like me), the choice is easy.  You
can do (2) and know that the Mosaic 2.0 user will get a better
than average interface and all the other current browsers still
recognize the misplaced <ISINDEX> tag OK so no problem.

But if you want DTD conforming documents (and you're justified since
it's your only guarantee that future browsers will interoperate),
Mosaic 2.0 users see things a little weird.

So how about this:  If <ISINDEX> is in the <HEAD>, Mosaic puts the 
input field at the end of the document.  Otherwise, it puts the
input field wherever <ISINDEX> appears.  As long as your search
pages are short, this will give you very similar behaviour to
Mosaic 1.2.  And maybe it's not that hard to implement (but if
it is, don't bother).



From wmperry@indiana.edu  Tue Nov 16 07:04:40 1993 +0000
Message-Id: <13038.753433480@tartarus.uwa.edu.au>
Date: Tue, 16 Nov 1993 07:04:40 +0000
From: wmperry@indiana.edu (William M. Perry,,855-2896,331-9062)
Subject: New Version of the Emacs WWW Browser

Hello folks,

   This is to announce version 1.5Beta of the emacs world wide web browser.
This is getting very close to a non-beta release, and I would like some
additional testing done before I officially call it 1.0 and stable.  Here
is part of the README:

Features of the Emacs WWW Browser
Date: Tue Nov 16 06:48:11 1993
Version: 1.50Beta

What does the emacs browser do?

The emacs browser will allow you to access this great information service, all
from within emacs.  The emacs browser supports all major network protocols.

	* FTP: transparently finds files over ftp by using ange-ftp.
	  Directories on remote sites can be viewed either with dired or
	  converted into a simple hypertext document and viewed like all the
	  others.
	* NNTP: uses the nntp.el package by Masanobu UMEDA to retrieve news
	  articles and then converts them into hypertext documents.  There is
	  no support for reading the users .newsrc yet, but it is planned for
	  the future.
	* Gopher: Can either use the gopher.el package by Scott Snyder, or
	  convert the gopher output into hypertext and view it normally in
	  w3-mode.
	* HTTP: This is the World Wide Web's hypertext transfer protocol used
	  to request hypertext documents.  The preferred way to retrieve Web
	  documents.  Uses open-network-stream, but also has support for using
	  an external program in a subprocess (to get around firewalls, or
	  similar obstacles).

Features of the emacs WWW browser:
	* Extremely portable - if your machine can run emacs, odds are it
	  can use the emacs browser.  (has been run on DOS, Windows, OS/2,
	  NeXTstep, Xwindows, vt100s, etc)
	* Easy to use from other elisp programs (functions to easily parse
	  a buffer for just links, etc.  For GNUS & VM users)
	* Support for different fonts, bold, italics, etc, if in Xwindows and
	  using Emacs 19, Epoch, or Lucid Emacs.
	* Mouse support if in Emacs 19, Epoch, Lucid Emacs, or NeXT Emacs.
	* Fill out forms support as specified in the HTML+ specification, plus
	  all the Xmosaic extensions.  Forms work on tty's and in Xwindows.
	* Compatibility with Xmosaic so they can use the same hotlist file,
	  global history file, and personal annotation directory.
	* Lots of HTML+ support - headers/paragraphs with ID support,
	  RENDER hints, NOTE tags, etc.
	* Full image support within Epoch.
		* Images are cached
		* Delayed image loading
	* Full HTTP/1.0 support, including redirection, authentication, and
	  specifying viewers by MIME types.
		* Can specify MIME viewers in emacs lisp, or let it parse
		  your .mailcap file directly.
		* Fairly complete listing of file extensions and what MIME
		  types they represent, plus the ability to change them.
		* 'Basic' authorization works, and public key is being
		  worked on.
	* Can print or save a document you are viewing in HTML source,
	  formatted output, or LaTeX source.  (LaTeX is converted to
	  postscript before printing).
	* Ability to 'preview' any emacs buffer as an HTML document.
	* Lots more

Where can I get the emacs WWW browser:
	* You can always ftp the latest and greatest from cs.indiana.edu in
	  /pub/elisp/w3.  The files you will need are w3.tar.z and
	  extras.tar.z.  If you already have ange-ftp, nntp, and gopher.el
	  installed, you will only need the w3.tar.z file.

Please send me some mail if you get this package, so that I can get a rough
estimate of how many people are using it, and so I can send you mail if I
find a really urgent mistake. :)  Doesn't happen often anymore, but just in
case.

Thanks,
   Bill Perry, wmperry@indiana.edu

PS: I will be in Ireland for the next 10 days or so - not sure what my
email access will be like, but probably limited to non-existent.  Please
send in bug reports, but be prepared for a wait.  Please feel free to use
the w3-beta@indiana.edu mailing list for questions/discussion.



From terry@ora.com  Tue Nov 16 07:14:38 1993 PST
Message-Id: <199311161514.AA07136@rock.west.ora.com>
Date: Tue, 16 Nov 1993 07:14:38 PST
From: terry@ora.com (Terry Allen)
Subject: Re: Mosaic2.0 and ISINDEX

Your longer explanation is much more reasonable; thanks.

Regards,

-- 
Terry Allen  (terry@ora.com)
Editor, Digital Media Group
O'Reilly & Associates, Inc.
Sebastopol, Calif., 95472



From luotonen@ptsun00.cern.ch  Tue Nov 16 16:50:13 1993 +0100
Message-Id: <9311161550.AA00665@ptsun03.cern.ch>
Date: Tue, 16 Nov 93 16:50:13 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: CERN httpd and libwww 2.14 released


CERN-httpd 2.14 and libwww 2.14 have been released.

Anonymous ftp cite:	info.cern.ch:
Sources:		/pub/www/src/
Library context diff:	/pub/www/src/diffs/
Binaries:		httpd, htadm, htimage
under:			/pub/www/bin/

	*****************************************************
	**                                                 **
	**   Everybody using CERN-httpd older than 2.13:   **
	**                                                 **
	**             IT IS TIME TO UPGRADE!              **
	**                                                 **
	*****************************************************

IMPORTANT: If you do script programming, also upgrade to 2.14.

ATTENTION: If you have already 2.13 scripts they may be a little
broken, but it is _very_easy_ to repair them.  After this version our
script interface will NEVER change without being back-compatible!

httpd 2.14:
	* clickable image support
		- as an /htbin program htimage, comes together
		  with daemon
	* htadm (also with daemon) has new capabilities:
		- an option for checking a password
		  (for scripts that want to do AA checks)
		- now also creates password file
		- prompts password twice when changing it
	* index search utility interface (you can have a plug-in
	  /htbin script to do the search)
	* forms support
 |	* /htbin script interface CHANGED a little:
 |		- first parameter to script is *always* the rest of
 |		  the URL pathname part;
 |		  if there is nothing first parameter is an empty string
 |		- form submits are parsed sanely:
 |		   * script parameters on even places are form field
 |		     names (appended with =)
 |		   * script parameters on odd places are corresponding
 |		     values
 |		- /htbin script interface is now FIXED -- it will not
 |		  change so any scripts that you write to CERN server
 |		  will work with any future version of CERN server
 |		- currently is also compatible with NCSA server with
 |		  the exception of parameter unescaping
	* parameters to scripts are _still_ unescaped -- there is no
	  need for scripts to do any unescaping (easy interface)
	* 'on-fly redirection': if script gives a non-full URL as a
	  Location:  field it is passed through rule system, access
	  authorization and served as if it was the original request
	  (faster than sending first a redirection to client which
	  will re-connect to server to get the document anyway)
	* ignores SIGPIPE
	* Content-Type: field wildcard matching; image/* etc. work
	* this version has been running over a week on a real WWW
	  server machine which makes use of all its capabilities
	  with no problems -- no major bugs
	* contains VMS port (many thanks to Mark Donszelmann):
		- /htbin scripts work on VMS
		[ Access authorization still has some minor problems. ]
		[ Contains sources but .mms file may be incomplete. ]

Server script doc:

	http://info.cern.ch/hypertext/WWW/Daemon/HTBinDoc.html

Clickable image doc:

	http://info.cern.ch/hypertext/WWW/Daemon/HTImageDoc.html

libwww 2.14:
	* HTML generator linewrap bug fixed
	* VMS port
	* minor bug fixes


Report any problems as soon as possible to luotonen@dxcern.cern.ch or
www-bug@info.cern.ch.

--
Ari Luotonen		 |
World-Wide Web Project	 |
CERN			 | phone: +41 22 767 8583
CH - 1211 Geneve 23	 | email: luotonen@dxcern.cern.ch



From tom@fatty.law.cornell.edu  Tue Nov 16 11:50:00 1993 -0500 (EST)
Message-Id: <9311161650.AA21580@fatty.law.cornell.edu>
Date: Tue, 16 Nov 1993 11:50:00 -0500 (EST)
From: tom@fatty.law.cornell.edu (Thomas R. Bruce)
Subject: Cello Beta r9 released

Folks:

Cello Beta version .9 is hereby released.  Pick it up from 
ftp.law.cornell.edu, in the pub/LII/Cello directory.  With 
luck, this will be the last beta release.

Among the more important features of this release is a 
completely revised help system which should be taken as the 
authoritative documentation for Cello.  Please send feedback.


Fixed in this release:
----------------------

--Some lingering problems with whitespace folding eliminated.
--Slight adjustment made to color-palette handling.
--Improper handling of direct launches to Gophers on 
non-standard ports fixed.
--Problems related to transfers of multiple graphics files were 
repaired, except in the case of the FTP Software winsock (see note below).
--Problems related to FTP transfer-hanging were fixed.
--Assorted problems and annoyances with bookmarks fixed.
--Problem with "empty anchors" crashing Cello eliminated; it 
now tolerates <A HREF=>An empty anchor</A>.
--Assorted problems related to font selection were fixed.
--Inversion of .xbm images (interestingly enough reported by 
only 2 Alert Cellists) repaired.


Enhanced/added in this release:
-------------------------------

--Printing of graphics is now supported, though there is as yet 
no halftoning or dithering.  This enhancement also repaired 
problems with printing of certain text structures like nested 
lists and the <HR> horizontal rule.

--A "stop transfer" feature is now implemented via a visible 
button.

--Drag and drop of files is now supported.  Basically, when you 
drop a file on Cello, one of two things happens:

   1) if the file extension is .URL, Cello expects that the 
   file will contain a valid URL as the first line of the file, 
   and will launch to that resource.
   2) any other file is expected to be HTML.
   
-- A "peek mode" is implemented.  If you hold down the CTRL key 
while clicking on a link to a Gopher or HTTP server, only the 
first 4K of the file will be retrieved.  This is especially 
useful in the case of large Gopher files posted without warning 
as to size.

-- Ad hoc launches of TN3270 clients are now supported via the 
menu.

-- ISMAP is now supported.

Known problems:
---------------

FTP Software's winsock has trouble with rapid-fire, successive 
transfer of small graphics files, in part because limited 
numbers of sockets are available and in part because they don't 
close quickly.  The problem is perhaps most visible when 
viewing the GNN home page.  A solution is in the works.

Regards,
Tb.

-- 
+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+
|  Thomas R. Bruce                           trb2@cornell.edu |
|  Research Associate                                         |
|  Cornell Law School                     Voice: 607-255-1221 |
|  Myron Taylor Hall                        FAX: 607-255-7193 |
|  Ithaca, NY 14853                                           |
+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+



From montulli@stat1.cc.ukans.edu  Tue Nov 16 12:24:36 1993 CST
Message-Id: <9311161824.AA66774@stat1.cc.ukans.edu>
Date: Tue, 16 Nov 93 12:24:36 CST
From: montulli@stat1.cc.ukans.edu (Lou Montulli)
Subject: html files not named .html

Lately there have been alot of people sending me messages
saying that they can't read an HTML file with Lynx because
all they see is markup.  The reason this is happening is people
are naming files with no extension and the NCSA http server
returns a mime message with no content-type. X Mosaic is rendering
them correctly, because it apparently looks for a <title> or some
other tag in the document to try to determine if its HTML.
So I would like to see at least two things happen. 

1) HTTP/1.0 servers should ALWAYS return a content-type tag!!!!!!!!!
2) HTTP/1.0 servers should use the same or similar methods as X mosaic to
   determine if files with no recognized extension are actually HTML.

:lou


-- 
  **************************************************************************
  *           T H E   U N I V E R S I T Y   O F   K A N S A S              *
  *         Lou  MONTULLI @ Ukanaix.cc.ukans.edu                           *
  *                         Kuhub.cc.ukans.edu      ACS Computing Services *
  *     913/864-0436        Ukanvax.bitnet             Lawrence, KS 66044  *
  *             UNIX! Cool! I know that!  Jurassic Park - The Movie        *
  **************************************************************************



From phillips@cs.ubc.ca  Mon Nov 16 11:11:00 1993 -0800
Message-Id: <6849*phillips@cs.ubc.ca>
Date: 16 Nov 93 11:11 -0800
From: phillips@cs.ubc.ca (George Phillips)
Subject: Re: CERN httpd and libwww 2.14 released

Ari Luotonen says:
> |		- currently is also compatible with NCSA server with
> |		  the exception of parameter unescaping

I wouldn't call it compatible if they differ on something so basic
as whether the arguments are unescaped or not.  There's a bigger
problem though -- NCSA's script interface is still a moving target.
It's not going to move far and it will be making some important
changes, but if CERN's script interface is frozen, it'll have
a hard time changing to be compatible.

I think this underscores why we really need something like a
SCRIPT_PROTO environment variable so that portable (between servers)
gateway scripts can be written.

While I'm whining, it occurs to me that it'd be useful for a script
to have some way of knowing what method it is doing.  NCSA HTTPD
seems to cover this now by having different GET and POST scripts.
This is workable, but tossing in something to let the script
explicitly know (environment variable?) would be nice and would
make the external gateway scripts easier to run under the x-exec:
URL scheme.

I hate to dote on this, but the ability to share stuff between servers
is important.  Even if the server's don't exactly agree, it would
be nice if either portable scripts are possible or if Plexus can
support every script interface under the sun.

			-- George



From m.koster@nexor.co.uk  Tue Nov 16 19:40:53 1993 +0000
Message-Id: <9311161941.AA19779@dxmint.cern.ch>
Date: Tue, 16 Nov 1993 19:40:53 +0000
From: m.koster@nexor.co.uk (Martijn Koster)
Subject: WWW Server indexing (again)


Hello all,

you may remember a discussion on this list a while back
about indexing WWW servers. 

Well, I have been working on and off on a indexing system 
which basically does an Archie-type thing with indices 
(based on IAFA templates) summarising the main services
of a WWW server. No, not the best scalable solution, but
maybe good enough for a while.

Although the implementation is very basic and experimental,
it seems to run along quite happily with a few sites.

Now I'd like to expand the user base, and see if a system like
this is useful, wether this implementation is useful as a pilot,
and what discussions it will start off. 

So, if there are any WWW server administrators out there who 
want to spend a couple of minutes indexing their servers to
make an automated global database of WWW servers possible, please
have a look at 
	HREF="http://web.nexor.co.uk/aliweb/doc/aliweb.html
for the details.

Please don't advertise this service everywhere just yet -- it is 
purely experimental, alpha etc.

Looking forward to your comments,

-- Martijn
__________
Internet: m.koster@nexor.co.uk
X-400: C=GB; A= ; P=Nexor; O=Nexor; S=koster; I=M
X-500: c=GB@o=NEXOR Ltd@cn=Martijn Koster
WWW: http://web.nexor.co.uk/mak/mak.html



From robm@ncsa.uiuc.edu  Tue Nov 16 14:40:29 1993 -0600
Message-Id: <9311162040.AA20573@void.ncsa.uiuc.edu>
Date: Tue, 16 Nov 1993 14:40:29 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: html files not named .html

/*
 * html files not named .html  by Lou Montulli (montulli@stat1.cc.ukans.edu)
 *    written on Nov 16, 12:24pm.
 *
 * Lately there have been alot of people sending me messages
 * saying that they can't read an HTML file with Lynx because
 * all they see is markup.  The reason this is happening is people
 * are naming files with no extension and the NCSA http server
 * returns a mime message with no content-type. X Mosaic is rendering
 * them correctly, because it apparently looks for a <title> or some
 * other tag in the document to try to determine if its HTML.
 * So I would like to see at least two things happen. 
 * 
 * 1) HTTP/1.0 servers should ALWAYS return a content-type tag!!!!!!!!!
 * 2) HTTP/1.0 servers should use the same or similar methods as X mosaic to
 *    determine if files with no recognized extension are actually HTML.
 */

This has been fixed in the recent release... it will now return a default
type.

--Rob



From robm@ncsa.uiuc.edu  Tue Nov 16 14:47:36 1993 -0600
Message-Id: <9311162047.AA20703@void.ncsa.uiuc.edu>
Date: Tue, 16 Nov 1993 14:47:36 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CERN httpd and libwww 2.14 released

/*
 * Re: CERN httpd and libwww 2.14 released  by George Phillips (phillips@cs.ubc.ca)
 *    written on Nov 16, 11:11am.
 *
 * Ari Luotonen says:
 * > |		- currently is also compatible with NCSA server with
 * > |		  the exception of parameter unescaping
 * 
 * I wouldn't call it compatible if they differ on something so basic
 * as whether the arguments are unescaped or not.  There's a bigger
 * problem though -- NCSA's script interface is still a moving target.
 * It's not going to move far and it will be making some important
 * changes, but if CERN's script interface is frozen, it'll have
 * a hard time changing to be compatible.
 * 
 * I think this underscores why we really need something like a
 * SCRIPT_PROTO environment variable so that portable (between servers)
 * gateway scripts can be written.

I have a created an env. variable called "SERVER_SOFTWARE" which contains
NCSA/1.0a6 right now. Is this what you had in mind?

 * While I'm whining, it occurs to me that it'd be useful for a script
 * to have some way of knowing what method it is doing.  NCSA HTTPD
 * seems to cover this now by having different GET and POST scripts.
 * This is workable, but tossing in something to let the script
 * explicitly know (environment variable?) would be nice and would
 * make the external gateway scripts easier to run under the x-exec:
 * URL scheme.

I have created an env. variable called $SCRIPT_METHOD which contains either
"GET" or "POST".

 * I hate to dote on this, but the ability to share stuff between servers
 * is important.  Even if the server's don't exactly agree, it would
 * be nice if either portable scripts are possible or if Plexus can
 * support every script interface under the sun.
 */

It is important. I'd like to see a uniform script interface as well. 

--Rob



From sanders@bsdi.com  Tue Nov 16 15:30:12 1993 -0600
Message-Id: <199311162130.PAA29310@austin.BSDI.COM>
Date: Tue, 16 Nov 1993 15:30:12 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: html files not named .html 

Lou Montulli writes:
>  * 1) HTTP/1.0 servers should ALWAYS return a content-type tag!!!!!!!!!
Rob McCool replies:
> This has been fixed in the recent release... it will now return a default
> type.

I don't agree that servers should ALWAYS return a content-type:
because there is a defined default if content-type is missing.
http://info.cern.ch/hypertext/WWW/Protocols/HTTP/Body.html sez:
    The data (if any) sent with an HTTP request or reply is in a format
    and encoding defined by the object header fields, the default being
    "plain/text" type with "8bit" encoding.
*However*, defensive programming would dictate that you be explicit.

Note that the HTTP/1.0 spec:
    http://info.cern.ch/hypertext/WWW/Protocols/HTTP/HTTP2.html
has changed a bit over the past few months.  Both server and browser
authors should probably re-read it.

--sanders



From montulli@stat1.cc.ukans.edu  Tue Nov 16 16:08:58 1993 CST
Message-Id: <9311162209.AA48904@stat1.cc.ukans.edu>
Date: Tue, 16 Nov 93 16:08:58 CST
From: montulli@stat1.cc.ukans.edu (Lou Montulli)
Subject: Re: html files not named .html

> 
> Lou Montulli writes:
> >  * 1) HTTP/1.0 servers should ALWAYS return a content-type tag!!!!!!!!!
> Rob McCool replies:
> > This has been fixed in the recent release... it will now return a default
> > type.
> 
> I don't agree that servers should ALWAYS return a content-type:
> because there is a defined default if content-type is missing.
> http://info.cern.ch/hypertext/WWW/Protocols/HTTP/Body.html sez:
>     The data (if any) sent with an HTTP request or reply is in a format
>     and encoding defined by the object header fields, the default being
>     "plain/text" type with "8bit" encoding.
> *However*, defensive programming would dictate that you be explicit.

This is what Lynx does.  Unfortunatly since Xmosaic doesn't do that
I get complaint after complaint about how Lynx is screwed up because
it renders what they think is fine (because it works in Xmosaic)
into crap.

> 
> Note that the HTTP/1.0 spec:
>     http://info.cern.ch/hypertext/WWW/Protocols/HTTP/HTTP2.html
> has changed a bit over the past few months.  Both server and browser
> authors should probably re-read it.
> 
> --sanders
> 
I did read it and look where it got me :)

(Perhaps the default should be changed since all of the Mosaic browsers
seem to default to text/HTML.)

:lou
-- 
  **************************************************************************
  *           T H E   U N I V E R S I T Y   O F   K A N S A S              *
  *         Lou  MONTULLI @ Ukanaix.cc.ukans.edu                           *
  *                         Kuhub.cc.ukans.edu      ACS Computing Services *
  *     913/864-0436        Ukanvax.bitnet             Lawrence, KS 66044  *
  *             UNIX! Cool! I know that!  Jurassic Park - The Movie        *
  **************************************************************************




From totic@milton.cs.uiuc.edu  Tue Nov 16 20:03:53 1993 CST
Message-Id: <199311170203.AA15322@milton.cs.uiuc.edu>
Date: Tue, 16 Nov 93 20:03:53 CST
From: totic@milton.cs.uiuc.edu (Aleksandar Totic)
Subject: Re: html files not named .html

> I don't agree that servers should ALWAYS return a content-type:
> because there is a defined default if content-type is missing.
> http://info.cern.ch/hypertext/WWW/Protocols/HTTP/Body.html sez:
>     The data (if any) sent with an HTTP request or reply is in a format
>     and encoding defined by the object header fields, the default being
>     "plain/text" type with "8bit" encoding.
> *However*, defensive programming would dictate that you be explicit.
> 
> Note that the HTTP/1.0 spec:
>     http://info.cern.ch/hypertext/WWW/Protocols/HTTP/HTTP2.html
> has changed a bit over the past few months.  Both server and browser
> authors should probably re-read it.

Oh no. I think that XMosaic and MacMosaic assume HTML. I have had it
set on plain, but changed it to HTML because too many people have
complained about crappy documents. Example is NII server.

Aleks



From decoux@moulon.inra.fr  Wed Nov 17 07:20:31 1993 +0100
Message-Id: <9311170620.AA29392@moulon.moulon.inra.fr>
Date: Wed, 17 Nov 93 07:20:31 +0100
From: decoux@moulon.inra.fr (ts)
Subject: WWW-Oracle


 Hello,

 I've make a few modification to WWW-oracle :

  * I've adopted Sanders's modification for "rowid" and "lock"

  * add tag "<TEXTAREA>" for Oracle datatype "LONG CHAR". Don't forget you
can only have one column with this datatype in a table.

  * You must confirm a "DELETE"

  * server display comments associated with a table or a column

 Example :

moulon% sqlplus
moulon% SQL> COMMENT ON TABLE PROJETS IS '<img src="/moon.xbm"><p>';
moulon% SQL> COMMENT ON COLUMN PROJETS.PROJET IS 'Please,if you have a nice
moon, <a href="http:/ts.html">send me it</a><p>'; 
moulon% SQL> EXIT

 Problem : length <= 255 (Oracle restriction)

  * I've a problem with "release_lock" : when a user put a lock, I send it
in a document. To release a lock, the user must give the good lock. If he
lost his lock, he can't release it.

 I use this special convention :

   - If a user has "CHECKIN" and "CHECKOUT" : he can put a lock and release
only his own lock.

   - If a user has all privileges "GET ... CHECKOUT" : he can release any
lock.

 Please, send me any suggestions or comments before I try to debug it.

 Thanks,

Guy Decoux



From luotonen@ptsun00.cern.ch  Wed Nov 17 10:45:36 1993 +0100
Message-Id: <9311170945.AA01186@ptsun03.cern.ch>
Date: Wed, 17 Nov 93 10:45:36 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: Re: CERN httpd and libwww 2.14 released


> I have a created an env. variable called "SERVER_SOFTWARE" which contains
> NCSA/1.0a6 right now. Is this what you had in mind?

Let me clear out any misconseptions before we have a war again.
All I said was that scripts written for our server now will not
be broken by next versions like they were this time, which was
very unlucky.

I didn't promise that scripts will be compatible with final NCSA
1.0 because it doesn't exist yet.  But once they release it I'll
introduce any environment variables etc it might have to make
it possible for scripts to run on different servers.

All I have "frozen" are the parameters, the format of output, and
my hands this morning.  I have no mention about any environment
variables or anything else yet so I can do whatever I need with
them.


> I'd like to see a uniform script interface as well. 

So would I -- so will you put the unescaping and parsing to your
server?? :-)  It's crazy to leave it for scripts since there exists
a standard way of doing it and scripts would do this anyway.  And
no information is lost.


And my ten cents about XMosaic <ISINDEX> incident:  it's very
nice, I use it, it makes other people use it, and finally all
the browsers will have to support this new way of rendering
it although it is in conflict with the DTD.  I say nothing more.


-- Cheers, Ari --




From timbl@www3.cern.ch  Wed Nov 17 13:59:16 1993 +0100
Message-Id: <9311171259.AA00544@www3.cern.ch>
Date: Wed, 17 Nov 93 13:59:16 +0100
From: timbl@www3.cern.ch (Tim Berners-Lee)
Subject: Re: html files not named .html 

>Date: Tue, 16 Nov 1993 16:58:26 -0600
>From: Tony Sanders <sanders@bsdi.com>
>
>> > http://info.cern.ch/hypertext/WWW/Protocols/HTTP/Body.html sez:
>> >     The data (if any) sent with an HTTP request or reply is in a  
format
>> >     and encoding defined by the object header fields, the  
default being
>> >     "plain/text" type with "8bit" encoding.
>...
>> This is what Lynx does.  Unfortunatly since Xmosaic doesn't do  
that
>> I get complaint after complaint about how Lynx is screwed up  
because
>> it renders what they think is fine (because it works in Xmosaic)
>> into crap.
>> (Perhaps the default should be changed since all of the Mosaic  
browsers
>> seem to default to text/HTML.)
>
>Maybe Tim will change it.  Tim, what do you think?
>
>--sanders

What server now sends back an HTTP1.0 reply with no Content-Type  
field?  Seems like a difficult thing to do specially.
The only case I can see is when one wants to dump error messages
etc onto the line, in which case plain text is probably more
appropriate.  It also happens to be the default for mail,
so one can use the same MIME+WWW parser for both. Which is useful.

Tim





From timbl@www3.cern.ch  Wed Nov 17 14:39:50 1993 +0100
Message-Id: <9311171339.AA00566@www3.cern.ch>
Date: Wed, 17 Nov 93 14:39:50 +0100
From: timbl@www3.cern.ch (Tim Berners-Lee)
Subject: Comments of HTML+ draft

Dave,

A list of points

0.	Thanks for the very great effort.

1.	Editorial...

1.	The draft filename is unfortunate in that "plus" is
	missed out,
	and the name looks different from the html draft name
		
		draft-ietf-iiir-html-00
		
		draft-raggett-www-html-00
		
	I don't know what we do about that.  It is reasobal to miss
	out iiir as they are not involved with that yet but it is
	their area.  They can both go under the new nominal WG.

1.5	The document needs an index.  It is difficult, for example,
	to find the discussion of LANG on p6 and I never found a
	discussion of the INDEX attribute. (Comes from my
	reading in a order random.)

1.6	May I suggest as a question of style -- and an aid to
	convergence -- that you wrod the spec in a conventional
	way as a specification -- with "should" and "shall"
	to specify levels of imperitiveness?  The "could"s
	which are comments about how the spec should be changed
	should be compleetly separate -- like in a different font.
	That way one can say "I am happy with the spec as it stands
	at <date> except...".

2.	ISMAP attributes are in the FIG, IMG, etc.  I really want to
	make them obsolete as quickly as possible.

3.	Where is HR? Not in Appendix IV

4.	Why does INPUT have no ID? Does Name serve it's purpose - if
	so, tehn it should be "ID", else it ID should exist
	separately.

5.	ISINDEX I would also like to see "obsolescenbt", with the
	use of LINK instead.

6.	LINK should have PRINT if A has PRINT.  LINK should also have
	ID.

7.	I think you should be more precise about the entity names,
	rather than "most browers support".  Make two levels if you
	have to, but please define them.  Perhaps a minimum set and
	also a very large set.  For example, the upper part of
	a left brace is not necessarily the way to go for math...
	
	We want to be able to establish real poratability for
	HTMLplus conforming documents -- not postscript-like
	kindaportability.
	
	We can add to this recommendations for how to
	make extensions ina non-destructive way, as we always have.
	
8.	PRE no longer has "WIDTH". That stops HTML+ being a
	superset of HTML.

9.	If HTML+ is to be a superset of HTML, it musg include the 

	<HTML> element.  


10.	Entity names are case sensitive. Looks like the example
	&oacute;engus should be  &Oacute;engus on p5.

11.	Do we need ID on TITLE? Specify that the title is not
	part of the document contents.
	
12.	p32 -- what is a "conventional hypertext-based index"?

13.	p22: Yes, I think a separate METHOD attribute would
	be cleaner.  POST should be the default.
	
14.	10.1, p25:  next to last para. "In the near future..."
	This spec should not be limited. Insist on floats
	now.  It will be much more difficult later!!!

	10.2 p26:  The definitions of the formats for sending
	forms by HTTP, mail, etc., need to be more clear.

I forget exactly the dates of the Irish meeting, but hope it goes
well anyway.




From phillips@cs.ubc.ca  Mon Nov 17 11:33:00 1993 -0800
Message-Id: <6865*phillips@cs.ubc.ca>
Date: 17 Nov 93 11:33 -0800
From: phillips@cs.ubc.ca (George Phillips)
Subject: Re: CERN httpd and libwww 2.14 released

Ari says:
>Let me clear out any misconseptions before we have a war again.

I don't mean to start a war.  Just want to avoid future problems,
where possible.

>All I have "frozen" are the parameters, the format of output, and
>my hands this morning.  I have no mention about any environment
>variables or anything else yet so I can do whatever I need with
>them.

Well, it might be that the parameter positions for NCSA httpd
may change, but your point about making changes to be compatible
is well taken.

>So would I -- so will you put the unescaping and parsing to your
>server?? :-)  It's crazy to leave it for scripts since there exists
>a standard way of doing it and scripts would do this anyway.  And
>no information is lost.

For simple scripts, escaping and parsing is what you want and it
does make sense.  For complex scripts, you really want the server
to touch the URL as little as possible.  It doesn't know what your
escaping scheme is and it shouldn't know because your script will
have to be responsible for escaping URLs in the HTML output.
Moreover, your escaping scheme may not be the "standard" one
(for http: scheme URLs, there's no requirement you use % hex escapes).
I often do escaping which keeps the URLs smaller and more human
decodable (e.g., translating ' ' -> '_').

There are two conflicting directions for an external gateway interface
to go.  Either it can fully digest the request and leave the gateway
script with just the task of spitting HTML or it can keep an entirely
hands off posture and let the gateway do decoding and protocol work too.
Both are useful, but if I _had_ to choose I'd take the hand's off
version because it isn't limiting.

Escaping is fine, but an option to turn it off would be necessary.

			-- George




From luotonen@ptsun00.cern.ch  Wed Nov 17 21:21:05 1993 +0100
Message-Id: <9311172021.AA01525@ptsun03.cern.ch>
Date: Wed, 17 Nov 93 21:21:05 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: Re: CERN httpd and libwww 2.14 released


> For simple scripts, escaping and parsing is what you want and it
> does make sense.  For complex scripts, you really want the server
> to touch the URL as little as possible.  It doesn't know what your
> escaping scheme is and it shouldn't know because your script will
> have to be responsible for escaping URLs in the HTML output.
> Moreover, your escaping scheme may not be the "standard" one
> (for http: scheme URLs, there's no requirement you use % hex escapes).
> I often do escaping which keeps the URLs smaller and more human
> decodable (e.g., translating ' ' -> '_').

??? I thought HTTP doc specifies how to escape illegal characters
in URL?

Tony's private message, however, pointed out that in future my current
_parsing_ scheme can lose information.  I still would like casual
script programmers have a very clear and easy interface that is not
burdened with the ability of coping every possible future feature.

So what I was thinking of just this afternoon was that the _script_
should be able to request the server to call it in the way it (script)
wants, and not vice versa.  This could be done e.g. by filename extensions.
This way the script could, at it's own will, be called with raw URL,
or with pre-parsed URL (which is very nice for 90% of the cases).
Script could also ask URL to be passed to it from stdin instead of
command line.

By the way, I must admit I was very busy with AA when the original
/htbin discussion went on.  Was there a strong opposition to having
scripts just anywhere and not only in bindir directory;  and was there
any reason for having the URL start with /htbin/ (I know that can
be configured for NCSA server, but it is still constant once it's
defined)?

I've been thinking of having an exec rule that would, when URL
matches a given template, execute a given script.  Just for
an example current htbin field in our rule file:

	htbin /x/y/z

(which gives the physical bindirectory to CERN daemon) could be
expressed as:

	exec  /htbin/*  /x/y/z/*

This would free us from /htbin/ being translated specially in URL,
and would introduce more flexibility and power to scripts.


-- Cheers, Ari --




From sanders@bsdi.com  Wed Nov 17 15:14:57 1993 -0600
Message-Id: <199311172114.PAA00313@austin.BSDI.COM>
Date: Wed, 17 Nov 1993 15:14:57 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: CERN httpd and libwww 2.14 released 

> There are two conflicting directions for an external gateway interface
> to go.  Either it can fully digest the request and leave the gateway
As I said in private mail to Ari and Rob, what's probably best is
to decode for the common case but make the untouched request
available (via stdin probably).

--sanders



From robm@ncsa.uiuc.edu  Wed Nov 17 15:12:03 1993 -0600
Message-Id: <9311172112.AA04016@void.ncsa.uiuc.edu>
Date: Wed, 17 Nov 1993 15:12:03 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CERN httpd and libwww 2.14 released

/*
 * Re: CERN httpd and libwww 2.14 released  by Ari Luotonen (luotonen@ptsun00.cern.ch)
 *    written on Nov 17,  9:21pm.
 *
 * 
 * > For simple scripts, escaping and parsing is what you want and it
 * > does make sense.  For complex scripts, you really want the server
 * > to touch the URL as little as possible.  It doesn't know what your
 * > escaping scheme is and it shouldn't know because your script will
 * > have to be responsible for escaping URLs in the HTML output.
 * > Moreover, your escaping scheme may not be the "standard" one
 * > (for http: scheme URLs, there's no requirement you use % hex escapes).
 * > I often do escaping which keeps the URLs smaller and more human
 * > decodable (e.g., translating ' ' -> '_').
 * 
 * ??? I thought HTTP doc specifies how to escape illegal characters
 * in URL?
 * 
 * Tony's private message, however, pointed out that in future my current
 * _parsing_ scheme can lose information.  I still would like casual
 * script programmers have a very clear and easy interface that is not
 * burdened with the ability of coping every possible future feature.
 * 
 * So what I was thinking of just this afternoon was that the _script_
 * should be able to request the server to call it in the way it (script)
 * wants, and not vice versa.  This could be done e.g. by filename extensions.
 * This way the script could, at it's own will, be called with raw URL,
 * or with pre-parsed URL (which is very nice for 90% of the cases).
 * Script could also ask URL to be passed to it from stdin instead of
 * command line.

File name extensions may work. My approach has been to provide C code and an
externally callable program to unescape the URL's.

 * By the way, I must admit I was very busy with AA when the original
 * /htbin discussion went on.  Was there a strong opposition to having
 * scripts just anywhere and not only in bindir directory;  and was there
 * any reason for having the URL start with /htbin/ (I know that can
 * be configured for NCSA server, but it is still constant once it's
 * defined)?

It used to be, now it isn't. See below.

As far as the background of server scripts, there was never a discussion.
Nor was there any particular reason to pick /htbin. The script interface was
something I put together because I saw the gateway capabilities in Plexus
and thought it would be great to have them in our daemon. So I designed an
interface, implemented it, and released it. It was never intended as a
standard, it was just a feature. 

 * I've been thinking of having an exec rule that would, when URL
 * matches a given template, execute a given script.  Just for
 * an example current htbin field in our rule file:
 * 
 * 	htbin /x/y/z
 * 
 * (which gives the physical bindirectory to CERN daemon) could be
 * expressed as:
 * 
 * 	exec  /htbin/*  /x/y/z/*
 * 
 * This would free us from /htbin/ being translated specially in URL,
 * and would introduce more flexibility and power to scripts.
 */

The ScriptAlias directive does that in 1.0a5. It's exactly like what you
describe above.

--Rob




From phillips@cs.ubc.ca  Mon Nov 17 13:55:00 1993 -0800
Message-Id: <6868*phillips@cs.ubc.ca>
Date: 17 Nov 93 13:55 -0800
From: phillips@cs.ubc.ca (George Phillips)
Subject: URL escaping

Ari says:
>??? I thought HTTP doc specifies how to escape illegal characters
>in URL?

Maybe this is something that should be clarified.  From the point
of view of a browser, here's how I see it:

URL's are opaque, except:

	you know how to parse the //host:port stuff
	you understand "/" so you can do relative paths
	you understand "#" for hopping into documents and "?" for searches

For certain schemes, URLs become even less opaque to the broswer.
For example, for "gopher:", you _must_ use % hex escaping because
the browser must decode the URL for use in gopher.  This is probably
true for "file:", "news:" and other URLs as well -- the browser
must know about the escaping because it will do the decoding.

For "http:", it's different.  The browser doesn't do the decoding
(except for some /#? stuff) and depends on the HTTP server to
give it 7-bit ascii encoded URLs.  As long as it spits out
7-bit ascii, the encoding is completely up to the server.

Is this the way things are, or am I way off here?

			-- George



From robm@ncsa.uiuc.edu  Wed Nov 17 18:39:28 1993 -0600
Message-Id: <9311180039.AA06991@void.ncsa.uiuc.edu>
Date: Wed, 17 Nov 1993 18:39:28 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: CGP/1.0 specification



I have spent some time writing up a formal specification for the
Server-gateway interface. I invite any and all comments and
suggestions. I would like the discussion to occur either on c.i.w3 or
www-talk. This document is available online for reference at

http://hoohoo.ncsa.uiuc.edu/beta-docs/external-protocol.txt


--------------------------------------------------------------------------




This is a preliminary specification of the Common Gateway Protocol, or
CGP. The version defined by this spec will be CGP/1.0. Once this
specification is discussed and (hopefully) agreed upon, all revisions
must be backward compatible.

Most of this is fairly specific to HTTP, since it will be implemented
under http servers. If anyone has other applications in mind, and
thinks these ideas would make those other applications difficult,
speak up.

*** Environment Variables

To pass most data from the server to the scripts, I propose we use
environment variables.  This way, we escape command line length
restrictions, and complications of short scripts having to parse stdin.

Defined environment variables, which are not request-specific:

SERVER_PROTOCOL:       HTTP, gopher, etc.
SERVER_SOFTWARE:       NCSA/1.0 or whatever
SERVER_NAME:           Server hostname or IP address
GATEWAY_PROTOCOL:      The revision of this spec to which the server complies

Request-specific variables:

SERVER_PORT:           The port answering this request
PROTOCOL_REV:          HTTP/1.0, HTTP/0.9, etc.
PROTOCOL_METHOD:       GET, PUT, POST, etc. for HTTP
FULL_URL:              The argument to the HTTP method untouched
                       (like /htbin/foo/extra/path/info?foo.bar
QUERY_STRING:          That which follows the ?, untouched
QUERY_DECODED:         The decoded string (see below)
PATH_INFO:             The extra path information, as given by client
PATH_TRANSLATED:       The extra path information, with any path
                       mapping done
REMOTE_HOST:           The client host making the request
REMOTE_USER:           The user the client has authenticated as
CONTENT_TYPE:          As given, applies to PUT and POST
CONTENT_LENGTH:        Length of content


The item which is difficult to pass as an env. variable is the decoded
query string. If we pass it as a single string separated by spaces, a
space in the middle of an item will screw it up. We could pass it as a
list of quoted items, but then there can't be quotes in the items. 

Alternatively, we could escape backslashes and spaces in such a list
with \.


*** The Command Line

On the command line, there should be two arguments:

argv[1] is always the path info, untouched. If there is no path info,
this is "".

argv[2....] is the decoded query info, split on spaces or ampersands.

Example: /htbin/script/extra/path?foo=bar&bar=foo

Command line:

script /extra/path foo=bar bar=foo

Example: /htbin/script?foo+bar+foo

Command line:

script "" foo bar foo

If the server does not use popen() or system(), and instead uses
fork() and execl(), the command-line length limitation should not
apply. I haven't verified this.


*** The script's STDIN

The server should pass the header for the request as given by the
client to the script as stdin. It should also, after the header, pass
the client's data stream.

Note that above, the server must know what content-type and
content-length are in order to put them in environment variables.
Should this be necessary, or should the server pass the entire header
without touching it, and make the script pull content-type and
content-length out?


*** The script's STDOUT

The script passes its output to the server through stdout. The output
consists of a header followed by a document. The header is parsed by
the server, and the following directives are valid:

Parse-header:

If the script returns a header line of "Parse-header: false", the
server will pass the rest of the output stream directly to the client.

Location:

If the argument to this is a URL, it is passed to the client as a 300
redirect.

If the argument to this is a path, the server will perform access
control checks on it and send the appropriate header and document to
the client. Should this be a virtual path, or a filesystem path? I
currently implement it as a filesystem path for flexibility.

Content-type:

This is the MIME type of what you're returning.


--Rob




From sanders@bsdi.com  Wed Nov 17 22:32:46 1993 -0600
Message-Id: <199311180432.WAA01737@austin.BSDI.COM>
Date: Wed, 17 Nov 1993 22:32:46 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: CGP/1.0 specification 


> REMOTE_USER:           The user the client has authenticated as
State that if unset or null then it's an unauthenticated request

> The item which is difficult to pass as an env. variable is the decoded
> query string. If we pass it as a single string separated by spaces, a
I think argv[2...] is enough, I don't think we need an env variable also.

I think what we should state is that if the resulting command line would
excede system maximuns (length or # arguments) then *NO* argv[2] is
passed and you must decode the URL yourself or punt.  This is also
the case if there is no query string (then you check $SERVER_QUERY
or whatever it's called and if it's not set there is no query at all).

> On the command line, there should be two arguments:
I would restate that, even if you don't adopt the suggestion above
it's not true.

> argv[1] is always the path info, untouched. If there is no path info,
> this is "".
> 
> argv[2....] is the decoded query info, split on spaces or ampersands.
You can't split on spaces, you mean pluses `+'.  How do you decide
if it's spaces or ampersands?  I assume if it has &'s then you split
on & else +, just need to make that clear.

> If the server does not use popen() or system(), and instead uses
> fork() and execl(), the command-line length limitation should not
> apply. I haven't verified this.
It does, it's a low-level problem with exec.

> The server should pass the header for the request as given by the
> client to the script as stdin. It should also, after the header, pass
> the client's data stream.
I assume this includes the ``GET /foobar HTTP/1.0'' part.

> Note that above, the server must know what content-type and
> content-length are in order to put them in environment variables.
> Should this be necessary, or should the server pass the entire header
> without touching it, and make the script pull content-type and
> content-length out?
I think the server must always touch the data so this isn't a problem,
the server will always have to relay the information.  I don't see a clean
way around this because there is no way to read "just" the right amount
of information so you don't snarf in some of the headers or the data.
That would require length information *before* you read the request.
A smarter HTTP protocol would have a fixed size data header with this
information, but without it you can't do what you imply.

> *** The script's STDOUT

I need to look at all the plexus gateways and see what "callbacks" they
will require (the two you listed are the big ones).

--sanders



From luotonen@ptsun00.cern.ch  Thu Nov 18 10:32:57 1993 +0100
Message-Id: <9311180932.AA01561@ptsun03.cern.ch>
Date: Thu, 18 Nov 93 10:32:57 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: Re: CGP/1.0 specification


> We could pass it as a
> list of quoted items, but then there can't be quotes in the items. 

We can:  it's  becomes:  'it'\''s'


> argv[1] is always the path info, untouched. If there is no path info,
> this is "".
> 
> argv[2....] is the decoded query info, split on spaces or ampersands.
> 
> Example: /htbin/script/extra/path?foo=bar&bar=foo
> 
> Command line:
> 
> script /extra/path foo=bar bar=foo

Otherwise agreed, but I'd still wish you'd consider doing it like
I did, which would cause command line:

	script /extra/path	'foo=' 'bar' 'bar=' 'foo'

In this case equal signs in values (or even names) wouldn't cause
any confusion, and spaces in values aren't a problem, either.


> Location:
> 
> If the argument to this is a URL, it is passed to the client as a 300
> redirect.
> 
> If the argument to this is a path, the server will perform access
> control checks on it and send the appropriate header and document to
> the client. Should this be a virtual path, or a filesystem path? I
> currently implement it as a filesystem path for flexibility.

At least for CERN server it *must* be a virtual path, because the
rule file starts protecting already before the filesystem path is
found out.  Otherwise I'd have to be able to translate filesystem
path back to virtual path which is indeterministic.


-- Cheers, Ari --




From luotonen@ptsun00.cern.ch  Thu Nov 18 10:56:36 1993 +0100
Message-Id: <9311180956.AA01568@ptsun03.cern.ch>
Date: Thu, 18 Nov 93 10:56:36 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: Re: URL escaping


> ...
> For "http:", it's different.  The browser doesn't do the decoding
> (except for some /#? stuff) and depends on the HTTP server to
> give it 7-bit ascii encoded URLs.  As long as it spits out
> 7-bit ascii, the encoding is completely up to the server.

The unescaping that we've been arguing about is %xx to ASCII.
Escaping is done _by_the_client_ if keywords/form fields contain
characters that are illegal (or otherwise would cause confusion)
in URLs, %xx escapes are used.  Clearly the escaping scheme has
to be well known between browser and server, because this escaping
is done in the part of the URL that is composed _by_the_client_
(so it is bound to be non-opaque to it).

These will be unescaped either by server or the script; both of
them know how to do it.  The problem was that there are other
reserved characters than just +&= and if they are left unparsed
by server, but %xx are still unescaped, the result may
contain characters that have a special meaning in URL, but
the script cannot tell anymore if those stand for their special
meaning, or if they were escaped in the first place.

-- Cheers, Ari --




From robm@ncsa.uiuc.edu  Thu Nov 18 03:07:04 1993 -0600
Message-Id: <9311180907.AA11935@void.ncsa.uiuc.edu>
Date: Thu, 18 Nov 1993 03:07:04 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGP/1.0 specification

/*
 * Re: CGP/1.0 specification  by Tony Sanders (sanders@bsdi.com)
 *    written on Nov 17, 10:32pm.
 *
 * 
 * > REMOTE_USER:           The user the client has authenticated as
 * State that if unset or null then it's an unauthenticated request

Done.

 * > The item which is difficult to pass as an env. variable is the decoded
 * > query string. If we pass it as a single string separated by spaces, a
 * I think argv[2...] is enough, I don't think we need an env variable also.

I think you're right, it would be a real pain to put the data in an env.
variable also.

 * I think what we should state is that if the resulting command line would
 * excede system maximuns (length or # arguments) then *NO* argv[2] is
 * passed and you must decode the URL yourself or punt.  This is also
 * the case if there is no query string (then you check $SERVER_QUERY
 * or whatever it's called and if it's not set there is no query at all).

Are the maximums a per-system thing, or should we specify what the maximum
length is?

 * > On the command line, there should be two arguments:
 * I would restate that, even if you don't adopt the suggestion above
 * it's not true.

You're right, it's something I wrote and later forgot to edit out.

 * > argv[1] is always the path info, untouched. If there is no path info,
 * > this is "".
 * > 
 * > argv[2....] is the decoded query info, split on spaces or ampersands.
 * You can't split on spaces, you mean pluses `+'.  How do you decide
 * if it's spaces or ampersands?  I assume if it has &'s then you split
 * on & else +, just need to make that clear.

Yes, I meant pluses. We have to trust the client to encode ampersands if
it's an ISINDEX query, and trust it to encode pluses if it's a form query.
Mosaic is good about it, are there any that aren't?

 * > If the server does not use popen() or system(), and instead uses
 * > fork() and execl(), the command-line length limitation should not
 * > apply. I haven't verified this.
 * It does, it's a low-level problem with exec.

Oh well. I was hoping.

 * > The server should pass the header for the request as given by the
 * > client to the script as stdin. It should also, after the header, pass
 * > the client's data stream.
 * I assume this includes the ``GET /foobar HTTP/1.0'' part.

Should we pass that part? The scripts can get the info from the other data
if I'm not mistaken...

 * > Note that above, the server must know what content-type and
 * > content-length are in order to put them in environment variables.
 * > Should this be necessary, or should the server pass the entire header
 * > without touching it, and make the script pull content-type and
 * > content-length out?
 * I think the server must always touch the data so this isn't a problem,
 * the server will always have to relay the information.  I don't see a clean
 * way around this because there is no way to read "just" the right amount
 * of information so you don't snarf in some of the headers or the data.
 * That would require length information *before* you read the request.
 * A smarter HTTP protocol would have a fixed size data header with this
 * information, but without it you can't do what you imply.

Hmmm. I suppose the server will have to buffer it and spit it back for the
script. The thing which bothers me about this is that the header sometimes
becomes quite lengthy, with all of the Accept: header lines.

 * > *** The script's STDOUT
 * 
 * I need to look at all the plexus gateways and see what "callbacks" they
 * will require (the two you listed are the big ones).
 */

Let me know if there are more.

--Rob



From robm@ncsa.uiuc.edu  Thu Nov 18 03:24:08 1993 -0600
Message-Id: <9311180924.AA12114@void.ncsa.uiuc.edu>
Date: Thu, 18 Nov 1993 03:24:08 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGP/1.0 specification

/*
 * Re: CGP/1.0 specification  by frans van hoesel (hoesel@chem.rug.nl)
 *    written on Nov 18,  9:27am.
 *
 * > *** Environment Variables
 * > 
 * > To pass most data from the server to the scripts, I propose we use
 * > environment variables.  This way, we escape command line length
 * > restrictions, and complications of short scripts having to parse stdin.
 * 
 * maybe I missed part of this discussion, but why not send this data all
 * to stdin. If simple scripts need this info as environment variables
 * then they do need to call a (standard) subroutine to read the environment.
 * 
 * If you would supply the data on stdin (perhaps just the same list as you
 * use below, endig with a special mark (which could be as simple as the
 * first blank line, for very simple scripts)) then people who would
 * need this infi will simply call onathore not-so-standard subroutine
 * to parse this info from stdin. You could supply this not-so-standard
 * routine for them.

Shell scripts would still have a difficult time with this. C programs would
have no problem.

 * I got interested, because you stated that environment variables would not
 * have limits. 
 * First of all, your proposol does have limits, because I cannot have many
 * queries. This is because you still can have a lot of arguments.

I don't understand. Can you restate this? What do you mean by "cannot have
many queries"?

 * Secondly to test if environment is unlimited in length 
 * I did
 * setenv TEST `ls -l`
 * on a 450 file directory. That took an extremly long time in tcsh (an 
 * equivalent for csh). You might try this to see how long it takes!

I did. I could not get Sun's version of csh to do that, it would complain
about too many words. Our version of csh requires that the second argument
to setenv be a word or quoted string.

I tried your example in zsh, with a 78K file instead of a large directory
listing. Setting an environment variable equal to the contents of this file
took just under 3 seconds on an unloaded sun 4. A little slower than I'd
like, but not bad.

 * So using environment isn't very efficient.

...... I don't think I can agree with your conclusion given your evidence,
sorry.

 * secondly 
 * printenv failed after I had set this variable.
 * everything came back ok after I removed this variable.
 * So even environment variable might have problems with long queries.
 * (I say might, because printenv could be broken or whatever)

Sounds to me like csh is broken. zsh handled the 78K environment variable
with flying colors. From the implementation of the library call putenv,
also, I see no reason why environment variables would be limited. Is there
something I'm missing?

 * 'm not really against environment variable, but the very long time it
 * took to set the above environment did scare me a bit, and I really don't see
 * the point in using them at all. (eg I don;t see the reason you cannot use
 * a special purpose routine for parsing stdin, and for very simple
 * scripts it can be as sinple as skipping to the first blank line). But as Is
 * said, I may have missed part of the discussion.
 */

But it's not that simple. I have no problem with the stdin based approach
for C programs and PERL scripts, but shell scripts are another matter
entirely. 

--Rob



From luotonen@ptsun00.cern.ch  Thu Nov 18 13:22:20 1993 +0100
Message-Id: <9311181222.AA01645@ptsun03.cern.ch>
Date: Thu, 18 Nov 93 13:22:20 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: Re: CGP/1.0 specification


>  * Secondly to test if environment is unlimited in length 
>  * I did
>  * setenv TEST `ls -l`
>  * on a 450 file directory. That took an extremly long time in tcsh (an 
>  * equivalent for csh). You might try this to see how long it takes!

That's probably because you have filename globbing on so tcsh goes
through that stuff searching and matching any wildcards it finds.
With "set noglob":

	set FOO=`cat big.html`

completes in less than 2 seconds with a 100K file (on my Sparc IPX
with no heavy load).  In Bourne shell it's even faster.


-- Cheers, Ari --




From luotonen@ptsun00.cern.ch  Thu Nov 18 13:49:26 1993 +0100
Message-Id: <9311181249.AA01662@ptsun03.cern.ch>
Date: Thu, 18 Nov 93 13:49:26 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: Re: CGP/1.0 specification


> That's probably because you have filename globbing on so tcsh goes
> through that stuff searching and matching any wildcards it finds.
> With "set noglob":
> 
> 	set FOO=`cat big.html`
> 
> completes in less than 2 seconds with a 100K file (on my Sparc IPX
> with no heavy load).  In Bourne shell it's even faster.

Oups, ignore tcsh-part of what I said.  I should have said 'setenv'
and not 'set'... With a 100K file 'setenv' practically never returns.
I waited 5 mins and then killed my tcsh... :-(

But Bourne shell really does the set and then export in less than
2 secs.

-- Cheers, Ari --





From Jon.Tetzchner@nta.no  Thu Nov 18 14:18:50 1993 +0100
Message-Id: <199311181318.AA17102@hal.nta.no>
Date: Thu, 18 Nov 1993 14:18:50 +0100
From: Jon.Tetzchner@nta.no (Jon von Tetzchner Stephenson)
Subject: Frame2html filter


	Frame 2 Html filter, version 0.8, 8th November 19993
	====================================================

This filter has been made as part of my work at Norwegian Telecom Research.
All rights to the filter belong to Norwegian Telecom Research.
The filter can be modified as long as the top lines of each source file
indicating the original source of the filter is kept. We would also
appriciate being sent information about bugs, bug fixes, etc.

The current version of the filter:

	o Handles frame files and books.
	o Is customable, through a tags file mapping frame tags to 
		logical tags used by the filter.
	o All frame X-refs become html links.
	o An index is automatically generated based on chapter
		headings in the frame documents.
	o The file structure of the frame document is kept in the
		html document. Single frame files become single
		html files. Frame books become multiple html files,
		one html file for each frame file. FrameMaker generated
		files are removed.
	o Graphics and maths are separated to files, which are then 
		translated to postscript and ultimately gif.
	o Tables are handled through the <pre> html tag.
	o Italics and bold parts of paragraphs are handled.

Problems and bugs:

	o Characters in frame not in html, including Greek character.
	o Documents that are divided into sections using the FrameMaker
		'frame'.
	o FrameMaker documents which do not use tags and operate on
		text directly.
	o Very large pictures are not handled well (bigger than an A4).

This program was made for internal use only. I will try to make it portable,
but it is not unlikely that a few paths have to be changed.



Below is a list of environment variables that need to be set:

	FRAME2HTMLTAGSFILE (e.g. /local/lib/frame2html.tags)
	FRAME2HTMLPRINTFILE (e.g. /local/lib/printout.frame)

Useage: 
	fm2html frame-file [title] [author]
	Fm2html can take 3 parameters.
	The first specifies the name of the file or book to translate.
	The second optional parameter is the title of the file.
	The third optional parameter is the author of the file.

Warning:
	The filter operates in the current version on
	your local directory. It uses a lot of memory and will
	very easily run out of space, unless you give it a lot
	of swap space.

Some comments:

	The tags file uses TABs to separate internal tags and
	FrameMaker tags. To see a list of the internal tags,
	have a look at the start of the trans-code.c file.

	You may have to change the line in the start of the perl
	scripts identifying the location of the perl interpreter.
	Do this in the Makefile.
	
	You will probably have to edit the directories in ps2gif
	so that they show where the pnm and ppm filters lie. Other
	programs that have to be available on your machine include
	gs (GhostScript), FrameMaker (fmbatch), flex, yacc, cc and
	gcc (I actually needed both to get it all compiled).
	
Acknowledgement:

	I would like to thank Geir Ivarsoey of Norwegian Telecom Research
	and Duncan Fraser and Randy Roesler of MacDonald Detwiller for
	their assistance in improving this program. 

Availability:

	ftp bang.nta.no:pub/fm2html.tar.Z


Disclaimer:

	Use this program at your own risk.









From terry@ora.com  Thu Nov 18 13:55:38 1993 PST
Message-Id: <199311182155.AA29212@rock.west.ora.com>
Date: Thu, 18 Nov 1993 13:55:38 PST
From: terry@ora.com (Terry Allen)
Subject: ISINDEX clarification

My apologies for not checking more carefully.  Only in the HTML+
DTD may ISINDEX appear only before the body of a document.  In other
variants of the HTML DTD, through the inclusion of %oldstyle; in
an OR group, anything may be done.  The June 1993 draft which 
references itself as http://info.cern.ch/hypertext/WWW/MarkUp/HTML.html
(by Tim B-L and Dan Connolly), doesn't seem to regard docs tagged
with <HTML> as Old Style, but the HTML DTD does not make the
distinction.

That is, the doc is a little out of kilter with the DTD here;
HTML+ handles the matter differently.

Regards,

-- 
Terry Allen  (terry@ora.com)
Editor, Digital Media Group
O'Reilly & Associates, Inc.
Sebastopol, Calif., 95472



From robm@ncsa.uiuc.edu  Thu Nov 18 17:44:26 1993 -0600
Message-Id: <9311182344.AA25629@void.ncsa.uiuc.edu>
Date: Thu, 18 Nov 1993 17:44:26 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGP/1.0 specification

/*
 * Re: CGP/1.0 specification  by Ari Luotonen (luotonen@ptsun00.cern.ch)
 *    written on Nov 18, 10:32am.
 *
 * 
 * > We could pass it as a
 * > list of quoted items, but then there can't be quotes in the items. 
 * 
 * We can:  it's  becomes:  'it'\''s'

As Tony and I were discussing, perhaps we should not make the unescaped
query string available as an env. variable at all but simply put it on the
command line.

 * Otherwise agreed, but I'd still wish you'd consider doing it like
 * I did, which would cause command line:
 * 
 * 	script /extra/path	'foo=' 'bar' 'bar=' 'foo'
 * 
 * In this case equal signs in values (or even names) wouldn't cause
 * any confusion, and spaces in values aren't a problem, either.

But the equal signs are frivolous, and the script just has to parse them out
anyway. So why put them in there?

 * At least for CERN server it *must* be a virtual path, because the
 * rule file starts protecting already before the filesystem path is
 * found out.  Otherwise I'd have to be able to translate filesystem
 * path back to virtual path which is indeterministic.
 */

Hmmmm. Here's the two choices as I see them. 

1. A full real pathname

Pluses: Flexibility. Any file can be returned.
Minuses: Security. These files don't necessarily have to be subject to
access control.

2. A virtual pathname

Pluses: Security. Only normally servable documents are allowed.
Minuses: Must return documents that are normally available to the client.


As far as implementation, I can easily do either. The question is, then,
what will the scripts want? Would it be difficult with the CERN server to
enter the document mapping process with an already translated pathname? If
it's overly difficult, and scripts do not necessarily want to return outside
documents, we should pick the virtual path. Tony, which method would be
easier for Plexus?

--Rob




From phillips@cs.ubc.ca  Mon Nov 18 18:36:00 1993 -0800
Message-Id: <6890*phillips@cs.ubc.ca>
Date: 18 Nov 93 18:36 -0800
From: phillips@cs.ubc.ca (George Phillips)
Subject: Re: CGP/1.0 specification 

It's useful for scripts to know what part of the URL was used to invoke
them (Rob suggested $SCRIPT_NAME before).  That information is currently
implicit in the spec.  It can be derived by looking at the first
length(FULL_URL) - length(PATH_INFO) characters of FULL_URL.  If
this is true, that's fine, but maybe we'd rather just have
SCRIPT_NAME and PATH_INFO and drop FULL_URL in favor of it the
simple $SCRIPT_NAME$PATH_INFO derivation.  Or have all 3, whatever.

A few other comments:

>GATEWAY_PROTOCOL:      The revision of this spec to which the server complies

Why not make this a mime-like typename, say "CGP/1.0" for this version?

>*** The script's STDOUT
...
>If the script returns a header line of "Parse-header: false", the
>server will pass the rest of the output stream directly to the client.

This is not really part of the protocol, but if the server had some
way to tell that the script was always going to do it's own headers,
we could avoid the extra overhead of having the server chop the
(constant) "Parse-header: false\r\n\r\n" bit and re-copying the data.
I suppose it would save a little cross-configuration if the server
told the script what it expected.  That begs for breaking the
GATEWAY_PROTOCOL variable into GATEIN_PROTOCOL and GATEOUT_PROTOCOL.
We still only have "CGP/1.0" for GATEIN_PROTOCOL, but we'd have
"CGP/1.0" for GATEOUT_PROTOCOL where the server looks at things and
"HTTP/1.0" for GATEOUT_PROTOCOL which means do it yourself
(or HTTP/0.9).

As to the question of whether Location: should interpret a virtual
of real pathname, I'd say that it should be virtual.  If the
script wants to output a real path name, it can "cat /a/real/path/name".
Also, the virtual path name gives it the flexibility to activate
some other gateway.

			-- George



From joe@mit.edu  Fri Nov 19 01:41:25 1993 -0500
Message-Id: <9311190641.AA26826@theodore-sturgeon.MIT.EDU>
Date: Fri, 19 Nov 93 01:41:25 -0500
From: joe@mit.edu (joe@mit.edu)
Subject: WWW Indexing initative


This is to announce the creation of a mailing list to discuss the
Globewide Network Academy Meta-Library, an initiative to index
Internet servers including those dealing with WWW.  The list will be
used to coordinate development and maintence of the meta-library.

To subscribe to the mailing list, send email to listserv@mcmuse.maricopa.edu
with the message

   SUBSCRIBE gna-meta-library-admin

The address of the meta-library itself is

    http://uu-gna.mit.edu:8001/uu-gna/meta-library/index.html

and this address contains links to local documentation for the
meta-library.





From Jill.Foster@newcastle.ac.uk  Fri Nov 19 08:40:10 1993 GMT
Message-Id: <199311190840.IAA05235@tuda.ncl.ac.uk>
Date: Fri, 19 Nov 1993 08:40:10 GMT
From: Jill.Foster@newcastle.ac.uk (Jill.Foster@newcastle.ac.uk)
Subject: Re: WWW Indexing initative

At  1:41 am 19/11/93 -0500, joe@mit.edu wrote:
>This is to announce the creation of a mailing list to discuss the
>Globewide Network Academy Meta-Library, an initiative to index
>Internet servers including those dealing with WWW.  The list will be
>used to coordinate development and maintence of the meta-library.
>
>To subscribe to the mailing list, send email to listserv@mcmuse.maricopa.edu
>with the message
>
>   SUBSCRIBE gna-meta-library-admin
>
>The address of the meta-library itself is
>
>    http://uu-gna.mit.edu:8001/uu-gna/meta-library/index.html
>
>and this address contains links to local documentation for the
>meta-library.

As there are many many initiatives  to organise the info on the network,
how is yours different?
Is it funded for example?

-- Jill Foster (chair RARE Information Services and User Support Working Group)




From luotonen@ptsun00.cern.ch  Fri Nov 19 11:58:55 1993 +0100
Message-Id: <9311191058.AA02218@ptsun03.cern.ch>
Date: Fri, 19 Nov 93 11:58:55 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: Re: CGP/1.0 specification


Rob:
> As Tony and I were discussing, perhaps we should not make the unescaped
> query string available as an env. variable at all but simply put it on the
> command line.

Good.

>  * 	script /extra/path	'foo=' 'bar' 'bar=' 'foo'
>  * 
>  * In this case equal signs in values (or even names) wouldn't cause
>  * any confusion, and spaces in values aren't a problem, either.
> 
> But the equal signs are frivolous, and the script just has to parse them out
> anyway. So why put them in there?

In the common case for a given script there is a certain well-known
set of field names that it can expect.  In that case it doesn't need
to parse ='s away, but strcmp with fieldname possibilities that are
appended with an equal sign.  This makes scripts a little clearer to
read and debugging easier as the tester can see which one is the field
name and which is the value.  But ok, if everybody thinks this is oh so
stupid I will seriously consider taking my word back a bit and strip
those ='s away, if that's what it takes.


> [Should Location: be absolute or virtual]
> 
> As far as implementation, I can easily do either. The question is, then,
> what will the scripts want? Would it be difficult with the CERN server to
> enter the document mapping process with an already translated pathname? If
> it's overly difficult,

Try impossible :-(  at least if I want to do it properly.  Rule file
can do many-to-one mappings.  Reverse to this would sometimes
produce funny results.

Well never mind that, I might be able to do something about it,
but as George Phillips said:

> As to the question of whether Location: should interpret a virtual
> of real pathname, I'd say that it should be virtual.  If the
> script wants to output a real path name, it can "cat /a/real/path/name".
> Also, the virtual path name gives it the flexibility to activate
> some other gateway.

I couldn't agree more; especially the last point is very important.


-- Cheers, Ari --




From Jon.Tetzchner@nta.no  Fri Nov 19 13:02:24 1993 +0100
Message-Id: <199311191202.AA22669@hal.nta.no>
Date: Fri, 19 Nov 1993 13:02:24 +0100
From: Jon.Tetzchner@nta.no (Jon von Tetzchner Stephenson)
Subject: Frame2html filter.


A bug managed to creep into the Frame2html filter I just released.
The effect of this bug is that books will not be translated. I am
sorry for the inconvenience this has caused. Please get the new 
version from bang.nta.no:pub.

	Jon.



From swb@nr-tech.cit.cornell.edu  Fri Nov 19 08:04:14 1993 -0500
Message-Id: <199311191305.IAA11287@mitchell.cit.cornell.edu>
Date: Fri, 19 Nov 1993 08:04:14 -0500
From: swb@nr-tech.cit.cornell.edu (Scott W Brim)
Subject: Re: WWW Indexing initative

I have a feeling there are many such initiatives, but if someone asked
me to list them and evaluate their status I couldn't possibly.  Does
anyone have a list of the current efforts?  If not, could some
knowledgeable person (Jill???) please take a few minutes and put one
together?

                                                Thanks ... Scott

At  8:40 AM 11/19/93 +0000, Jill.Foster@newcastle.ac.uk wrote:
  >As there are many many initiatives  to organise the info on the network,
  >how is yours different?
  >Is it funded for example?





From luotonen@ptsun00.cern.ch  Fri Nov 19 16:36:48 1993 +0100
Message-Id: <9311191536.AA02439@ptsun03.cern.ch>
Date: Fri, 19 Nov 93 16:36:48 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: Re: CGP/1.0 specification


I wrote:
> Rob:
> > As Tony and I were discussing, perhaps we should not make the unescaped
> > query string available as an env. variable at all but simply put it on the
> > command line.
> 
> Good.

Aargh!  I'm certainly in a need of weekend, or I have a terrible case
of dyslexia;  I didn't mean to say good.  But it's better I don't say
anything else, either... I'll be quiet until next Monday...


-- It's me again, Ari --

Sign at CERN entrance:
       --------------------------------------
                  Critical period
           reduce band-width consumption
       --------------------------------------
And naturally I must rebel... :-)



From lvirden@cas.org  Fri Nov 19 11:40:57 1993 EST
Message-Id: <9311191640.AA17523@cas.org>
Date: Fri, 19 Nov 93 11:40:57 EST
From: lvirden@cas.org (Larry W. Virden, ext 2487)
Subject: Re: WWW Indexing initative


I don't seem to be able to access info.cern.ch today using my Mosaic 2.0
sun client.
ERROR
*****

Requested document (URL http://info.cern.ch/) could not be accessed.

The information server either is not accessible or is refusing to serve
the document to you.


is the error I get

-- 
:s 
:s Larry W. Virden                 INET: lvirden@cas.org
:s Personal: 674 Falls Place,   Reynoldsburg, OH 43068-1614



From roeber@vxcrna.cern.ch  Fri Nov 19 18:32:07 1993 +0100
Message-Id: <9311191732.AA22770@dxmint.cern.ch>
Date: Fri, 19 Nov 1993 18:32:07 +0100
From: roeber@vxcrna.cern.ch (Frederick G.M. Roeber)
Subject: Re: WWW Indexing initative

>I don't seem to be able to access info.cern.ch today using my Mosaic 2.0
>sun client.
>ERROR
>*****
>
>Requested document (URL http://info.cern.ch/) could not be accessed.
>
>The information server either is not accessible or is refusing to serve
>the document to you.

Yes, info.cern.ch seems to be hosed an awful lot lately.  I think it's
NFS problems, or at least the Domain-iac inside me wants to believe that.

Often, you can get a copy by trying http://www1.cern.ch/... instead.
Unfortunately, 1) not everything is duplicated, and 2) even in the
duplicated stuff, not all the pointers are relative, so you often get
landed back onto the inoperative server.

--
<a href="http://info.cern.ch/roeber/fgmr.html">Frederick</a>



From timbl@www3.cern.ch  Fri Nov 19 17:09:30 1993 +0100
Message-Id: <9311191609.AA03469@www3.cern.ch>
Date: Fri, 19 Nov 93 17:09:30 +0100
From: timbl@www3.cern.ch (Tim Berners-Lee)
Subject: Re: WWW Indexing initative


>I have a feeling there are many such initiatives, but if someone  
asked
>me to list them and evaluate their status I couldn't possibly.  Does
>anyone have a list of the current efforts?  If not, could some
>knowledgeable person (Jill???) please take a few minutes and put one
>together?
>
>                                                Thanks ... Scott

	I have a feeling there are many such lists... Could some
	knowledgable person make a list of them?  ;-))))
	
	A list of all known (to us) subject-oriented collections
	going across protocol boundaries is
	
http://info.cern.ch/hypertext/DataSources/bySubject/Virtual_libraries/ 
Overview.html

	I append it without the links if you are interested.
	
	One of the collections is one which we started, and which
	we delegate by subject.  Anyone interested in keeping up to
	date the definitive list of internet resources in a
	 restricted subject area is VERY welcome to take on a
	"department".  Anyone who wants to start a new effort from
	scratch should think about scaling.  Similarly, if anyone
	feels the urge to make another metalist, then why not just
	add or take over ours?  There is room for comptetive lists
	but not yet at this level -- there ought to be a limited
	number.
	
	(BTW: If you start from http://info.cern.ch/default.html
	you should find any collection, by subject, server type, etc
	but I think you are only talking of arrangements by
	subject)	


Tim Berners-Lee
CERN

________________________________________________________
                              A list of Virtual Libraries on the Web
                         VIRTUAL LIBRARIES
                                  

 Please mail www-request@info.cern.ch if you know of any arrangement
                of information by subject not in this list of lists.
                                                                    

   These are collections of information by subject matter, good
   places to start when looking for information.
   

Browsing by subject

      The World Wide Web Virtual Library[1] is distributed in that
      different subjects are handled by different sites.
      

Searchable libraries

      The UU-NNA metalibrary[2] wishes to create a fully accredited
      university over computer networks
      

      The W3 searchable catalog[3] built from other sources here.
      

      The Internet Services list[4] (based on Yanoff's Internet
      List)
      

      The Whole Internet Catalogue[5] from O'Reilly (updated from
      the bestselling "The Whole Internet Catalog User's Guide
      Catalog")
      

Other catalogues

  HYPERTEXT
  

      Big Dummy's Guide to the Internet[6] will help you join the
      global village known as Cyberspace or the Net (1.02)
      

      Marc Andreessen's big "loosely catagorized" meta index[7] has
      pointers for example to the many Gopher subject trees.
      

  NOT HYPERTEXT
  

  UMich's list of resource lists[8]
                          collects and makes widely  available
                         guides to Internet resources which are
                         subject-oriented.
                         

  The HCI Bibliography Project
                          A free-access online extended bibliography
                            on Human-Computer Interaction (gathers
                         most books, journals, and conference
                         proceedings on HCI dating back to 1980)
                         

   





From robm@ncsa.uiuc.edu  Fri Nov 19 15:35:07 1993 -0600
Message-Id: <9311192135.AA10317@void.ncsa.uiuc.edu>
Date: Fri, 19 Nov 1993 15:35:07 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: CGP/1.0 specification

/*
 * Re: CGP/1.0 specification  by Tony Sanders (sanders@BSDI.COM)
 *    written on Nov 19, 11:06am.
 *
 * > As far as implementation, I can easily do either. The question is, then,
 * > what will the scripts want? Would it be difficult with the CERN server to
 * > enter the document mapping process with an already translated pathname? If
 * > it's overly difficult, and scripts do not necessarily want to return outside
 * > documents, we should pick the virtual path. Tony, which method would be
 * > easier for Plexus?
 * 
 * Whatever you guys think is best.  The comment about `cat /realpath' seems
 * valid so I guess virtual paths will be the way to go.
 * 
 * --sanders
 */

My only problem with making it virtual is that if the script needs to send a
file outside the web's tree, it will have to type it itself (since it has to
cat it or use a short C function to send it).

--Rob



From robm@ncsa.uiuc.edu  Fri Nov 19 16:26:28 1993 -0600
Message-Id: <9311192226.AA18159@void.ncsa.uiuc.edu>
Date: Fri, 19 Nov 1993 16:26:28 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGP/1.0 specification

/*
 * Re: CGP/1.0 specification  by George Phillips (phillips@cs.ubc.ca)
 *    written on Nov 18,  6:36pm.
 *
 * It's useful for scripts to know what part of the URL was used to invoke
 * them (Rob suggested $SCRIPT_NAME before).  That information is currently
 * implicit in the spec.  It can be derived by looking at the first
 * length(FULL_URL) - length(PATH_INFO) characters of FULL_URL.  If
 * this is true, that's fine, but maybe we'd rather just have
 * SCRIPT_NAME and PATH_INFO and drop FULL_URL in favor of it the
 * simple $SCRIPT_NAME$PATH_INFO derivation.  Or have all 3, whatever.

This is true, it makes FULL_URL frivolous. Unless there are any serious
objections, I'd like to remove it from the spec.

 * A few other comments:
 * 
 * >GATEWAY_PROTOCOL:      The revision of this spec to which the server complies
 * 
 * Why not make this a mime-like typename, say "CGP/1.0" for this version?

This is what I had in mind.

I was thinking about it, and this is not really a protocol but an interface.
What do you all think about changing it to CGI/1.0?

 * >*** The script's STDOUT
 * ...
 * >If the script returns a header line of "Parse-header: false", the
 * >server will pass the rest of the output stream directly to the client.
 * 
 * This is not really part of the protocol, but if the server had some
 * way to tell that the script was always going to do it's own headers,
 * we could avoid the extra overhead of having the server chop the
 * (constant) "Parse-header: false\r\n\r\n" bit and re-copying the data.
 * I suppose it would save a little cross-configuration if the server
 * told the script what it expected.  That begs for breaking the
 * GATEWAY_PROTOCOL variable into GATEIN_PROTOCOL and GATEOUT_PROTOCOL.
 * We still only have "CGP/1.0" for GATEIN_PROTOCOL, but we'd have
 * "CGP/1.0" for GATEOUT_PROTOCOL where the server looks at things and
 * "HTTP/1.0" for GATEOUT_PROTOCOL which means do it yourself
 * (or HTTP/0.9).

The problem is that I'd like scripts to have the flexibility of returning
the header if they so choose, without the server deciding for them.

How about, instead of "Parse-header", changing it to "Gateway-protocol" and
making it a word such as "HTTP/1.0" or "CGI/1.0"? This does not help your
concern of header-parsing overhead, but I think we can't avoid it anyway.

 * As to the question of whether Location: should interpret a virtual
 * of real pathname, I'd say that it should be virtual.  If the
 * script wants to output a real path name, it can "cat /a/real/path/name".
 * Also, the virtual path name gives it the flexibility to activate
 * some other gateway.
 */

See my response in another note...

--Rob



From robm@ncsa.uiuc.edu  Fri Nov 19 16:46:58 1993 -0600
Message-Id: <9311192246.AA18776@void.ncsa.uiuc.edu>
Date: Fri, 19 Nov 1993 16:46:58 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: revised CGI/1.0 specification


I have revised the CGI/1.0 spec according to suggestions made on www-talk, so
please take a look at it. I have changed the name to CGI because it's really an
interface and not a protocol. I know, picky picky.

The passing of forms args is somewhat like what Ari does, for compatibility's
sake. For most forms, the scripts will probably want to decode the URL from an
env. variable to escape restrictions anyway.

Also, I've changed the Parse-header line to Gateway-protocol, which can be the
version of the protocol the script complies to, and whether it wants to send
its own HTTP header. This is important for future modifications, and seems
more flexible.

Outstanding gray area:

Sending the whole header to the script. Tony has had problems, and I
agree that all of those byte operations keeping the data from the stream
will probably cause problems. Should we send the header, or have the server
make its information available somehow? What will be used except Accept?


Are there any other gray areas still out there? Any objections to any part
of the document? I'd like to get coding soon.

--Rob



From phillips@cs.ubc.ca  Mon Nov 19 16:18:00 1993 -0800
Message-Id: <6899*phillips@cs.ubc.ca>
Date: 19 Nov 93 16:18 -0800
From: phillips@cs.ubc.ca (George Phillips)
Subject: revised CGI/1.0 specification

Rob sez:
>The problem is that I'd like scripts to have the flexibility of returning
>the header if they so choose, without the server deciding for them.

Well, my concern was purely an efficiency one, but it's not the
header parsing that's the problem.  It's the copying of the
rest of the data that I wish to avoid.  If the script and the
server agree ahead of time, the script can be forked with its
output directed straight at the network rather than having to
go through the server.  You can decide for yourself if that
copying overhead is worth avoiding.  I would expect the
server and the script to have some extra-interface agreement
on the output format -- the server would never unilaterally
demand that the script do HTTP/1.0 output unless configuration
information said the script wanted it.

Anyhow, I think the change to "Gateway-protocol:" is a good one.

>Sending the whole header to the script.

If you feel it's too complex to send the header, then let's not do
that.  I think you're right, the script will rarely care about
anything but "Accept:".  How about we add another environment
variable for "Accept:" fields and leave room for more fields as
that becomes necessary.  Call it "HDR_ACCEPT", and it will contain
";" separated concatenations of the Accept: headers (I think ";"
separated is within the MIME way of things).  Future header fields
will use the variables "HDR_fieldname".

Or, we could just dump the whole header into "HEADER".

Now for a couple of picky naming things of my own:

GATEWAY_PROTOCOL -- should be GATEWAY_INTERFACE now
PROTOCOL_METHOD -- is "REQUEST_METHOD" more meaningful?

And a few minor points:

>QUERY_STRING:          That which follows the ?, untouched

Will not be in the environment if original URL has no "?"

>argv[2....] is the decoded query info, split on pluses or ampersands.

And should not appear if there is no query.  But this conflicts
with:

>If the resulting string is too lengthy to place on the command line,
>the server will not provide argv[2.....] at all and the script must
>either report an error to the client or decode the URL itself.

Well, if QUERY_STRING is only optionally in the environment, it
doesn't matter what happens with argv[2....].

			-- George



From henrich@crh.cl.msu.edu  Sat Nov 20 16:52:50 1993 -0500 (EST)
Message-Id: <9311202152.AA08106@crh.cl.msu.edu>
Date: Sat, 20 Nov 1993 16:52:50 -0500 (EST)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: Future browsers...

What do you all feel is the most important next HTML+ features for Browser's to
implement?  I currently would *really* like to see text flow around <img>'s and
tables!

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                      http://rs560.msu.edu/~henrich



From sfsh@rome.classics.lsa.umich.edu  Sat Nov 20 17:40:33 1993 -0500 (EST)
Message-Id: <Pine.3.87.9311201733.B12159-0100000@rome.classics.lsa.umich.edu>
Date: Sat, 20 Nov 1993 17:40:33 -0500 (EST)
From: sfsh@rome.classics.lsa.umich.edu (Sebastian Francis Heath)
Subject: Re: Future browsers...



Two things I would like to see:

In other hypermedia applications I have worked on, it has been useful to 
allow users to select any text and initiate a link from it.  This allows, 
for example, a user to select a word s/he doesn't understand and ask that 
it be looked up in a dictionary/glossary  or a site name can be looked up 
in an atlas.  This is allowed on the "Perseus 1.0: INteractive 
sources and Studies on Ancient Greece" CD-ROM.  The interface on that 
version is not the model for how things should be done, just one 
implementation.  Could there be an "<ISSELECTABLE>" tag with an 
"action=" attribute that made use of the existing htbin architecture?  
When this tag is present a "Link on Selection" button could appear 
somewhere on the page.  Obviously this is not just a client side change.


The second request may seem to go against the spirit of the web.  I would 
like to put Mosaic clients in a museum public gallery.  This is 
unrealistic with the existing set of actions that the current clients 
support.  I do not want users to be able to quit, open new windows, close 
existing ones, open any URL, etc.  On X servers, resizing windows can be 
controlled by the window manager.  The mac and windows? client would need to 
support window type choices.  What would people think of a public 
access/kiosk version of the client?  

-Sebastian Heath





From totic@milton.cs.uiuc.edu  Sat Nov 20 17:32:13 1993 CST
Message-Id: <199311202332.AA28881@milton.cs.uiuc.edu>
Date: Sat, 20 Nov 93 17:32:13 CST
From: totic@milton.cs.uiuc.edu (Aleksandar Totic)
Subject: Re: Future browsers...

> The second request may seem to go against the spirit of the web.  I would 
> like to put Mosaic clients in a museum public gallery.  This is 
> unrealistic with the existing set of actions that the current clients 
> support.  I do not want users to be able to quit, open new windows, close 
> existing ones, open any URL, etc.  On X servers, resizing windows can be 
> controlled by the window manager.  The mac and windows? client would need to 
> support window type choices.  What would people think of a public 
> access/kiosk version of the client?  
> 
MacMosaic is very customizable (like any other Mac applications),
through ResEdit. You can arbitrarily rearrange the menus, and delete
those that are not needed. The windows can be edited through ViewEdit,
and you could change window type through it.

Aleks



From sfsh@rome.classics.lsa.umich.edu  Sat Nov 20 19:42:04 1993 -0500 (EST)
Message-Id: <Pine.3.87.9311201904.B12500-0100000@rome.classics.lsa.umich.edu>
Date: Sat, 20 Nov 1993 19:42:04 -0500 (EST)
From: sfsh@rome.classics.lsa.umich.edu (Sebastian Francis Heath)
Subject: Re: Future browsers...

While it is true that all Mac applications can be customized
with resedit and that I will happily resort to this if need
be, I do not consider this the optimal implementation of a 
kiosk ready client.  Most museum people I know would not 
want to mess with resedit.

-Sebastian Heath

p.s.  no flame intended, just discussion




From altis@ibeam.jf.intel.com  Sat Nov 20 17:59:14 1993 -0800
Message-Id: <m0p143N-0003WAC@ibeam.intel.com>
Date: Sat, 20 Nov 1993 17:59:14 -0800
From: altis@ibeam.jf.intel.com (Kevin Altis)
Subject: Re: Future browsers...

At  7:42 PM 11/20/93 -0500, Sebastian Francis Heath wrote:
>While it is true that all Mac applications can be customized
>with resedit and that I will happily resort to this if need
>be, I do not consider this the optimal implementation of a
>kiosk ready client.  Most museum people I know would not
>want to mess with resedit.

No problem. Just write a small application that modifies the ResEdit
resources for them automatically (this is a very simple app). You would
want to change the default window size and placement and get rid of command
key combinations such as Command-Q for Quit. The worst item is that Mosaic
isn't built with the concept of hiding the menu bar (that I know of) so you
would probably want to adjust the monitors on the kiosks so that the top 20
pixels of the screen isn't visible by changing the vertical positioning.

Okay, that is a hack and a half, but hey it works and it is cheap, safe,
and doesn't require making lots of special hooks into the application.

ka





From sanders@bsdi.com  Sat Nov 20 20:08:54 1993 -0600
Message-Id: <199311210208.UAA04980@austin.BSDI.COM>
Date: Sat, 20 Nov 1993 20:08:54 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: Future browsers... 

> for example, a user to select a word s/he doesn't understand and ask that 
> it be looked up in a dictionary/glossary  or a site name can be looked up 
...
> implementation.  Could there be an "<ISSELECTABLE>" tag with an 
That's exactly what <LINK REV="UseGlossary" HREF="...">
per http://info.cern.ch/hypertext/WWW/MarkUp/Relationships.html
is supposed to do.  <LINK>/REL/REV seem to be the most misunderstood
(or at least under-implemented) part of the WWW design.

> somewhere on the page.  Obviously this is not just a client side change.
Actually, it pretty much is just a client side change.  All you have to
do is query the HREF with the selected word (using the standard "URL?query"
syntax).  Yes, you need server support for the query but that's not really
a "change" as we already know how to do queries.  Also, this would only
require a trivial amount of code in the browser (select current word and
initiate a normal URL jump).

> support window type choices.  What would people think of a public 
> access/kiosk version of the client?  
...
> The second request may seem to go against the spirit of the web.  I would 
Sounds easy enough to do.  You probably want a "start over" button or
something.  I don't think it goes against the spirit of the web at all.

--sanders



From server@mcmuse.mc.maricopa.edu  Fri Nov 19 11:01:17 1993 MST
Message-Id: <9311191801.AA17827@mcmuse.mc.maricopa.edu>
Date: Fri, 19 Nov 93 11:01:17 MST
From: server@mcmuse.mc.maricopa.edu (listserv)
Subject: gna-meta-library-admin

gna-meta-library-admin is not a listserv-based discussion list.  instead,
it is an alias for joe wang who currently heads the gna-meta-library project.

To subscribe to the mailing list, send email to listserv@mcmuse.maricopa.edu
with the message

   SUBSCRIBE gna-meta-library-admin



From decoux@moulon.inra.fr  Sun Nov 21 13:24:27 1993 +0100
Message-Id: <9311211224.AA27665@moulon.moulon.inra.fr>
Date: Sun, 21 Nov 93 13:24:27 +0100
From: decoux@moulon.inra.fr (ts)
Subject: WWW-Oracle



 WWW-Oracle
 ==========

 A better example for Oracle and WWWDaemon 2.14 is in :

 ftp://moulon.inra.fr/pub/www-oracle/example.tar.Z

 Features :

  * method GET, PUT, POST, DELETE, SHOWMETHOD, CHECKIN and CHECKOUT
  * access control based on method name
  * form
  * minimal configuration : you just have to add an URL in a document
  * you can add a general comment for the database, comments on tables and
comments on columns.
  * you can add links to go from a row in a table to rows in other tables.

 Documentation is "http://moulon.inra.fr/update_eng.html"

 Demo is "http://moulon.inra.fr/oracle/A/update/table?action=tables"


  



From carol@csos.orst.edu  Sun Nov 21 09:45:18 1993 -0800 (PST)
Message-Id: <Pine.3.87.9311210918.A538-0100000@CSOS.ORST.EDU>
Date: Sun, 21 Nov 1993 09:45:18 -0800 (PST)
From: carol@csos.orst.edu (Carol Smedberg)
Subject: 

unsubscribe

carol.CSOS.ORST.EDU





From luotonen@ptsun00.cern.ch  Sun Nov 21 19:14:35 1993 +0100
Message-Id: <9311211814.AA02916@ptsun03.cern.ch>
Date: Sun, 21 Nov 93 19:14:35 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: Re: WWW Indexing initative


> >Requested document (URL http://info.cern.ch/) could not be accessed.
> >
> >The information server either is not accessible or is refusing to serve
> >the document to you.
> 
> Yes, info.cern.ch seems to be hosed an awful lot lately.  I think it's
> NFS problems, or at least the Domain-iac inside me wants to believe that.

info is just a poor-ol' NeXT, it will be upgraded soon to a Sun.
It crashes from time to time, probably because of memory running
out or something like that (I'm not a NeXTpert, this is only what
the big boys have told me).

So please be patient with us, these problems will soon be history.


> Often, you can get a copy by trying http://www1.cern.ch/... instead.

Yes, this is currently true, BUT I want to EMPHASIZE that this
is NOT official, so DO NOT in any circumstances make links to www1
that start with /hypertext/...!!!


> Unfortunately, 1) not everything is duplicated,

There is no duplication; both info and www1 NFS mount /hypertext
from the same machine;  so you should get exactly the same stuff
from either machine (please don't flame us, we know this NFS mounting
is very stupid, and we'll fix it once we get enough diskspace).


> and 2) even in the
> duplicated stuff, not all the pointers are relative, so you often get
> landed back onto the inoperative server.

This is very true and oh, so sad.


-- Cheers, Ari --




From robm@ncsa.uiuc.edu  Sun Nov 21 19:12:50 1993 -0600
Message-Id: <9311220112.AA10804@void.ncsa.uiuc.edu>
Date: Sun, 21 Nov 1993 19:12:50 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: revised CGI/1.0 specification

/*
 * revised CGI/1.0 specification  by George Phillips (phillips@cs.ubc.ca)
 *    written on Nov 19,  4:18pm.
 *
 * Rob sez:
 * >The problem is that I'd like scripts to have the flexibility of returning
 * >the header if they so choose, without the server deciding for them.
 * 
 * Well, my concern was purely an efficiency one, but it's not the
 * header parsing that's the problem.  It's the copying of the
 * rest of the data that I wish to avoid.  If the script and the
 * server agree ahead of time, the script can be forked with its
 * output directed straight at the network rather than having to
 * go through the server.  You can decide for yourself if that
 * copying overhead is worth avoiding.  I would expect the
 * server and the script to have some extra-interface agreement
 * on the output format -- the server would never unilaterally
 * demand that the script do HTTP/1.0 output unless configuration
 * information said the script wanted it.

Hmmm, I see what you mean. Yes, the copying overhead is definitely worth
avoiding. I can't really think of a good way to configure whether a script
will want to have the header parsed or not...

 * Anyhow, I think the change to "Gateway-protocol:" is a good one.
 * 
 * >Sending the whole header to the script.
 * 
 * If you feel it's too complex to send the header, then let's not do
 * that.  I think you're right, the script will rarely care about
 * anything but "Accept:".  How about we add another environment
 * variable for "Accept:" fields and leave room for more fields as
 * that becomes necessary.  Call it "HDR_ACCEPT", and it will contain
 * ";" separated concatenations of the Accept: headers (I think ";"
 * separated is within the MIME way of things).  Future header fields
 * will use the variables "HDR_fieldname".
 * 
 * Or, we could just dump the whole header into "HEADER".

I'd rather just have an env. variable like "HTTP_ACCEPT" with what you
describe above.

 * Now for a couple of picky naming things of my own:
 * 
 * GATEWAY_PROTOCOL -- should be GATEWAY_INTERFACE now
 * PROTOCOL_METHOD -- is "REQUEST_METHOD" more meaningful?

Both good points.

 * And a few minor points:
 * 
 * >QUERY_STRING:          That which follows the ?, untouched
 * 
 * Will not be in the environment if original URL has no "?"

Clarified.

 * >argv[2....] is the decoded query info, split on pluses or ampersands.
 * 
 * And should not appear if there is no query.  But this conflicts
 * with:
 * 
 * >If the resulting string is too lengthy to place on the command line,
 * >the server will not provide argv[2.....] at all and the script must
 * >either report an error to the client or decode the URL itself.
 * 
 * Well, if QUERY_STRING is only optionally in the environment, it
 * doesn't matter what happens with argv[2....].
 */

With QUERY_STRING specified, if argv[2...] is unset then the script knows it
was too long to translate.

--Rob



From timbl@www3.cern.ch  Mon Nov 22 11:58:12 1993 +0100
Message-Id: <9311221058.AA01370@www3.cern.ch>
Date: Mon, 22 Nov 93 11:58:12 +0100
From: timbl@www3.cern.ch (Tim Berners-Lee)
Subject: Re: WWW Indexing initative



info.cern.ch has had some problems, and will be upgraded shortly. 

In the meantime, just try 20 minutes later or so.

Apologies for the inconvenience

Tim BL



From bobs@sco.com  Mon Nov 22 10:02:22 1993 PST
Message-Id: <9311221002.aa29842@scobob.sco.com>
Date: Mon, 22 Nov 93 10:02:22 PST
From: bobs@sco.com (Bob Stayton)
Subject: Re: Future browsers...

> From: Tony Sanders <sanders@bsdi.com>
> 
> That's exactly what <LINK REV="UseGlossary" HREF="...">
> per http://info.cern.ch/hypertext/WWW/MarkUp/Relationships.html
> is supposed to do.  <LINK>/REL/REV seem to be the most misunderstood
> (or at least under-implemented) part of the WWW design.

To put large documents online in modular form, LINKs are
essential.  At minimum, we could really use Next, Previous, 
Table of Contents, and Index buttons on the interface
that are activated by appropriate LINKs in a document.

Beyond that, implementing section hierarchy LINKs would
be very useful, especially if there was some way to print
out a section with its children in the proper order.
Currently, printing out a webbed document is tedious
and prone to error in reassembly.

bobs



From rbrown@zambia.jpl.nasa.gov  Mon Nov 22 15:13:15 1993 PST
Message-Id: <9311222313.AA17231@zambia.jpl.nasa.gov>
Date: Mon, 22 Nov 93 15:13:15 PST
From: rbrown@zambia.jpl.nasa.gov (Robert L. Brown Jr.)
Subject: Info


I was wondering if I could be e-mailed any information on exactly
what WWW World Wibe Web and how to get it if it's downloadable.

Robert Brown
rbrown@zambia.jpl.nasa.gov



From rchiang@peacock.tnjc.edu.tw  Tue Nov 23 12:07:23 1993 CST
Message-Id: <9311230407.AA09293@peacock.tnjc.edu.tw>
Date: Tue, 23 Nov 93 12:07:23 CST
From: rchiang@peacock.tnjc.edu.tw (rchiang@peacock.tnjc.edu.tw)
Subject: mailrobot for Solaris 2.x

To all the WWW server developer:

  Is anybody out there can help me to find a mailrobot source code
for Solaris 2.x!

Your help is much appreciated!!

Rick Chiang                    rchiang@peacock.tnjc.edu.tw



From kevinh@pulua.hcc.hawaii.edu  Mon Nov 22 19:26:38 1993 HST
Message-Id: <9311230526.AA29072@pulua.hcc.Hawaii.Edu>
Date: Mon, 22 Nov 93 19:26:38 HST
From: kevinh@pulua.hcc.hawaii.edu (Kevin 'Kev' Hughes)
Subject: HCC's main Web server has moved


	For all those linking to Honolulu Community College, please note
that the new server is at:

http://www.hcc.hawaii.edu/

	It's running on a new Sun SPARCstation 10 under Solaris 2.3, so
you may notice some speed improvements.
	Have fun!

	-- Kevin



From peveritt@pandora.ncts.navy.mil  Tue Nov 23 07:37:23 1993 +0600
Message-Id: <9311231337.AA00253@voltaire.ncts.navy.mil>
Date: Tue, 23 Nov 1993 07:37:23 +0600
From: peveritt@pandora.ncts.navy.mil (Paul Everitt)
Subject: Re: WWW-Oracle


Hi sportsfans.

Is anyone doing WWW-Sybase?

Thanks, in advance, as always, ad nauseum.

Paul.Everitt@ncts.navy.mil



From dsr@hplb.hpl.hp.com  Tue Nov 23 14:01:31 1993 GMT
Message-Id: <9311231401.AA05166@manuel.hpl.hp.com>
Date: Tue, 23 Nov 93 14:01:31 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: Future browsers...

Charles Henrich writes:

> What do you all feel is the most important next HTML+ features for Browser's
> to implement?  I currently would *really* like to see text flow around
> <img>'s and tables!

At the WWW/TEI meeting in Ireland last week, we felt that the FIG element
should be extended so that it behaves like IMG when you specify ALIGN =
top, middle or bottom and as currently specified when ALIGN = left, center
or right. Text flow is only appropriate when ALIGN = left or right. The
IMAGE element has now been dropped. I will describe this in detail in the
next issue of the HTML+ internet draft, which I expect to have completed by
Christmas. [too many demands on my time :(]

In this meeting we attempted to rank new features in order of priority.
The revised DTD will be structured as a core DTD plus a number of
"toppings" for tables etc. This will make it practical to define browser
compliance rigorously.

Sebastian Francis Heath writes:

> In other hypermedia applications I have worked on, it has been useful to 
> allow users to select any text and initiate a link from it.  This allows, 
> for example, a user to select a word s/he doesn't understand and ask that 
> it be looked up in a dictionary/glossary  or a site name can be looked up 
> in an atlas.

This is the idea behind <LINK REL="UseIndex" HREF="..."> as described in
the current draft of the HTML+ spec, see:

        ftp://15.254.100.100/pub/draft-raggett-www-html-00.ps

This LINK element would cause browsers to show an "Index" button on a toolbar
or as a menu item. Users would select a word with the mouse and press the
button to initiate the search on the specified server (you could also just
type words into a search box, as now).

Regards,

Dave Raggett



From stumpf@informatik.tu-muenchen.de  Tue Nov 23 15:27:14 1993 +0100
Message-Id: <93Nov23.152719mesz.311437@hprbg5.informatik.tu-muenchen.de>
Date: Tue, 23 Nov 1993 15:27:14 +0100
From: stumpf@informatik.tu-muenchen.de (Markus Stumpf)
Subject: Re: revised CGI/1.0 specification

Hoi folx,

I am really unhappy about the term "gateway" in the spec.
I cannot see any possibilities to use it as a *real* gateway.

I'd like the possibility to receive something like
    GATE prot://hostname:port/some_more_info
    [ followed by some protocol specific info ]
The "gateway" could then make a connection to the host/port, send the
protocol specific info it received from the client and simply gate the answer
back to the requestor.
I cannot imagine how this would be possible with the current spec.
Therefor I'd prefer a name like CSI "Common Script Interface" or something
like that.
I am sorry to say that I don't have any "on the fly" proposals to be added
to the spec to allow for a "real gateway" behaviour as I understand it :-(
However, besides that I think the spec is really useful and needed.

	\Maex
-- 
______________________________________________________________________________
 Markus Stumpf                        Markus.Stumpf@Informatik.TU-Muenchen.DE 



From stumpf@informatik.tu-muenchen.de  Tue Nov 23 16:28:24 1993 +0100
Message-Id: <93Nov23.162827mesz.311438@hprbg5.informatik.tu-muenchen.de>
Date: Tue, 23 Nov 1993 16:28:24 +0100
From: stumpf@informatik.tu-muenchen.de (Markus Stumpf)
Subject: Some comments on http protocol draft

Hello,

I'd like to make some comments on the HTTP draft recently published by the
IETF (draft-ietf-iiir-http-00.{txt,ps} dated 5 Nov 1993.

1) on the METHODS:
   I'd really like to have a method called "GATE", which would be
   followed by a URL and any other method.
   This would allow servers to only open a connection to the specified
   host/port, send the "real" method and information from the requestor
   and send back the answer without having to further interpret the
   data. Using the URL with the GATE method allows for access restrictions
   on the server side based on protocol (i.e. allow all http requests
   regardless the port number they use).

2) I have thought on some mechanisms providing help in administering
   HTML documents.
   Using the "Referer:" field of the request a server may detect
   originators of bad links (as already stated in the draft).
   How about some protocol, at best UDP based I think, that would allow
   servers to exchange this kind of information.
   If a server detects such a bad link and has a requestor field it
   could send a datagram to the originating server. It could look like
      BADLINK  <requested URL>   <originators URL>
   Maybe we could get UDP port 80 for this (dunno whether this is already
   allocated by some other service). Server could then save this information
   to some logfile and/or notify the servers admin.
  
   Maybe we could have another HTML+ tag like <TITLE> that could be
   called <AUTHOR> and contain a email address of the author(s) of the
   document. This could be passed along with the request maybe in a
   "Author:" field or (if not present within the document) a server could
   send back the email address(es) of the Author of a document along
   with the response code or input it in the stream of a html document
   (which I think would be bad, as the server would have to interpret
   the document in some way).

Bye
	\Maex
-- 
______________________________________________________________________________
 Markus Stumpf                        Markus.Stumpf@Informatik.TU-Muenchen.DE 



From robm@ncsa.uiuc.edu  Tue Nov 23 10:11:37 1993 -0600
Message-Id: <9311231611.AA29969@void.ncsa.uiuc.edu>
Date: Tue, 23 Nov 1993 10:11:37 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: revised CGI/1.0 specification

/*
 * Re: revised CGI/1.0 specification  by Markus Stumpf (stumpf@informatik.tu-muenchen.de)
 *    written on Nov 23,  3:27pm.
 *
 * Hoi folx,
 * 
 * I am really unhappy about the term "gateway" in the spec.
 * I cannot see any possibilities to use it as a *real* gateway.

It depends on how you define gateway, and what you're gatewaying to. It
seems our definitions are not in sync. We're referring to gateway as "an
interface to external server programs which allow you to interface with
services you may not normally have access to". This includes, finger, man,
wais, archie, and even all of the W3 supported ones (see below).

 * I'd like the possibility to receive something like
 *     GATE prot://hostname:port/some_more_info
 *     [ followed by some protocol specific info ]
 * The "gateway" could then make a connection to the host/port, send the
 * protocol specific info it received from the client and simply gate the
 * answer back to the requestor.
 * I cannot imagine how this would be possible with the current spec.

I don't see why not. I'm assuming you're referring to GATE as a new HTTP
method. The entry for SERVER_PROTOCOL is confusing since it mentions gopher.
I think we may want to change this so it's HTTP only since HTTP servers are
going to really use the spec.

The spec does not say that you must use one of the already defined methods.
If a server implemented GATE, and used CGI scripts to do so, these scripts
could easily implement any gatewaying you would want.

I'm not sure what exactly you're talking about by "followed by some protocol
specific info"... since you use a URL for the argument to GATE, this could
simply be a URL which should contain all the information you need. Thus,
ideas spring to mind of a CGI script which is linked with the W3 libraries
and does basically what CERN's server does when acting as a gateway. Since
the W3 conversion libraries all return HTML, the script could easily pass
results back to a Web browser.

If this was not what you meant, the specification allows for scripts which
blast data directly back to the client. This means scripts could gate the
answer without HTTP intervention (if that's what you want).

 * Therefor I'd prefer a name like CSI "Common Script Interface" or something
 * like that.
 * I am sorry to say that I don't have any "on the fly" proposals to be added
 * to the spec to allow for a "real gateway" behaviour as I understand it :-(
 * However, besides that I think the spec is really useful and needed.
 */

--Rob



From waterbug@epims1.gsfc.nasa.gov  Tue Nov 23 10:49:13 1993 +0500
Message-Id: <9311231549.AA00782@epims1>
Date: Tue, 23 Nov 1993 10:49:13 +0500
From: waterbug@epims1.gsfc.nasa.gov (Steve Waterbury)
Subject: Re: WWW-Oracle



Paul Everitt writes:

> Hi sportsfans.
> 
> Is anyone doing WWW-Sybase?

Well, as long as we are diversifying, is anyone doing 
WWW-Ingres?  

Steve Waterbury
NASA/GSFC



From nikos@cbl.leeds.ac.uk  Tue Nov 23 18:10:54 1993 GMT
Message-Id: <20118.9311231810@cbl.leeds.ac.uk>
Date: Tue, 23 Nov 93 18:10:54 GMT
From: nikos@cbl.leeds.ac.uk (N F Drakos)
Subject: Re: WWW-Oracle

>Paul Everitt writes:
>
>> Hi sportsfans.
>> 
>> Is anyone doing WWW-Sybase?
>
>Well, as long as we are diversifying, is anyone doing 
>WWW-Ingres?  
>
>Steve Waterbury
>NASA/GSFC
>

A possible starting point for WWW database integration might be 
a single gateway for dbperl (a standard database interface for
Perl). Although dbperl is still under development there are several
SQL interfaces defined according to this "standard".

More information on dbperl is available at
ftp://ftp.demon.co.uk/pub/perl/db/

Here is an extract from ftp://ftp.demon.co.uk/pub/perl/db/README
by Tim Bunce <timbo@ig.co.uk>:

* Existing SQL Database Interfaces for Perl
oraperl   ORACLE 6 & 7  By Kevin Stock
sybperl   SYBASE 4      By Michael Peppler, mpeppler@itf.ch, mpeppler@bix.com
sqlperl   INGRES        By Ted Lemon, mellon@ncd.com
isqlperl  INFORMIX      By William Hails, bill@tardis.co.uk
interperl INTERBASE     By Buzz Moschetti, buzz@bear.com
uniperl   UNIFY 5.0     By Rick Wargo, rickers@coe.drexel.edu
pgperl    POSTGRES      By Igor Metz, metz@iam.unibe.ch

* Non-SQL Databases and Database Interfaces for Perl and/or /bin/sh
rdb      RDB is a perl RDBMS. By Walt Hobbs, hobbs@rand.org
shql     SHQL is an interactive SQL database engine.  Written as a shell
          script, SHQL interprets SQL commands and manipulates flat files
          based on those commands. By Bruce Momjian, root@candle.uucp

Nikos.

____________________________

Nikos Drakos 
Computer Based Learning Unit    
University of Leeds

email: nikos@cbl.leeds.ac.uk
WWW  : http://cbl.leeds.ac.uk/nikos/personal.html



From stumpf@informatik.tu-muenchen.de  Tue Nov 23 19:39:36 1993 +0100
Message-Id: <93Nov23.193951mesz.311437@hprbg5.informatik.tu-muenchen.de>
Date: Tue, 23 Nov 1993 19:39:36 +0100
From: stumpf@informatik.tu-muenchen.de (Markus Stumpf)
Subject: Re: revised CGI/1.0 specification

Rob,

|>It depends on how you define gateway, and what you're gatewaying to. It
|>seems our definitions are not in sync.

Definitely. But I wanted this to be discussed. Maybe we are not in sync
with others, too :-)

|>                     I'm assuming you're referring to GATE as a new HTTP
|>method. The entry for SERVER_PROTOCOL is confusing since it mentions gopher.
|>I think we may want to change this so it's HTTP only since HTTP servers are
|>going to really use the spec.

Yep, I'd sent another message right after the one you answered to making
a proposal for such a method.
How do you determine what to use for SERVER_PROTOCOL? Is that the type
of daemon that's running? How about GN that supports http and gopher?
Should it set the SERVER_PROTOCOL according to whether it was a gopher
or http request? (that's important, as the script has to answer in the right
format) If we chage to http only, this is of course obvious.

|>I'm not sure what exactly you're talking about by "followed by some protocol
|>specific info"... since you use a URL for the argument to GATE, this could
|>simply be a URL which should contain all the information you need.

With GATE I want a *simple* gateway which only plugs to host/ports.
This means the clients sends a
    GATE <full_url_of_document>
and then a GET or PUT or any other method as it would without using a gateway.

|>                                                                   Thus,
|>ideas spring to mind of a CGI script which is linked with the W3 libraries
|>and does basically what CERN's server does when acting as a gateway. Since
|>the W3 conversion libraries all return HTML, the script could easily pass
|>results back to a Web browser.

And that is exactly what I wanted to avoid.
There is really no need to have the server do the conversion from e.g.
gopher to html as all clients (I know of) are able to do this pretty
well and IMHO much better than a server ever can do. Just think of the nice
little icons Mosaic uses for the various gopher types. Having the
conversion take place in the server makes you loose much of the look 'n feel
that clients can provide. That is IMHO nothing that is desirable.

	\Maex
-- 
______________________________________________________________________________
 Markus Stumpf                        Markus.Stumpf@Informatik.TU-Muenchen.DE 



From masinter@parc.xerox.com  Tue Nov 23 11:43:53 1993 PST
Message-Id: <93Nov23.114403pst.2732@golden.parc.xerox.com>
Date: Tue, 23 Nov 1993 11:43:53 PST
From: masinter@parc.xerox.com (Larry Masinter)
Subject: use of HTML forms in mail

Many a year ago, there was a fairly strenuous effort to try to allow
people to send each other, in email, forms to fill out. I get forms
all the time via email: registration forms, application forms, etc.

The result of filling out a form is to mail the form back to another
address, after filling it out.

What I'm wondering is whether HTML forms could be used for this, which
is an application totally independent of HTTP, or, for that matter,
most of the rest of the web.

It would be very dandy if it were.

Comments?





From henrich@crh.cl.msu.edu  Tue Nov 23 14:55:55 1993 -0500 (EST)
Message-Id: <9311231955.AA16388@crh.cl.msu.edu>
Date: Tue, 23 Nov 1993 14:55:55 -0500 (EST)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: Mosaic in Open Sys Today

In the article SEC documents to go online, Mosaic is mentioned explicity,
sentence :

"Comapnies and individuials with internet servies will use electronic mail or
one of seceral access tools -- such as World Wide Web, Mosaic, gopher and ftp
-- to call up the data".

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                      http://rs560.msu.edu/~henrich



From davis@dri.cornell.edu  Tue Nov 23 15:25:41 1993 -0500
Message-Id: <199311232025.AA25117@willow.tc.cornell.edu>
Date: Tue, 23 Nov 1993 15:25:41 -0500
From: davis@dri.cornell.edu (Jim Davis)
Subject: Mosaic vs WWW


Am I the only one who is getting irritated by this constant
confusion in the press between WWW and Mosaic?  Don't get
me wrong, Mosaic is a major blessing, I am grateful beyond
words to NCSA for funding it, but why can't people understand
that Mosaic is NOT the WWW, but just one of the possible
tools that work with it - that WWW is the client-server system,
and Mosaic just one of those clients.  

it would probably help if the "What's New" page called itself
"what's new with the WWW" instead of "whats new with Mosaic".




From wade@cs.utk.edu  Tue Nov 23 15:46:41 1993 -0500
Message-Id: <9311232046.AA29269@galoob.cs.utk.edu>
Date: Tue, 23 Nov 1993 15:46:41 -0500
From: wade@cs.utk.edu (Reed Wade)
Subject: Re: Mosaic vs WWW 


>Am I the only one who is getting irritated by this constant
>confusion in the press between WWW and Mosaic?  Don't get

That sort of thing is inevitable. I'd consider it a good sign.
It shows that www and mosaic are in use by non-experts.

Reed Wade
wade@cs.utk.edu




From Gary.Adams@east.sun.com  Tue Nov 23 16:12:25 1993 EST
Message-Id: <9311232112.AA02666@mrmarx.East.Sun.COM>
Date: Tue, 23 Nov 93 16:12:25 EST
From: Gary.Adams@east.sun.com (Gary Adams - Sun Microsystems Labs BOS)
Subject: Re: Mosaic vs WWW


> From www-talk-request@dxcern.cern.ch Tue Nov 23 16:00:51 1993
 
> >Am I the only one who is getting irritated by this constant
> >confusion in the press between WWW and Mosaic?  Don't get
> 
> That sort of thing is inevitable. I'd consider it a good sign.
> It shows that www and mosaic are in use by non-experts.
> 
> Reed Wade
> wade@cs.utk.edu

One of the confusions that I have heard repeated a number of times
at our site, is people looking for the Mosaic server. Many applications
are shipped with a client and a server component, so it makes sense when
people ask if they need to install the server software.

A decent diagram of the web clients and the web services which shows
how the various applications can plug & play would go along way to 
reducing end user confusion about the various roles each tool 
provides in navigating through the web.



From marca@ncsa.uiuc.edu  Wed Nov 24 02:47:23 1993 -0800
Message-Id: <9311241047.AA17645@wintermute.ncsa.uiuc.edu>
Date: Wed, 24 Nov 93 02:47:23 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: solidifying a really neat forms hack

Due to a cute little trap door we put into the Mosaic for X 2.0 forms
support, forms that consist of only a single text entry field with
NAME="isindex" result in query strings that look like:

        action?query

...and NOT:

        action?isindex=query

The reason we did this is because it was the cleanest way to handle
ISINDEX via inlined forms -- when the HTML parser sees an ISINDEX tag,
it replaces it with a fill-out form with a single text entry field
named "isindex", and Mosaic subsequently special-cases the handling of
forms with only a single value and NAME="isindex" when sending out a
query from such a form.

So then, Tony Sanders (originator of the incredibly useful ISMAP
attribute to IMG -- how is it he comes up with these things before
everyone else??? :-) realized that this means that *normal* forms in
arbitrary documents that contain, you guessed it, only a single text
entry field with NAME="form", provide transparent access to normal
ISINDEX servers (WAIS servers, Gopher search engines, etc.).

Some of you have already seen the a sample of the implications of this
paradigm shift (God, I love that term); e.g.,

    http://www.ncsa.uiuc.edu/SDG/Software/Mosaic/Demo/metaindex.html

Also, yesterday I noticed:

    http://cui_www.unige.ch/meta-index.html

For those of you without forms-enabled browsers, these documents
contain a series of forms as described above that point to existing
ISINDEX servers.  For example, the NCSA document given above allows
you to search on the CUI WWW catalog, the GNA Meta-Library, the Whole
Internet Catalog, Veronica, Jughead, the WAIS directory of servers,
etc. all from a single document -- a text entry field is provided for
earch search engine.

I propose that this technique be institutionalized by a one-time-only
special case in the forms spec that will insure that all forms-enabled
browsers can provide this capability.  It's really quite powerful, and
I think it's well worth a special case in the spec -- existing query
databases from a wide variety of information services can be folded
into arbitrary HTML documents very smoothly.

Cheers,
Marc




From hoesel@chem.rug.nl  Wed Nov 24 11:31:59 1993 +0100 (MET)
Message-Id: <9311241032.AA00656@Xtreme>
Date: Wed, 24 Nov 1993 11:31:59 +0100 (MET)
From: hoesel@chem.rug.nl (frans van hoesel)
Subject: Mosaic 2.0 fixes and improvements

There were some important fixes in the postscriptcode that did not make it in
the 2.0 release of Xmosaic. (I did send them in just before the release so
those overworked guys at NCSA didn't have time to test it for you)

the current version gives you 'dancing' letters when you mix font
styles on one line (eg the bold font uses a different baseline than
the normal font)

Also the printer will now print in times, helvetica or new-century schoolbook
depending on the font family you use for viewing. Besides giving you
the choise for your printout, it also results in much better
horizontal layout, because the postscript layout is directly related
to the placement of the text inside the viewer.

it also adds support for the <hr> horizontal ruler and fixes a bug
with wrong %%Page comments.

the major improvement comes from the support for fixed-width italics
and fixed-width bold font, in both the viewer, and the postscript module.

these fixes are both releases as a context diff (so you can use 'patch'
to get the better Mosaic version) and as complete new source files
(but only for the source files that are affected by these changes)

Note that this is an unofficial release, so ncsa, may or may not
include this in their next release. But when that release is going to happen
is known only to the gods.

No binaries are made available. you will have to get the full XMosaic source
yourself.

the files are available through anonymous ftp from
rugch4.chem.rug.nl in the directory pub/Mosaic-2.0b

happy patching,

- frans






From P.Lister@cranfield.ac.uk  Wed Nov 24 10:18:50 1993 GMT
Message-Id: <9311241018.AA01772@xdm039.ccc.cranfield.ac.uk>
Date: Wed, 24 Nov 93 10:18:50 GMT
From: P.Lister@cranfield.ac.uk (Peter Lister, Cranfield Computer Centre)
Subject: Re: Mosaic vs WWW

> That sort of thing is inevitable. I'd consider it a good sign.
> It shows that www and mosaic are in use by non-experts.

Use by non-experts is good, confusion is not. Mosaic is a particular
WWW browser, and it has a cute name. One of the differences between WWW
and Gopher (and sadly it is a really *major* difference to those who
don't appreciate the technical points) is that Gopher - the entire
system -  has a cute name. And most people remember cute names. Had WWW
been christened by CERN as "Proton", "Accelerator", or even "Fred",
many more people would be happier with it.

Don't get me wrong; I'm a fan of WWW, and all the clients and servers
which make it up (in particular Mosaic and Plexus). But the name "WWW"
sucks -  the only thing that makes "World Wide Web" a proper noun is
the fact that the WWW community uses it as such, and we conventionally
(though not always) refer to it capitalised. As soon as it's
uncapitalized "world wide web" applies to virtually anything - The
Internet as a whole, the telephone network, railways, airline routes,
anything international that consists of interconnected lines. And the
identity of our beloved system of HTTP, HTML, FTP, Gopher, etc is lost.

All the examples I can think of where a generic term has been pressed
into service to name a particular system also cause confusion. I would
understand "FTP" to be Internet FTP. However, to a layman, the generic
term applies equally to Blue Book (the UK's X25 based system which,
still in use), Kermit (now there *is* a cute name), SneakerNet, etc.
Even "windows" - to a PC user this means MS-Windows, but a Unix
workstation user knows about X11 (commonly, if wrongly known as "X
windows"). Right, now try explaining why they're different ("Yes, they
both use windows, but not the same windows OK?").

Oh, and by the way, can I please make it clear that I do know what the
Internet and WWW and Mosaic and everything else are? :-) The last time
I expressed any similar opinions, I got a reply from a terribly helpful
guy who carefully explained to me that I had confused the Internet with
the World-Wide Web.... which rather proved the point I'd been trying to make.

Finally, if you think the term "cute" is rather too whimsical,
substitute "easily remembered" in the message above. The meaning will be unchanged.

Peter Lister                             Email: p.lister@cranfield.ac.uk
Computer Centre, Cranfield University    Voice: +44 234 754200 ext 2828
Cranfield, Bedfordshire MK43 0AL UK        Fax: +44 234 750875
--- Almost (but not quite) entirely unlike tea ---



From bert@let.rug.nl  Wed Nov 24 12:35:28 1993 +0100 (MET)
Message-Id: <9311241134.AA21187@freya.let.rug.nl>
Date: Wed, 24 Nov 1993 12:35:28 +0100 (MET)
From: bert@let.rug.nl (Bert Bos)
Subject: Re: solidifying a really neat forms hack

Marc Andreessen writes:

 |Due to a cute little trap door we put into the Mosaic for X 2.0 forms
 |support, forms that consist of only a single text entry field with
 |NAME="isindex" result in query strings that look like:
 |
 |        action?query
 |
 |...and NOT:
 |
 |        action?isindex=query

Yes, a very useful feature for various reasons...

 |The reason we did this is because it was the cleanest way to handle
 |ISINDEX via inlined forms -- when the HTML parser sees an ISINDEX tag,
 |[...]

but I don't think that an ISINDEX element should be equated with a
FORM. They serve different purposes: the layout and placement of
ISINDEX is under the control of the browser (a French browser displays
a French prompt, etc.) and it is *global*, i.e., it is available no
matter how far you scrolled through the document. A FORM, on the other
hand, is tied to a specific location in the text, with suitable
prompts provided by the document's author.

 |So then, Tony Sanders (originator of the incredibly useful ISMAP
 |attribute to IMG -- how is it he comes up with these things before
 |everyone else??? :-) realized that this means that *normal* forms in
 |arbitrary documents that contain, you guessed it, only a single text
 |entry field with NAME="form", provide transparent access to normal
                        ^^^^^^
you mean "isindex" ?

 |ISINDEX servers (WAIS servers, Gopher search engines, etc.).
 |
 |Some of you have already seen the a sample of the implications of this
 |paradigm shift (God, I love that term); e.g.,
 |[...]

Rather a "paradigm collapse", I think.

 |I propose that this technique be institutionalized by a one-time-only
 |special case in the forms spec that will insure that all forms-enabled
 |browsers can provide this capability.  It's really quite powerful, and
 |[...]

I agree, but it can be independent of the implementation of ISINDEX.
E.g., specify that the "=" is omitted when the INPUT NAME attribute is
empty or omitted:

      <INPUT name="foo">	----> some-url?foo=bar
      <INPUT name="">		----> some-url?bar
or:
      <INPUT>			----> some-url?bar



Bert
-- 
                     _________________________________
                    / _   Bert Bos <bert@let.rug.nl>  |
           ()       |/ \  Alfa-informatica,           |
            \       |\_/  Rijksuniversiteit Groningen |
             \_____/|     Postbus 716                 |
                    |     9700 AS GRONINGEN           |
                    |     Nederland                   |
                    \_________________________________|



From marca@ncsa.uiuc.edu  Wed Nov 24 06:15:38 1993 -0800
Message-Id: <9311241415.AA18742@wintermute.ncsa.uiuc.edu>
Date: Wed, 24 Nov 93 06:15:38 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Re: solidifying a really neat forms hack

Bert Bos writes:
> [...] I don't think that an ISINDEX element should be equated with a
> FORM. They serve different purposes: the layout and placement of
> ISINDEX is under the control of the browser (a French browser
> displays a French prompt, etc.) and it is *global*, i.e., it is
> available no matter how far you scrolled through the document.

Didn't we just go through this a week or so ago?  The behavior you
seem to be claiming is mandated is not in the domain of any spec I've
read.  ISINDEX is used to declare that this document represents a
searchable index; it doesn't declare how the search is to be done or
how the user is to enter the search keyword.

> A FORM, on the other hand, is tied to a specific location in the
> text, with suitable prompts provided by the document's author.

Correct -- and what I'm suggesting is that some forms be allowed to
talk to existing ISINDEX-style servers, period.  This is independent
of your opinion of how Mosaic 2.0 handles ISINDEX normally.  Other
browsers can handle ISINDEX however they want; I'm not trying to
mandate Mosaic's ISINDEX handling method on anyone.

>  |So then, Tony Sanders (originator of the incredibly useful ISMAP
>  |attribute to IMG -- how is it he comes up with these things before
>  |everyone else??? :-) realized that this means that *normal* forms in
>  |arbitrary documents that contain, you guessed it, only a single text
>  |entry field with NAME="form", provide transparent access to normal
>                         ^^^^^^
> you mean "isindex" ?

Oops -- yup.

>  |I propose that this technique be institutionalized by a one-time-only
>  |special case in the forms spec that will insure that all forms-enabled
>  |browsers can provide this capability.  It's really quite powerful, and
>  |[...]
> 
> I agree, but it can be independent of the implementation of ISINDEX.
> E.g., specify that the "=" is omitted when the INPUT NAME attribute is
> empty or omitted:
> 
>       <INPUT name="foo">	----> some-url?foo=bar
>       <INPUT name="">		----> some-url?bar
> or:
>       <INPUT>			----> some-url?bar

Either way a spec modification is needed (since NAME is currently
required for all instances of INPUT).  I vote that we go with what
currently works.

Marc




From henrich@crh.cl.msu.edu  Wed Nov 24 07:44:04 1993 -0500 (EST)
Message-Id: <9311241244.AA18945@crh.cl.msu.edu>
Date: Wed, 24 Nov 1993 07:44:04 -0500 (EST)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: Postscript patches

FYI Cause an instant coredump in 2.0 on a Rs/6k...

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                      http://rs560.msu.edu/~henrich



From bloemer@tnt.uni-hannover.de  Wed Nov 24 13:55:35 1993 +0100
Message-Id: <9311241255.AA06910@helios.tnt.uni-hannover.de>
Date: Wed, 24 Nov 93 13:55:35 +0100
From: bloemer@tnt.uni-hannover.de (Arnold Bloemer)
Subject: Re: Mosaic vs WWW

> From www-talk-request@dxcern.cern.ch Wed Nov 24 12:36:16 1993
> To: Reed Wade <wade@cs.utk.edu>
> Cc: ccprl@cranfield.ac.uk, www-talk@nxoc01.cern.ch
> Subject: Re: Mosaic vs WWW
> From: "Peter Lister, Cranfield Computer Centre" <P.Lister@cranfield.ac.uk>
> 
> > That sort of thing is inevitable. I'd consider it a good sign.
> > It shows that www and mosaic are in use by non-experts.
> 
> Use by non-experts is good, confusion is not. Mosaic is a particular
> WWW browser, and it has a cute name. One of the differences between WWW
> and Gopher (and sadly it is a really *major* difference to those who
> don't appreciate the technical points) is that Gopher - the entire
> system -  has a cute name. And most people remember cute names. Had WWW
> been christened by CERN as "Proton", "Accelerator", or even "Fred",
> many more people would be happier with it.

Full support to your opinion !

I critized the lack of a single speakable and easily remembered term
one year ago. The curent situation in WWW is a horror scenario for
everybody who has some knowledge about Corporate Identity.

When you browse through comp.infosystems.www for example you will
find the following terms for WWW:

WWW, www, W3, w3, World-Wide Web, World Wide Web, world-wide-web,
WorldWideWeb, Web, web ...

and even worse there is no WWW Server like a Gopher Server but there
are HTTP Server and Pages are written in HTML which can be served by
different httpd's and ftpd's. And there is not really a World Wide Web
page or format like a Gopher menu, instead we speak about HTML Pages
which is just one but the native format (or not ?) for WWW. WWW should
be the the name for a universe of information in different formats. And
www is one browser for WWW. And there are a lot of other terms which
are essential to understand WWW.

Even if you are a WWW Wizard, it is hard to always use the right
terms. So nobody should wonder that a non-expert just talks about
Mosaic, Mosaic Server and Mosaic Pages.

I think it is overdue to setup some kind of Corporate Identity for the
World-Wide Web. Otherwise we will loose control over the correct usage
of the relevant terms and at least the Mosaic Users will use Mosaic as
the single, easily remembered term for everything around WWW.

Arnold


________________________________________________________________________________

Dipl.-Ing. Arnold Bloemer	   Universitaet Hannover
				   Institut fuer Theoretische Nachrichtentechnik
				   und Informationsverarbeitung
bloemer@tnt.uni-hannover.de        Appelstrasse 9A
fax:    +49 511 762-5333           D-30167 Hannover
phone:  +49 511 762-5320           Germany
________________________________________________________________________________




From lou@vax.ox.ac.uk  Wed Nov 24 14:11:58 1993 +0000
Message-Id: <0097605C.5659D890.14854@vax.ox.ac.uk>
Date: Wed, 24 Nov 1993 14:11:58 +0000
From: lou@vax.ox.ac.uk (Lou Burnard)
Subject: www/mosaic

What's wrong with calling it "The Web"? (the "world wide" part is a bit
unnecessary). People talk about the network-based activities as "the
Net" (including both Internet and say Listserv-type things under this
heading), so you can point out that a Web is a bit more precisely
organized than a net. One important difference is that a web has a centre,
which applies to the Web as people actually experience it -- you have
to start with a home page somewhere.

Lou Burnard

p.s. Chris, what happened to the WWW/TEI Meeting report?






From WIGGINS@msu.edu  Wed Nov 24 08:48:55 1993 EST
Message-Id: <9311241405.AA02686@dxmint.cern.ch>
Date: Wed, 24 Nov 93 08:48:55 EST
From: WIGGINS@msu.edu (Rich Wiggins)
Subject: Re: Mosaic vs WWW

>I critized the lack of a single speakable and easily remembered term
>one year ago. The curent situation in WWW is a horror scenario for
>everybody who has some knowledge about Corporate Identity.
>
>When you browse through comp.infosystems.www for example you will find
>the following terms for WWW:
>
>WWW, www, W3, w3, World-Wide Web, World Wide Web, world-wide-web,
>WorldWideWeb, Web, web ...

It's great to see this discussion started.

A week ago at the Assoc of Research Libraries conference I heard several
speakers state that they were looking at Mosaic as a way of delivering
e journals.  Probably true, they are looking at Mosaic, or more
precisely they've seen how rich an HTML document looks through a Mosaic
lens.

For some time I've thought that the term "Web" itself may not connote
the image we all want to convey. The Wall Street Journal section on
technology from a week ago Monday (generally a very disappointing use of
newsprint, IMHO) had a banner headline of "World-Wide Web" with a
drawing of a user sitting in front of a workstation and a spider's web.
This didn't strike me as an image that would encourage new uses. There's
a strong perception among many that hypertext is inherently complicated,
and the metaphor of something that ensnares the user may not be the most
helpful in confronting that perception.  (By the way, the WSJ piece was a
very breezy overview, expropriating the term "World-Wide Web" without
explaining Gopher versus Web at all.)

It's not clear what the wisest course of action might be, with all the
terms you list in common use; neither World-Wide Web nor Mosaic should
be renamed. But it would be useful to consider minimizing of jargon and
collapsing of terms visible to users whenever possible.  For instance,
yesterday someone I know who is quite savvy in Gopher and WAIS was
feeling his way along with Mosaic and the Web; he said he kept wanting
to be able to quickly "gopher" elsewhere.  He did not know what "Open URL"
would do; that revelation alone opened things up.  Would "Open Network
Resource" be more inviting?  What's obvious to a wizard isn't to a newbie.

/Rich Wiggins, CWIS Coordinator, Michigan State U



From P.Lister@cranfield.ac.uk  Wed Nov 24 15:39:39 1993 GMT
Message-Id: <9311241539.AA02982@xdm039.ccc.cranfield.ac.uk>
Date: Wed, 24 Nov 93 15:39:39 GMT
From: P.Lister@cranfield.ac.uk (Peter Lister, Cranfield Computer Centre)
Subject: Re: www/mosaic


Lou Burnard sez
> What's wrong with calling it "The Web"? (the "world wide" part is a bit
> unnecessary). People talk about the network-based activities as "the
> Net" (including both Internet and say Listserv-type things under this
> heading), so you can point out that a Web is a bit more precisely
> organized than a net. One important difference is that a web has a centre,
> which applies to the Web as people actually experience it -- you have
> to start with a home page somewhere.

What's wrong is that it doesn't change the idea of a generic term used
specifically. Everything I opined about applies if you subsitute "The
Web" for "World Wide Web", with the exception of the "World wide" bit,
which (as you say) irrelevant.

I generally take "The Net" to mean what you do - the Internet and those
other nets easily accessible to it by email. If I say "networking" to a
student here, he will assume I mean the campus Ethernet (and probably
just the network served PCs), unless he's from the Cranfield School of
Management, in which case he will assume I mean the process of
cultivating useful business contacts. It doesn't help me to identify
the Internet to them, especially if they haven't come across it before.

Arnold Bloemer sez

> I critized the lack of a single speakable and easily remembered term
> one year ago. The curent situation in WWW is a horror scenario for
> everybody who has some knowledge about Corporate Identity.

Thank you Arnold; "coporate identity" is just the buzz-phrase I was looking for. :=)

Rich Wiggins sez

> It's not clear what the wisest course of action might be, with all the
> terms you list in common use; neither World-Wide Web nor Mosaic should
> be renamed. But it would be useful to consider minimizing of jargon and
> collapsing of terms visible to users whenever possible.  For instance,
> yesterday someone I know who is quite savvy in Gopher and WAIS was
> feeling his way along with Mosaic and the Web; he said he kept wanting
> to be able to quickly "gopher" elsewhere.  He did not know what "Open URL"
> would do; that revelation alone opened things up.  Would "Open Network
> Resource" be more inviting?  What's obvious to a wizard isn't to a newbie.

I would have said that "Go to..." was even better.

As to renaming WWW, I agree that a revolution would be *really*
confusing. But introducing an official nickname would be reasonable -
more and more people would get used to it and eventually the original
full title would be forgotten (who, for instance, can name the title of
the Elgar's march that we all think of as "Land of Hope and Glory" off
the top their heads?)

I think that Rich made a very good point - his user wanted 'to quickly
"gopher" elsewhere'. He easily "verbised" the noun, and we all
understand what he meant. No one would naturally coin the verb "to
world wide web". Would they? Doesn't trip of the tongue. People might,
however be tempted "to Boris" elsewhere, (keeping the spider Motif).

I feel a competition coming on. Of course, the problem is finding a
cute name that hasn't yet been appropriated for something else. This
seems already to be a problem in the car (auto) market, to judge by
some the monikers that have been attached to recent models.

My entries

* Boris		(the spider)
* IncyWincy	(*too* cute?)
* HyLite	("Highlighted hypertext") - this must exist already, surely?
* HyRoad

Doubtless we'll think of more.

Peter Lister                             Email: p.lister@cranfield.ac.uk
Computer Centre, Cranfield University    Voice: +44 234 754200 ext 2828
Cranfield, Bedfordshire MK43 0AL UK        Fax: +44 234 750875
--- Almost (but not quite) entirely unlike tea ---




From stumpf@informatik.tu-muenchen.de  Wed Nov 24 16:42:28 1993 +0100
Message-Id: <1993Nov24.154228.10173@Informatik.TU-Muenchen.DE>
Date: Wed, 24 Nov 1993 16:42:28 +0100
From: stumpf@informatik.tu-muenchen.de (Markus Stumpf)
Subject: Re: Mosaic vs WWW


In article <9311241018.AA01772@xdm039.ccc.cranfield.ac.uk>, "Peter Lister, Cranfield Computer Centre" <P.Lister@cranfield.ac.uk> writes:
|> Use by non-experts is good, confusion is not. Mosaic is a particular
|> WWW browser, and it has a cute name. One of the differences between WWW
|> and Gopher (and sadly it is a really *major* difference to those who

Hmmmm ... isn't WorldWideWeb a name for the "document universe" ???
I.e. a name for all the "documents" (in the most global meaning of this
word you can imagine) that can be accessed by any existing protocol?
You cannot compare WWW to gopher, als gopher and e.g. ftp and USENET news
are all parts of WWW. If you want to compare you have to compare
HTTP and gopher.

That's the way I've always seen the terms ... am I wrong?

However INHO you're right calling Mosaic a WWW browser, as it knows to
handle lots of protocols that are part of the WWW.

	\Maex
-- 
______________________________________________________________________________
 Markus Stumpf                        Markus.Stumpf@Informatik.TU-Muenchen.DE 



From waterbug@epims1.gsfc.nasa.gov  Wed Nov 24 10:49:02 1993 +0500
Message-Id: <9311241549.AA02467@epims1>
Date: Wed, 24 Nov 1993 10:49:02 +0500
From: waterbug@epims1.gsfc.nasa.gov (Steve Waterbury)
Subject: Re: Mosaic vs WWW


>... The curent situation in WWW is a horror scenario for
>everybody who has some knowledge about Corporate Identity.

Yeah ... WWW, Mosaic and the whole conceptual universe of 
the Web and even the Internet could stand some non-threatening 
"packaging" words and pictures ... in my opinion, one of 
the best efforts in this direction is Kevin Hughes's 
"Guide to Cyberspace" -- maybe the "cyberspace" image 
would be a good one to extend ... ?  

> ...  For instance,
> yesterday someone I know who is quite savvy in Gopher and WAIS was
> feeling his way along with Mosaic and the Web; he said he kept wanting
> to be able to quickly "gopher" elsewhere.  He did not know what "Open URL"
> would do; that revelation alone opened things up.  Would "Open Network
> Resource" be more inviting?  What's obvious to a wizard isn't to a newbie.

This is a good point -- the Most Excellent Mosaic is even 
as we speak getting its trial by fire at the hands of the Great 
Unwashed who (can you imagine?) don't know from beta products.  
And even the literate few, as in this example, could benefit by 
some clarity of language (and, of course, jargon avoidance).  

I think even "Open Network Resource", while a step in 
the right direction, is a little stodgy -- we probably need some 
PR types to suggest something more graphic ... "resource" may be 
kind of vague ... maybe "node" or something more image-inducing?    

Steve Waterbury
NASA/GSFC



From rbntjc@rohmhaas.com  Wed Nov 24 11:16:02 1993 +22305823 (EST)
Message-Id: <9311241616.AA23321@atlas.br.RohmHaas.Com>
Date: Wed, 24 Nov 1993 11:16:02 +22305823 (EST)
From: rbntjc@rohmhaas.com (Mr. Tom Cozzolino)
Subject: Request: Oracle/Sybase dirt-simple example?


We're seeing many WWW users start to use forms as front-ends
for programs, perl scripts, etc.

And there has been discussion about using WWW clients as a front-end
to Oracle/Sybase/Your-fave-Db.

NCSA has done a nice job in contributing step-by-step directions
to put up forms and hook them to back-end servers.  Anyone care
to do the same for a "generic" (ha-ha) database application?

Whoops!  Forgot about that @#$% authentication..

Comments?
   
+============================================+
|   Thomas J. Cozzolino - Rohm and Haas Co.   = 
|   InterNet:    tcozz@rohmhaas.com            =
|   Phone/Fax: (215) 781-4087/4112              =
|                                                =
|   InterNet access for Everyone..                =
|         - Isn't it Time?                         = 
|                                                   =
|   -- Opinions expressed are my own, not            =
|      necessarily those of Rohm and Haas Company     =
+======================================================+



From sanders@bsdi.com  Wed Nov 24 10:30:00 1993 -0600
Message-Id: <199311241630.KAA02555@austin.BSDI.COM>
Date: Wed, 24 Nov 1993 10:30:00 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: solidifying a really neat forms hack 

> Marc Andreessen writes:
>  |NAME="isindex" result in query strings that look like:
>  |        action?query
>  |...and NOT:
>  |        action?isindex=query
...
Bert Bos replies:
> I agree, but it can be independent of the implementation of ISINDEX.
> E.g., specify that the "=" is omitted when the INPUT NAME attribute is
> empty or omitted:

Exactly, all Marc is really saying is that a form with a single
NAME="isindex" should generate url?foo instead of url?isindex=foo.
Browsers are still free to do whatever they like with <ISINDEX>.

However, let me also say that I personally would rather see the query
encoding specified in a generic way rather than special case the NAME
(I think we did this already).

I did my little demo to show what you could do if you could query multiple
existing databases from a single document.  I would prefer that we don't
special case NAME="isindex".

Just for the record:  ISMAP was a hack also, the proper HTTP/1.0 way of
doing this is to serve the image with attribute "Public: SPACEJUMP".
However, when all servers were HTTP/0.9 there was no other choice.

--sanders



From P.Lister@cranfield.ac.uk  Wed Nov 24 17:26:18 1993 GMT
Message-Id: <9311241726.AA03235@xdm039.ccc.cranfield.ac.uk>
Date: Wed, 24 Nov 93 17:26:18 GMT
From: P.Lister@cranfield.ac.uk (Peter Lister, Cranfield Computer Centre)
Subject: File size indication

Having used the fantastically wonderful piece Mosaic 2.0 for a couple
of days, I am chuffed to bits with being able to URLs before clicking
on them, see the progress of the current transaction.

A really nice devlopment of this would be the ability to see the size
of a file before its pulled in, and whether there are uncached in-lined
images (and their size), whether they're cached, so that I can delay
image loading if it looks like a biggie. To avoid confusing newbies and
wasting time, I'd only want this this info if the file size exceeds a
configurable threshold, and resided off the local network.

During the load, a scale widget (or percentage) indicates how far the
transfer has got. Again, only if the transaction exceeds a threshold size or time.

And, if the file is bigger than I'd  expected, the net slower, or
something hangs, the ability to view what I've got so far, while the
net call continues (i.e. I can see the HTML, while the inlined images
are still being dragged over), and stop the call leaving the page so far in view.

Can HTTP 1.0 pass back file sizes? and things like image content? I
haven't been following the spec lately. If so, this would really help
newbies to understand that while WWW is nice and easy, they are still
using real resources, and it's not their local sys admin's fault if
things are a bit slow at times. Anyone else recognise this last sentiment?

Peter Lister                             Email: p.lister@cranfield.ac.uk
Computer Centre, Cranfield University    Voice: +44 234 754200 ext 2828
Cranfield, Bedfordshire MK43 0AL UK        Fax: +44 234 750875
--- Almost (but not quite) entirely unlike tea ---



From neuss@igd.fhg.de  Wed Nov 24 19:50:04 1993 +0100
Message-Id: <9311241850.AA10921@wildturkey.igd.fhg.de>
Date: Wed, 24 Nov 93 19:50:04 +0100
From: neuss@igd.fhg.de (neuss@igd.fhg.de)
Subject: Forms suggestion

Dear fellow Webbers,

we are currently playing around with forms, and have run into the problem  
that it's difficult to identify from which HTML document a query has been
initiated. This information can be quite important, since it 

  a) enables you to have one /htbin/query script to server different
     classes of form documents, and
  b) in the case of virtual documents (e.g. result of a database query)
     it gives you a possibility to encode things like state of a transaction.

It would at least be a very nice feature to e.g. have the name of the 

original file as part of the URL given (I'm not sure what the state
of the CGP spec is, so please excuse me if that is already the case).

It'd be even more usefull to have some "invisible" attribute which could 

serve as an additional means of passing info to the server. Let me give
you an example: You want to program a userinterface for some relational
database application like e.g. a reservation system. Different users
can log in and do all kinds of operations. Now in order to identify
the specific user (and thus his/her transaction), it'd be nice to create
a virtual HTML document with some kind of "transaction id". This could be 

done by supplying some attributes that are not visible in the HTML browser,
but would create additional "name=value" pairs that are passed to the server.
The document could look like:
  <FORM ACTION="http://turkey/htbin/query">
  ...
  <ATTRIBUTE NAME="transactionid" VALUE="42">
  </FORM>
which would not be displayed in the browser, but be passed to the server
just like the other fields.

What do you think? Those who develop database frontend certainly have run
into similar problems. IMHO, this does not add to much overhead, since it
has no consequences for the server side, and adds only very little to the
server software.

Many greetings,
Chris
--
/*
 *  Christian Neuss  %  neuss@igd.fhg.de  %  ..in the humdrum
 */



From sanders@bsdi.com  Wed Nov 24 13:24:25 1993 -0600
Message-Id: <199311241924.NAA03421@austin.BSDI.COM>
Date: Wed, 24 Nov 1993 13:24:25 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: Forms suggestion 

> we are currently playing around with forms, and have run into the problem  
> that it's difficult to identify from which HTML document a query has been
You just put the information in the URL, that's what it's for.

Don't use:
>   <FORM ACTION="http://turkey/htbin/query">
>   <ATTRIBUTE NAME="transactionid" VALUE="42">
Use instead:
    <FORM ACTION="http://turkey/htbin/query/transactionid=42">

You do not want to add busy work like this into the client.

--sanders



From rivero@sol.unizar.es  Wed Nov 24 20:45:35 1993 +0000 (GMT)
Message-Id: <9311242045.AA05133@sol.cie.unizar.es>
Date: Wed, 24 Nov 1993 20:45:35 +0000 (GMT)
From: rivero@sol.unizar.es (Alejandro Rivero)
Subject: html draft, graphics, nets, lattice, buttons ...

Tim,

I have just read the draft 13 july 93 on html and taking a look on
the graphics embedding proposals, from IMG (html optional in the
RFC) to the htmlplus suggestions. It is really obscure... Could 
you clarify me which format would I actually use if I want to
include a "clickable" graphic or map in a html document? Which
clients can read such protocols?

By other hand, if we follow the RFC, it results we can draw a
map by using  a combination of formatted text and
embbeded graphics. This has the advantage of backward compatibilty,
and even vt100-compatiblility. So I wonder if this possibility would
be remarked when specifing the new format.
Surely a text-formmated document with something as
a LINETO command could be suitable for drawing maps and nets,
and a terminal-oriented browser would simply ignore such drawing
commands, but we could browse into the doc anyway.

				-Alejandro Rivero



 

===============Old Comments follow===============================

If you allow an image, then suppose we also allow some content which  
includes anchors with x,y coordinates within the image. Then the
document can intercept mouse clicks and allow hypergraphics

I don't want to change HTML now if I can help it, until it has gone
to RFC track

Tim
---------------------
 
 HMML is in fact already an extension of HTML for multimedia from  
O'Reilly.  There are similar extenstions from NCSA.  We just have to  
standardize on them for the next DTD which we define.  HTML was  
checkpointed so as not to make a moving target.  NCSA's (released)  
Mosaic for X handles embedded images in the hypertext, as does  
O'Reilly's (unreleased) Viola.
----------------------------------

This is a pre-announcement that Mosaic 1.1 will include support for
Tony Sanders' ISMAP attribute as part of IMG elements (see
http://www.bsdi.com/server/walk/walk.html for details) as an HTML
extension.  

I realize that this is another unplanned change that I'm making
without getting a consensus or having it added to the spec or
whatever.  I also realize that, as with the IMG tag, it may be used
fairly widely in documents on the net even though it's not part of the
HTML spec, possibly making those documents not as friendly to other
browsers (although I hear the next Midas will support this, and
really, it's not that complex to add to an existing image-capable
browser).

Marc
---------------

Something like ISMAP is what you'd want for applications like, say,
a cartographic service, where the user could select an area (mouseDown
for x0,y0, mouseUp for x1,y1), and have the selected area sent to the
server, which will return the image (or vectors) for the new area.
And in the future (with common availability of 3D pointing devices :-) 
this should be easily extensible to 3D-space selection. 

...

So, as I've indicated to Tony before off www-talk, I feel that both are
necessary and have their respective uses. In HMML (my working version 
anyway-- have to sync it with Dave), there's a FIGURE tag which could 
be used in the following ways (fictitious services):
....
Pei Y. Wei
O'Reilly & Associates
-----------------


... and a lot more.
-------------------



From masinter@parc.xerox.com  Wed Nov 24 12:19:14 1993 PST
Message-Id: <93Nov24.121923pst.2732@golden.parc.xerox.com>
Date: Wed, 24 Nov 1993 12:19:14 PST
From: masinter@parc.xerox.com (Larry Masinter)
Subject: Re: solidifying a really neat forms hack

Maybe Mosaic could use something like this for gopher `search' menu
items, rather than making you pop to another page and lose the
context.




From Nathan.Torkington@vuw.ac.nz  Thu Nov 25 11:42:12 1993 +1300
Message-Id: <199311242242.AA16187@kauri.vuw.ac.nz>
Date: Thu, 25 Nov 1993 11:42:12 +1300
From: Nathan.Torkington@vuw.ac.nz (Nathan Torkington)
Subject: Re: www/mosaic

"Peter Lister, Cranfield Computer Centre" writes:

> (who, for instance, can name the title of the Elgar's march that we
> all think of as "Land of Hope and Glory" off the top their heads?)

Pomp And Circumstance.  Who can play it on their banjos? (raises
hand).

Nat



From rik@rdt.monash.edu.au  Thu Nov 25 10:28:00 1993 +1100
Message-Id: <199311242328.KAA25307@daneel.rdt.monash.edu.au>
Date: Thu, 25 Nov 93 10:28:00 +1100
From: rik@rdt.monash.edu.au (Rik Harris)
Subject: Re: www/mosaic 

Nat wrote:
> "Peter Lister, Cranfield Computer Centre" writes:
> 
> > (who, for instance, can name the title of the Elgar's march that we
> > all think of as "Land of Hope and Glory" off the top their heads?)
> 
> Pomp And Circumstance.  Who can play it on their banjos? (raises
> hand).

This must certainly be an FAQ.  Is it on the list?  :-)

rik.
--
Rik Harris - rik.harris@vifp.monash.edu.au              || Systems Programmer
+61 3 560-3265 (AH) +61 3 565-3227 (BH)                 || and Administrator
Fac. of Computing & Info.Tech., Monash Uni, Australia   || Vic. Institute of
http://www.vifp.monash.edu.au/people/rik.html           || Forensic Pathology



From carol@csos.orst.edu  Wed Nov 24 20:01:49 1993 -0800 (PST)
Message-Id: <Pine.3.87.9311242049.A26209-0100000@CSOS.ORST.EDU>
Date: Wed, 24 Nov 1993 20:01:49 -0800 (PST)
From: carol@csos.orst.edu (Carol Smedberg)
Subject: 

unsubscribe

carol.CSOS.ORST.EDU





From JCTS001%TWNMOE10.BITNET@cearn.bitnet  Thu Nov 25 15:01:20 1993 EST
Message-Id: <9311250702.AA03152@dxmint.cern.ch>
Date: Thu, 25 Nov 93 15:01:20 EST
From: JCTS001%TWNMOE10.BITNET@cearn.bitnet (JCTS001%TWNMOE10.BITNET@cearn.bitnet)
Subject: 

UNSUBSCRIBE  JCTS001@MOE10.EDU.TW



From JCTS001%TWNMOE10.BITNET@cearn.bitnet  Thu Nov 25 15:04:46 1993 EST
Message-Id: <9311250707.AA04459@dxmint.cern.ch>
Date: Thu, 25 Nov 93 15:04:46 EST
From: JCTS001%TWNMOE10.BITNET@cearn.bitnet (JCTS001%TWNMOE10.BITNET@cearn.bitnet)
Subject: 

SUBSCRIBE JOE@PEACOCK.TNJC.EDU.TW



From Paul.Wain@brunel.ac.uk  Thu Nov 25 08:41:17 1993 +0000 (GMT)
Message-Id: <19162.9311250841@thor.brunel.ac.uk>
Date: Thu, 25 Nov 1993 08:41:17 +0000 (GMT)
From: Paul.Wain@brunel.ac.uk (Paul )
Subject: Re: File size indication

@ [lots of stuff about file sizes and amount of a document read deleted]

This one got me :) 

Having used Mosaic 2.0 and PC-Mosaic 1 (?) (the recent full release) you
can see that it is possible to obtain image sizes and ammount recieved
so far (you read say the GIF header and I believe that has the size
info in it or something :) 

In PC-Mosaic it tells you something like 20K read (of 100K) - 80% to go...

That would be a nice addition :) But I dare say people have discussed
this already :)

Paul



From Paul.Wain@brunel.ac.uk  Thu Nov 25 08:50:23 1993 +0000 (GMT)
Message-Id: <19250.9311250850@thor.brunel.ac.uk>
Date: Thu, 25 Nov 1993 08:50:23 +0000 (GMT)
From: Paul.Wain@brunel.ac.uk (Paul )
Subject: Security and stuff

Hi,

I know this has probably all be dealt with before but a question anyway :)

I am looking at a Web (erm did we agree to use this short form :)
application that needs some inherent security built into it for passing
information access rights/usernames & passwords to the server from the
client. 

The problem being that ideally this doesnt want to be left around in a
URL or indeed end up being included into a URL, since we do not want the
information that is providing access being left around.

We cannot also assume that the person accessing the information will be
on the same host all the time (for example although this is coming at
you from 134.83.128.30, I am sitting on 134.83.112.57, and could indeed
be running my Mosaic 2.0 client from anywhere of our 12 or so sub
nets).

Has there been any discussion on this and cryptographic authentication
techniques? Are there any documents on it? Or is it an up and coming
issue? Sorry for all the questions :)

Oh one last thing we cant always assume that the request is going to be
coming in from a UNIX box, or even using a pure URL/HTML style request
since ideally we are also looking at DOS Gopher access to it too :) Yeah
I know a pain, but...

Anyway any information would be appreciated.

Paul

(p.s. Sorry if I got some of my WWW terminology wrong but its early :)
      If it had been later in the day I would have been awake :)
--

 ******************************************************************** 
** Paul Wain, (X.500 Project Engineer & WWW/httpd person), Computer **
*   Centre, Brunel University, UXBRIDGE, Middlesex UB8 3PH, ENGLAND  *
**                  E-MAIL: Paul.Wain@brunel.ac.uk                  **
 ******************************************************************** 



From Paul.Wain@brunel.ac.uk  Thu Nov 25 10:11:22 1993 +0000 (GMT)
Message-Id: <20138.9311251011@thor.brunel.ac.uk>
Date: Thu, 25 Nov 1993 10:11:22 +0000 (GMT)
From: Paul.Wain@brunel.ac.uk (Paul )
Subject: Re: Security and stuff

Thanks to Guy Decoux and Martijn Koster for their quick replies :)

I found what I was looking for on:

	http://info.cern.ch/hypertext/WWW/AccessAuthorization/Overview.html

This is ideal :)

Paul

 ******************************************************************** 
** Paul Wain, (X.500 Project Engineer & WWW/httpd person), Computer **
*   Centre, Brunel University, UXBRIDGE, Middlesex UB8 3PH, ENGLAND  *
**                  E-MAIL: Paul.Wain@brunel.ac.uk                  **
 ******************************************************************** 



From guenther.fischer@hrz.tu-chemnitz.de  Thu Nov 25 11:44:07 1993 +0100 (MET)
Message-Id: <9311251044.AA04059@flash1.hrz.tu-chemnitz.de>
Date: Thu, 25 Nov 1993 11:44:07 +0100 (MET)
From: guenther.fischer@hrz.tu-chemnitz.de (Guenther Fischer)
Subject: HTTP Draft

I'm lucky to find the Last-modified at some new servers (Plexus, NCSA/1.0a5)
but the format is different:

1) Plexus: Last-modified: Saturday, 30-Oct-93 19:34:48 GMT

2) NCSA/1.05a: Last-modified: Tue Nov 23 16:00:43 1993 GMT


The draft says see RFC850 but with GMT ...
The draft says as I see: do it like 1) but understand 2) also, with
the difference that GMT is not in the old form of RFC850.

Could'nt we say for HTML take 1).

	~Guenther

-- 
Name:      Guenther Fischer
Institute: TU Chemnitz, Universitaetsrechenzentrum
Phone:     0371 668 361
mail:      fischer@hrz.tu-chemnitz.de



From timbl@www3.cern.ch  Thu Nov 25 17:27:13 1993 +0100
Message-Id: <9311251627.AA04494@www3.cern.ch>
Date: Thu, 25 Nov 93 17:27:13 +0100
From: timbl@www3.cern.ch (Tim Berners-Lee)
Subject: Re: Mosaic vs WWW


>Date: Tue, 23 Nov 1993 15:25:41 -0500
>From: Jim Davis <davis@dri.cornell.edu>

>Am I the only one who is getting irritated by this constant
>confusion in the press between WWW and Mosaic?

It does cause a lot of confusion.  We hear that "Gopher
and Mosaic" were on the White house lawn sun; we hear
that "Mosaic integrates gopher and web access".  The last
one really grates, as WWW was designed to integrate the
works. The "web" is the result of the integration.

> Don't get
>me wrong, Mosaic is a major blessing, I am grateful beyond
>words to NCSA for funding it,

Agreed.  Mosaic is fantastic.  And noone else has time
to keep Marc's "What's new" list up to date (and program..
how does he do it?  What brand of coffee?)

> but why can't people understand
>that Mosaic is NOT the WWW, but just one of the possible
>tools that work with it - that WWW is the client-server system,
>and Mosaic just one of those clients.  


Now that NCSA have clearly demonstrated their dominance of the client
scene, perhaps they could take care that the web does not threaten
to become an application-specific creation.  When you start
Mosaic, you get the Mosaic documentation, which lets you know
all about Mosaic.  NCSA should be careful to be fair and fit
into the web along with the smaller players.  The strong must
be just.

>it would probably help if the "What's New" page called itself
>"what's new with the WWW" instead of "whats new with Mosaic".

Or "What's new on the Web".  They could even put in
pointers to announcements of new Lynx and Cello versions...

Tim



From azhao@cc.gatech.edu  Thu Nov 25 13:12:33 1993 EST
Message-Id: <199311251812.NAA16794@oakmont.cc.gatech.edu>
Date: Thu, 25 Nov 93 13:12:33 EST
From: azhao@cc.gatech.edu (Q. Alex Zhao)
Subject: Synchronized...

Hi,

Can X-Mosaic handle "synchronized media"? Basically, I want the
following effect:

 - There's a link; when I click on it, I will get a MPEG movie _AND_
   some audio information.

 - Based on the first one, can the audio part somehow synchronize with
   the video part at some certain points, like there may be some
   interesting points in the video, and when I see one, I will hear the
   corresponding audio explanation...

Can Mosaic do these? If so, how? Thanks in advance.

Cheers,
= Q. Alex Zhao    ~{0"UT~}    ! Graphics, Visualization & Usability Center
  Email: azhao@cc.gatech.edu  ! College of Computing
  FAX:   404-853-9378         ! Georgia Institute of Technology
  Lab:   404-894-9633         ! Atlanta, Georgia 30332-0280



From nilsson@dxcern.cern.ch  Fri Nov 26 10:30:14 1993 +0100
Message-Id: <9311260930.AA04937@dxcern.cern.ch>
Date: Fri, 26 Nov 1993 10:30:14 +0100
From: nilsson@dxcern.cern.ch (Bjorn S. Nilsson)
Subject: VMS port of Mosaic 2.0

A port of Mosaic 2.0 for VMS is now available on info.cern.ch
in directory /pub/www/bin/vms It has also been submitted to
NCSA and should be available in the Mosaic/Mosaic-contrib
directory on ftp.ncsa.uiuc.edu in due time. People with DEC-
net access to CERN can copy a backup save set or the tar files
from ALWS::PD_ROOT:[MOSAIC] also (ALWS = 22.554 = 23082).
 
--
Bjorn S. Nilsson, ALEPH, CERN 
nilsson@alws.cern.ch 
http://alephinfo.cern.ch/@ALWHO?nilsson 



From kevinh@pulua.hcc.hawaii.edu  Thu Nov 25 23:33:36 1993 HST
Message-Id: <9311260933.AA13322@pulua.hcc.Hawaii.Edu>
Date: Thu, 25 Nov 93 23:33:36 HST
From: kevinh@pulua.hcc.hawaii.edu (Kevin 'Kev' Hughes)
Subject: Re:  Forms suggestion

Christian Neuss (neuss@igd.fhg.de) writes:

> done by supplying some attributes that are not visible in the HTML browser,
> but would create additional "name=value" pairs that are passed to the server.
> ...
> which would not be displayed in the browser, but be passed to the server
> just like the other fields.

	I'd love to see this implemented too! I came across this problem
while putting together a neat forms hack, and only partially solved it by
making a SELECT menu with one option, it's rather ugly.
	Also, what do people think of being able to make the ACTION
selectable, so a user can choose where to send a form? For instance,
something like:

<select name="menu">
<option action="http://ncsa.uiuc.edu/htbin/formd"> Send to NCSA
<option action="http://info.cern.ch/htbin/formd"> Send to CERN
</select>

	I have the feeling this was brought up before...

	-- Kevin



From udi@wisdom.weizmann.ac.il  Fri Nov 26 12:11:00 1993 IST
Message-Id: <9311261011.AA02781@dror.wisdom.weizmann.ac.il>
Date: Fri, 26 Nov 93 12:11:00 IST
From: udi@wisdom.weizmann.ac.il (Ehud Shapiro)
Subject: An NFS vs HTTP query


If an http URL is pointing to a file that is accessible via
NFS (i.e. the file resides in a directory mounted by the client),
then in principle the client can read the file directly from the file
system rather than go via HTTP to the server, essentially
treating the URL as if it was of type "file:" rather than "http:".

Has anyone considered this shortcut?  What problems can it
cause (e.g. incorrect interpretation of file type)?
Is there any performance advantage?

Thanks,
-- Udi



From kevinh@pulua.hcc.hawaii.edu  Fri Nov 26 01:42:45 1993 HST
Message-Id: <9311261142.AA14423@pulua.hcc.Hawaii.Edu>
Date: Fri, 26 Nov 93 01:42:45 HST
From: kevinh@pulua.hcc.hawaii.edu (Kevin 'Kev' Hughes)
Subject: WAIS indexing directory hierarchies


	Thanks to Marc's excellent "Mosaic and WAIS Tutorial", I've
managed to get a WAIS server up and running. But to index our entire
Web directory tree, I ran into some problems. Using the -r flag to
waisindex would only work if I tried to index *all* files in the
directories. When waisindex hit a directory as an option, only then would
it go into it.
	I didn't want this, so I made the small shell script below. I'm
not sure if it's entirely correct for indexing, but it seems to do the trick.
I can't wait until the day when WAIS servers can return full URLs!

	-- Kevin

---

#! /bin/csh

set rootdir = /www
set index = /usr/local/etc/http/index
set indexprog = /usr/local/etc/http/waisindex

cd $rootdir
set num = 0
foreach pathname (`du $rootdir | cut -f2 | tail -r`)
	cd $pathname
	echo "Current pathname is: $pathname"
	if ($num == 0) then
		set exportflag = "-export"
	else
		set exportflag = "-a"
	endif
	$indexprog -d $index $exportflag -T HTML *.html
	$indexprog -d $index -a -T TEXT *.txt
	$indexprog -d $index -a -T PS -nocontents *.ps
	$indexprog -d $index -a -T GIF -nocontents *.gif
	$indexprog -d $index -a -T AU -nocontents *.au
	$indexprog -d $index -a -T HQX -nocontents *.hqx
	$indexprog -d $index -a -T XBM -nocontents *.xbm
	$indexprog -d $index -a -T MPG -nocontents *.mpg
	$indexprog -d $index -a -T C -nocontents *.c
	@ num++
end
echo "$num directories were indexed."



From neuss@igd.fhg.de  Fri Nov 26 12:44:25 1993 +0100
Message-Id: <9311261144.AA01606@wildturkey.igd.fhg.de>
Date: Fri, 26 Nov 93 12:44:25 +0100
From: neuss@igd.fhg.de (neuss@igd.fhg.de)
Subject: Announcement: Indexing extension

Dear fellow webbers,

we finally have finished a first version of our indexing extension
to HTTP servers. Feedback is very welcome.

Here's some info on it:
Chris
--
/*
 *  Christian Neuss  %  neuss@igd.fhg.de  %  ..in the humdrum
 */
================================ SNIP ==================================

Fraunhofer IGD proudly presents:

HTTP Index Server Extension
===========================

 Many thanks to Ari Luotonen from CERN for his contribution of
 the extract-title command, and to Stefanie Hoefling for many hours 

 of debugging. -- Chris

What it is:
The HTTP Index Server Extension allows for doing free text queries
on hierarchies of HTML files. The functionality is pretty close
to a WAISINDEX interface, but the package is a lot smaller and more
portable. What it basically does is have cron create an index file
in regular intervalls, and access this index file whenever an index
query from the client is being issued. The supported query syntax
allows combining keywords with AND and OR, so a query could look
like "server and script". As result of the index query, list of all 

HTML files containing both words will be created and sent back to the
client. Files will contain a relevance feedback, and are clickable
hyperlinks to the files themselves.

Another feature is the ability to use a thesaurus for conceptual
searches: Entering "{picture}" as query will not only retrieve
files containing the word "picture", but also related concepts
like "image" etc. The thesaurus format we support is the ANSI
standard Thsaurus Image Format (TIF). Thesaurus information is 

available from many sources, but the most important feature is
probably the ability to create specific technical thesauri
related to whatever is stored in your HTML text database.

How to get it:
Access it from
  ftp://ftp.igd.fhg.de/incoming/ICE-1.01a.tar.Z
  ftp://info.cern.ch/pub/www/src/ICE-1.0b.tar.Z
in order of preference. The version on the CERN server is slightly
older, but I'll send them an update, and they will probably soon
put up the 1.01a version.

Bugs:
Probably too numerous to mention :-) 

This is a very early version, and will be improved in the future.
The index extension will probably become part of the CERN httpd
server, and perhaps Rob McCool will also include it in the NCSA
distribution. The version I make available is mostly for those 

of you who need indexing badly, and don't want to wait for
future server releases. 


Please contact me if you have bug-reports or suggestions: 

Christian Neuss  

c/o Fraunhofer IGD  

Wilhelminenstr. 7  

64283 Darmstadt  

GERMANY
Fax: (+49)6151 155-199  

email:  neuss@igd.fhg.de

Have fun :-),
-- Chris



From dsr@hplb.hpl.hp.com  Fri Nov 26 12:40:14 1993 GMT
Message-Id: <9311261240.AA21741@manuel.hpl.hp.com>
Date: Fri, 26 Nov 93 12:40:14 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: X Mosaic 2.0 and Closed to Open subnet gateway

Those of you who work for companies with a closed subnet may be interested
in my patch to X Mosaic 2.0 to allow it to make connections transparently
to servers outside the closed subnet, via a simple TCP/IP gateway driven
by inetd.

The change is limited to libwww2 : HTTCP.c and the HTDoConnect() function.
If you want the patch and the gateway program, email me: dsr@hplb.hpl.hp.com

If there is sufficient interest I will try and get NCSA to take on the
code as part of their normal s/w distribution package.

Dave Raggett,

-----------------------------------------------------------------------------
Hewlett Packard Laboratories,           +44 272 228046
Bristol, England                        dsr@hplb.hpl.hp.com



From dsr@hplb.hpl.hp.com  Fri Nov 26 12:43:48 1993 GMT
Message-Id: <9311261243.AA22054@manuel.hpl.hp.com>
Date: Fri, 26 Nov 93 12:43:48 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re:  Forms suggestion

Christian Neuss (neuss@igd.fhg.de) writes:

> done by supplying some attributes that are not visible in the HTML browser,
> but would create additional "name=value" pairs that are passed to the server.
> ...
> which would not be displayed in the browser, but be passed to the server
> just like the other fields.

This is what the <MH> element in the HTML+ spec is for. It allows authors
to include RFC 822 headers in the request, which are/aren't shown to the
reader according to whether the HIDDEN attribute is missing/present.

Dave Raggett



From dsr@hplb.hpl.hp.com  Fri Nov 26 12:48:19 1993 GMT
Message-Id: <9311261248.AA22066@manuel.hpl.hp.com>
Date: Fri, 26 Nov 93 12:48:19 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: An NFS vs HTTP query

Ehud Shapiro writes:

> If an http URL is pointing to a file that is accessible via
> NFS (i.e. the file resides in a directory mounted by the client),
> then in principle the client can read the file directly from the file
> system rather than go via HTTP to the server, essentially
> treating the URL as if it was of type "file:" rather than "http:".

Yes, my browser works that way. It does improve performance, especially
when the server would otherwise have to use nfs itself to access the file
in addition to sending the file via HTTP.

The browser is left to interpret the file type on the basis of file name
suffix or pattern match on data contents. I have this code left over from
the old HTTP/0.9 days when you had to guess the file type.

Dave Raggett



From kevinh@pulua.hcc.hawaii.edu  Fri Nov 26 04:02:43 1993 HST
Message-Id: <9311261402.AA15781@pulua.hcc.Hawaii.Edu>
Date: Fri, 26 Nov 93 04:02:43 HST
From: kevinh@pulua.hcc.hawaii.edu (Kevin 'Kev' Hughes)
Subject: WAIS indexing with URLs


	Off of Marc's early documentation, I've put together the following
script using URL support in freeWAIS 2.0.2. However, using the feature
seems to break the -nocontents flag, so I've commented out the lines that
index image/code things. (It gets painfully slow if you have a lot of images.)
	IMHO, I don't think it works all that well. I suppose I like
seeing the full URL more, but I still want it to refer to a real URL,
not this WAIS docid stuff.
	For now, the index is going through

	http://www.ncsa.uiuc.edu:8001/www.hcc.hawaii.edu:2010/index

	-- Kevin

----

#! /bin/csh

set rootdir = /www
set index = /usr/local/etc/http/index
set indexprog = /usr/local/etc/http/waisindex
set url = http://www.hcc.hawaii.edu

cd $rootdir
set num = 0
foreach pathname (`du $rootdir | cut -f2 | tail -r`)
	echo "Current pathname is: $pathname"
	if ($num == 0) then
		set exportflag = "-export"
	else
		set exportflag = "-a"
	endif
	$indexprog -d $index $exportflag -t URL $rootdir $url $pathname/*.html
	$indexprog -d $index -a -t URL $rootdir $url $pathname/*.txt
# 	$indexprog -d $index -a -t URL $rootdir $url $pathname/*.ps
# 	$indexprog -d $index -a -t URL $rootdir $url $pathname/*.gif
#	$indexprog -d $index -a -t URL $rootdir $url $pathname/*.au
#	$indexprog -d $index -a -t URL $rootdir $url $pathname/*.hqx
#	$indexprog -d $index -a -t URL $rootdir $url $pathname/*.xbm
#	$indexprog -d $index -a -t URL $rootdir $url $pathname/*.mpg
#	$indexprog -d $index -a -t URL $rootdir $url $pathname/*.c
	@ num++
end
echo "$num directories were indexed."



From altis@ibeam.jf.intel.com  Fri Nov 26 13:49:08 1993 -0800
Message-Id: <m0p3B0s-0003WDC@ibeam.intel.com>
Date: Fri, 26 Nov 1993 13:49:08 -0800
From: altis@ibeam.jf.intel.com (Kevin Altis)
Subject: HTTP batch file fetcher?

Has anyone written an application (perhaps a Perl script) to automatically
fetch a series of files from an HTTP server, storing them on a local disk?
Most Web clients have the ability to download to disk, but they can't be
used yet to get a series of files automatically.

The other problem is that when downloading to disk, the user is prompted
for a filename, even though the last part of the URL could have been used
for the name; at least Lynx (thanks Lou) uses the last part of the URL for
files it can't display, but alas Lynx has no download to disk "mode" and no
remote control options.

As more and more HTTP and Gopher servers pop up, the ability to get files
automatically via FTP, including batch download and recursive download of
whole directory trees seems to have gone away. Pointers to tools for Mac,
Windows, Unix that allow me to do batch downlods via HTTP... would be
greatly appreciated.

ka





From altis@ibeam.jf.intel.com  Fri Nov 26 13:49:13 1993 -0800
Message-Id: <m0p3B0y-0003WFC@ibeam.intel.com>
Date: Fri, 26 Nov 1993 13:49:13 -0800
From: altis@ibeam.jf.intel.com (Kevin Altis)
Subject: self-referencing Web indexes/documents

Indexes to information on the Web are starting to pop up all over the
place. Until we have URNs and URN servers, most users will likely go to
NCSA for the NCSA Starting Points document, CERN for the complete Web
server list, etc.

I would like to reduce network traffic by keeping local copies of at least
the main index pages on our local server. Once a day or week via a cron
job, our local server could fetch the latest HTML document from the main
index points around the Web. I assume some people are already doing this.
Our server home page would then refer to the local copies of the indexes,
rather than the originals.

What's missing is a link within the HTML documents themselves, back to
their original location. This would allow the "local caching" to be
extended further to individual client machines and gives a workable
self-reference until HTML+ is fully implemented. With just regular HTML,
document authors could change their documents, to look something like:

<TITLE>Starting Points for Internet Exploration</TITLE>
<H1><A HREF
="http://www.ncsa.uiuc.edu/SDG/Software/Mosaic/StartingPoints/NetworkStartin
gPoints.html">Starting Points for Internet Exploration</A></H1>

That way, if someone wants to get the latest version to save to disk - this
is really handy for portable and home users browsing through documents
before connecting to the net - they just click on the link, get the latest
version and save to disk.

I know this will change once we have URNs and real distributed files, but
for now, there is usually a real home for a document, and I would like an
easy way to get it.

ka





From marca@ncsa.uiuc.edu  Sat Nov 27 14:28:43 1993 -0800
Message-Id: <9311272228.AA06556@wintermute.ncsa.uiuc.edu>
Date: Sat, 27 Nov 93 14:28:43 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: proposal for new HTTP/1.0 directive

It occasionally is useful to have the results of a HTTP/1.0
transaction return *nothing* (no significant response data) -- the
client should not display a new document or do anything else other
than stay on exactly the same document it's already on.

An example of where this would be useful: tape-deck-style
fast-forward/stop/reverse/play/pause/etc. controls implemented with
forms or hyperlinks as part of a multicasting transmission
application.  You want to be able to trigger as many actions as you
want (play, pause, play, fast-forward, play, etc.) without moving to a
different document each time.

How about "204 NoResponse"?

Marc




From hoesel@chem.rug.nl  Sun Nov 28 12:03:24 1993 +0100 (MET)
Message-Id: <9311281103.AA00475@Xtreme>
Date: Sun, 28 Nov 1993 12:03:24 +0100 (MET)
From: hoesel@chem.rug.nl (frans van hoesel)
Subject: Postscript & font enhancements.

hi,

for those who got the patches for xmosaic from rugch4.chem.rug.nl the
next message:

it seems that somehow the makefile that comes with xmosaic isn't working
correctly on all systems. So after you have retrieved the pathces, you might
want to 'touch */*.c' and rebuild xmosaic from scratch.

(my guess is some hidden dependencies on Mosaic.h)

- frans





From decoux@moulon.inra.fr  Sun Nov 28 16:31:01 1993 +0100
Message-Id: <9311281531.AA19975@moulon.moulon.inra.fr>
Date: Sun, 28 Nov 93 16:31:01 +0100
From: decoux@moulon.inra.fr (ts)
Subject: mask-group



> Protecting Entire Tree as one Entity
> 
> If you want to control access only to entire trees of documents and don't care to
> restrict access differently to individual files, it suffices to give a mask-group in
> setup file (and you don't need any ACL files): 
> 
>    mask-group  group, user, group@address, ...

 In this case, all methods (GET ... DELETE) are allowed ?

Guy Decoux




From luotonen@ptsun00.cern.ch  Sun Nov 28 17:02:41 1993 +0100
Message-Id: <9311281602.AA08558@ptsun03.cern.ch>
Date: Sun, 28 Nov 93 17:02:41 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: Re: mask-group


> >    mask-group  group, user, group@address, ...
> 
>  In this case, all methods (GET ... DELETE) are allowed ?

No; I will add fields get-mask, post-mask, ... to protectioon
setup file now that I'm adding PUT to our server, and mask-group
will be a synonym for get-mask.  And I think it's appropriate
that other methods than GET always require authentication (or
then there must be an explisit mention about letting anybody do
PUT etc in the ACL or setup file).

-- Cheers, Ari --





From guenther.fischer@hrz.tu-chemnitz.de  Mon Nov 29 08:41:30 1993 +0100 (MET)
Message-Id: <9311290741.AA14535@flash1.hrz.tu-chemnitz.de>
Date: Mon, 29 Nov 1993 08:41:30 +0100 (MET)
From: guenther.fischer@hrz.tu-chemnitz.de (Guenther Fischer)
Subject: How to print more than one html document

We are on the way to set up HTML documents. 
Till now we have done all documentation in latex. The first step was
to convert latex documents to html. But there is some work after that.

What should we do in the future?
We could write most documents in HTML, but we need one simple way to
print a HTML-document collection. 

Printing from Mosaic is fine for one document but not for a set of.

Any help?

	~Guenther
-- 
Name:      Guenther Fischer
Institute: TU Chemnitz, Universitaetsrechenzentrum
Phone:     0371 668 361
mail:      fischer@hrz.tu-chemnitz.de



From robm@ncsa.uiuc.edu  Mon Nov 29 02:11:52 1993 -0600
Message-Id: <9311290811.AA19957@void.ncsa.uiuc.edu>
Date: Mon, 29 Nov 1993 02:11:52 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: HTTP Draft

/*
 * HTTP Draft  by Guenther Fischer (guenther.fischer@hrz.tu-chemnitz.de)
 *    written on Nov 25, 11:44am.
 *
 * I'm lucky to find the Last-modified at some new servers (Plexus, NCSA/1.0a5)
 * but the format is different:
 * 
 * 1) Plexus: Last-modified: Saturday, 30-Oct-93 19:34:48 GMT
 * 
 * 2) NCSA/1.05a: Last-modified: Tue Nov 23 16:00:43 1993 GMT
 * 
 * 
 * The draft says see RFC850 but with GMT ...
 * The draft says as I see: do it like 1) but understand 2) also, with
 * the difference that GMT is not in the old form of RFC850.
 * 
 * Could'nt we say for HTML take 1).
 */

Yes, we should. Guess I was reading the wrong section of the RFC. I'll fix
mine to look more the RFC expects.

--Rob



From robm@ncsa.uiuc.edu  Mon Nov 29 03:05:23 1993 -0600
Message-Id: <9311290905.AA20602@void.ncsa.uiuc.edu>
Date: Mon, 29 Nov 1993 03:05:23 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI/1.0 status

/*
 * CGI/1.0 status  by Ari Luotonen (luotonen@ptsun00.cern.ch)
 *    written on Nov 28,  5:08pm.
 *
 * 
 * what is the status of CGI/1.0, can we start coding soon??
 */

I haven't recieved anything that I haven't addressed (to my knowledge, if
something slipped by someone please say so). The doc at
http://hoohoo.ncsa.uiuc.edu/beta-docs/external-protocol.txt is the latest.
Note the addition of the naming convention "nph:scriptname" for scripts
which require direct output to the client.

There's only one more touchy subject I want to discuss before we finalize,
and that's the who-decodes-the-arguments issue. I've been busy converting
some scripts over to my preliminary CGI/1.0 implementation, and I'm finding
that I really don't like having the server decode the arguments. 

Here are the pro-arguments as I remember them, and my reasons for
disagreeing:

Argument: If the server does it, scripts don't have to do it, so there are
          simpler scripts.

Counter: However, a prudent script must have code to decode long arguments
         anyway. Therefore, if the scripts may have to do it themselves
         anyway, why bother decoding it in the first place, if the scripts 
         need the code anyway?

Argument: We already know how to decode the URL, there is ISINDEX and FORMs,
          and we know how to decode both.

Counter: FORMS are part of HTML+. What if there are other aspects of HTML+,
         or HTML++ which are not compatible with these two methods? I don't
         want to have people upgrading their server every time a new
         convention is invented.

My arguments for having the scripts do the decoding:

1. It's painfully simple to do it even from a shell script, one line with a
   C support program. PERL and C code is available to do so. What's the
   advantage of having the server do it, besides avoiding a little confusion
   for novice script writers?

2. Any script which needs to decode its own URL still has the server decode
   it, possibly in a way the script doesn't want it to.  Wasted effort for
   the server, CPU time which could be better spent servicing the ~130 other
   waiting users (at least, if you're www.ncsa).

3. POST scripts which handle forms need the unescaping code regardless.
   Again, duplication of effort.

Is there a compelling argument which I am missing? 

--Rob




From F.Zwarts@kvi.nl  Mon Nov 29 11:46:47 1993 +0000 (WET)
Message-Id: <01H5VXG7L5IQ95NO0Q@KVI.nl>
Date: Mon, 29 Nov 1993 11:46:47 +0000 (WET)
From: F.Zwarts@kvi.nl (Fred Zwarts, KVI, Groningen, NL.)
Subject: File: access to non-Unix FTP servers

I like the way WWW allows me to browse through anonymous FTP sites. I did not
succeed, however, to access files from FTP sites with a non-Unix file system.

I tried, for example, to access a file from a FTP site running VMS, but it
failed. The error message suggests that the FTP server rejects the connection,
but FTP access outside WWW succeeds. Looking into HTFTP.c seems to indicate
that the connection to the FTP server succeeds, but that the client only
continues connections with servers that allow file specifications beginning
with a a slash (/).

The FTP protocol itself does not have this limitation, so I must assume that
this restriction has been built into the WWW software. Is there a good reason
for this restriction or is it a remainder from an overlooked possibility for
the use of WWW in its design phase? Are there plans to remove this restriction?

I understand that it is complicated to build additional browsers for other file
systems, (this might be simpeler if the NLST command was used instead of the
LIST command,) but it would be nice if at least a file in a non-Unix format
could be specified.

Fred Zwarts	KVI, Groningen, Netherlands	Internet:	F.Zwarts@KVI.nl
Phone:		(+31)50-633619			Telefax:	(+31)50-634003
X400:		C=nl;ADMD=400net;PRMD=surf;O=KVI;S=Zwarts;G=Fred



From dolesa@smtp-gw.spawar.navy.mil  Mon Nov 29 06:27:38 1993 EDT
Message-Id: <9310297545.AA754583258@smtp-gw.spawar.navy.mil>
Date: Mon, 29 Nov 93 06:27:38 EDT
From: dolesa@smtp-gw.spawar.navy.mil (Andre Doles)
Subject: Re: No subject given


     
unsubscribe dolesa@smtp-gw.spawar.navy.mil




From dolesa@smtp-gw.spawar.navy.mil  Mon Nov 29 06:55:32 1993 EDT
Message-Id: <9310297545.AA754584932@smtp-gw.spawar.navy.mil>
Date: Mon, 29 Nov 93 06:55:32 EDT
From: dolesa@smtp-gw.spawar.navy.mil (Andre Doles)
Subject: cc:Mail SMTPLINK 2.0 Undeliverable Message


     
I'm looking for anyone that has experience comiling http server 
software running under A/UX (Apple's Unix.)  I'm probably the only sole 
in the universe "trying" to use A/UX, but just thought I'd check.  I'm 
kinda new to alot of this, so a knowledgable A/UX person who is doing 
this kinda thing would be helpful.  Volunteers?
     
                            Andre' Doles
                            dolesa@smtp-gw.spawar.navy.mil
                            Space & Naval Warfare Systems Command HQ
     
     
     



From P.Lister@cranfield.ac.uk  Mon Nov 29 12:29:13 1993 GMT
Message-Id: <9311291229.AA02482@xdm039.ccc.cranfield.ac.uk>
Date: Mon, 29 Nov 93 12:29:13 GMT
From: P.Lister@cranfield.ac.uk (Peter Lister, Cranfield Computer Centre)
Subject: FTP messages

Talk of FTP reminds me of another wish for the list.

Many FTP servers have instructions, disclaimers, diagnostics, etc,
which are not visible when using e.g. Mosaic. I would really like to
see these at the top of my directory listing.

Peter Lister                             Email: p.lister@cranfield.ac.uk
Computer Centre, Cranfield University    Voice: +44 234 754200 ext 2828
Cranfield, Bedfordshire MK43 0AL UK        Fax: +44 234 750875
--- Almost (but not quite) entirely unlike tea ---



From P.Lister@cranfield.ac.uk  Mon Nov 29 12:40:17 1993 GMT
Message-Id: <9311291240.AA02570@xdm039.ccc.cranfield.ac.uk>
Date: Mon, 29 Nov 93 12:40:17 GMT
From: P.Lister@cranfield.ac.uk (Peter Lister, Cranfield Computer Centre)
Subject: Mosaic USENET client?

It occurs to me that, now we have forms and mechanisms for posting
things, it should be entirely possible to write an HTTP server that
posts USENET news articles, and behaves like a full function USENET
news client, while the donkey work of actually browsing articles is
still done directly using NNTP.

Anyone doing this? I'm not volunteering (too little time), but it's a
neat project for someone, and I would find it much preferable to browse
in Mosaic rather than xrn. An obvious candidate for a PERL module in Plexus....

Peter Lister                             Email: p.lister@cranfield.ac.uk
Computer Centre, Cranfield University    Voice: +44 234 754200 ext 2828
Cranfield, Bedfordshire MK43 0AL UK        Fax: +44 234 750875
--- Almost (but not quite) entirely unlike tea ---



From Axel.Belinfante@cs.utwente.nl  Mon Nov 29 14:46:19 1993 +0100
Message-Id: <9311291346.AA01062@utis179.cs.utwente.nl>
Date: Mon, 29 Nov 93 14:46:19 +0100
From: Axel.Belinfante@cs.utwente.nl (Axel Belinfante)
Subject: Re: Mosaic USENET client? 

Peter Lister <p.lister@cranfield.ac.uk> writes
in message <9311291240.AA02570@xdm039.ccc.cranfield.ac.uk>:
> It occurs to me that, now we have forms and mechanisms for posting
> things, it should be entirely possible to write an HTTP server that
> posts USENET news articles, and behaves like a full function USENET
> news client, while the donkey work of actually browsing articles is
> still done directly using NNTP.
> 
> Anyone doing this? I'm not volunteering (too little time), but it's a
> neat project for someone, and I would find it much preferable to browse
> in Mosaic rather than xrn. An obvious candidate for a PERL module in Plexus..

I did make an attempt to integrate the webthread.pl (v1.1) code by
Ian Goldberg <iagoldberg@undergrad.math.uwaterloo.ca> into plexus.

The result is running as
	http://utis179.cs.utwente.nl:8001/news/newshier

Right now, when you request an article, it is requested from the nntp
server and run through a converter that 'detects/creates' hyperlinks,
if you are allowed to read news via that nntp server, or you will get
a redirect URL news:message-id, which will allow you to read the
article from your own nntp server... but you won't get the 'hyperlink-
detection' in that case.

Adding support for posting and support for the .newsrc file are on the
TODO list, as far as i know. I don't know whether Ian reads this list.

Regards,
Axel.

<Axel.Belinfante@cs.utwente.nl>   tel. +31 53 893774   fax. +31 53 333815
     University of Twente, Tele-Informatics & Open Systems Group
       P.O. Box 217    NL-7500 AE Enschede      The Netherlands
     "ili ne sciis ke estas neebla do ili simple faris" -- Loesje




From dsr@hplb.hpl.hp.com  Mon Nov 29 15:16:19 1993 GMT
Message-Id: <9311291516.AA05105@manuel.hpl.hp.com>
Date: Mon, 29 Nov 93 15:16:19 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Improved FTP access for Mosaic

Call for volunteers:

The current FTP code for X Mosaic 2.0 requires FTP servers to connect
to the client for data transfers. This fails for users running Mosaic
in a closed subnet when trying to access hosts outside that subnet,
even with my gateway :-(

The solution is to rewrite HTFTP.c to use the PASV command which
causes the server to send the client an address/port so that the
client connects to the server for data transfers.

It seems timely, to also consider displaying the instructions,
disclaimers, diagnostics, etc, that servers send when you first
connect to them. We should also drop the assumption that the
"home" directory is '/' and ensure that we can access non-Unix
systems like VMS or Windows NT(*) in a more robust fashion than now.

I would be happy to patch HTFTP.c but am very pressed for time
right now. Has anyone the time to help us all out?

Dave Raggett

(*) e.g. ftp://rhino.microsoft.com/ which is Windows NT based



From guenther.fischer@hrz.tu-chemnitz.de  Mon Nov 29 16:45:57 1993 +0100 (MET)
Message-Id: <9311291545.AA17661@flash1.hrz.tu-chemnitz.de>
Date: Mon, 29 Nov 1993 16:45:57 +0100 (MET)
From: guenther.fischer@hrz.tu-chemnitz.de (Guenther Fischer)
Subject: HTML Standard

To the www gurus:

I see some nive icons in Mosaic (inlined icons), but have no way to refer
to them from my documents. I mean such as for ftp or gopher URLs.

It would save much traffic over the lines if we could have a
standard set of icons on the client site I could refer from the server site
(I will say from the documents on a server).

My vote:

<IMG SRC=/INLINE/icon01.gif>

The path component INLINE is reserved to be interpreted by the clients.
If client found INLINE the next component is interpreted as one of
a welldefined set of icons - nothing to transfer.

If the client hasn't this feature he could transfer as till now. 
Because of that the server should have these "Standard-Icons" in the
INLINE directory too.

Could this be a area of standardization? - It would be so nice.

It could also help to get a "real" WWW look and feel ...

	~Guenther
-- 
Name:      Guenther Fischer
Institute: TU Chemnitz, Universitaetsrechenzentrum
Phone:     0371 668 361
mail:      fischer@hrz.tu-chemnitz.de



From henrich@crh.cl.msu.edu  Mon Nov 29 14:21:00 1993 -0500 (EST)
Message-Id: <9311291921.AA01539@crh.cl.msu.edu>
Date: Mon, 29 Nov 1993 14:21:00 -0500 (EST)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: Mpeg with sound?

Has anyone written a mpeg player with sound for unix boxes yet?  Anyone
thinking of doing it?

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                      http://rs560.msu.edu/~henrich



From joe@mit.edu  Mon Nov 29 14:47:54 1993 -0500
Message-Id: <9311291947.AA02982@theodore-sturgeon.MIT.EDU>
Date: Mon, 29 Nov 93 14:47:54 -0500
From: joe@mit.edu (joe@mit.edu)
Subject: tkWWW 0.10 Prerelease 2 is out


I've uploaded a prerelease for tkWWW 0.10 into info.cern.ch.  In a
short time, it should migrate to /pub/www/dev.

The main new thing about tkWWW 0.10 is that the configuration is now
done via a configure script, which makes installation much easier.

I'd like for some brave and hardy souls to test out the prerelease and
send back bug reports, to reduce the problems with the actual release
of 0.10 in one or two weeks.





From kevinh@pulua.hcc.hawaii.edu  Mon Nov 29 10:41:10 1993 HST
Message-Id: <9311292041.AA25385@pulua.hcc.Hawaii.Edu>
Date: Mon, 29 Nov 93 10:41:10 HST
From: kevinh@pulua.hcc.hawaii.edu (Kevin 'Kev' Hughes)
Subject: Hypertext '93 WWW Report


        A report on Web-related activities at the Hypertext '93
conference in Seattle is online in HTML format. Those with Web browsers
can point to:
 
        http://www.hcc.hawaii.edu/hypertext/ht93.report.html
 
        Notes on the Web birds-of-a-feather meeting are there, as well as
general comments on Web-related demos, etc. Enjoy!
 
        -- Kevin



From Nathan.Torkington@vuw.ac.nz  Tue Nov 30 12:28:43 1993 +1300
Message-Id: <199311292328.AA11043@kauri.vuw.ac.nz>
Date: Tue, 30 Nov 1993 12:28:43 +1300
From: Nathan.Torkington@vuw.ac.nz (Nathan Torkington)
Subject: tn3270 gopher types

It appears that Mosaic 2.0 doesn't handle these
(gopher://chico.rice.edu/11/Subject/Economics has one that it barfs
on) and from that I guess that libwww don't grok it either.

Any chance of a fix? :)

Nat



From mcarthur@fit.qut.edu.au  Tue Nov 30 10:20:36 1993 EST
Message-Id: <199311300020.KAA28442@fitmail.fit.qut.edu.au>
Date: Tue, 30 Nov 93 10:20:36 EST
From: mcarthur@fit.qut.edu.au (Mr Robert McArthur)
Subject: Re: Mosaic USENET client?

> It occurs to me that, now we have forms and mechanisms for posting
> things, it should be entirely possible to write an HTTP server that
> posts USENET news articles, and behaves like a full function USENET
> news client, while the donkey work of actually browsing articles is
> still done directly using NNTP.

I am currently writing a module that will provide automatic
links for quotes in mail, digests and news articles.  I found
it annoying in the extreme when I know the thread and what people
have written, to have it quoted back and one or two lines added.
It is even more important when reading digests et al that are older -
ie. the whole thread is available to you and you are just wandering
around it.  Hopefully available sometime soon as I am slowly getting
some more time to devote to it...

Robert



From robm@ncsa.uiuc.edu  Mon Nov 29 19:57:34 1993 -0600
Message-Id: <9311300157.AA07983@void.ncsa.uiuc.edu>
Date: Mon, 29 Nov 1993 19:57:34 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: proposal for new HTTP/1.0 directive

/*
 * proposal for new HTTP/1.0 directive  by Marc Andreessen (marca@ncsa.uiuc.edu)
 *    written on Nov 27,  2:28pm.
 *
 * It occasionally is useful to have the results of a HTTP/1.0
 * transaction return *nothing* (no significant response data) -- the
 * client should not display a new document or do anything else other
 * than stay on exactly the same document it's already on.
 * 
 * An example of where this would be useful: tape-deck-style
 * fast-forward/stop/reverse/play/pause/etc. controls implemented with
 * forms or hyperlinks as part of a multicasting transmission
 * application.  You want to be able to trigger as many actions as you
 * want (play, pause, play, fast-forward, play, etc.) without moving to a
 * different document each time.
 * 
 * How about "204 NoResponse"?
 */

I second the motion. I've gotten several people asking for a way to do that
exact thing from scripts.

--Rob



From robm@ncsa.uiuc.edu  Mon Nov 29 20:30:02 1993 -0600
Message-Id: <9311300230.AA08562@void.ncsa.uiuc.edu>
Date: Mon, 29 Nov 1993 20:30:02 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: cc:Mail SMTPLINK 2.0 Undeliverable Message

/*
 * cc:Mail SMTPLINK 2.0 Undeliverable Message  by "Andre Doles" (dolesa@smtp-gw.spawar.navy.mil)
 *    written on Nov 29,  6:55am.
 *
 * 
 *      
 * I'm looking for anyone that has experience comiling http server 
 * software running under A/UX (Apple's Unix.)  I'm probably the only sole 
 * in the universe "trying" to use A/UX, but just thought I'd check.  I'm 
 * kinda new to alot of this, so a knowledgable A/UX person who is doing 
 * this kinda thing would be helpful.  Volunteers?
 */

You don't mention what http server you're trying to compile.

For NCSA httpd, I've had inquiries in the past about A/UX support, but no
one ever sent me any changes. I can offer you some advice and help you with
problems you encounter.

If you're trying to compile the CERN httpd, you should probably ask
luotonen@ptsun00.cern.ch.

--Rob



From joe@peacock.tnjc.edu.tw  Tue Nov 30 11:05:10 1993 CST
Message-Id: <9311300305.AA00513@peacock.tnjc.edu.tw>
Date: Tue, 30 Nov 93 11:05:10 CST
From: joe@peacock.tnjc.edu.tw (joe@peacock.tnjc.edu.tw)
Subject: ADD

SUBSCRIBE joe@peacock.tnjc.edu.tw
.\



From E65247@vm.cc.metu.edu.tr  Tue Nov 30 09:19:12 1993 TUR
Message-Id: <9311300727.AA08110@dxmint.cern.ch>
Date: Tue, 30 Nov 93 09:19:12 TUR
From: E65247@vm.cc.metu.edu.tr (Murat Balci)
Subject: help

hello,
I want to install WWW to our sytem ( IBM-3090 , VM ), bun unforyunately
when trnsfer it from anonymous ftpsite info.cern.ch  it did not work here.
As its said, I trnasfer it in binary mod ( WWW MODULE ). but as far as I know
the module files must be trnasfered in TYPE E and MODE B . but since your
system is a UNIX machine , it does not support this types.!
 if possible, can you help me ?. for examaple, is there any VM site there
it works ?, can i take it ?, or can you send me this file by SENDFILE via
BITNET ?
        thanx for everything.
                            murat.



From F.Zwarts@kvi.nl  Tue Nov 30 09:15:17 1993 +0000 (WET)
Message-Id: <01H5X61BGIMA95NPMZ@KVI.nl>
Date: Tue, 30 Nov 1993 09:15:17 +0000 (WET)
From: F.Zwarts@kvi.nl (Fred Zwarts, KVI, Groningen, NL.)
Subject: Mosaic 2.0 in CPU loop.

I have a problem with Mosaic 2.0 under VMS. It enters a CPU loop when I access
a Gopher HTML document which has an inline image for which the URL is specified
as "./Logo.gif". The CPU loop is probably caused by an improper Gopher type for
a gif file. I am not sure whether this is general Mosaic problem or a problem
specific for the VMS version.

I would like to know the best way to fix it. I made the following change:

************
File KVI$ROOT:[KVIMAIN.WWW.MOSAIC2-0.SRC]GIFREAD.C;2
  363   /*	while (GetDataBlock(fd, (unsigned char*) buf) != 0) F.Z. */
  364   	while (GetDataBlock(fd, (unsigned char*) buf) > 0)
  365   		;
******
File KVI$ROOT:[KVIMAIN.WWW.MOSAIC2-0.SRC]GIFREAD.C_ORIGINAL;1
  363   	while (GetDataBlock(fd, (unsigned char*) buf) != 0)
  364   		;
************

because it turned out that GetDataBlock kept returning a value of -1. This now
prevents the CPU loop, but the inline images are not displayed correctly. Is
there a better way to fix it? Or is the only hope that that the owner of the
document fixes the URL for the image?

Fred Zwarts	KVI, Groningen, Netherlands	Internet:	F.Zwarts@KVI.nl
Phone:		(+31)50-633619			Telefax:	(+31)50-634003
X400:		C=nl;ADMD=400net;PRMD=surf;O=KVI;S=Zwarts;G=Fred



From dsr@hplb.hpl.hp.com  Tue Nov 30 11:43:02 1993 GMT
Message-Id: <9311301143.AA09392@manuel.hpl.hp.com>
Date: Tue, 30 Nov 93 11:43:02 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: X Mosaic 2.0 and Closed to Open subnet gateway

The opensubnet relay patch for X Mosaic 2.0 and source code for the
gateway itself can be found at:

        ftp://15.254.100.100/pub/subnet.tar.Z

with contents:

-rw-r--r--   1 dsr      rubicon    18653 Nov 29 12:29 HTTCP.c
-rw-r--r--   1 dsr      rubicon     2662 Nov 29 14:25 README
-rw-r--r--   1 dsr      rubicon    16430 Nov 30 11:04 relay.c

The relay program is designed to be invoked by inetd on a trusted host
with direct access to systems outside the firewall. We use inetd.sec
to act as a first line of defence, prohibiting outsiders from accessing
the relay. The program itself provides a second line of defence with
a match on the client's IP address via a simple mask. It also supports
a user name/password check which is useful when traveling else where
in the company. This feature is not supported by the patch to Mosaica and
*must* be omitted at compile time if your site doesn't support inetd.sec

The relay was designed for minimal maintenance in conjunction with our
admin folks. You will need to edit a few equates at the start of the file
before compiling relay.c. Its simplicity and operation under inetd were
requirements for audit purposes.

Note that I haven't yet provided a patch to HTFTP.c to use PASV. This is
needed to allow Mosaic to access external FTP servers as currently servers
try (and fail) to connect to the client to transfer data. The PASV command
(see RFC 859 - October 1985) allows the client to connect to the server
for data transfers, which will then work with the relay as provided.

The tcp/ip relay is simpler than the socks package and avoids the need
for a separate configuration file. The time out interval is the same
for both programs - 5 minutes of inactivity will cause the connection with
client and remote host to be closed and the process terminated. No logging
is performed since the pattern of useage for WWW would quickly swamp the
syslog files. The relay program goes beyond socks in supporting user name
+ password access for users with accounts on the trusted system. I hope
to persuade NCSA (with your help) to support this feature in due course.

Regards,

Dave Raggett



From Axel.Belinfante@cs.utwente.nl  Tue Nov 30 16:08:27 1993 +0100
Message-Id: <9311301508.AA06408@utis179.cs.utwente.nl>
Date: Tue, 30 Nov 93 16:08:27 +0100
From: Axel.Belinfante@cs.utwente.nl (Axel Belinfante)
Subject: Re: Forms suggestion 

It looks like no NAME=VALUE pairs are returned for 'submit' entries
in forms, so it seems to be impossible to do something like:

<FORM>
<INPUT NAME="entry">
<INPUT TYPE="submit" NAME="action" VALUE="Ok">
<INPUT TYPE="submit" NAME="action" VALUE="Cancel">
</FORM>

For some applications it would be interesting to be able to see if
such a form was submitted 
 - via a return in the text field (ie. no action= binding or no value)
 - via the Ok button (action=Ok)
 - via the Cancel button (action=Cancel)

Is it possible to do something like that?
I remember I have seen a form with just one submit button, and
select-options to define the action..

On a somewhat related note: how do i submit a form in lynx?
I can edit the fields, but how can i submit??

Regards,
Axel.

PS: passing 'state information' from one form to another via the URL,
    as suggested earlier in this thread, works fine.

<Axel.Belinfante@cs.utwente.nl>   tel. +31 53 893774   fax. +31 53 333815
     University of Twente, Tele-Informatics & Open Systems Group
       P.O. Box 217    NL-7500 AE Enschede      The Netherlands
     "ili ne sciis ke estas neebla do ili simple faris" -- Loesje




From guenther.fischer@hrz.tu-chemnitz.de  Tue Nov 30 18:47:02 1993 +0100 (MET)
Message-Id: <9311301747.AA22842@flash1.hrz.tu-chemnitz.de>
Date: Tue, 30 Nov 1993 18:47:02 +0100 (MET)
From: guenther.fischer@hrz.tu-chemnitz.de (Guenther Fischer)
Subject: Have a look at this, if you want ...

I've done some hacks on looking from www to my ftp-archiv. For well
defined archives as  simtel one can do very nice things. Have a look
at this:

http://www.tu-chemnitz.de/ftp/ftp.html

From the to the simtel - sorry the page above is in german, but most
of my users are German :-)

	~Guenther


-- 
Name:      Guenther Fischer
Institute: TU Chemnitz, Universitaetsrechenzentrum
Phone:     0371 668 361
mail:      fischer@hrz.tu-chemnitz.de



From guenther.fischer@hrz.tu-chemnitz.de  Tue Nov 30 19:39:01 1993 +0100 (MET)
Message-Id: <9311301839.AA23060@flash1.hrz.tu-chemnitz.de>
Date: Tue, 30 Nov 1993 19:39:01 +0100 (MET)
From: guenther.fischer@hrz.tu-chemnitz.de (Guenther Fischer)
Subject: the 2. - sorry for mail traffic

Much of you are looking only at the first link:
honk.cs.utk.edu [Tue Nov 30 18:07:30 GMT 1993] GET /ftp/ftp.html
honk.cs.utk.edu [Tue Nov 30 18:07:54 GMT 1993] GET /info/rfc
hpfrs8.physik.uni-freiburg.de [Tue Nov 30 18:08:14 GMT 1993] GET /ftp/ftp.html HTTP/1.0
hpfrs8.physik.uni-freiburg.de [Tue Nov 30 18:08:48 GMT 1993] GET /info/rfc HTTP/1.0
oakmont.cc.gatech.edu [Tue Nov 30 18:09:02 GMT 1993] GET /ftp/ftp/ HTTP/1.0
hpzenger4.informatik.tu-muenchen.de [Tue Nov 30 18:09:19 GMT 1993] GET /ftp/ftp.html HTTP/1.0
hpzenger4.informatik.tu-muenchen.de [Tue Nov 30 18:09:39 GMT 1993] GET /info/rfc HTTP/1.0
oakmont.cc.gatech.edu [Tue Nov 30 18:10:13 GMT 1993] GET /ftp/ftp.html HTTP/1.0
hpzenger4.informatik.tu-muenchen.de [Tue Nov 30 18:10:15 GMT 1993] GET /info/rfc?WWW HTTP/1.0
honk.cs.utk.edu [Tue Nov 30 18:10:34 GMT 1993] GET /info/rfc?snmp
utis179.cs.utwente.nl [Tue Nov 30 18:13:28 GMT 1993] GET /ftp/ftp.html HTTP/1.0
atotic1.ncsa.uiuc.edu [Tue Nov 30 18:15:30 GMT 1993] GET /ftp/ftp.html HTTP/1.0
hpopf1.cern.ch  [Tue Nov 30 18:18:23 GMT 1993] GET /ftp/ftp.html HTTP/1.0
volterra.ai.mit.edu [Tue Nov 30 18:20:09 GMT 1993] GET /ftp/ftp.html HTTP/1.0
spartacus.gdb.org [Tue Nov 30 18:21:48 GMT 1993] GET /ftp/ftp.html HTTP/1.0
kern.biochem.duke.edu [Tue Nov 30 18:25:39 GMT 1993] GET /ftp/ftp.html HTTP/1.0
hpzenger4.informatik.tu-muenchen.de [Tue Nov 30 18:33:11 GMT 1993] GET /info/rfc/rfc1543.txt HTTP/1.0

I would like it tyou would see in simtel/msdos and try the dir walk
and search ....
-- 
Name:      Guenther Fischer
Institute: TU Chemnitz, Universitaetsrechenzentrum
Phone:     0371 668 361
mail:      fischer@hrz.tu-chemnitz.de



From joe@mit.edu  Tue Nov 30 15:15:11 1993 EST
Message-Id: <9311302015.AA09109@theodore-sturgeon.MIT.EDU>
Date: Tue, 30 Nov 93 15:15:11 EST
From: joe@mit.edu (Joseph Wang)
Subject: tkWWW 0.10 prerelease is CORRUPT on info.cern.ch 


The version of tkWWW 0.10 prerelease 2 originally at info.cern.ch was
corrupt due to me forgetting to do the upload in binary mode.  I've
uploaded a new version in /pub/incoming/joe which should shortly
migrate to /pub/www/dev.

Note that this version is a prerelease and you will likely have to
pull some hairs out to get it to work.






From cheung@eplrx7.es.dupont.com  Tue Nov 30 16:41:04 1993 EST
Message-Id: <9311302141.AA02406@eplrx7.es.duPont.com>
Date: Tue, 30 Nov 93 16:41:04 EST
From: cheung@eplrx7.es.dupont.com (Bryan Cheung)
Subject: Submit/Reset Button names on Forms

Is there any way to change the names of the Submit and Reset buttons
displayed on an HTML form?? I have read throught the forms section of the
HTML+ draft and there is apparently no way to specify ANY name. If the text
label on these buttons is left up to the client, then we will have to
maintain language-specific clients rather than creating HTML forms in other
languages. Have I missed something?? 

-- Bryan 
   cheung@eplrx7.es.dupont.com

P.S. I am currently running NCSA httpd 1.0a5. Is there an NCSA feature
     which handles this issue?





From montulli@stat1.cc.ukans.edu  Tue Nov 30 20:30:10 1993 CST
Message-Id: <9312010230.AA29287@stat1.cc.ukans.edu>
Date: Tue, 30 Nov 93 20:30:10 CST
From: montulli@stat1.cc.ukans.edu (Lou Montulli)
Subject: Re: Forms suggestion

> 
> It looks like no NAME=VALUE pairs are returned for 'submit' entries
> in forms, so it seems to be impossible to do something like:
> 
> <FORM>
> <INPUT NAME="entry">
> <INPUT TYPE="submit" NAME="action" VALUE="Ok">
> <INPUT TYPE="submit" NAME="action" VALUE="Cancel">
> </FORM>
> 
> For some applications it would be interesting to be able to see if
> such a form was submitted 
>  - via a return in the text field (ie. no action= binding or no value)
>  - via the Ok button (action=Ok)
>  - via the Cancel button (action=Cancel)
> 
> Is it possible to do something like that?
> I remember I have seen a form with just one submit button, and
> select-options to define the action..

This is not currently possible but I would like to see it become
possible and I suspect that it will be possible sometime in
the future. (is that confusing enough?)

> 
> On a somewhat related note: how do i submit a form in lynx?
> I can edit the fields, but how can i submit??

Sorry, can't do it yet.  Ver 2.0.12 had just the beginnings of
forms-mode in it.  version 2.1 will contain FULL FORMS SUPPORT.
(all accept image/ismap support that is :)

:lou
-- 
  **************************************************************************
  *           T H E   U N I V E R S I T Y   O F   K A N S A S              *
  *         Lou  MONTULLI @ Ukanaix.cc.ukans.edu                           *
  *                         Kuhub.cc.ukans.edu      ACS Computing Services *
  *     913/864-0436        Ukanvax.bitnet             Lawrence, KS 66044  *
  *             UNIX! Cool! I know that!  Jurassic Park - The Movie        *
  **************************************************************************



From dsr@hplb.hpl.hp.com  Wed Dec  1 10:25:28 1993 GMT
Message-Id: <9312011025.AA13193@manuel.hpl.hp.com>
Date: Wed, 1 Dec 93 10:25:28 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: Submit/Reset Button names on Forms

Bryan Cheung writes:

> Is there any way to change the names of the Submit and Reset buttons
> displayed on an HTML form?? I have read throught the forms section of the
> HTML+ draft and there is apparently no way to specify ANY name. If the text
> label on these buttons is left up to the client, then we will have to
> maintain language-specific clients rather than creating HTML forms in other
> languages. Have I missed something?? 

This fits nicely with Axel.Belinfante's suggestion:

> It looks like no NAME=VALUE pairs are returned for 'submit' entries
> in forms, so it seems to be impossible to do something like:

> <FORM>
>  <INPUT NAME="entry">
>  <INPUT TYPE="submit" NAME="action" VALUE="Ok">
>  <INPUT TYPE="submit" NAME="action" VALUE="Cancel">
> </FORM>

In this case the VALUE attribute can be used as the button label.
I am currently revising the HTML+ draft spec and will include this.

Note that using an SGML attribute for the label text prevents us
from using character entities such as &Eacute; - we are therefore
restricted to Latin-1 characters for labels and initial values for
text input fields (this doesn't apply to TEXTAREA). I hope this isn't
a problem.

Dave Raggett



From bert@let.rug.nl  Wed Dec  1 11:12:37 1993 +0100 (MET)
Message-Id: <9312011012.AA02532@freya.let.rug.nl>
Date: Wed, 1 Dec 1993 11:12:37 +0100 (MET)
From: bert@let.rug.nl (Bert Bos)
Subject: HTML+ has no <!-- comments? -->

Another note on the HTML+ draft:

The old HTML specification allows comments in documents, bracketed by
<!-- and -->, but I couldn't find it in the HTML+ draft. Since HTML+
is an SGML application, one would assume that comments are supported,
but I think it should be mentioned explicitly.

-- 
                     _________________________________
                    / _   Bert Bos <bert@let.rug.nl>  |
           ()       |/ \  Alfa-informatica,           |
            \       |\_/  Rijksuniversiteit Groningen |
             \_____/|     Postbus 716                 |
                    |     9700 AS GRONINGEN           |
                    |     Nederland                   |
                    \_________________________________|



From m.koster@nexor.co.uk  Wed Dec  1 11:12:34 1993 +0000
Message-Id: <9312011114.AA24676@dxmint.cern.ch>
Date: Wed, 01 Dec 1993 11:12:34 +0000
From: m.koster@nexor.co.uk (Martijn Koster)
Subject: Re: HTML+ has no <!-- comments? -->

> <!-- and -->, but I couldn't find it in the HTML+ draft.

I was wondering about comments too. Does/could HTML+ provide
comments around other tags? 


-- Martijn
__________
Internet: m.koster@nexor.co.uk
X-400: C=GB; A= ; P=Nexor; O=Nexor; S=koster; I=M
X-500: c=GB@o=NEXOR Ltd@cn=Martijn Koster
WWW: http://web.nexor.co.uk/mak/mak.html



From zgee9119@qmw.ac.uk  Wed Dec  1 14:09:33 1993 +0000 (GMT)
Message-Id: <Pine.3.03.9312011433.E15755-c100000@shark>
Date: Wed, 1 Dec 1993 14:09:33 +0000 (GMT)
From: zgee9119@qmw.ac.uk (Johnson M J)
Subject: new ? resource discovery idea

I am working on a Resource Discovery tool for the internet as
the final year project of my degree.  The aim of my work is to
develop a system that unites browsing and searching, and
integrates human and automatic indexing/organising effort. 
 
The basic approach is to organsise URL's (Universal Resource
Locator) into sets by subject.  A particular ULR may be in many
subjects.  Searches can be performed using the usual set
operations, and the selected resources are then browsed - ie the
same strategy as WAIS.  Subjects that have common URL's are
considered to be related, hence the subject space can be viewed
as a graph.  The nodes are the subjects, and the links are
common resources.  This gives possibilities of browsing, users
can just browse from general entry points, ala WWW and gopher. 
Browsing techniques can be used to widen search results if the
required resource is not found.  The dual view should allow
existing systems: WAIS; WWW; gopher; (hopefully) TopNode; to map
easily to the subject space. 
 
 
Human resource organisation efforts are by individuals
organising the resources and resource sources that they find
usefull.  Users of NCSA mosaic use a simple list (the Hotlist)
to remember usefull resources.  I intend to build a simple
extension to xmosaic to replace the hotlist, based on the
set/graph subject space.  Users can consider the tool as set or
graph based as they wish, and create their own subjects.  By
joining individual subject spaces to a global subject space, the
resources are discovered and organised by the users, without any
extra effort.  Once a global subject space is populated with
resources, it can be used by individuals to discover resources
by searching and browsing it.  Information about how a global
subject space is used, eg how often a user follows a particular
link, the most/least common paths across the graph to find a
particular resource, may be used for automatic reorganisation of
the subject space.  Automatic indexing can be performed by using
a tool such as Essence (Resource Discovery at the University of
Colorado, Schwartz), which uses file semantics to generate
compact keyword lists. 
 
Currently I am building a subject space tool.  Next I will
investigate the properties of the subject space :- various ways
to weight the links, how several boolean subject spaces (the
individual users) can be merged into fuzzy subject spaces (the
global), searching using fuzzy information retrieval techniques,
GUI's to the subject space.  I aim to build the extension to
XMosaic and a subject space server (probably speaking HTTP). 
 
Do you have any comments?  Do you think my ideas are sensible? 
Do you know of anything that could help me?  Any and all
corrispondance will be greatfully recieved.
 
 
Thankyou
 
Mark Johnson
Queen Mary and Westfield College
University of London
UK
 






From M.T.Hamilton@lut.ac.uk  Wed Dec  1 15:25:33 1993 +0000 (GMT)
Message-Id: <199312011525.PAA11301@lust.mrrl.lut.ac.uk>
Date: Wed, 1 Dec 1993 15:25:33 +0000 (GMT)
From: M.T.Hamilton@lut.ac.uk (Martin Hamilton)
Subject: Re: new ? resource discovery idea

[ Mark said: ]

/                                                           By
/ joining individual subject spaces to a global subject space, the
/ resources are discovered and organised by the users, without any
/ extra effort.  Once a global subject space is populated with
/ resources, it can be used by individuals to discover resources
/ by searching and browsing it.

Just me being curious really, but what is this global subject space,
and how are you going to populate it?  If we're just talking about
putting things onto a single server (remember the NCSA annotation
server :-) then fair enough - I was wondering if there might be
anything more to it!

Martin




From dsr@hplb.hpl.hp.com  Wed Dec  1 15:47:51 1993 GMT
Message-Id: <9312011547.AA15374@manuel.hpl.hp.com>
Date: Wed, 1 Dec 93 15:47:51 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: HTML+ has no <!-- comments? -->

Bert Bos writes:

> The old HTML specification allows comments in documents, bracketed by
> <!-- and -->, but I couldn't find it in the HTML+ draft. Since HTML+
> is an SGML application, one would assume that comments are supported,
> but I think it should be mentioned explicitly.

Thanks for the tip!

You can use "<!--" around other tags and the first "-->" sequence will
terminate the comment, i.e. you can't nest comments, just like c :-)

Dave



From zgee9119@qmw.ac.uk  Wed Dec  1 16:30:41 1993 +0000 (GMT)
Message-Id: <Pine.3.03.9312011639.G15833-b100000@shark>
Date: Wed, 1 Dec 1993 16:30:41 +0000 (GMT)
From: zgee9119@qmw.ac.uk (Johnson M J)
Subject: Re: new ? resource discovery idea


> [ Mark said: ]
> 
> /                                                           By
> / joining individual subject spaces to a global subject space, the
> / resources are discovered and organised by the users, without any
> / extra effort.  Once a global subject space is populated with
> / resources, it can be used by individuals to discover resources
> / by searching and browsing it.
> 
> Just me being curious really, but what is this global subject space,
> and how are you going to populate it?  If we're just talking about
> putting things onto a single server (remember the NCSA annotation
> server :-) then fair enough - I was wondering if there might be
> anything more to it!
> 

I use _global_ to mean a service used by several people, be it everyone 
at a department, or all internet users.  So yes - just a server.
The annotation server is new to me, so thanks for putting me onto it!
The original idea is that a global subject space grows as it is used,
users _pay_ for its help by sending their own subject spaces.  Of course,
no one will use it if it's empty!  Two ideas are to manually build an
internet begginers guide, and to use WAIS indexes, to start it off. 


Mark






From rivero@sol.unizar.es  Wed Dec  1 19:04:16 1993 +0000 (GMT)
Message-Id: <9312011904.AA11611@sol.cie.unizar.es>
Date: Wed, 01 Dec 1993 19:04:16 +0000 (GMT)
From: rivero@sol.unizar.es (Alejandro Rivero)
Subject: Re: new ? resource discovery idea

> From www-talk-request@dxcern.cern.ch Wed Dec  1 17:33:49 1993
> Received: from dxmint.cern.ch by sol.unizar.es with SMTP id AA11172
>   (5.67a8/IDA-1.5 for rivero); Wed, 1 Dec 1993 17:33:42 GMT
> Received: from dxcern.cern.ch by dxmint.cern.ch (5.65/DEC-Ultrix/4.3)
> 	id AA07357; Wed, 1 Dec 1993 17:20:54 +0100
> Received: by dxcern.cern.ch (5.65/DEC-Ultrix/4.3)
> 	id AA03885; Wed, 1 Dec 1993 16:26:10 +0100
> Received: from dxmint.cern.ch by dxcern.cern.ch (5.65/DEC-Ultrix/4.3)
> 	id AA03661; Wed, 1 Dec 1993 16:26:02 +0100
> Received: from nxoc01.cern.ch by dxmint.cern.ch (5.65/DEC-Ultrix/4.3)
> 	id AA22457; Wed, 1 Dec 1993 16:26:01 +0100
> Received: from dxmint.cern.ch by  nxoc01.cern.ch  (NeXT-1.0 (From Sendmail 5.52)/NeXT-2.0)
 
> X-Lines: 17
> Status: RO
> 
> [ Mark said: ]
> 
> /                                                           By
> / joining individual subject spaces to a global subject space, the
> / resources are discovered and organised by the users, without any
> / extra effort.  Once a global subject space is populated with
> / resources, it can be used by individuals to discover resources
> / by searching and browsing it.
> 
> Just me being curious really, but what is this global subject space,
> and how are you going to populate it?  If we're just talking about
> putting things onto a single server (remember the NCSA annotation
> server :-) then fair enough - I was wondering if there might be
> anything more to it!
> 
> Martin
> 
> 
One sugesstion to populate a graphical browser is to use ISI approach
to Science classification. They draw the graph of references between
papers, so by example the distance between two publications is the 
number or common (or even mutual) references. 

This approach translates easily to gopherspace or to the Web, as it is
possible to use the hyperlinks to draw the graph and calculate the
"subject" distance between servers. We sopke about this in the gopher 
list time ago, but I dont know if someone is working on. Obviusly,
a www browser with graphical add-ons, such as xmosaic, would be more
appropiate (even thought that the actual bitmapped maps are not very
efficient to store lattices and nets)

					Alejandro Rivero
					Zaragoza Univ, Spain



From phillips@cs.ubc.ca  Mon Dec  1 13:07:00 1993 -0800
Message-Id: <6969*phillips@cs.ubc.ca>
Date: 1 Dec 93 13:07 -0800
From: phillips@cs.ubc.ca (George Phillips)
Subject: Re: CGI/1.0 status

Rob says:
>I haven't recieved anything that I haven't addressed (to my knowledge, if
>something slipped by someone please say so). The doc at
>http://hoohoo.ncsa.uiuc.edu/beta-docs/external-protocol.txt is the latest.
>Note the addition of the naming convention "nph:scriptname" for scripts
>which require direct output to the client.

I'd wager that the spec is pretty stable.  If "nph:scriptname" is the
expected name of the script, then the ":" should be changed to
something else as it's problematic for DOS, OS/2, NT and possibly
Mac systems.  If, however, the "nph:" is stripped by server and
it execs "scriptname", all is fine.

>There's only one more touchy subject I want to discuss before we finalize,
>and that's the who-decodes-the-arguments issue.

I'm not sure what you mean by "decoding" in this context, but I assume
you're talking about parsing off the search string for an ISINDEX
or FORM request.  I also assume that you still want the server
parsing the headers like "Accept:".  If these assumptions are
correct and you promise to give me SCRIPT_NAME, SERVER_PORT and
SERVER_NAME, then it doesn't matter much to me, but let me
play devil's advocate.

>Here are the pro-arguments as I remember them, and my reasons for
>disagreeing:
>
>Argument: If the server does it, scripts don't have to do it, so there are
>          simpler scripts.
>
>Counter: However, a prudent script must have code to decode long arguments
>         anyway. Therefore, if the scripts may have to do it themselves
>         anyway, why bother decoding it in the first place, if the scripts 
>         need the code anyway?

Rebuttal: Simple scripts don't care if they break on long arguments.  They
	  just want to be quick hacks.  If someone tries to use a finger
	  gateway with too big an argument, they lose and that's OK.

>Argument: We already know how to decode the URL, there is ISINDEX and FORMs,
>          and we know how to decode both.
>
>Counter: FORMS are part of HTML+. What if there are other aspects of HTML+,
>         or HTML++ which are not compatible with these two methods? I don't
>         want to have people upgrading their server every time a new
>         convention is invented.

Rebuttal: New conventions will require a change somewhere.  Better it be
	  in the server rather than every script which wishes to stay
	  current.  What if HTML+++ provides a new way to give a search
	  string?  If the server understands that, the scripts will be
	  magically upgraded.  Also, partial decoding leaves some hope
	  of writing gateway scripts which can respond to entirely
	  different protocols like gopher or gopher+.  What with gopher
	  letting you spit back HTML, the gn server, and ASK blocks
	  being so similar to forms, the protocols could converge
	  at this CGI.

>My arguments for having the scripts do the decoding:
>
>1. It's painfully simple to do it even from a shell script, one line with a
>   C support program. PERL and C code is available to do so. What's the
>   advantage of having the server do it, besides avoiding a little confusion
>   for novice script writers?

Why have the scripts repeat common boilerplate?  The server's already
decoding lots of other stuff so why not throw in a little extra.

>2. Any script which needs to decode its own URL still has the server decode
>   it, possibly in a way the script doesn't want it to.  Wasted effort for
>   the server, CPU time which could be better spent servicing the ~130 other
>   waiting users (at least, if you're www.ncsa).

Well, if you're crying for CPU, better integrate those scripts into your
server since the exec + sh/perl parsing overhead is much greater.  The
small amount of CPU time in an extra decode is neglible.  If you're really
concerned, add a configuration option to the server that tells it
about any scripts which don't want stuff decoded.

>3. POST scripts which handle forms need the unescaping code regardless.
>   Again, duplication of effort.

Lots of scripts won't handle POST; they just want GET + HEAD.  Why
make every script work harder for just a few exceptions?

Anyhow, I think this is pretty much a tempest in a teapot.  Based on
my experience in writing gateway scripts, I like the extra bit of
decoding -- just seemed more convenient and never got in the way.
Mind you, that was only for <ISINDEX> decoding.  Maybe FORMs decoding
is less useful.  Maybe a split is in order:  decode ISINDEX stuff
'cause it won't overflow and is semantically simply, don't decode
FORMs stuff cause there's a good chance it'll be too big anyway
and it's hard to decode the information into a usable form.



From joe@peacock.tnjc.edu.tw  Thu Dec  2 14:46:24 1993 CST
Message-Id: <9312020646.AA00754@peacock.tnjc.edu.tw>
Date: Thu, 2 Dec 93 14:46:24 CST
From: joe@peacock.tnjc.edu.tw (joe@peacock.tnjc.edu.tw)
Subject: .flc on Mosaic

	I have lots of .flc files that i would like to put on my Mosaic http
server. But, when i retrieved the .flc using my Mosaic PC browser, Messy codes
appeared instead of the expected pop up window of the AUTODESK ANIMATION PLAY
---.flc player. I have tried to retrieve the .flc from my hard disk instead,
i.e. href="file:///c|/test.flc" , and it works OK!
        I AM PUZZLE!

        *** Point of no return... HELP!!!

						JOE HSU, TNJC



From robm@ncsa.uiuc.edu  Thu Dec  2 01:31:25 1993 -0600
Message-Id: <9312020731.AA22706@void.ncsa.uiuc.edu>
Date: Thu, 2 Dec 1993 01:31:25 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI/1.0 status

/*
 * Re: CGI/1.0 status  by George Phillips (phillips@cs.ubc.ca)
 *    written on Dec  1,  1:07pm.
 *
 * I'd wager that the spec is pretty stable.  If "nph:scriptname" is the
 * expected name of the script, then the ":" should be changed to
 * something else as it's problematic for DOS, OS/2, NT and possibly
 * Mac systems.  If, however, the "nph:" is stripped by server and
 * it execs "scriptname", all is fine.

Good point. Mac systems will not like the : one bit. I'll change it to
"nph-", are there any objections to that? VMS? I think DOS, OS/2, NT,
and System 7 don't have any problem with it. I'm not sure about VMS.

 * I'm not sure what you mean by "decoding" in this context, but I assume
 * you're talking about parsing off the search string for an ISINDEX
 * or FORM request.  I also assume that you still want the server
 * parsing the headers like "Accept:".  If these assumptions are
 * correct and you promise to give me SCRIPT_NAME, SERVER_PORT and
 * SERVER_NAME, then it doesn't matter much to me, but let me
 * play devil's advocate.

Yes, you get those env. vars. The wording is unclear in the section
regarding the script's stdin, so I will change it. I would rather have the
server parsing the headers since sending them all intact would get messy and
complicate scripts.

 * >Here are the pro-arguments as I remember them, and my reasons for
 * >disagreeing:
 * >
 * >Argument: If the server does it, scripts don't have to do it, so there are
 * >          simpler scripts.
 * >
 * >Counter: However, a prudent script must have code to decode long arguments
 * >         anyway. Therefore, if the scripts may have to do it themselves
 * >         anyway, why bother decoding it in the first place, if the scripts 
 * >         need the code anyway?
 * 
 * Rebuttal: Simple scripts don't care if they break on long arguments.  They
 * 	  just want to be quick hacks.  If someone tries to use a finger
 * 	  gateway with too big an argument, they lose and that's OK.

A good point.

 * >Argument: We already know how to decode the URL, there is ISINDEX and 
 * >          FORMs, and we know how to decode both.
 * >
 * >Counter: FORMS are part of HTML+. What if there are other aspects of HTML+,
 * >         or HTML++ which are not compatible with these two methods? I don't
 * >         want to have people upgrading their server every time a new
 * >         convention is invented.
 * 
 * Rebuttal: New conventions will require a change somewhere.  Better it be
 * 	  in the server rather than every script which wishes to stay
 * 	  current.  What if HTML+++ provides a new way to give a search
 * 	  string?  If the server understands that, the scripts will be
 * 	  magically upgraded.  Also, partial decoding leaves some hope
 * 	  of writing gateway scripts which can respond to entirely
 * 	  different protocols like gopher or gopher+.  What with gopher
 * 	  letting you spit back HTML, the gn server, and ASK blocks
 * 	  being so similar to forms, the protocols could converge
 * 	  at this CGI.

I would hope HTML+* will keep the old methods around for backward
compatibility. However, your point regarding gopher is very well taken.
Perhaps I should have John Franks look over the spec and offer his comments.

 * >My arguments for having the scripts do the decoding:
 * >
 * >1. It's painfully simple to do it even from a shell script, one line with a
 * >   C support program. PERL and C code is available to do so. What's the
 * >   advantage of having the server do it, besides avoiding a little confusion
 * >   for novice script writers?
 * 
 * Why have the scripts repeat common boilerplate?  The server's already
 * decoding lots of other stuff so why not throw in a little extra.

For ISINDEX scripts, I would probably have to agree. However, for forms, I
don't know...

 * >2. Any script which needs to decode its own URL still has the server decode
 * >   it, possibly in a way the script doesn't want it to.  Wasted effort for
 * >   the server, CPU time which could be better spent servicing the ~130 other
 * >   waiting users (at least, if you're www.ncsa).
 * 
 * Well, if you're crying for CPU, better integrate those scripts into your
 * server since the exec + sh/perl parsing overhead is much greater.  The
 * small amount of CPU time in an extra decode is neglible.  If you're really
 * concerned, add a configuration option to the server that tells it
 * about any scripts which don't want stuff decoded.

I shy away from adding configuration options since they're server-specific.

While the CPU time is neglible, it is impossible to integrate scripts into
the server unless you're Plexus. Therefore, I'd like to save as much time as
possible, since our server (and probably info.cern.ch) could use all of the
extra CPU time they can get.

 * >3. POST scripts which handle forms need the unescaping code regardless.
 * >   Again, duplication of effort.
 * 
 * Lots of scripts won't handle POST; they just want GET + HEAD.  Why
 * make every script work harder for just a few exceptions?

Most ISINDEX scripts only handle GET and HEAD. Most FORMs scripts will
eventually have to use POST when they grow large enough to cross GET's
boundaries.

 * Anyhow, I think this is pretty much a tempest in a teapot.  Based on
 * my experience in writing gateway scripts, I like the extra bit of
 * decoding -- just seemed more convenient and never got in the way.
 * Mind you, that was only for <ISINDEX> decoding.  Maybe FORMs decoding
 * is less useful.  Maybe a split is in order:  decode ISINDEX stuff
 * 'cause it won't overflow and is semantically simply, don't decode
 * FORMs stuff cause there's a good chance it'll be too big anyway
 * and it's hard to decode the information into a usable form.
 */

This, I think, is a good idea. I would agree to making ISINDEX queries
decoded, but not FORMs queries (at least not with GET).

Ari? Tony? Everyone else?

--Rob




From Axel.Belinfante@cs.utwente.nl  Thu Dec  2 10:42:40 1993 +0100
Message-Id: <9312020942.AA09352@utis179.cs.utwente.nl>
Date: Thu, 02 Dec 93 10:42:40 +0100
From: Axel.Belinfante@cs.utwente.nl (Axel Belinfante)
Subject: Re: Submit/Reset Button names on Forms 

Dave_Raggett <dsr@hplb.hpl.hp.com> writes:
> Note that using an SGML attribute for the label text prevents us
> from using character entities such as &Eacute; - we are therefore
> restricted to Latin-1 characters for labels and initial values for
> text input fields (this doesn't apply to TEXTAREA). I hope this isn't
> a problem.

It is a limitation, it would be nice if it could be avoided.

Axel.

<Axel.Belinfante@cs.utwente.nl>   tel. +31 53 893774   fax. +31 53 333815
     University of Twente, Tele-Informatics & Open Systems Group
       P.O. Box 217    NL-7500 AE Enschede      The Netherlands
     "ili ne sciis ke estas neebla do ili simple faris" -- Loesje




From luotonen@ptsun00.cern.ch  Thu Dec  2 10:56:00 1993 +0100
Message-Id: <9312020956.AA11673@ptsun03.cern.ch>
Date: Thu, 2 Dec 93 10:56:00 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: Re: CGI/1.0 status


George:
>  * If "nph:scriptname" is the expected name of the script, then
>  * the ":" should be changed to...
>  * ... If, however, the "nph:" is stripped by server and
>  * it execs "scriptname", all is fine.

Rob:
> Good point. Mac systems will not like the : one bit. I'll change it to
> "nph-", are there any objections to that? VMS? I think DOS, OS/2, NT,
> and System 7 don't have any problem with it. I'm not sure about VMS.

I would do the opposite of what George suggested (stripping "nph:" off):
Why does nph: (or now nph-) have to be present in the URL at all? -- It's
information controlling the server.  I would prefer it being in the
script filename suffix, automatically added by the server when searching
for executable.  If you want to change a previously normal script to
an nph- script you would have to modify all the docs containing URLs
to that script.  If .nph is added by server no docs need to be changed.

I can see, however, the performance point of view.  But then again
.nph shouldn't be forbidden in URL -- if it's there then server knows
for sure right away that this is an nph script.  Only if the suffix
is missing it has to look for the actual script name.

This is how I'll handle the difference between current CERN daemon
interface and CGI/1.0 anyway.

As for the decoding/parsing issue -- I don't like having both preparsed
and full URL made available -- it's unnecessary duplication.  If the
script doesn't want preparsing then it gets it unparsed and that's it.
If it wants to have preparsed stuff that's what it gets (only).  If
there is an overflow somewhere then too bad, life is hard sometimes.
Like George said -- quick hacks need not cope with the craziest possible
argument to be useful.

>  * Anyhow, I think this is pretty much a tempest in a teapot.  Based on
>  * my experience in writing gateway scripts, I like the extra bit of
>  * decoding -- just seemed more convenient and never got in the way.
>  * Mind you, that was only for <ISINDEX> decoding.  Maybe FORMs decoding
>  * is less useful.  Maybe a split is in order:  decode ISINDEX stuff
>  * 'cause it won't overflow and is semantically simply, don't decode
>  * FORMs stuff cause there's a good chance it'll be too big anyway
>  * and it's hard to decode the information into a usable form.
>  */
> 
> This, I think, is a good idea. I would agree to making ISINDEX queries
> decoded, but not FORMs queries (at least not with GET).
> 
> Ari?

Sounds ok to me.

-- Cheers, Ari --




From dsr@hplb.hpl.hp.com  Thu Dec  2 10:42:46 1993 GMT
Message-Id: <9312021042.AA17520@manuel.hpl.hp.com>
Date: Thu, 2 Dec 93 10:42:46 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: Submit/Reset Button names on Forms

>> Note that using an SGML attribute for the label text prevents us
>> from using character entities such as &Eacute; - we are therefore
>> restricted to Latin-1 characters for labels and initial values for
>> text input fields (this doesn't apply to TEXTAREA). I hope this isn't
>> a problem.

> It is a limitation, it would be nice if it could be avoided.

Here are two ways around this (involving changes to current implementations)

    a)  to define a new element, say <BUTTON> ... </BUTTON>
        for which the content defines the label, and attributes that
        define its action, e.g. <BUTTON ACTION=SUBMIT NAME="Update">...
        (we could then phase out use of <INPUT> for submit and cancel)

    b)  if other input fields can be made to submit you can place the
        caption in the body of the form, e.g.

            Update <INPUT TYPE=IMAGE NAME="Update" SRC="http://...">

         this approach allows us to use iconic buttons, but won't
         look so good on VT-100 terminals :(

I am also working on ways to make forms appear dynamic, in that making
one choice greys out others. The best bet so far looks like allowing
servers to send updates to form contents rather than replacing the whole
document. Should we send the full SGML markup (slow) for the form rather than
just the field contents (fast)? This would avoid the whole window flashing
when only localised changes are needed. To allow servers to set an error
message it looks like we would need a new element

    e.g. <MESSAGE> ...</MESSAGE>

so that the browser knows where to display the message.

Dave Raggett



From J.Larmouth@iti.salford.ac.uk  Mon Dec  2 11:38:00 1993
Message-Id: <9312021153.AA20102@dxmint.cern.ch>
Date: 2 Dec 93 11:38
From: J.Larmouth@iti.salford.ac.uk (J.Larmouth@iti.salford.ac.uk)
Subject: Miscellaneous points

=========================================================================
E-mail from: Prof J Larmouth              J.Larmouth @ ITI.SALFORD.AC.UK
             Director                       Telephone: +44 61 745 5657
             IT Institute                         Fax: +44 61 745 8169
             University of Salford              Telex: 668680 (Sulib)
             Salford M5 4WT
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

To:     WWW-talk @ info.cern.ch

(I sent the following on another list,  and it was suggested that the
WWW-talk list - of which I am not a member - would be a better place to
send it.  I DO NOT KNOW HOW TO SUBSCRIBE - COULD SOMEBODY LET ME KNOW SO
THAT I CAN SEE ANY RESULTING DISCUSSION?   Thanks.  John L)

Some of the following (use of WWW in the UK.AC and Error and congestion
handling) is probably less relevant for WWW-talk than it was for the
original list,  so please skip these sections.

The original mail follows:

>>>>>>>>>>>>>>>>>>>>>>

Subject:      Miscellaneous points

(If you don't like long and rambling E-mails,  delete this NOW!
If you do,  and you think some of the thoughts are worth wider
discussion,  please copy to other lists if you wish.)

Contents:

1.      Use of WWW in UK.AC
2.      Negative remarks about WWW
        2.1     HTTP
        2.2     HTML
        2.3     Error and congestion handling
3.      Philosophical thoughts on networked information
        3.1     Stateless servers are good?
        3.2     Synchronisation primitives
4.      Proposed WWW/APW feasibility study project
5.      Final philosophical mutterings

1.      Use of WWW in UK.AC
===========================

I believe that the UK.AC needs a top-level WWW home page (probably
maintained by someone on the JNT or on contract to them) which carries
pointers to **ALL** known networked information sources in the UK.AC.

(When I say ALL,  I mean top-level - a site may well contain a subsidiary
page giving sources at that site.  These would be listed at the UK level
only if they were widely accessed from other sites and of general utility
such as the Lancaster archives or the BIDs database.)

It would contain sections on WWW home pages for sites,   gopher,  archie
WAIS,  etc servers,  anonymous ftp sites,  sites providing information
via an E-mail request,  software archives,  BIDs etc databases,  and
mailing list servers with the lists they contain.   In each case there
should be enough information to identify the sort of information
available from that site via that means,  and (where it is not a simple
URL) details on how to go about getting the info.

I would suggest a primary document with this info,  with indexes
(supported by hypertext links) that would reveal the data either by
subject category or by access mechanism.

I suspect the info should not only be an HTML document,  but should also
be searchable with WAIS,  Gopher,  Archie,  Winifred (or whatever her
name is!)  etc.

Over to someone!

2.      Negative remarks about WWW
==================================

2.1     HTTP
------------

The main function of HTTP seems to be to do the OSI presentation layer
negotiation of transfer syntaxes,  with announcement of the abstract
syntaxes supported.   I am *very* pleased these concepts have been
introduced,  but would have preferred to have seen closer alignment of
terminology with (and recognition of) the OSI work.

2.2     HTML
------------

(This is based on MOSAIC documents,  not the primary reference material,
so there could be a misunderstanding - someone please correct me.)

HTML is *NOT* SGML-conformant.  It should be mended.   What I am
referring to is the ridiculous use of <P> as an *end*-tag for a
paragraph,  with compulsory ommission of the start-tag - there is no
start-tag!   This violates the rules of SGML on tag-ommission,  and makes
authoring an HTML document distinctly non-ergonomic.

If this is not mended quickly,  it will be too late.  Perhaps too late
now.

Does anyone have access to the right places to get this problem
addressed?

I have yet to locate an actual HTML DTD (as opposed to tutorials) but I
get the impression that ommission of end-tags on <H1>,  <H2>,  etc is not
permitted (or at least not supported by most clients).   If I am right,
then this is again very *unergonomic*,  and should be addressed.

2.3     Error and congestion handling
=====================================

When using both MOSAIC and CELLO,   there are frequent occasions when
they cannot connect to a site and/or when the transfer of material just
grinds to a halt.  Even when it doesn't,  transfer rates of about 2K
bytes per minute seem quite common!

The error reports on failures to connect are not very helpful.   This is
partly poor design of the client software and/or lack of diagnostic
parameters in WINSOCK specifications,  and/or the fact that we are in
early releases,  but I think it may also reflect a lack of appropriate
information at the network level.

For example,  am I getting failures to connect and/or poor transfer rates
and/or halts because of the link from Salford to the Janet back-bone,
because of the pipe across the atlantic,  or because the server is very
congested/slow,  or because my PC is too slow,  or what?   I have a
strongish suspicion it may be the Salford link and/or routers,  but there is
no easy way to find out.

I have no answer to these sort of problems,  but as world-wide access to
information servers becomes more common,  pin-pointing where problems lie
will become more important.  Certainly at present there is no way I would
want to expose the VC to either MOSAIC or CELLO - too many failures,  and
far,  far too slow.   Hope it changes soon tho' - the idea is great!

3.      Philosophical thoughts on networked information
=======================================================

I think we need to ponder a little on the appropriate metaphors for
developing multi-media services.   There was some discussion earlier on
what to base JNT and European activity on,  and the consensus seemed to
be WWW,  which really means HTML.  I don't wish to quarrel with that
decision - it looks like a fair starting point (but see the negative
comments above).

Someone,  however,  remarked in earlier discussion on this list that
there were two sorts of multi-media information/presentation,  and WWW
was good for one but APW was optimised for the other.

I think we need to think a bit more about that.

3.1     Stateless servers are good?
-----------------------------------

As a starting point,  I see the concept of STATELESS SERVERS as a
fundamental issue.   WWW is based on the philosophy of a single
world-wide distributed server that is stateless.  Stateless servers are
clearly easier to implement efficiently because there is no need for the
server to maintain per-user information.  They are probably a GOOD THING.

But they *do* limit what you can do!

If you think about a computer game (take LEGEND as an example of one I
know fairly well),   you will recognise that retention of state is
fundamental to the operation of the game.   This goes from simple
parameterisation to let you give characters names of your own choosing
through to quite complex data-structures holding details of the objects
being carried at any point in time and spells that have been mixed.
There is also a database that relates to whether a particular hot-spot
has an object in it that can be picked up.   Hitting particular hot-spots
up-dates these data-structures,  sometimes with a conditional test (is
the character already carrying as much as can be carried?)

It is part of my thesis here that anything you need to handle a networked
computer game,  you also need for more professionally oriented services.

HTML appears to have a tag for a "variable",  but I have not seen it in
use in any actual document,  and am not fully clear how powerful the
mechanism is,  but it sounds as tho' it relates to the above,  and could
perhaps form the basis for providing support for controlled (by the HTML
document) state retention by the client with a stateless server.

Indeed,  I could foresee a useful world-wide standardisation of some
variables (please use OBJECT IDENTIFIERS for the variable names!),  such
as the user's name and/or e-mail address.  Information delivered to users
could then be personalised without introducing state into the server.

Going far enough to support LEGEND in this way requires rather more
study,   but I commend the intellectual activity!

3.2     Synchronisation primitives
----------------------------------

If we are seriously considering extending WWW to have the functionality
of APW,  then we have an interesting task in hand.

WWW is a mesh of information,  and the delivery of various parts of that
are largely uncoordinated (in-line images v non-in-line) is about the
only synchronisation that is present.

A fundamental need is to introduce into the HTML mark-up tags that
reflect various synchronisation requirements between the delivery of
different sources,  and indeed the whole concept of multiple presentation
threads.

As a starting point,  it would be an excellent intellectual exercise to
take the functionality represented by an APW tree of icons and see if we
can produce a definition of tags that would completely reflect that
functionality.

(This is actually another way of saying "Extend HTML so that the
underlying format for APW *could* be HTML,  with no loss of
functionality".)

Only if this is done can the vendors of Authorware (or anyone else if
Authorware were prepared to release their private formats) produce
software to turn an Authorware program into a "standard"
vendor-inbdependent form.

I am,  by the way,  fairly convinced that the job can be done,  that SGML
*is* man enough for it,  but it will need a conscious effort and
coordinated programme.

4.      Proposed WWW/APW feasibility study project
==================================================

It would be interesting to tackle the following project,  which would
result in an extended HTML (XHTML) and a prototype APW look-alike that
would run on any XHTML client:

        a)      Examine the APW icon and flow diagram functionality and
        define an appropriate set of tags to reflect that functionality.

        (This would in principle make it possible for a human being to
        translate any APW program into XHTML such that any XHTML client
        could play the programme back with a result for the user that is
        identical to the playing of the original APW programme.)

        In order to do this,  the problems of synchronisation tags
        and of tags for state variables,  and of tags for DO WHILE loops
        will have to be addressed.   The work of tag definition should,
        of course,  be done in a general way,  but must provide the full
        APW functionality - at least!

        b)      Consider a further extension of XHTML to define tags
        that,  when encountered by an XXHTML client,  cause it to take
        actions that result in the production of an HTML document.  This
        could be extended to other sorts of actions,  particularly
        related to the disposal (for example,  E-mailing) of the
        document,  or the automatic invocation (controlled by clicking
        a hot-spot in the document) of FTP or TELNET or E-mail.

        c)      Using the work of b),   define an XXHTML document that
        provides a display similar to the APW display of programme icons,
        and such that "browsing" that document in a suitable way causes
        an XHTML document to be generated that is equivalent to an APW
        programme.  In other words,  an XXHTML document that gives any
        XXHTML client the functionality of APW to produce a multi-media
        programme,  albeit perhaps with a poorer user interface.

5.      Final philosophical mutterings
======================================

If you have followed the last section,  you will see the overall
direction I am seem to be heading in.

I can already hear mutterings of "horses for courses".  SGML is *not*,
and never can be a programming language.  Tags that cause actions (by
the client) when encountered,  rather than merely identifying document
components,   is outside the "spirit" of SGML.   But I reply so are tags
that cause hypertext links to be activated!  And those are fundamental to
HTML.

It is possible the mutterers are right,   but we will never know unless
we explore the feasibility in more detail.

If the mutterers *are* right,  then WWW is,  I think,  *not* a suitable
tool for providing networked support for the sort of multi-media
programmes that APW is used to produce,  and we need to investigate some
other base for these sorts of multi-media programmes.

Personally,  however,  I have little sympathy with the view that "there
are two sorts of programme,  and we need different tools for each".  I
believe there will be many programmes that will need both approaches,
and a common (or at least integrated) tool base would be important.

John L




From dsr@hplb.hpl.hp.com  Thu Dec  2 16:28:51 1993 GMT
Message-Id: <9312021628.AA22731@manuel.hpl.hp.com>
Date: Thu, 2 Dec 93 16:28:51 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: X Mosaic, FTP and PASV

I found it easier than expected to patch X Mosaic to use the PASV
command and would like to make the new version of HTFTP.c available
to others. At the same I changed it over to display a conventional
directory listing so that users can see the file permissions and
size. This is done in a robust way and should be at least as robust
as the previous code. In place of the icons it now shows a trailing
character at the end of the file name with "/" for directories,
"@" for links and "*" for executables.

The new version works with my opensubnet gateway so those of you
working behind firewalls will now be able to FTP outside. Right now
Mosaic logs into the FTP server afresh each time you click on the
directory listing - further work is needed to keep the control
connection open, but this needs hooks into other part of Mosaic
and I will need NCSA's help.

You can get the sources from:

        ftp://15.254.100.100/pub/subnet.tar.Z

Best wishes,

Dave Raggett



From phillips@cs.ubc.ca  Mon Dec  2 10:31:00 1993 -0800
Message-Id: <6981*phillips@cs.ubc.ca>
Date: 2 Dec 93 10:31 -0800
From: phillips@cs.ubc.ca (George Phillips)
Subject: Re: CGI/1.0 status

Ari:
>Why does nph: (or now nph-) have to be present in the URL at all? -- It's
>information controlling the server.  I would prefer it being in the
>script filename suffix, automatically added by the server when searching
>for executable.  If you want to change a previously normal script to
>an nph- script you would have to modify all the docs containing URLs
>to that script.  If .nph is added by server no docs need to be changed.

Ah, yes, I knew there was some other reason why "nph-" in the URL
can cause you trouble.  However, I believe this is not a problem
under NCSA HTTPD because you can use ScriptAlias to hide the
script name (right?).  Even without the "nph" problem I'd use
scriptalias anyways -- no need to hard-code script names into the
URL.

I'll assume plexus is only one line of perl code away from a
similar mechanism, but maybe the CERN server can't do ScriptAlias
as easily.  Certainly I'd go along with Ari's suggestion, but
it may be a little painful for DOS, NT, OS/2 users -- they may
depend on .exe suffixes to execute things, I think.

			-- George




From luotonen@ptsun00.cern.ch  Thu Dec  2 20:36:37 1993 +0100
Message-Id: <9312021936.AA12766@ptsun03.cern.ch>
Date: Thu, 2 Dec 93 20:36:37 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: Re: CGI/1.0 status


> I'll assume plexus is only one line of perl code away from a
> similar mechanism, but maybe the CERN server can't do ScriptAlias
> as easily.  Certainly I'd go along with Ari's suggestion, but
> it may be a little painful for DOS, NT, OS/2 users -- they may
> depend on .exe suffixes to execute things, I think.

Oh well, no problem.  I have something coming that can be used to
do the same thing as ScriptAlias does, anyway -- I'll just use that
then, too.

-- Good night, Ari --





From rik@rdt.monash.edu.au  Fri Dec  3 10:05:16 1993 +1100
Message-Id: <199312022305.KAA09837@daneel.rdt.monash.edu.au>
Date: Fri, 03 Dec 93 10:05:16 +1100
From: rik@rdt.monash.edu.au (Rik Harris)
Subject: Re: Miscellaneous points 

> The error reports on failures to connect are not very helpful.   This is
> partly poor design of the client software and/or lack of diagnostic
> parameters in WINSOCK specifications,  and/or the fact that we are in
> early releases,  but I think it may also reflect a lack of appropriate
> information at the network level.
> 
> For example,  am I getting failures to connect and/or poor transfer rates
> and/or halts because of the link from Salford to the Janet back-bone,
> because of the pipe across the atlantic,  or because the server is very
> congested/slow,  or because my PC is too slow,  or what?   I have a
> strongish suspicion it may be the Salford link and/or routers,  but there is
> no easy way to find out.
> 
> I have no answer to these sort of problems,  but as world-wide access to
> information servers becomes more common,  pin-pointing where problems lie
> will become more important.  Certainly at present there is no way I would
> want to expose the VC to either MOSAIC or CELLO - too many failures,  and
> far,  far too slow.   Hope it changes soon tho' - the idea is great!

I don't have the experience with SGML or OSI to comment on your other
points, but with this one I would suggest that it is not up to
application software to pinpoint network failures.  This should be left
to network management software, as it is a complicated task that
requires detailed knowledge of the network topology, link types,
operating behaviour, protocols, and other factors.

I feel the most you want is distinction between "host does not exist",
"host was not contactable - temporary", "service not available at
host", "network error looking up host name" and possibly "service not
available at host - temporary".  Better still: "none of the redundant
hosts were contactable"  :-)

rik.
--
Rik Harris - rik.harris@fcit.monash.edu.au
+61 3 560-3265 (AH & ans.mach)      +61 3 565-3227 (BH)
Department of Robotics and Digital Technology, FCIT, Clayton Campus,
Monash University, Australia   http://www.vifp.monash.edu.au/people/rik.html



From rik@rdt.monash.edu.au  Fri Dec  3 10:05:16 1993 +1100
Message-Id: <199312022305.KAA09837@daneel.rdt.monash.edu.au>
Date: Fri, 03 Dec 93 10:05:16 +1100
From: rik@rdt.monash.edu.au (Rik Harris)
Subject: Re: Miscellaneous points 

> The error reports on failures to connect are not very helpful.   This is
> partly poor design of the client software and/or lack of diagnostic
> parameters in WINSOCK specifications,  and/or the fact that we are in
> early releases,  but I think it may also reflect a lack of appropriate
> information at the network level.
> 
> For example,  am I getting failures to connect and/or poor transfer rates
> and/or halts because of the link from Salford to the Janet back-bone,
> because of the pipe across the atlantic,  or because the server is very
> congested/slow,  or because my PC is too slow,  or what?   I have a
> strongish suspicion it may be the Salford link and/or routers,  but there is
> no easy way to find out.
> 
> I have no answer to these sort of problems,  but as world-wide access to
> information servers becomes more common,  pin-pointing where problems lie
> will become more important.  Certainly at present there is no way I would
> want to expose the VC to either MOSAIC or CELLO - too many failures,  and
> far,  far too slow.   Hope it changes soon tho' - the idea is great!

I don't have the experience with SGML or OSI to comment on your other
points, but with this one I would suggest that it is not up to
application software to pinpoint network failures.  This should be left
to network management software, as it is a complicated task that
requires detailed knowledge of the network topology, link types,
operating behaviour, protocols, and other factors.

I feel the most you want is distinction between "host does not exist",
"host was not contactable - temporary", "service not available at
host", "network error looking up host name" and possibly "service not
available at host - temporary".  Better still: "none of the redundant
hosts were contactable"  :-)

rik.
--
Rik Harris - rik.harris@fcit.monash.edu.au
+61 3 560-3265 (AH & ans.mach)      +61 3 565-3227 (BH)
Department of Robotics and Digital Technology, FCIT, Clayton Campus,
Monash University, Australia   http://www.vifp.monash.edu.au/people/rik.html



From hotsand!ellson  Fri Dec  3 01:33:20 1993 EST
Message-Id: <9312030633.AA07627@hotsand.dacsand>
Date: Fri, 3 Dec 93 01:33:20 EST
From: hotsand!ellson (John Ellson)
Subject: Re:  X Mosaic, FTP and PASV

Dave,

> From: Dave_Raggett <dsr@hplb.hpl.hp.com>
> Subject: X Mosaic, FTP and PASV
> 
> I found it easier than expected to patch X Mosaic to use the PASV
> command and would like to make the new version of HTFTP.c available
> to others. 

Your PASV code is great!  It gets rid of all of the AT&T firewall patches
from HTFTP.c and it considerably simplifies even the non-firewall
version of the code.

Assuming that we don't run across ftp servers without PASV support
then you have my vote to include this code in vanilla Mosaic.

> At the same I changed it over to display a conventional
> directory listing so that users can see the file permissions and
> size. This is done in a robust way and should be at least as robust
> as the previous code. In place of the icons it now shows a trailing
> character at the end of the file name with "/" for directories,
> "@" for links and "*" for executables.

I like seeing the file sizes, but I also liked the icons in the
previous version.  What would you think about just adding file sizes
to the the icon version?   The only other information ls provides is
file owner but I don't see that as very useful in an anonymous ftp
situation.

At the moment the ftp listing lines are too long to fit on Mosaic's
default window size and font, and the <pre> formatting is not
pleasing to the eye. 

I'm not trying to start a war of the icons.  If there are strong
feelings about them then I'll stay out of the way.  Otherwise
I'll be pleased to code up a merged icon + file size version
this weekend for folks to try, based on Dave's code.


John Ellson
AT&T Bell Labs



From robm@ncsa.uiuc.edu  Fri Dec  3 04:04:15 1993 -0600
Message-Id: <9312031004.AA12618@void.ncsa.uiuc.edu>
Date: Fri, 3 Dec 1993 04:04:15 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI/1.0 status

/*
 * Re: CGI/1.0 status  by George Phillips (phillips@cs.ubc.ca)
 *    written on Dec  2, 10:31am.
 *
 * Ari:
 * >Why does nph: (or now nph-) have to be present in the URL at all? -- It's
 * >information controlling the server.  I would prefer it being in the
 * >script filename suffix, automatically added by the server when searching
 * >for executable.  If you want to change a previously normal script to
 * >an nph- script you would have to modify all the docs containing URLs
 * >to that script.  If .nph is added by server no docs need to be changed.
 * 
 * Ah, yes, I knew there was some other reason why "nph-" in the URL
 * can cause you trouble.  However, I believe this is not a problem
 * under NCSA HTTPD because you can use ScriptAlias to hide the
 * script name (right?).  Even without the "nph" problem I'd use
 * scriptalias anyways -- no need to hard-code script names into the
 * URL.
 * 
 * I'll assume plexus is only one line of perl code away from a
 * similar mechanism, but maybe the CERN server can't do ScriptAlias
 * as easily.  Certainly I'd go along with Ari's suggestion, but
 * it may be a little painful for DOS, NT, OS/2 users -- they may
 * depend on .exe suffixes to execute things, I think.
 */

What I have currently implemented in NCSA httpd 1.0a6 is ScriptAlias for
CGI scripts and OldScriptAlias for non-CGI scripts. 

The other problem I see with Ari's suggestion (I'm picking performance nits
again) is that in order to implement extra path information, under my server
I'd have to do twice the stat() calls, and Ari would have to do three times
the stat() calls (assuming he's still using a .cgi extension to identify CGI
scripts).

I support using ScriptAlias to hide the nph-, even though it requires that
no-parse-header scripts either reside in a different directory, or (in NCSA
httpd's case) that the scripts that are nph- are explicitly listed before
their directory... i.e.

ScriptAlias /cgi/blast /usr/local/httpd/cgi/nph-blast

Or, better, would be to keep them in a separate directory and have

ScriptAlias /cgi/ /usr/local/httpd/cgi-nph/

Does this sound sensible?

--Rob



From dsr@hplb.hpl.hp.com  Fri Dec  3 11:13:10 1993 GMT
Message-Id: <9312031113.AA26961@manuel.hpl.hp.com>
Date: Fri, 3 Dec 93 11:13:10 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re:  X Mosaic, FTP and PASV

> Your PASV code is great!  It gets rid of all of the AT&T firewall patches
> from HTFTP.c and it considerably simplifies even the non-firewall
> version of the code.

Thanks!

>> At the same I changed it over to display a conventional
>> directory listing so that users can see the file permissions and
>> size. This is done in a robust way and should be at least as robust
>> as the previous code. In place of the icons it now shows a trailing
>> character at the end of the file name with "/" for directories,
>> "@" for links and "*" for executables.

> I like seeing the file sizes, but I also liked the icons in the
> previous version.  What would you think about just adding file sizes
> to the the icon version?   The only other information ls provides is
> file owner but I don't see that as very useful in an anonymous ftp
> situation.

It would be nice to show the file size under the icon and to use
a multicolumn format when practical. This could all be done with
HTML+ e.g.

    <UL PLAIN WRAP=VERT>
        <LI><A HREF="circus.gif"><FIG SRC="file_icon" ALIGN=TOP>
            <CAPTION>278104</CAPTION>file</FIG>circus.gif</A>
        ...
    </UL>

But this will have to wait until Erik gets some free time :-)

Getting the file size explicitly is perhaps less robust, but as Andy
Norman of angeftp fame is a colleague of mine, I reckon I can beef up
the code to deal with the 15 formats or so of directory listings from
different platforms, e.g. VMS FTP servers produce 3 varieties alone!

Regards,

Dave Raggett



From davis@dri.cornell.edu  Fri Dec  3 10:26:02 1993 -0500
Message-Id: <199312031526.AA18189@willow.tc.cornell.edu>
Date: Fri, 3 Dec 1993 10:26:02 -0500
From: davis@dri.cornell.edu (Jim Davis)
Subject: HTTP MIme content-type parameters

The HTTP draft RFC violates the MIME RFC 1341 specification for the
use of parameters in content types.  There are two problems.

1) The MIME RFC states that parameters are separated from the subtype
by a semi-colon, e.g.

 text/plain; charset=us-ascii

But the HTTP draft says uses semi-colon to separate alternative
content-types, and uses comma to separate parameters.

HTTP should change to conform to MIME, e.g. the example on p 8 should
be:

Accept: text/x-dvi; q=.8;mxb=10000;xmt=5.0, text/x-c

2) The MIME spec considers period to be a tspecial, which means it is
forbidden to use it within a token.  It must instead be quoted.  So
the example on page 8 should be:

Accept: text/x-dvi; q=".8";mxb=10000;xmt="5.0", text/x-c

Can we agree to bring the HTTP spec in line with MIME standard?

As far as I know, no one (besides me) is using or caring about
parameters for content types.



From cheung@eplrx7.es.dupont.com  Fri Dec  3 10:48:17 1993 EST
Message-Id: <9312031548.AA23860@eplrx7.es.duPont.com>
Date: Fri, 3 Dec 93 10:48:17 EST
From: cheung@eplrx7.es.dupont.com (Bryan Cheung)
Subject: HTML draft - clarification of quoted string processing

I may just be blind, but I don't see a place in the HTML spec which 
describes what is supposed to happen to special characters inside quoted
strings. Consider an HTML statement such as:

<form method=post action="/htbin-post/banner hello > foobar">
...form goes here
</form>

My question relates to how the i/o redirection character (or any special
character) is to be treated when used within quotes inside of a standard
HTML directive. Should special characters be completely protected when
quoted inside of a directive?? Does it make sense to specify that escapes
such as &gt; be used within quoted strings? Where should this go in the
spec? (I looked for it, and can't find it - please point me there if I
missed it.

On a related note, the above question was generated by some strange
behavior I discovered in the following abuse of NCSA httpd, and X Mosaic:

HTML file:
===========================================================
<pre>
<inc srv "|echo Backslash escapes:">
<inc srv "| echo greater than: \>">
<inc srv "| echo less than: \<">
<inc srv "|echo HTML amper/semi escapes:">
<inc srv "| echo greater than: &gt;">
<inc srv "| echo less than: &lt;">
</pre>
===========================================================

Source received by X Mosaic:
===========================================================
<pre>
Backslash escapes:

greater than:
">
less than: <
HTML amper/semi escapes:

greater than:

less than:

</pre>
===========================================================


A few questions:

1) Why are extra newlines generated after each <inc srv "|blah">
   directive?

2) Why doesn't \> work when \< seems to.

3) Does this happen only to me?


I am using XMosaic 2.0 and httpd 1.0a5 under AIX 3.2.4.


                              -- Bryan Cheung
                                 cheung@eplrx7.es.dupont.com





From hotsand!ellson  Fri Dec  3 11:01:49 1993 EST
Message-Id: <9312031601.AA17607@hotsand.dacsand>
Date: Fri, 3 Dec 93 11:01:49 EST
From: hotsand!ellson (John Ellson)
Subject: Re:  X Mosaic, FTP and PASV

> From: Dave_Raggett <dsr@hplb.hpl.hp.com>
> 
> Getting the file size explicitly is perhaps less robust, but as Andy
> Norman of angeftp fame is a colleague of mine, I reckon I can beef up
> the code to deal with the 15 formats or so of directory listings from
> different platforms, e.g. VMS FTP servers produce 3 varieties alone!

OK. Now I see the problem.

Apparently the filename can be extracted reliably from the 15
varieties of ls, so how about this for now:

	icon + filename + ls line as received
	---------------
	   anchor

The ls line will often disappear of the r.h.s of the default window size
but the information won't be so necessary for normal use.


John Ellson



From roeber@vxcrna.cern.ch  Fri Dec  3 18:06:17 1993 +0100
Message-Id: <9312031706.AA13051@dxmint.cern.ch>
Date: Fri, 3 Dec 1993 18:06:17 +0100
From: roeber@vxcrna.cern.ch (Frederick G.M. Roeber)
Subject: Re: X Mosaic, FTP and PASV

>It would be nice to show the file size under the icon and to use
>a multicolumn format when practical. This could all be done with

If we had a place for storing information related to a document,
(do we?  There's talk about a "Hyperdoc" type in HTAnchor.c, but
it's never flushed out.), then the size (as a number) should be
put there.  Then all those browsers that currently give transfer
status in bytes could give it as a percentage.

A browser could implement a selection for http-served documents
which invokes a HEAD to find out this kind of information.  If
this info included the time changed, it could be compared against
the global history.

--
<a href="http://info.cern.ch/roeber/fgmr.html">Frederick</a>



From weber@eit.COM  Fri Dec  3 09:32:43 1993 PST
Message-Id: <9312031732.AA24770@eit.COM>
Date: Fri, 3 Dec 93 09:32:43 PST
From: weber@eit.COM (Jay C. Weber)
Subject: a compromise on tables, etc.


We've seen a couple applications developers beg for HTML+ table support
in browsers, and we've seen browser developers uses tables as the main
example of the impractical side of HTML+.  Being a little bit of both
sides I'll suggest a compromise.  How about a BOX tag that works like
this:

  <BOX size=20>
  This is some text to be put in the box.
  </BOX>

What this does is put the text into a rectangle of real estate of
width 20 "em"s.  Height depends on how the text wraps.  Then the
whole thing is treated like a single character ala the IMG tag.

One can build a wide range of tables with this, including spanning
titles.  It won't be as easy to use as the LaTeX-style header
description, but hey, I can live with that.  It should be very easy
for browser developers to implement, especially those that use
widgetry for display management.

One can also fake text that flows around images using BOX.

Of course, there are a number of nice bells and whistles that we could
add to this; here are some in my order of increasing work:

o add an align (top, middle, bottom) parameter, ala IMG

o add a rows parameter, ala TEXTAREA, for explicit height

o change or enhance the size parameter to take a multiplier of the current
  window width, e.g. size=.1 says take 10% of the window width.  This will
  scale better in some cases.

o add an ialign (right, left, center) "internal align" parameter, to
  specify how to align text inside the box

o allow for tags to next inside <BOX>...</BOX>, e.g., for images, forms
  components, sub-BOXes, etc.

What do people think?

Jay



From dsr@hplb.hpl.hp.com  Fri Dec  3 17:54:45 1993 GMT
Message-Id: <9312031754.AA27754@manuel.hpl.hp.com>
Date: Fri, 3 Dec 93 17:54:45 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: HTML draft - clarification of quoted string processing

Bryan Cheung writes:

> I may just be blind, but I don't see a place in the HTML spec which 
> describes what is supposed to happen to special characters inside quoted
> strings. Consider an HTML statement such as:

> <form method=post action="/htbin-post/banner hello > foobar">
>  ...form goes here
> </form>

> My question relates to how the i/o redirection character (or any special
> character) is to be treated when used within quotes inside of a standard
> HTML directive. Should special characters be completely protected when
> quoted inside of a directive?? Does it make sense to specify that escapes
> such as &gt; be used within quoted strings? Where should this go in the
> spec? (I looked for it, and can't find it - please point me there if I
> missed it.

Page 331 of Goldfarb's SGML Handbook says that parsers derive the attribute
value from the attribute value literal (the stuff between the quote marks)
by replacing any entity references or character references within the literal
and then normalising by replacing any contiguous whitespace by a single
space character. Note you can use " or ' as quote marks for attribute value
literals.

Thanks for pointing out this topic - it is rather obscure and clearly needs
to be included in the HTML+ spec. I can garantee that most browsers are
currently doing the wrong thing for attributes!

Dave Raggett



From dsr@hplb.hpl.hp.com  Fri Dec  3 18:04:12 1993 GMT
Message-Id: <9312031804.AA27766@manuel.hpl.hp.com>
Date: Fri, 3 Dec 93 18:04:12 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re:  X Mosaic, FTP and PASV

>> Getting the file size explicitly is perhaps less robust, but as Andy
>> Norman of angeftp fame is a colleague of mine, I reckon I can beef up
>> the code to deal with the 15 formats or so of directory listings from
>> different platforms, e.g. VMS FTP servers produce 3 varieties alone!

> OK. Now I see the problem.

> Apparently the filename can be extracted reliably from the 15
> varieties of ls, so how about this for now:

>        icon + filename + ls line as received
>        ---------------
>           anchor

> The ls line will often disappear of the r.h.s of the default window size
> but the information won't be so necessary for normal use.

That sounds kind of ugly to me. I think its better to fix up HTFTP.c
to deal correctly with the different platforms and just show icon
filename and size, all in a hypertext link.

I won't have any time to work on this though until after Christmas.
Also on the stack is a simple scheme to cache all offsite http requests
- our admin staff are worried about network costs (we pay $10 per Mbyte).

Dave



From dsr@hplb.hpl.hp.com  Fri Dec  3 18:12:52 1993 GMT
Message-Id: <9312031812.AA27780@manuel.hpl.hp.com>
Date: Fri, 3 Dec 93 18:12:52 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: X Mosaic, FTP and PASV

> If we had a place for storing information related to a document,
> (do we?  There's talk about a "Hyperdoc" type in HTAnchor.c, but
> it's never flushed out.), then the size (as a number) should be
> put there.  Then all those browsers that currently give transfer
> status in bytes could give it as a percentage.

In the HTML+ spec I introduced a SIZE attribute for anchors with
this in mind. People persuaded me to take it out, but maybe we
should put it back again :-)

> A browser could implement a selection for http-served documents
> which invokes a HEAD to find out this kind of information.  If
> this info included the time changed, it could be compared against
> the global history.

Yup. I see two scenarios:

  (A)   Browser builds directory listing for FTP host/path.
        The size is stuck into each <A> element for use when
        the user clicks on a file

  (B)   HTTP server builds directory listing on behalf of client
        The size is stuck into each <A> element for use when
        the user clicks on a file

In each case the information is fresh and so valuable for displaying
a progress gauge.

Thanks for bringing this up - I will write it up in the next version
of the HTML+ spec.

Cheers,

Dave Raggett



From dsr@hplb.hpl.hp.com  Fri Dec  3 18:29:16 1993 GMT
Message-Id: <9312031829.AA27795@manuel.hpl.hp.com>
Date: Fri, 3 Dec 93 18:29:16 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: a compromise on tables, etc.

Jay C. Weber writes:

> We've seen a couple applications developers beg for HTML+ table support
> in browsers, and we've seen browser developers uses tables as the main
> example of the impractical side of HTML+.  Being a little bit of both
> sides I'll suggest a compromise.  How about a BOX tag that works like
> this:

>  <BOX size=20>
>  This is some text to be put in the box.
>  </BOX>

I think we should go for proper tables. They are actually quite easy
to implement, and I intend to release an X11 browser which supports
them in the early spring.

Dave Raggett

p.s. there are three steps to handling tables

   a) determine number of columns and their min/max widths
      (you don't need to be accurate for the max values)

   b) assign widths for current window size

   c) render each cell in turn - you need a way of setting the
      left and right margins (but all browser can do this can't they?)
      its then just like normal rendering.

For efficiency, I do all three steps once and generate a paint stream
which is then interpreted to paint each text line to the window.
Splitting (a) and (b) means you can avoid redoing (a) when users
change the size of the window - probably not worth the extra effort.



From CJA@ml0.ucs.edinburgh.ac.uk  Mon Dec  3 16:32:10 1993 GMT
Message-Id: <MAILQUEUE-101.931203163210.384@ml0.ucs.ed.ac.uk>
Date: 3 Dec 93 16:32:10 GMT
From: CJA@ml0.ucs.edinburgh.ac.uk (Chris Adie)
Subject: Re: Synchronized...

Thus wrote "Q. Alex Zhao" <azhao@cc.gatech.edu> on Thu, 25 Nov 93 13:12:33 EST:

> Can X-Mosaic handle "synchronized media"? Basically, I want the
> following effect:
> 
>  - There's a link; when I click on it, I will get a MPEG movie _AND_
>    some audio information.
> 
>  - Based on the first one, can the audio part somehow synchronize with
>    the video part at some certain points, like there may be some
>    interesting points in the video, and when I see one, I will hear the
>    corresponding audio explanation...
> 
> Can Mosaic do these?

Not really, no.  I'm currently trying to write a proposal to RARE to
add better multimedia presentation facilities to WWW along the lines of
John Larmouth's message and yours.  The list will have a chance to
review it in January some time (I hope!).


Regards,

Chris Adie                                   Phone:  +44 31 650 3363
Edinburgh University Computing Service       Fax:    +44 31 662 4809
University Library, George Square            Email:  C.J.Adie@edinburgh.ac.uk
Edinburgh EH8 9LJ, United Kingdom



From marca@ncsa.uiuc.edu  Fri Dec  3 14:12:03 1993 -0800
Message-Id: <9312032212.AA09229@wintermute.ncsa.uiuc.edu>
Date: Fri, 3 Dec 93 14:12:03 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Re: Synchronized...

> Thus wrote "Q. Alex Zhao" <azhao@cc.gatech.edu> on Thu, 25 Nov 93 13:12:33 EST:
> 
> > Can X-Mosaic handle "synchronized media"? Basically, I want the
> > following effect:
> > 
> >  - There's a link; when I click on it, I will get a MPEG movie _AND_
> >    some audio information.

One way to do this is to use a MIME message and have metamail fork off
the requisite viewers.  This is splitting functionality, but it does
work.

Marc




From vinay@eit.COM  Fri Dec  3 12:46:45 1993 PST
Message-Id: <9312032046.AA25757@eit.COM>
Date: Fri, 3 Dec 93 12:46:45 PST
From: vinay@eit.COM (Vinay Kumar)
Subject: Re: Synchronized...

Yes, XMosaic itself cannot handle sync. multimedia. However, the way i
am handling synchronized multimedia is by spawning off my external viewer,
a MIME Multiplayer. It creates synch. MIME multipart+parallel messages that 
can be stuck in the Web. Using XMosaic's ".mailcap", one can spawn off this
external viewer from XMosaic to play MIME multimedia messages. As of now, 
i can handle Synchronized Graphics, Audio and PointerMotion Gestures (no video 
yet). 

I am not sure if this is the right way, take this more as an fyi.
--
  Vinay Kumar
vinay@eit.com

---------------------------------
> From: Chris Adie <CJA@ml0.ucs.edinburgh.ac.uk>
> 
> Thus wrote "Q. Alex Zhao" <azhao@cc.gatech.edu> on Thu, 25 Nov 93 13:12:33 EST:
> 
> > Can X-Mosaic handle "synchronized media"? Basically, I want the
> > following effect:
> > 
> >  - There's a link; when I click on it, I will get a MPEG movie _AND_
> >    some audio information.
> > 
> >  - Based on the first one, can the audio part somehow synchronize with
> >    the video part at some certain points, like there may be some
> >    interesting points in the video, and when I see one, I will hear the
> >    corresponding audio explanation...
> > 
> > Can Mosaic do these?
> 
> Not really, no.  I'm currently trying to write a proposal to RARE to
> add better multimedia presentation facilities to WWW along the lines of
> John Larmouth's message and yours.  The list will have a chance to
> review it in January some time (I hope!).
> 
> 
> Regards,
> 
> Chris Adie                                   Phone:  +44 31 650 3363
> Edinburgh University Computing Service       Fax:    +44 31 662 4809
> University Library, George Square            Email:  C.J.Adie@edinburgh.ac.uk
> Edinburgh EH8 9LJ, United Kingdom
> 



From masinter@parc.xerox.com  Fri Dec  3 16:23:59 1993 PST
Message-Id: <93Dec3.162407pst.2732@golden.parc.xerox.com>
Date: Fri, 3 Dec 1993 16:23:59 PST
From: masinter@parc.xerox.com (Larry Masinter)
Subject: Patches for a different proxy gateway

I have a set of patches for Mosaic 2.0 that allow it to work with the
Sun Consulting proxy internet gateway. This is different from Socks,
or the gateway Dave Raggart posted patches for.

I too would like these folded into the Mosaic sources (under an #ifdef
SUNPROXY), but I don't know how receiptive NCSA would be.

I also have similar patches for lynx and the standard WWW library
(unfortunately, they all use different versions of 'libwww' in ways
that impact how the proxy software is to run.)

If you're interested, please contact me.

Larry Masinter <masinter@parc.xerox.com> Xerox Palo Alto Research Center (PARC)
3333 Coyote Hill Road; Palo Alto, CA 94304; (415) 812-4365 Fax: (415) 812-4333



From dale@ora.com  Fri Dec  3 20:49:47 1993 -0800
Message-Id: <9312032049.ZM17793@rock.west.ora.com>
Date: Fri, 3 Dec 1993 20:49:47 -0800
From: dale@ora.com (Dale Dougherty)
Subject: Re: a compromise on tables, etc.

Dave writes that tables are easy.  I don't want to argue
that point either way.  However, I have wondered if
tables are a special multimedia object that requires
its own "viewer," just as XV handles graphics.  I imagine
a separate table processor that WWW browsers can 
invoke.  It might even permit some manipulation of the
data, as would a spreadsheet.

This doesn't make tables any harder or easier to implement,
only that the resulting table processor could be invoked
from WWW browser instead of a lot of developers having to
write their own code.  

Dale

-- 
Dale Dougherty (dale@ora.com) 
Publisher, Global Network Navigator, O'Reilly & Associates, Inc.
103A Morris Street, Sebastopol, California 95472 
(707) 829-3762 (home office); 1-800-998-9938



From weber@eit.COM  Fri Dec  3 23:11:47 1993 -0800
Message-Id: <199312040711.XAA00900@kmac.eit.com>
Date: Fri, 3 Dec 1993 23:11:47 -0800
From: weber@eit.COM (Jay C. Weber)
Subject: Re: a compromise on tables, etc.


> From: dale@ora.com (Dale Dougherty)
>
> I have wondered if
> tables are a special multimedia object that requires
> its own "viewer," just as XV handles graphics.  I imagine
> a separate table processor that WWW browsers can 
> invoke.  It might even permit some manipulation of the
> data, as would a spreadsheet.

Yeah, someone else suggested I use excel data files.  Of course
that is pretty platform-specific (and not to mention proprietary),
but there are more platform-independent formats (SYLK?).  I've
already played with this and it helps a little, but falls short for
a number of applications.

I would use tables for layout of forms, simulated text flow around
embedded images, simulated two-column pages, and table cells containing
links.  (You could do the latter with a custom viewer that remote
controls the browser, but it'll get pretty hairy.)  Basically, tables
are the key to advanced use of HTML widget real estate.

In TeX, the basic mechanism for advanced layout is the construction
and stacking of boxes.  My BOX tag suggestion is analogous.  Is there
no one else who thinks that it is both simple and useful?

Jay



From wei@sting.berkeley.edu  Fri Dec  3 23:59:50 1993 -0800
Message-Id: <9312040759.AA08833@sting.Berkeley.EDU>
Date: Fri, 3 Dec 93 23:59:50 -0800
From: wei@sting.berkeley.edu (Pei Y. Wei)
Subject: Re: a compromise on tables, etc.

> In TeX, the basic mechanism for advanced layout is the construction
> and stacking of boxes.  My BOX tag suggestion is analogous.  Is there
> no one else who thinks that it is both simple and useful?
>
> Jay

Oh I agree. I've been *using* something just like this BOX tag in the
new ViolaWWW. Except I've been calling it HPANE, and it has MINWIDTH
and MAXWIDTH constraint attributes. Good idea about using em units--
am currently using pixel units (started as a quick simple experiemnt,
ya know). Yeah, I find it a very simple and useful way to format
things.

Such tags are of course rendering/formatting oriented, but sometimes
when one just gotta have certain formatting behaviour, it's better to
just use this box tag rather than convolute the use of semantic tags
to get certain layout.


-Pei



From robm@ncsa.uiuc.edu  Sat Dec  4 03:26:15 1993 -0600
Message-Id: <9312040926.AA29883@void.ncsa.uiuc.edu>
Date: Sat, 4 Dec 1993 03:26:15 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: CGI/1.0: last call

I have written the CGI specification into a set of HTML documents, at URL
http://hoohoo.ncsa.uiuc.edu/cgi/

Per the discussion, I have changed it so that ISINDEX queries have their
query string decoded, but no others. Additionally, the path information is
no longer sent on the command line, only in environment variables.

I'd like to make this last call before the interface is set in stone. I have
implemented most of the specification for the next version of NCSA httpd, and
haven't hit any major snags, which is a good sign. The night is still young,
though.

--Rob



From luotonen@ptsun00.cern.ch  Sat Dec  4 15:46:32 1993 +0100
Message-Id: <9312041446.AA13555@ptsun03.cern.ch>
Date: Sat, 4 Dec 93 15:46:32 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: Re: CGI/1.0: last call


> I have written the CGI specification into a set of HTML documents, at URL
> http://hoohoo.ncsa.uiuc.edu/cgi/

Good!

As for Location:, if the returned URL is not full, but has a #label
in the end, the server either has to do a redirection anyway, or
you'll have to mark this as illegal.

Could you give me an example of PATH_INFO, PATH_TRANSLATED and
SCRIPT_NAME, if I have a request:

	/htbin/script/foo/bar?a=b&c=d

I didn't fully understand them... Thanks!



-- Cheers, Ari --




From decoux@moulon.inra.fr  Sat Dec  4 16:12:13 1993 +0100
Message-Id: <9312041512.AA12686@moulon.moulon.inra.fr>
Date: Sat, 4 Dec 93 16:12:13 +0100
From: decoux@moulon.inra.fr (ts)
Subject: Re: CGI/1.0: last call

> 
> I have written the CGI specification into a set of HTML documents, at URL
> http://hoohoo.ncsa.uiuc.edu/cgi/
> 

 Sorry, but I don't see header lines in the standard input,

 Do you send header lines before extra-information ?


Guy Decoux




From john@math.nwu.edu  Sat Dec  4 10:09:42 1993 -0600 (CST)
Message-Id: <9312041609.AA14166@hopf.math.nwu.edu>
Date: Sat, 4 Dec 1993 10:09:42 -0600 (CST)
From: john@math.nwu.edu (John Franks)
Subject: Re: CGI/1.0: last call (fwd)

According to Ari Luotonen:

> Good!
> 
> As for Location:, if the returned URL is not full, but has a #label
> in the end, the server either has to do a redirection anyway, or
> you'll have to mark this as illegal.
> 
> Could you give me an example of PATH_INFO, PATH_TRANSLATED and
> SCRIPT_NAME, if I have a request:
> 
> 	/htbin/script/foo/bar?a=b&c=d
> 
> I didn't fully understand them... Thanks!
> 
> 
> 
> -- Cheers, Ari --
> 
> 

Generally very good.  I have no problems with the spec.  I also would
like to see the examples Ari mentions.  In fact it would be nice if
there were simple minded examples of almost everything.  Not example
scripts, but something along the lines of

------------------
Script writes to stdout:

	Location: http://hoohoo.ncsa.uiuc.edu/cgi/

Server action:

	Issues HTTP/1.0 redirect message redirecting to URL
		http://hooh0.ncsa.edu/cgi/

------------------

Also I find the following passage somewhat unclear:

> The command line is only used in the case of an ISINDEX query. It is
> not used in the case of an HTML form or any as yet undefined query
> type. The server should search the query information for a non-encoded
> + character to determine if the command line is to be used.

> If the server finds one, it will decode the query information by first
> splitting it on the pluses given in the URL. It will then perform the
> additional decoding before placing the resulting words on
> argv[1....].

> If the server finds that it cannot send the string due to internal
> limitations (such as exec() or /bin/sh command line restrictions) the
> server should include NO command line information and provide the
> non-decoded query information in the environment variable
> QUERY_STRING.

I assume the query information is everything after the ? in the URL.
Will the client always put a + in this string?  What if it is a single
word search term?  I guess I don't understand how the + works to
determine whether or not to use the command line.  What does the
server do if there is no + so it shouldn't the commannd line?
(presumably it does the same thing it does when command line
retstrictions prevent it from using the command line.)  Examples here
would help a lot.  Probably I don't understand this because I haven't
been paying attention, but of course new people will need to read this
document without the benefit of the discussion in its creation.

Should the server always put the query information in the variable 
QUERY_STRING, even when using the command line?

I have no quibble, but is there a rationale for decoding for the
command line and not for the QUERY_STRING?  Also a reference to what
it means to decode the query information, i.e. say it means the
standard URL decoding and give a reference for that.

A final nit. I would find it easier to read (and print) if it were a
single html doc with internal links rather than several html docs with
hyperlinks.



John Franks 	Dept of Math. Northwestern University
		john@math.nwu.edu




From decoux@moulon.inra.fr  Sat Dec  4 17:31:22 1993 +0100
Message-Id: <9312041631.AA13802@moulon.moulon.inra.fr>
Date: Sat, 4 Dec 93 17:31:22 +0100
From: decoux@moulon.inra.fr (ts)
Subject: CGI/1.0: last call (fwd)


> Should the server always put the query information in the variable 
> QUERY_STRING, even when using the command line?

 Yes, I want always this information in QUERY_STRING

Guy Decoux



From c18g@zfn.uni-bremen.de  Sat Dec  4 18:27:28 1993 +0100
Message-Id: <9312041727.AA12605@rs60.zfn.uni-bremen.de>
Date: Sat, 4 Dec 1993 18:27:28 +0100
From: c18g@zfn.uni-bremen.de (Patrick Hausmann)
Subject: 


Please INFO



From rst@ai.mit.edu  Sat Dec  4 14:56:22 1993 EST
Message-Id: <9312041956.AA17966@volterra>
Date: Sat, 4 Dec 93 14:56:22 EST
From: rst@ai.mit.edu (Robert S. Thau)
Subject: Re:  CGI/1.0: last call

A belated minor request --- it would be good if there were an environment
variable which contained the IP address of the remote host (in addition to
REMOTE_HOST, which as I read the spec, is just the DNS hostname).  Perhaps
REMOTE_HOSTADDR would do.

This would allow scripts to easily use all the same authentication criteria
as the http servers themselves allow, including criteria based on subnet
masking, which may not be reflected in the DNS structure.

Otherwise, nice job.  Thanks.

rst



From robm@ncsa.uiuc.edu  Sat Dec  4 19:58:17 1993 -0600
Message-Id: <9312050158.AA06520@void.ncsa.uiuc.edu>
Date: Sat, 4 Dec 1993 19:58:17 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI/1.0: last call

/*
 * Re: CGI/1.0: last call  by Ari Luotonen (luotonen@ptsun00.cern.ch)
 *    written on Dec  4,  3:46pm.
 *
 * 
 * As for Location:, if the returned URL is not full, but has a #label
 * in the end, the server either has to do a redirection anyway, or
 * you'll have to mark this as illegal.

Good point. Since there may also be ? in the path, I think we should require
that people use a full URL if they want to send a # or ? in the file name.

 * Could you give me an example of PATH_INFO, PATH_TRANSLATED and
 * SCRIPT_NAME, if I have a request:
 * 
 * 	/htbin/script/foo/bar?a=b&c=d
 * 
 * I didn't fully understand them... Thanks!
 */

I'll add examples to make things clearer. Anyway, to answer this particular
example, assume that you're using NCSA httpd and DocumentRoot is
/document_root, and that /htbin/script is the actual script to be executed.

PATH_INFO=/foo/bar
PATH_TRANSLATED=/document_root/foo/bar
SCRIPT_NAME=/htbin/script


To elaborate on PATH_TRANSLATED: This is the physical file that the server
would return if the client requested /foo/bar. For some servers, this may be
the same as PATH_INFO.

I'll add a complete example.

--Rob




From robm@ncsa.uiuc.edu  Sat Dec  4 19:59:07 1993 -0600
Message-Id: <9312050159.AA06530@void.ncsa.uiuc.edu>
Date: Sat, 4 Dec 1993 19:59:07 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI/1.0: last call

/*
 * Re: CGI/1.0: last call  by ts (decoux@moulon.inra.fr)
 *    written on Dec  4,  4:12pm.
 *
 * > 
 * > I have written the CGI specification into a set of HTML documents, at URL
 * > http://hoohoo.ncsa.uiuc.edu/cgi/
 * > 
 * 
 *  Sorry, but I don't see header lines in the standard input,
 * 
 *  Do you send header lines before extra-information ?
 */

No, we found that the server had to parse some of the header anyway, and
therefore did not make the header lines available to the script for
implementation reasons. Is there something from the header you'd like to see
that isn't in the spec?

--Rob



From robm@ncsa.uiuc.edu  Sat Dec  4 20:12:59 1993 -0600
Message-Id: <9312050213.AA06691@void.ncsa.uiuc.edu>
Date: Sat, 4 Dec 1993 20:12:59 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI/1.0: last call (fwd)

/*
 * Re: CGI/1.0: last call (fwd)  by John Franks (john@math.nwu.edu)
 *    written on Dec  4, 10:09am.
 *
 * Generally very good.  I have no problems with the spec.  I also would
 * like to see the examples Ari mentions.  In fact it would be nice if
 * there were simple minded examples of almost everything.  Not example
 * scripts, but something along the lines of
 * 
 * ------------------
 * Script writes to stdout:
 * 
 * 	Location: http://hoohoo.ncsa.uiuc.edu/cgi/
 * 
 * Server action:
 * 
 * 	Issues HTTP/1.0 redirect message redirecting to URL
 * 		http://hooh0.ncsa.edu/cgi/
 * 
 * ------------------

I'll add examples to everything to make things clearer.

 * Also I find the following passage somewhat unclear:
 * 
 * > The command line is only used in the case of an ISINDEX query. It is
 * > not used in the case of an HTML form or any as yet undefined query
 * > type. The server should search the query information for a non-encoded
 * > + character to determine if the command line is to be used.
 * 
 * > If the server finds one, it will decode the query information by first
 * > splitting it on the pluses given in the URL. It will then perform the
 * > additional decoding before placing the resulting words on
 * > argv[1....].
 * 
 * > If the server finds that it cannot send the string due to internal
 * > limitations (such as exec() or /bin/sh command line restrictions) the
 * > server should include NO command line information and provide the
 * > non-decoded query information in the environment variable
 * > QUERY_STRING.
 * 
 * I assume the query information is everything after the ? in the URL.

Yep. 

 * Will the client always put a + in this string?  What if it is a single
 * word search term?  I guess I don't understand how the + works to
 * determine whether or not to use the command line.  What does the
 * server do if there is no + so it shouldn't the commannd line?
 * (presumably it does the same thing it does when command line
 * retstrictions prevent it from using the command line.)  Examples here
 * would help a lot.  Probably I don't understand this because I haven't
 * been paying attention, but of course new people will need to read this
 * document without the benefit of the discussion in its creation.

Hmmm. This is a problem. I hadn't thought of that. To answer your question,
a plus would only appear in an isindex query, since we are trusting the
client to % encode spaces in form requests. However, I had forgotten that
not all ISINDEX queries will have a + in them. 

Perhaps instead of using a + to test if a given request is an isindex
request, perhaps we should use whether there is an = in the request to
detect if it's a form request and only decode if it's not a form request.

The problem with that is that it leaves room for error in future
endeavors... what if the next FORMS+ interface doesn't have = in it? The
server shouldn't decode the string but it will if it doesn't find an =
sign...

 * Should the server always put the query information in the variable 
 * QUERY_STRING, even when using the command line?

Yes.

 * I have no quibble, but is there a rationale for decoding for the
 * command line and not for the QUERY_STRING?  Also a reference to what
 * it means to decode the query information, i.e. say it means the
 * standard URL decoding and give a reference for that.

Some scripts will want the query information untouched, which is what
QUERY_STRING is for. Decoding the command line for ISINDEX scripts is to
reduce the load on small script writers.

 * A final nit. I would find it easier to read (and print) if it were a
 * single html doc with internal links rather than several html docs with
 * hyperlinks.
 * 
 * 
 * 
 * John Franks 	Dept of Math. Northwestern University
 * 		john@math.nwu.edu
 * 
 */



From robm@ncsa.uiuc.edu  Sat Dec  4 20:13:29 1993 -0600
Message-Id: <9312050213.AA06699@void.ncsa.uiuc.edu>
Date: Sat, 4 Dec 1993 20:13:29 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI/1.0: last call (fwd)

/*
 * CGI/1.0: last call (fwd)  by ts (decoux@moulon.inra.fr)
 *    written on Dec  4,  5:31pm.
 *
 * 
 * > Should the server always put the query information in the variable 
 * > QUERY_STRING, even when using the command line?
 * 
 *  Yes, I want always this information in QUERY_STRING
 * 
 * Guy Decoux
 */

Yes, it always should be in there. I'll update the docs to be more specific.

--Rob




From robm@ncsa.uiuc.edu  Sat Dec  4 19:52:11 1993 -0600
Message-Id: <9312050152.AA06499@void.ncsa.uiuc.edu>
Date: Sat, 4 Dec 1993 19:52:11 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re:  CGI/1.0: last call

/*
 * Re:  CGI/1.0: last call  by Robert S. Thau (rst@ai.mit.edu)
 *    written on Dec  4,  2:56pm.
 *
 * A belated minor request --- it would be good if there were an environment
 * variable which contained the IP address of the remote host (in addition to
 * REMOTE_HOST, which as I read the spec, is just the DNS hostname).  Perhaps
 * REMOTE_HOSTADDR would do.
 * 
 * This would allow scripts to easily use all the same authentication criteria
 * as the http servers themselves allow, including criteria based on subnet
 * masking, which may not be reflected in the DNS structure.
 */

Updated.

--Rob



From marca@ncsa.uiuc.edu  Sat Dec  4 21:57:56 1993 -0800
Message-Id: <9312050557.AA15565@wintermute.ncsa.uiuc.edu>
Date: Sat, 4 Dec 93 21:57:56 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Re: CGI/1.0: last call (fwd)

Rob McCool writes:
> Perhaps instead of using a + to test if a given request is an isindex
> request, perhaps we should use whether there is an = in the request to
> detect if it's a form request and only decode if it's not a form request.

Yup!  Use =.

> The problem with that is that it leaves room for error in future
> endeavors... what if the next FORMS+ interface doesn't have = in it? The
> server shouldn't decode the string but it will if it doesn't find an =
> sign...

The next forms interface will use POST or something similar.  Testing
for lack of = to determine ISINDEX is safe.

Marc




From marca@ncsa.uiuc.edu  Sun Dec  5 01:48:50 1993 -0800
Message-Id: <9312050948.AA16357@wintermute.ncsa.uiuc.edu>
Date: Sun, 5 Dec 93 01:48:50 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: HTTP MIme content-type parameters

Jim Davis writes:
> The HTTP draft RFC violates the MIME RFC 1341 specification for the
> use of parameters in content types.  There are two problems.
> 
> 1) The MIME RFC states that parameters are separated from the subtype
> by a semi-colon, e.g.
> 
>  text/plain; charset=us-ascii
> 
> But the HTTP draft says uses semi-colon to separate alternative
> content-types, and uses comma to separate parameters.
> 
> HTTP should change to conform to MIME, e.g. the example on p 8 should
> be:
> 
> Accept: text/x-dvi; q=.8;mxb=10000;xmt=5.0, text/x-c
>
> 2) The MIME spec considers period to be a tspecial, which means it is
> forbidden to use it within a token.  It must instead be quoted.  So
> the example on page 8 should be:
> 
> Accept: text/x-dvi; q=".8";mxb=10000;xmt="5.0", text/x-c
> 
> Can we agree to bring the HTTP spec in line with MIME standard?

I think this is essential.  Anyone have a problem with the proposed
changes?  Tim?

Cheers,
Marc




From marca@ncsa.uiuc.edu  Sun Dec  5 02:00:55 1993 -0800
Message-Id: <9312051000.AA16444@wintermute.ncsa.uiuc.edu>
Date: Sun, 5 Dec 93 02:00:55 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Re: proposal for new HTTP/1.0 directive

Rob McCool writes:
> /*
>  * proposal for new HTTP/1.0 directive  by Marc Andreessen (marca@ncsa.uiuc.edu)
>  *    written on Nov 27,  2:28pm.
>  *
>  * It occasionally is useful to have the results of a HTTP/1.0
>  * transaction return *nothing* (no significant response data) -- the
>  * client should not display a new document or do anything else other
>  * than stay on exactly the same document it's already on.
>  * 
>  * An example of where this would be useful: tape-deck-style
>  * fast-forward/stop/reverse/play/pause/etc. controls implemented with
>  * forms or hyperlinks as part of a multicasting transmission
>  * application.  You want to be able to trigger as many actions as you
>  * want (play, pause, play, fast-forward, play, etc.) without moving to a
>  * different document each time.
>  * 
>  * How about "204 NoResponse"?
>  */
> 
> I second the motion. I've gotten several people asking for a way to do that
> exact thing from scripts.

Having received no other comments, I'm going to code it for Mosaic
2.1.  Tim, can you add it to the spec?

Marc




From marca@ncsa.uiuc.edu  Sun Dec  5 02:31:47 1993 -0800
Message-Id: <9312051031.AA16590@wintermute.ncsa.uiuc.edu>
Date: Sun, 5 Dec 93 02:31:47 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Re: HTML draft - clarification of quoted string processing

Dave_Raggett writes:
> Bryan Cheung writes:
> 
> > I may just be blind, but I don't see a place in the HTML spec which 
> > describes what is supposed to happen to special characters inside quoted
> > strings. Consider an HTML statement such as:
> 
> > <form method=post action="/htbin-post/banner hello > foobar">

Heavily illegal.  The special characters should be encoded, as usual,
as %xx.  (This is because ACTION specifies a URL.)

> >  ...form goes here
> > </form>
> 
> > My question relates to how the i/o redirection character (or any special
> > character) is to be treated when used within quotes inside of a standard
> > HTML directive. Should special characters be completely protected when
> > quoted inside of a directive?? Does it make sense to specify that escapes
> > such as &gt; be used within quoted strings? Where should this go in the
> > spec? (I looked for it, and can't find it - please point me there if I
> > missed it.
> 
> Page 331 of Goldfarb's SGML Handbook says that parsers derive the attribute
> value from the attribute value literal (the stuff between the quote marks)
> by replacing any entity references or character references within the literal
> and then normalising by replacing any contiguous whitespace by a single
> space character. Note you can use " or ' as quote marks for attribute value
> literals.
> 
> Thanks for pointing out this topic - it is rather obscure and clearly needs
> to be included in the HTML+ spec. I can garantee that most browsers are
> currently doing the wrong thing for attributes!

Bleah.  Let's be more restrictive.  An encoding method exists for URLs
anyway; other attributes/values can be limited to reasonable characters.
This keeps things simple.

Marc




From decoux@moulon.inra.fr  Sun Dec  5 09:45:51 1993 +0100
Message-Id: <9312050845.AA14699@moulon.moulon.inra.fr>
Date: Sun, 5 Dec 93 09:45:51 +0100
From: decoux@moulon.inra.fr (ts)
Subject: CGI/1.0: last call


> No, we found that the server had to parse some of the header anyway, and
> therefore did not make the header lines available to the script for
> implementation reasons. Is there something from the header you'd like to see
> that isn't in the spec?

 Yes, I want header line "authenticate" to have the password for the
username or an environemental variable with "username:password" uuencoded.

 Thanks,

Guy Decoux




From decoux@moulon.inra.fr  Sun Dec  5 11:09:39 1993 +0100
Message-Id: <9312051009.AA15297@moulon.moulon.inra.fr>
Date: Sun, 5 Dec 93 11:09:39 +0100
From: decoux@moulon.inra.fr (ts)
Subject: CGI/1.0: last call


>> No, we found that the server had to parse some of the header anyway, and
>> therefore did not make the header lines available to the script for
>> implementation reasons. Is there something from the header you'd like to see
>> that isn't in the spec?
>
> Yes, I want header line "authenticate" to have the password for the
>username or an environemental variable with "username:password" uuencoded.

 Sorry, there is a bug ... it is header line "authorization" and not
"authenticate".

Guy Decoux



From luotonen@ptsun00.cern.ch  Sun Dec  5 13:40:08 1993 +0100
Message-Id: <9312051240.AA13709@ptsun03.cern.ch>
Date: Sun, 5 Dec 93 13:40:08 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: Re: CGI/1.0: last call


> >> No, we found that the server had to parse some of the header anyway, and
> >> therefore did not make the header lines available to the script for
> >> implementation reasons. Is there something from the header you'd like to see
> >> that isn't in the spec?
> >
> > Yes, I want header line "authenticate" to have the password for the
> >username or an environemental variable with "username:password" uuencoded.
> 
>  Sorry, there is a bug ... it is header line "authorization" and not
> "authenticate".

No.  Password should be kept inside the server for security reasons.
The environment variable REMOTE_USER is only defined if user has
successfully authenticated himself.  This should be enough.


-- Cheers, Ari --




From decoux@moulon.inra.fr  Sun Dec  5 13:40:59 1993 +0100
Message-Id: <9312051240.AA15703@moulon.moulon.inra.fr>
Date: Sun, 5 Dec 93 13:40:59 +0100
From: decoux@moulon.inra.fr (ts)
Subject: Re: CGI/1.0: last call

> No.  Password should be kept inside the server for security reasons.
> The environment variable REMOTE_USER is only defined if user has
> successfully authenticated himself.  This should be enough.
> 
> 

 I *need* a password to open an Oracle database,  I don't want to write
a cracker to retrieve it from password file.

 username:password can be send in stdin.

Guy Decoux




From neuss@igd.fhg.de  Sun Dec  5 15:48:34 1993 +0100
Message-Id: <9312051448.AA10448@wildturkey.igd.fhg.de>
Date: Sun, 5 Dec 93 15:48:34 +0100
From: neuss@igd.fhg.de (neuss@igd.fhg.de)
Subject: Re: CGI/1.0: last call (fwd)

Rob McCool wrote:
> Perhaps instead of using a + to test if a given request is an isindex
> request, perhaps we should use whether there is an = in the request to
> detect if it's a form request and only decode if it's not a form request.

> The problem with that is that it leaves room for error in future
> endeavors... what if the next FORMS+ interface doesn't have = in it? The
> server shouldn't decode the string but it will if it doesn't find an =
> sign...

Uhm.. I must be overlooking something.. as far as I have understood it, 

issuing an ISINDEX query will result in a URL like 

  "http://server.some.where/oldpath/oldfile?word",
where oldpath/file points to the document that the query was issued from,
while a form request will point to a virtual file in the /htbin dir.

Isn't that the easiest way to find whether it was a FROM request or an
ISINDEX query?

Confused, 

Chris
--
/*
 *  Christian Neuss  %  neuss@igd.fhg.de  %  ..in the humdrum
 */



From luotonen@ptsun00.cern.ch  Sun Dec  5 16:21:57 1993 +0100
Message-Id: <9312051521.AA13805@ptsun03.cern.ch>
Date: Sun, 5 Dec 93 16:21:57 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: Re: CGI/1.0: last call (fwd)


> > The problem with that is that it leaves room for error in future
> > endeavors... what if the next FORMS+ interface doesn't have = in it? The
> > server shouldn't decode the string but it will if it doesn't find an =
> > sign...
> 
> Uhm.. I must be overlooking something.. as far as I have understood it, 
> 
> issuing an ISINDEX query will result in a URL like 
> 
>   "http://server.some.where/oldpath/oldfile?word",
> where oldpath/file points to the document that the query was issued from,
> while a form request will point to a virtual file in the /htbin dir.

Form request doesn't necessarily start with /htbin -- there may be
URLs that seem to point to regular files, but which are actually
mapped to scripts generating those files.

And Rob, ?queries in non-full URLs in Location: can be handled
directly by server without explicit redirection; only #labels
pose a problem since they are solely meant for the client.


-- Cheers, Ari --






From decoux@moulon.inra.fr  Sun Dec  5 16:19:57 1993 +0100
Message-Id: <9312051519.AA16088@moulon.moulon.inra.fr>
Date: Sun, 5 Dec 93 16:19:57 +0100
From: decoux@moulon.inra.fr (ts)
Subject: Re: CGI/1.0: last call (fwd)

> Uhm.. I must be overlooking something.. as far as I have understood it, 
> 
> issuing an ISINDEX query will result in a URL like 
> 
>   "http://server.some.where/oldpath/oldfile?word",
> where oldpath/file points to the document that the query was issued from,
> while a form request will point to a virtual file in the /htbin dir.
> 
> Isn't that the easiest way to find whether it was a FROM request or an
> ISINDEX query?
> 

 If for the browser , URL is :

   http://server/htbin/script/pathname

 With ISINDEX the URL is always "http://server/htbin/script/pathname?aaa"


Guy Decoux




From Axel.Belinfante@cs.utwente.nl  Sun Dec  5 16:36:32 1993 +0100
Message-Id: <9312051536.AA20918@utis179.cs.utwente.nl>
Date: Sun, 05 Dec 93 16:36:32 +0100
From: Axel.Belinfante@cs.utwente.nl (Axel Belinfante)
Subject: Re: Synchronized... 

marca@ncsa.uiuc.edu (Marc Andreessen) wrote:
> > Thus wrote "Q. Alex Zhao" <azhao@cc.gatech.edu> on Thu, 25 Nov 93 13:12:33 EST:
> > 
> > > Can X-Mosaic handle "synchronized media"? Basically, I want the
> > > following effect:
> > > 
> > >  - There's a link; when I click on it, I will get a MPEG movie _AND_
> > >    some audio information.
> 
> One way to do this is to use a MIME message and have metamail fork off
> the requisite viewers.  This is splitting functionality, but it does
> work.

In addition to the above use of MIME multipart messages,
it would be nice to be able to return a html document together with
audio or video, it would eg be nice for my 'esperanto demo', as
it would allow me to combine:
    http://utis179.cs.utwente.nl:8001/esperanto/hypercourse/oficej.html
    http://utis179.cs.utwente.nl:8001/esperanto/hypercourse/oficej_au.html
(click on an object, see its name, _and_ hear its pronounciation).

I suppose that one could return a MIME message that contains both
html and audio, but if it is handled to metamail, where does the
html show up? A quick hack could be to write a 'html-viewer' script
that talks to Mosaic via the 'external control' feature (very nice, btw!).
Is there a similar way to do this with the other browsers? Or is there
a better way?

Some time ago someone, in comp.infosystems.www someone wanted to
return in one 'message' both a generated image and the generated html
'envelope' that contains it as inline image. Could this be expressed as
well via multipart types? Could external bodyparts map onto URL's?
If this has been discussed before, are there some pointers?

Regards,
Axel.

<Axel.Belinfante@cs.utwente.nl>   tel. +31 53 893774   fax. +31 53 333815
     University of Twente, Tele-Informatics & Open Systems Group
       P.O. Box 217    NL-7500 AE Enschede      The Netherlands
     "ili ne sciis ke estas neebla do ili simple faris" -- Loesje




From robm@ncsa.uiuc.edu  Sun Dec  5 16:44:07 1993 -0600
Message-Id: <9312052244.AA17585@void.ncsa.uiuc.edu>
Date: Sun, 5 Dec 1993 16:44:07 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI/1.0: last call (fwd)

/*
 * Re: CGI/1.0: last call (fwd)  by ts (decoux@moulon.inra.fr)
 *    written on Dec  5,  4:19pm.
 *
 *  If for the browser , URL is :
 * 
 *    http://server/htbin/script/pathname
 * 
 *  With ISINDEX the URL is always "http://server/htbin/script/pathname?aaa"
 */

Not necessarily... when someone accesses an ISINDEX script without any query
data the URL looks like http://server/htbin/script/pathname.

The safe way to do this, which is how the spec has been updated, is to
search for an = sign in the query data since form requests if they have any
query info must have this character somewhere.

--Rob



From robm@ncsa.uiuc.edu  Sun Dec  5 17:08:05 1993 -0600
Message-Id: <9312052308.AA17863@void.ncsa.uiuc.edu>
Date: Sun, 5 Dec 1993 17:08:05 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI/1.0: last call

/*
 * Re: CGI/1.0: last call  by ts (decoux@moulon.inra.fr)
 *    written on Dec  5,  1:40pm.
 *
 * > No.  Password should be kept inside the server for security reasons.
 * > The environment variable REMOTE_USER is only defined if user has
 * > successfully authenticated himself.  This should be enough.
 * 
 *  I *need* a password to open an Oracle database,  I don't want to write
 * a cracker to retrieve it from password file.
 * 
 *  username:password can be send in stdin.
 */

The problem is that the username:password style doesn't work with future PEM
and Kerberos based authentication schemes. 

I don't know if I agree with Ari's security objection, but making the
unencrypted passwords places a large amount of trust between script writers
and system administrators (not necessarily in your case, but in general when
scripts are commonly available software). This is really the only reason I
can see for not making the password available to the script. Have I missed
something?

I would ask that you reconsider how you are planning to do this, perhaps you
should maintain your own simple password file and grab the user's Oracle
password from this file. This way, people do not have their Oracle passwords
sent across the net, only their HTTP passwords, and in the future, only an
encrypted request. The drawback is that you have to maintain two password
files.

If this is completely unacceptable, or I have missed something, please let
me know. I'll consider making the Authorization: line available to the
script, but I am objected to it.

--Rob




From decoux@moulon.inra.fr  Mon Dec  6 07:28:30 1993 +0100
Message-Id: <9312060628.AA16696@moulon.moulon.inra.fr>
Date: Mon, 6 Dec 93 07:28:30 +0100
From: decoux@moulon.inra.fr (ts)
Subject: CGI/1.0: last call


> I don't know if I agree with Ari's security objection, but making the
> unencrypted passwords places a large amount of trust between script writers
> and system administrators (not necessarily in your case, but in general when
> scripts are commonly available software). This is really the only reason I
> can see for not making the password available to the script. Have I missed
> something?
>
> I would ask that you reconsider how you are planning to do this, perhaps you
> should maintain your own simple password file and grab the user's Oracle
> password from this file. This way, people do not have their Oracle passwords
> sent across the net, only their HTTP passwords, and in the future, only an
> encrypted request. The drawback is that you have to maintain two password
> files.

 I don't want the unencrypted password, I can write C (or perl) code to
decrypt an encrypted request. 

 My problem is to retrieve a password with only an username. I can maintain
two password files but I don't want to have on my server a file where
passwords are stored in plaintext.

 I'm paranoid ... Example, my file "/etc/passwd" is like this (C2) :

   root:##root:0:1:Operator:/:/bin/csh
   nobody:##nobody:65534:65534::/:
   daemon:##daemon:1:1::/:
   sys:##sys:2:2::/:/bin/csh
   bin:##bin:3:3::/bin:
   audit:##audit:9:9::/etc/security/audit:/bin/csh
   AUpwdauthd:##AUpwdauthd:10:10:AUpwdauthd pseudo user::/bin/false
   AUyppasswdd:##AUyppasswdd:11:10:AUyppasswdd pseudo user::/bin/false

    ....

> If this is completely unacceptable, or I have missed something, please let
> me know. I'll consider making the Authorization: line available to the
> script, but I am objected to it.

 I'll try another solution ...

 Thanks,

Guy Decoux



From roeber@vxcrna.cern.ch  Mon Dec  6 11:12:59 1993 +0100
Message-Id: <9312061013.AA07524@dxmint.cern.ch>
Date: Mon, 6 Dec 1993 11:12:59 +0100
From: roeber@vxcrna.cern.ch (Frederick G.M. Roeber)
Subject: Re: X Mosaic, FTP and PASV

Friday evening, I said:

>> If we had a place for storing information related to a document,
>> (do we?  There's talk about a "Hyperdoc" type in HTAnchor.c, but
>> it's never flushed out.), then the size (as a number) should be
>> put there.  Then all those browsers that currently give transfer
>> status in bytes could give it as a percentage.

Then Dave replied:
>
>In the HTML+ spec I introduced a SIZE attribute for anchors with
>this in mind. People persuaded me to take it out, but maybe we
>should put it back again :-)

Actually, I meant in the standard libwww C code..  I'm one of the
folks who's firmly in the "information like this doesn't belong
in the html anchor" camp myself.

I was thinking that if the in-memory structures the browsers used
for the document anchors had such spaces, then perhaps another 
selection (e.g., shift-m1 or m3) could get and display header 
information from protocols (like http) which support it.  Things
like ftp, where directory listings give it for free, would just
stick it in.

--
<a href="http://info.cern.ch/roeber/fgmr.html">Frederick</a>



From timbl@www3.cern.ch  Mon Dec  6 11:45:38 1993 +0100
Message-Id: <9312061045.AA03141@www3.cern.ch>
Date: Mon, 6 Dec 93 11:45:38 +0100
From: timbl@www3.cern.ch (Tim Berners-Lee)
Subject: Re: Synchronized... 


Axel Belinfante <Axel.Belinfante@cs.utwente.nl>asked on
Sun, 05 Dec 93 16:36:32 +0100

>Some time ago someone, in comp.infosystems.www someone wanted to
>return in one 'message' both a generated image and the generated  
html
>'envelope' that contains it as inline image. Could this be expressed  
as
>well via multipart types? Could external bodyparts map onto URL's?
>If this has been discussed before, are there some pointers?


Check out the HTTP spec -- It has multipart handling in,
subject to negotiation.   This followed from a discussion on
this list. The relevant bit is [hidden in ;-)]

http://info.cern.ch/hypertext/WWW/Protocols/HTTP/Object_Headers.html

The code is not yet added to HTMIME.c in libwww -- volunteers?

Tim BL



From fielding@simplon.ics.uci.edu  Mon Dec  6 05:38:21 1993 -0800
Message-Id: <9312060538.aa26370@paris.ics.uci.edu>
Date: Mon, 06 Dec 1993 05:38:21 -0800
From: fielding@simplon.ics.uci.edu (Roy T. Fielding)
Subject: RFC: Multi-Owner Maintenance robot (MOMspider)


This is an informal request for comments on some issues related to
maintaining large-scale WWW information resource sites (infobases)
and a proposed multi-owner maintenance robot (MOMspider) for assisting
that maintenance.  It assumes that the reader is familiar with the WWW,
HTML, and HTTP.

The purpose of this request is to get feedback on maintenance requirements
in order to incorporate them into pre-release versions of MOMspider. 
In addition, I have already uncovered some problems that will (eventually)
require additions to the HTTP and HTML specifications and would like to
hear what others think of these additions.

I am sending this message to both the www-talk mailing list and to
the newsgroup comp.infosystems.www in order to maximize responses both
from programmers and infobase authors.  Since I will be actively reading
both areas, feel free to respond to those lists or by personal e-mail
addressed to <fielding@ics.uci.edu>.  Please tell me if you want your
comments to remain private.

This began as a class project (for Dr. Mark Ackerman's graduate course
on Distributed Information Services here at UCI) but will continue
indefinitely in order to support our own maintenance needs.  Once a
stable version of MOMspider is developed, it will be publicly distributed
as freeware (including source code) with the usual public-domain terms.

BTW, I do know about James Pitkow's html_analyzer program, so there's
no need to remind me of it.  That program handles different, although
complementary, aspects of HTML maintenance (consistency and completeness)
which will be ignored by MOMspider.  This should in no way be considered
as a replacement for html_analyzer.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The Problem
-----------

The documents available at each server site can be considered a form
of information resource database (infobase).  The infobase often
contains a wide variety of information in the form of interlinked
documents which are maintained by a number of different document
owners (usually, but not necessarily, the original document authors).
Since this information is rarely static, the structure and contents of
the infobase are likely to change over time.  Documents may be moved or
deleted, referenced information may change, and hypertext links may be
broken.

As it grows, the infobase becomes more complex and difficult to
maintain.  Such maintenance effort currently relies upon the error
logs of each server (often never relayed to the document owners), the
complaints of users (often not seen by the actual document
maintainers), and periodic manual traversals by each owner of all the
webs for which they are responsible.  Since thorough manual traversal
of a web can be time-consuming and boring, the result is that
maintenance is rarely or inconsistently performed and the infobase
eventually becomes corrupted.  What is needed is an automated means for
traversing a web of documents and checking for changes which may
require the attention of the human maintainers (owners) of that web.


Proposed Partial Solution
-------------------------

I propose to (at least partially) solve this maintenance problem by
building a robot client which can periodically traverse the webs of a
set of owners, check each web for any changes which may require its
owner's attention, and build a special index document for each owner
that lists out the attributes and connections of their web in a form
that can itself be traversed as a hypertext document.  This robot will
be called the Multi-Owner Maintenance spider (MOMspider).

MOMspider will look for three types of document change which may be of
interest to the owner:

   1) referenced objects which cannot be accessed (broken links);
   2) referenced objects with recent modification dates; and,
   3) owned objects with past expiration dates. 

MOMspider will (in effect) recursively traverse each owner's web from
a specified "top" document down to each leaf node, where a leaf node
is defined to be any information object which is not of document-type
HTML, is owned by a different or unspecified owner, or is interactively
generated by some program (i.e. a script or query).  [I may also include
a special mode wherein owner=all and the web is traversed for all links
at a particular site.]

As MOMspider analyzes each owner's web, it will build an index
document (complete with cross-references and links to the actual
documents) which contains the following entries:
[Note that this is an index in the traditional sense, not an <ISINDEX>]

 o  Information regarding how and when the index was generated
    (i.e. program options and execution time);

 o  A hypertext link to the one prior version of the index document;

 o  The following for each document owned and accessible via the "top":

    -- An anchor which links to the actual document;
    -- Document header info (Title, Modification Date, Expires Date);
    -- A list of all unique hypertext references made by the document.

 o  Each hypertext reference item will include:

    -- The type of reference made (i.e. get, query, ftp, script, etc.);
    -- An anchor which duplicates the reference;
    -- Document header info if available (Title and Modification Date);
    -- If the referenced object is owned by the current owner, then an
       additional anchor is provided to cross-reference jump to its
       own entry in the index document.

 o  A list of cross-reference anchors which point to interesting changes
    as reflected in the index entries.


The MOMspider program will be designed in such a way as to maximize
flexibility for each web owner.  This will be achieved through the use
of an external configuration file, read at the beginning of the
process, containing owner names and their associated set of program
options, top document URL, and e-mail address.  This allows the owner
of a document to be specified by an alias name rather than their true
name or e-mail address, thus preventing broadcast of that information
to all readers of the document.

When a suspected change is found, each owner will have the option of
being automatically notified of the list of changes via an e-mail
message.  The message will, as an added convenience, also include a
hypertext link to the owner's generated index document.

A key design constraint of MOMspider is that of efficiency -- both in
terms of execution time and network bandwidth usage.  It would be
irresponsible to develop a maintenance robot which overly taxed the
limited resources of the Internet.  Therefore, MOMspider will be
designed to keep track of where it has been (to avoid cycles and
needless repetition) and to use the HTTP request "HEAD" to locate
documents and examine their type and owner without transmitting the
document body.


Implementation Details
----------------------

The MOMspider program will be a WWW client with the expectation that
it will be run on a regular basis (i.e. perhaps as a crontab entry).

It will probably be written in Perl, although I may default to C if
I run into problems (as I have much more experience with C).  The
initial implementation will be designed to be portable, but I will
only be able to test it on Suns running SunOS 4.1.2.  Of course,
since the code will be in the public domain, others will be free to
port it to additional platforms.

Due to deficiencies in the HTTP and HTML specs, the initial versions
will require some small changes to maintained sites' httpd server and
a special information comment entered at the top of maintained HTML files.
Hopefully, these changes will eventually be obsoleted by changes to the
official HTTP and HTML specs.

Each maintained HTML file would include an HTML comment of the following
format as the first line of the file:

<!-- MOM Owner="AnyAuthorAlias" Expires="31 Dec 1993" -->

where the Expires parameter is optional.  In BNF (with literals surrounded
by single quotes `'), this would be:

   MOMtag      ::= `<!-- MOM ' OwnerParam [` ' ExpireParam] ` -->'

   OwnerParam  ::= `Owner="' AliasName `"'

   AliasName   ::= CDATA (max 20 characters)

   ExpireParam ::= `Expires="' Date `"'

   Date        ::= DD Mmm YYYY

Note that since this added line is a comment, it will have no effect on
existing servers or clients.

HTTP servers which want to serve documents maintainable by MOMspider would
need to parse the above MOMtag and send the information as headers in a
response to any GET or HEAD request for that document.  These headers would
appear after the HTTP status response and before the MIME headers.
The OwnerParam would be translated and output as an "Owner:" header
[or should this be WWW-Owner: or MOM-Owner: ???].  The ExpireParam
(if present) would be translated into an RFC850/RFC822 date format
(with time of 00:00:00 GMT) and output as an "Expires:" header as per the
HTTP/1.0 specification.   For example, a HEAD request on a document with

<!-- MOM Owner="RTF" Expires="01 Jan 1994" -->

as its first line would result in an OK response something like:

-----------------------------------------------------------
HTTP/1.0 200 OK
Owner: RTF
Expires: Sat, 1 Jan 1994 00:00:00 GMT
Date: Wed Nov 24 09:59:53 1993 GMT
Server: NCSA/1.0a5
MIME-version: 1.0
Content-type: text/html
Last-modified: Wed Nov 24 09:01:39 1993 GMT
Content-length: 32576
-----------------------------------------------------------

[Actually, I just noticed that the Date: and Last-modified: headers
output by NCSA httpd/1.0a5 are not compliant with RFC850.  Will this
be fixed in the next version???]


Proposed Changes to HTML and HTTP
---------------------------------

Obviously, the above method of getting the owner and expiration date
output is a bit of a kluge.  I would prefer to have official HTML
metainformation elements for OWNER and EXPIRES which would be optionally
specified within the HEAD element (similar to the TITLE element).
Similarly, the HTTP response would include that metainformation as
appropriate headers (note that this has already been suggested for
the Expires header but I haven't seen any mention of how the expire
date would be obtained from normal HTML files).

The relevant changes to the HTML DTD would be something like this:

-----------------------------------------------------------
<!ELEMENT HEAD - -  ( TITLE?  & ISINDEX?  & NEXTID?  & LINK* 
                              & BASE?     & OWNER?   & EXPIRES? )>

<!ELEMENT OWNER - -  CDATA    -- Alias name for document owner -->

<!ELEMENT EXPIRES - -  CDATA  -- Expiration date in RFC850 format -->
-----------------------------------------------------------

One point which I think may spark discussion is whether we should
specify the Owner as a LINK relationship rather than as its own
element.  I decided not to do so for reasons of efficiency and
understandability.  If the owner was specified as a LINK, MOMspider
(and any similar clients) would have to parse through all the fields
of every LINK header in order to find an owner relationship.
Furthermore, the document author would have to build a contrived
reverse LINK relationship with fields normally used for document
references -- a concept which is counter to understandability and
everything I know about software engineering.  I believe that the
notion of document ownership is encountered frequently enough to
justify a special HTML element for that purpose.

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Well, that should be enough to generate some healthy debate.
Please, please, please tell me if you think I have missed some
requirement or misinterpreted some part of WWW.

In about a week I will place this document (with corrections and
public comments) on our local WWW server (under construction) and
publish the URL.  Once I'm satisfied with the code, I'll also be
looking for additional test sites, so let me know if you want an
advance copy before the general release.


....Roy T. Fielding                                 (fielding@ics.uci.edu)   
    Department of Information & Computer Science            (714)856-4049
    University of California, Irvine, CA 92717-3425



From P.Lister@cranfield.ac.uk  Mon Dec  6 14:38:06 1993 GMT
Message-Id: <9312061438.AA03185@xdm039.ccc.cranfield.ac.uk>
Date: Mon, 06 Dec 93 14:38:06 GMT
From: P.Lister@cranfield.ac.uk (Peter Lister, Cranfield Computer Centre)
Subject: Re: CGI/1.0: last call

> Authentication must be the responsibility of the script writer.  While

What he said. Any authentication mechanism must allow for any
authentication data to be passed to the server. I want to write HTML
front ends to various Kerberos authenticated doobreys, and I MUST be
able to pass a ticket to the server, and preferably also encrypted data
using the Kerberos session key.

Peter Lister                             Email: p.lister@cranfield.ac.uk
Computer Centre, Cranfield University    Voice: +44 234 754200 ext 2828
Cranfield, Bedfordshire MK43 0AL UK        Fax: +44 234 750875
--- Widget. It's got a widget. A lovely widget. A widget it has got. ---



From koblas@netcom.com  Mon Dec  6 07:26:10 1993 -0800
Message-Id: <199312061526.HAA20862@mail.netcom.com>
Date: Mon, 6 Dec 1993 07:26:10 -0800
From: koblas@netcom.com (David Koblas)
Subject: International Document Server Support


Has anyone given this any thought, here is my problem/idea?

What I'm trying to do is create a WWW server that has multiple language
versions version of the same documents (ie. a top.html in both English
and Norwegian).  What would be nice to do is display the English version
by default, and the Norwgian to people interested in it.)  I would
prefer not having to do this via the Kiosk method of "click on your flag".

Now how to solve this problem;  I would think the best way to solve this
is to have a clients post a message that they accept:
        language/norwegian
        language/english
is this reasonable, or should there be a better way?

Thanks,
--koblas@netcom.com



From dsr@hplb.hpl.hp.com  Mon Dec  6 15:40:56 1993 GMT
Message-Id: <9312061540.AA05582@manuel.hpl.hp.com>
Date: Mon, 6 Dec 93 15:40:56 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: RFC: Multi-Owner Maintenance robot (MOMspider)

> <!ELEMENT HEAD - -  ( TITLE?  & ISINDEX?  & NEXTID?  & LINK* 
>                              & BASE?     & OWNER?   & EXPIRES? )>
> <!ELEMENT OWNER - -  CDATA    -- Alias name for document owner -->
> <!ELEMENT EXPIRES - -  CDATA  -- Expiration date in RFC850 format -->

Your suggestion for a multi-owner maintenance robot (MOMspider) seems
a good one, and I like the idea for making the owner and expiry date
part of the document HEAD. I never did like the <LINK REL="MADE" HREF=...">
notation. Perhaps we ought to stipulate the OWNER should be an email address?

When viewing a document with markup errors, or broken links, who should
the reader  mail - the author or the admin staff, e.g. www-admin@host?
The author may want responsibility, or the document may have been produced
automatically. Perhaps we should use an additional attribute, what do you
think?

I will be happy to include this in the revised HTML+ spec - so long
as there isn't vociferous feelings against the idea on the net.

Dave Raggett



From Gisle.Aas@nr.no  Mon Dec  6 18:09:54 1993 +0100
Message-Id: <9312061709.AA08652@nora.nr.no>
Date: Mon, 6 Dec 93 18:09:54 +0100
From: Gisle.Aas@nr.no (Gisle.Aas@nr.no)
Subject: Re: International Document Server Support

koblas@netcom.com  writes:
> What I'm trying to do is create a WWW server that has multiple language
> versions version of the same documents (ie. a top.html in both English
> and Norwegian).  What would be nice to do is display the English version
> by default, and the Norwgian to people interested in it.)  I would
> prefer not having to do this via the Kiosk method of "click on your flag".
> 
> Now how to solve this problem;  I would think the best way to solve this
> is to have a clients post a message that they accept:
>         language/norwegian
>         language/english
> is this reasonable, or should there be a better way?

That's the right way (it think), but I don't know any client that
provide this header information to the server.  I have implemented a
gateway (for Plexus) that selects the language based on the domain
name of the client.  This means that for instance clients that run on
hosts with names that ends with .no, get Norwegian replies while all
others get English replies.

Have a look at http://www.nr.no/demo/gateways.html

--Gisle



From montulli@stat1.cc.ukans.edu  Mon Dec  6 11:26:45 1993 CST
Message-Id: <9312061726.AA24583@stat1.cc.ukans.edu>
Date: Mon, 6 Dec 93 11:26:45 CST
From: montulli@stat1.cc.ukans.edu (Lou Montulli)
Subject: Re: RFC: Multi-Owner Maintenance robot (MOMspider)

> 
> > <!ELEMENT HEAD - -  ( TITLE?  & ISINDEX?  & NEXTID?  & LINK* 
> >                              & BASE?     & OWNER?   & EXPIRES? )>
> > <!ELEMENT OWNER - -  CDATA    -- Alias name for document owner -->
> > <!ELEMENT EXPIRES - -  CDATA  -- Expiration date in RFC850 format -->
> 
> Your suggestion for a multi-owner maintenance robot (MOMspider) seems
> a good one, and I like the idea for making the owner and expiry date
> part of the document HEAD. I never did like the <LINK REL="MADE" HREF=...">
> notation. Perhaps we ought to stipulate the OWNER should be an email address?

I support this very strongly.  I can't tell you how many comments I get
saying, "you made a typo on this page" where the Lynx user assumes that
their comment is going to the document owner (like it should).

I think that the document owners would really appreciate getting this
information :)  Rather than me having to return the message and say.
"That document has no defined owner, you might try sending your comment
to webmaster@host, but there's no guarantee that it will get through."
Most people don't bother at that point.


:lou

> 
> When viewing a document with markup errors, or broken links, who should
> the reader  mail - the author or the admin staff, e.g. www-admin@host?
> The author may want responsibility, or the document may have been produced
> automatically. Perhaps we should use an additional attribute, what do you
> think?
> 
> I will be happy to include this in the revised HTML+ spec - so long
> as there isn't vociferous feelings against the idea on the net.
> 
> Dave Raggett
> 


-- 
  **************************************************************************
  *           T H E   U N I V E R S I T Y   O F   K A N S A S              *
  *         Lou  MONTULLI @ Ukanaix.cc.ukans.edu                           *
  *                         Kuhub.cc.ukans.edu      ACS Computing Services *
  *     913/864-0436        Ukanvax.bitnet             Lawrence, KS 66044  *
  *             UNIX! Cool! I know that!  Jurassic Park - The Movie        *
  **************************************************************************



From sanders@bsdi.com  Mon Dec  6 11:58:41 1993 -0600
Message-Id: <199312061758.LAA05294@austin.BSDI.COM>
Date: Mon, 06 Dec 1993 11:58:41 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: CGI/1.0: last call 

bobj  <jern@spaceaix.jhuapl.edu> writes:
> Authentication must be the responsibility of the script writer.  While

Authentication must be the responsibility of the server.  If you want to
easily extend the possible authentication schemes then define a spec for
authentication scripts, but they should remain seperate from normal scripts,
which should not have to deal with authentication, that would be a HUGE
security hole.

--sanders



From sanders@bsdi.com  Mon Dec  6 12:18:23 1993 -0600
Message-Id: <199312061818.MAA05368@austin.BSDI.COM>
Date: Mon, 06 Dec 1993 12:18:23 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: International Document Server Support 

> Has anyone given this any thought, here is my problem/idea?
Yes, this is a core part of the WWW design (though still unimplemented).

> What I'm trying to do is create a WWW server that has multiple language
...
> Now how to solve this problem;  I would think the best way to solve this
> is to have a clients post a message that they accept:
>         language/norwegian
>         language/english
> is this reasonable, or should there be a better way?

Well, you wouldn't use "language/english" but pretty close.  What you
do is pass this information along with the Accept: headers, e.g.:
    Accept: plain/text,language="ISO3316",charset="..."
Of course, the server must be configured to do something useful with
this information (which nobody does yet), but your server could.
Also, you'll need the user's client to be able to configure this information.

Some more information in this general area:
    http://www.bsdi.com/HTTP:TNG/MIME-ClientProfile.html

--sanders



From mjr@syl.dl.nec.com	(Matt  Mon Dec  6 12:44:00 1993 -0600 (CST)
Message-Id: <9312061844.AA15594@nebraska.syl.dl.nec.com>
Date: Mon, 6 Dec 1993 12:44:00 -0600 (CST)
From: mjr@syl.dl.nec.com	(Matt (Matt Ranney)
Subject: Re: International Document Server Support

Gisle.Aas@nr.no Writes...
) 
) > Now how to solve this problem;  I would think the best way to solve this
) > is to have a clients post a message that they accept:
) >         language/norwegian
) >         language/english
) > is this reasonable, or should there be a better way?

I would like this as well.  It seems the cleanest way.  It would, of
course, require modification of all the browsers.

) name of the client.  This means that for instance clients that run on
) hosts with names that ends with .no, get Norwegian replies while all
) others get English replies.

That works for some cases, but I have some users in my office who
would always want the Japanese versions if available, and most who'd
always want the English.  Since we're in the same office, not only is
the domain name the same, but many times even the hostname is
identical, since some people are on X-terminals.
-- 
Matt Ranney -  mjr@syl.dl.nec.com
  "You know, I don't think theres a man, woman, or child alive today
   who doesn't enjoy a lovely beverage."  -DL



From alanb@ncsa.uiuc.edu  Mon Dec  6 12:51:11 1993 CST
Message-Id: <9312061851.AA00671@void.ncsa.uiuc.edu>
Date: Mon, 6 Dec 93 12:51:11 CST
From: alanb@ncsa.uiuc.edu (Alan Braverman)
Subject: Re: International Document Server Support 

Tony Sanders writes:
> > Has anyone given this any thought, here is my problem/idea?
> Yes, this is a core part of the WWW design (though still unimplemented).
> 
> > What I'm trying to do is create a WWW server that has multiple language
> ...
> > Now how to solve this problem;  I would think the best way to solve this
> > is to have a clients post a message that they accept:
> >         language/norwegian
> >         language/english
> > is this reasonable, or should there be a better way?
> 
> Well, you wouldn't use "language/english" but pretty close.  What you
> do is pass this information along with the Accept: headers, e.g.:
>     Accept: plain/text,language="ISO3316",charset="..."
> Of course, the server must be configured to do something useful with
> this information (which nobody does yet), but your server could.
> Also, you'll need the user's client to be able to configure this information.
> 
> Some more information in this general area:
>     http://www.bsdi.com/HTTP:TNG/MIME-ClientProfile.html
> 
> --sanders

On the subject, check out

  http://www.ntt.jp/Mosaic-l10n/README.html

--
Alan Braverman
Software Development Group
National Center for Supercomputing Applications
alanb@ncsa.uiuc.edu



From jern@spaceaix.jhuapl.edu  Mon Dec  6 14:13:51 1993 -0500 (EST)
Message-Id: <9312061913.AA18055@sdrmis.jhuapl.edu>
Date: Mon, 6 Dec 1993 14:13:51 -0500 (EST)
From: jern@spaceaix.jhuapl.edu (jern@spaceaix.jhuapl.edu)
Subject: Re: CGI/1.0: last call

sanders@BSDI.COM writes:> 
> bobj  <jern@spaceaix.jhuapl.edu> writes:
> > Authentication must be the responsibility of the script writer.  While
> 
> Authentication must be the responsibility of the server.  If you want to
> easily extend the possible authentication schemes then define a spec for
> authentication scripts, but they should remain seperate from normal scripts,
> which should not have to deal with authentication, that would be a HUGE
> security hole.
Of course this is right.  In the context of the original message,
passwords for accessing Oracle were the question but my response to
that used language that was too general.  To try to put my comment
in context, assuming that the incoming query has traversed the network,
gained access to the machine, is granted access to the scripts and is
attempting to access an Oracle database, the *Oracle authentication*
is the responsibility of the person writing the Oracle access script.  It
would seem unreasonable to pass Oracle authentication requirements up
a layer or two into httpd.  It could be done but then httpd would
end up with and application/authentication-scheme token for each  
application requiring authentication. Ne c'est pas?  

I merely propose that application be done without:
1.  a user:password token
2.  an application/authentication-scheme in the www server daemon.

bobj 



From speyer@mcc.com  Mon Dec  6 13:20:49 1993 CST
Message-Id: <9312061920.AA11872@faith.mcc.com>
Date: Mon, 6 Dec 93 13:20:49 CST
From: speyer@mcc.com (Bruce Speyer)
Subject: Re: International Document Server Support

I don't see serving up International documents as different
from serving up different configurations or versions of documents.

Each configuration/internationalization of a document set is
kept in its own document source tree configuration with appropriate
links between documents.  Users reference what they want to access.

In other words, no changes required.
-Spy



From davis@dri.cornell.edu  Mon Dec  6 14:22:29 1993 -0500
Message-Id: <199312061922.AA03422@willow.tc.cornell.edu>
Date: Mon, 6 Dec 1993 14:22:29 -0500
From: davis@dri.cornell.edu (Jim Davis)
Subject: Re: International Document Server Support


Matt Ranney writes:
  Subject: Re: International Document Server Support
  Date: Mon, 6 Dec 1993 12:44:00 -0600 (CST)

  ...I have some users in my office who would always want the 
  Japanese versions if available, and most who'd always want the 
  English.  Since we're in the same office, not only is
  the domain name the same, but many times even the hostname is
  identical, since some people are on X-terminals.


One can express one's language preferences with the Accept-Language
header in the request message.  But there are two problems, one
specific to Accept-Language, the other more general

The problem with Accept-Language (it's really quite minor) is
that the HTTP specification is not yet written on this point.  In particular
the means of expressing preferences is not worked out.  Note that
Accept has a means of expressing preferences (the q parameter).  But
it's not clear how q from Accept (which deals with content TYPE)
ought to interact with q from Accept-Language.  Can you say
for instance that you would prefer written Dutch to spoken Dutch,
but spoken English to written English?  (als je kan Engels heel
goed pratten, maar je vindt nederlands een beetje moeilijk?)

So suppose we extend the spec so that Accept-Language allows one
to ask for just what one wants, and that servers are able to handle it.
But we still have the problem that there's no way (at present) for
the user to tell the client (Mosaic, tkWWW, Cello...) about his or
her preferences.  To give another  example

  The client  might need to encode preferences based on the
type of hardware available (e.g. on black and white monitor,
or workstation with real good audio).  IN this case the client
can express preferences automatically, based perhaps on
a template taken from the user. The user might change those preferences in real time, e.g. would rather see a low-resolution image first, to make
the search faster.  (So this is independent of the hardware).

Anyway, what this means is that implementors of clients (may they see long
life and happiness) should provide means to specify information
such as required by headers like Accept and Accept-Language.

Best wishes to all

 



From broccol@arlut.utexas.edu  Mon Dec  6 13:28:10 1993 -0600
Message-Id: <199312061928.NAA22850@csdsun1.arlut.utexas.edu>
Date: Mon, 6 Dec 1993 13:28:10 -0600
From: broccol@arlut.utexas.edu (Jonathan Abbey)
Subject: Re: International Document Server Support

> Well, you wouldn't use "language/english" but pretty close.  What you
> do is pass this information along with the Accept: headers, e.g.:
>     Accept: plain/text,language="ISO3316",charset="..."

So, English is now officially called "ISO3316"?  Sort of loses some
of the flavor.. 8-)


-------------------------------------------------------------------------------
Jonathan Abbey				      broccol@csdsun1a.arlut.utexas.edu
Applied Research Laboratories                 The University of Texas at Austin
-------------------------------------------------------------------------------



From timbl@dxcern.cern.ch  Mon Dec  6 20:24:25 1993 +0100 (MET)
Message-Id: <Pine.3.07.9312062019.A19717-b100000@dxcern.cern.ch>
Date: Mon, 6 Dec 1993 20:24:25 +0100 (MET)
From: timbl@dxcern.cern.ch (Timothy Berners-Lee)
Subject: Re: HTTP MIme content-type parameters



On Sun, 5 Dec 1993, Marc Andreessen wrote:

> Jim Davis writes:
> > The HTTP draft RFC violates the MIME RFC 1341 specification for the
> > use of parameters in content types.  There are two problems.
> > 
> > 1) The MIME RFC states that parameters are separated from the subtype
> > by a semi-colon, e.g.
> > 
> >  text/plain; charset=us-ascii
> > 
> > But the HTTP draft says uses semi-colon to separate alternative
> > content-types, and uses comma to separate parameters.
> > 
> > HTTP should change to conform to MIME, e.g. the example on p 8 should
> > be:
> > 
> > Accept: text/x-dvi; q=.8;mxb=10000;xmt=5.0, text/x-c

No problems with that -- I should have checked more thoroughly
that we were using it  in the same way.  It feels kinda
strange to have, unlike in English, commas having higher
precedence than semicolons; I guess I will get used to it though.

> > 2) The MIME spec considers period to be a tspecial, which means it is
> > forbidden to use it within a token.  It must instead be quoted.  So
> > the example on page 8 should be:
> > 
> > Accept: text/x-dvi; q=".8";mxb=10000;xmt="5.0", text/x-c
> > 
> > Can we agree to bring the HTTP spec in line with MIME standard?
> 
> I think this is essential.  Anyone have a problem with the proposed
> changes?  Tim?

Definitely. I want in the end to be able to use the same
parser for mailed MIME as well as HTTP MIME -- with as
few flags as possible! (like 0)

I'll make the changes when I'm back at my desk.
Thanks for pointing them out.
Tim





From timbl@dxcern.cern.ch  Mon Dec  6 20:36:38 1993 +0100 (MET)
Message-Id: <Pine.3.07.9312062036.C19717-b100000@dxcern.cern.ch>
Date: Mon, 6 Dec 1993 20:36:38 +0100 (MET)
From: timbl@dxcern.cern.ch (Timothy Berners-Lee)
Subject: Re: X Mosaic, FTP and PASV



On Mon, 6 Dec 1993, Frederick G.M. Roeber wrote:

> Friday evening, I said:
> 
> >> If we had a place for storing information related to a document,
> >> (do we?  There's talk about a "Hyperdoc" type in HTAnchor.c, but
> >> it's never flushed out.), then the size (as a number) should be
> >> put there.  Then all those browsers that currently give transfer
> >> status in bytes could give it as a percentage.
> 
...
> Actually, I meant in the standard libwww C code..  I'm one of the
> folks who's firmly in the "information like this doesn't belong
> in the html anchor" camp myself.
> 
> I was thinking that if the in-memory structures the browsers used
> for the document anchors had such spaces, then perhaps another 
> selection (e.g., shift-m1 or m3) could get and display header 
> information from protocols (like http) which support it.  Things
> like ftp, where directory listings give it for free, would just
> stick it in.

Every object which has a URI has, in the libwww, an
HTParentAnchor object which contains the metainformation.
Currenty we are extending it with for example pointers to cache
items. It has the address, and known links for the object.
The size is not in there but should be.

The name of the HTAnchor module is kinda related to the
name of the A element in SGML but it has a lot more.
In fact the HTChildAnchor subclass is the thing which 
exists for each <A>.

Tim





From luotonen@ptsun00.cern.ch  Mon Dec  6 20:50:02 1993 +0100
Message-Id: <9312061950.AA16392@ptsun03.cern.ch>
Date: Mon, 6 Dec 93 20:50:02 +0100
From: luotonen@ptsun00.cern.ch (Ari Luotonen)
Subject: Re: International Document Server Support


> > Well, you wouldn't use "language/english" but pretty close.  What you
> > do is pass this information along with the Accept: headers, e.g.:
> >     Accept: plain/text,language="ISO3316",charset="..."
> > Of course, the server must be configured to do something useful with
> > this information (which nobody does yet), but your server could.
> > Also, you'll need the user's client to be able to configure this information.
> > 
> > Some more information in this general area:
> >     http://www.bsdi.com/HTTP:TNG/MIME-ClientProfile.html
> > 
> > --sanders
> 
> On the subject, check out
> 
>   http://www.ntt.jp/Mosaic-l10n/README.html

There is also an Accept-Language header line in HTTP2 spec:

    http://www0.cern.ch/hypertext/WWW/Protocols/HTTP/HTRQ_Headers.html#z12

Accept-Language:
 
	Similar to Accept, but lists the Language values which are preferable
	in the response. A response in an unspecifies language is not illegal.
	See also: Language.
 
	Language coding TBS. (ISO standard xxxx) 

Content-Language: code
 
	The language code is the ISO code for the language in which
	the document is written. If the language is not known, this
	field should be omitted of course . 
 
	The language code is an ISO 3316 language code with an
	optional ISO639 country code to specify a national variant. 
 
	Example
 
                 Language: en_UK
 
 
	means that the content of the message is in British English,
	while 
                  Language: en
 
	means that the language is English in one of its forms.
	(@@ If a document is in more than one language, for
	example requires both Greek Latin and French to be
	understood, should this be representable?)
 
	See also: Accept-Language.

-- Cheers, Ari --



From WIGGINS@msu.edu  Mon Dec  6 14:55:26 1993 EST
Message-Id: <9312062000.AA18566@dxmint.cern.ch>
Date: Mon, 06 Dec 93 14:55:26 EST
From: WIGGINS@msu.edu (Rich Wiggins)
Subject: Redundant Web services?

There have been various discussions of caching and redundant services,
and a lot of this dovetails with Uniform Resource Identifier issues.
I'm curious if there are any prospects for a simple scheme for
implementing redundant servers in Webspace.

The Gopher protocol provides a scheme for identifying a redundant
service for a given document.  Believe it or not, this is in the
original Gopher spec -- the "+" data type (not to be confused with
Gopher+).   If an item has a plus type, then it's a redundant
location for the previous document.

This seems straightforward and very useful.  To my knowledge, it's
never been implemented.   Is there any chance that the Web community
could define a similarly straightforward scheme, and actually get it
implemented?

The particular inspiration for this is that lately we've had a lot
of trouble connecting to the home page at CERN.  A few weeks ago
there was an all-day outage of NCSA due to power failure.  Mirroring
of key sites would be very useful not just in terms of outages, but
also in the interest of load-balancing.

/Rich Wiggins, CWIS Coordinator, Michigan State U



From gehmeyr@forwiss.uni-passau.de  Mon Dec  6 21:19:55 1993 +0100 (MET)
Message-Id: <199312062019.AA26576@gildor.forwiss.uni-passau.de>
Date: Mon, 6 Dec 1993 21:19:55 +0100 (MET)
From: gehmeyr@forwiss.uni-passau.de (Andreas Gehmeyr)
Subject: gnuinfo2html?

Hiho,
is there somewhere a
gnuinfo (=emacsinfo) converter to HTML?
thanx,
Andi
-- 
<I>
I have something to say:      
It's better to <A NAME=id HREF="http://www.fmi.uni-passau.de/worterklaerungen/burnout.html">burn out</A> 
than to fade away!
</I>
<P>
<ADDRESS>
Andreas Gehmeyr, FORWISS Passau <P>
gehmeyr@forwiss.uni-passau.de<P>
http://www.fmi.uni-passau.de/forwiss/mitarbeiter/hiwis/gehmeyr.html
</ADDRESS>




From timbl@dxcern.cern.ch  Mon Dec  6 20:48:03 1993 +0100 (MET)
Message-Id: <Pine.3.07.9312062002.D19717-d100000@dxcern.cern.ch>
Date: Mon, 6 Dec 1993 20:48:03 +0100 (MET)
From: timbl@dxcern.cern.ch (Timothy Berners-Lee)
Subject: Re: RFC: Multi-Owner Maintenance robot (MOMspider)



On Mon, 6 Dec 1993, Roy T. Fielding wrote:
> Each maintained HTML file would include an HTML comment of the following
> format as the first line of the file:
> 
> <!-- MOM Owner="AnyAuthorAlias" Expires="31 Dec 1993" -->
> 
...
> Note that since this added line is a comment, it will have no effect on
> existing servers or clients.

I agree with your later classification of this as a kludge, and
would much prefer to use either the existing LINK element
or new elements. Note that the HTML spec requires browsers to
ignore elements they do not understand -- that is, to treat
them as though the tags were not there. As this would leave
the contents within the HEAD of a message, it seems reasonable
to interpret this to mean that the contents (which would not
otherwise be allowed in the HEAD part) should be ignored.
 
This gives you a transition path from trying it out on a small
scale to standardising on it -- without breaking anything on the
way.

> HTTP servers which want to serve documents maintainable by MOMspider would
> need to parse the above MOMtag and send the information as headers in a
> response to any GET or HEAD request for that document.

I would like to draw your attention to the comments in the HTTP spec
about WWW_Link: and the isomorphism between HTTP object header feilds
and HTML head elements.  Therer is is suggested that a formal
relationship be made, automatically defining one set in terms of
the other.

The next point is that, although the two specs have the
metainformation in common, they should be kept separate.
This separation should include the MOMspider design.
Remember that GIFs have owners too -- and expiry dates, etc.

Supose we specify this metainformation in HTTP. I think that
it is really useful, and will put it in unless anyone objects.
Owner, that is, as Expires: is already in. You have to leave it
up to a server owner as to how he generates that field.
Nowhere does the HTTP spec say anything about how the feilds
are generated, only what they mean. For example, one could
take the uid or gid fields as a good guide. It is rather system
dependent.

So as a separate issue, we can add the fields for HTML, which
would probably be used by most servers (server admins) to generate
the HTTP headers.

> output is a bit of a kluge.  I would prefer to have official HTML
> metainformation elements for OWNER and EXPIRES which would be optionally
> specified within the HEAD element (similar to the TITLE element).
> Similarly, the HTTP response would include that metainformation as
> appropriate headers (note that this has already been suggested for
> the Expires header but I haven't seen any mention of how the expire
> date would be obtained from normal HTML files).

Again, it could be done in bulk, for examle by specifying that
anything in /internet-drafts expires 6 months after its creation
date.

A question: Suppose we have this info duplicated in the HTTP
headers and in HTML. What happens when a client PUTs a document
with conflicting information? Suppose the server stored all the
metainformation in a database.  Why ask the server to raed HTML
files all the way through, when for anything else (GIF, sound) etc
the server can just soak up the HTTP headers and treat the HTTP
body as opaque data?   Sounds to me as though the client
could be the one responsible for copying the metadata into the
HTML HEAD.  The HTTP metatdata (however it is stored) would be
the more fundamental.

> One point which I think may spark discussion is whether we should
> specify the Owner as a LINK relationship rather than as its own
> element.  I decided not to do so for reasons of efficiency and
> understandability. 

I'll play devil's advocate here.

> If the owner was specified as a LINK, MOMspider
> (and any similar clients) would have to parse through all the fields
> of every LINK header in order to find an owner relationship.

Hey, come on, it has to read all the header lines anyway to
look for OWNER. No more sweat for a machine to look for
LINK REL="OWNS"

> Furthermore, the document author would have to build a contrived
> reverse LINK relationship with fields normally used for document
> references

Not at all -- the LINK element is not normally used for document
references (the A element is usd for that normally).  The LINK
elementt was designed to define any two-ended relationship,
or binary predicate.  It was designed for relationships like

	Jack loves Jill
	Jill loves Jack
	Jack likes pie
	Jill makes pie
	Jack eats pie
	Jack adicted to pie
	Jack needs pie
	Jack needs Jill
	Jack demands pie
	Jill fears Jack
	Jack fears "Jack needs Jill"
	Jack hates Jill

Check out all the stuff on semantics in hypertext, like
the hairspray (keeps your ideas in places but I can't remember
which brand) from Halasz &co at PARC.

>  -- a concept which is counter to understandability and
> everything I know about software engineering.

From that point of vire, the useful thing about overloading LINK
is that a MOMspider (or anyone else) knows that a LINK has 
a parameter which is an object URI, and so can do quite a lot
with general machinery for all links. We can have general
routines like "find me all B such that A o B" rather than
special routnes "find me all B such that A owns B".

>  I believe that the
> notion of document ownership is encountered frequently enough to
> justify a special HTML element for that purpose.

Yes, we can, and maybe we will, but doesn't defining a special case
because one form of a general one is used frequently enough run counter
to everything you know about software engineering? :-)
 
There is the case for generality. I agree it looks horrid.

> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
> 
> Well, that should be enough to generate some healthy debate.

Yes.  It has brought up the general and important issue of what
to do about metadata, which is useful too.

Here is a final idea.  The HTML spec can be user-friendly
as people see it more often than the HTTP. So let the
HTTP have a general relationship field.  Then specify an
architectural form  (am I kidding?) to allow any DTD to
specify the semantics of a relationship element in terms of the
underlying relationship model.

Tim






From sanders@bsdi.com  Mon Dec  6 15:10:09 1993 -0600
Message-Id: <199312062110.PAA06464@austin.BSDI.COM>
Date: Mon, 06 Dec 1993 15:10:09 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: International Document Server Support 

> > Well, you wouldn't use "language/english" but pretty close.  What you
> > do is pass this information along with the Accept: headers, e.g.:
> >     Accept: plain/text,language="ISO3316",charset="..."
> 
> So, English is now officially called "ISO3316"?  Sort of loses some
> of the flavor.. 8-)
He he!  Just to clarify ISO3316 is 'language codes' and ISO639 is 'country
codes'.  What you end up with is something like en_US or en_UK.  Un*x
based software could use $LANG to choose a default since at least one
vendor is using it for this purpose.

http://info.cern.ch/hypertext/WWW/Protocols/HTTP/HTRQ_Headers.html
still says ISOXXX under Accept-Language.  I think that's where it was,
can't reach the server to verify, darn it.

TimBL should make a ruling on this so we can all head in one direction:
Someone else pointed out Accept-Language: but I think this is the wrong
approch.  I think this information should be in the Accept: header along
with the other client profile information.  I can see the arguments for
special casing headers for some client profile but I would opt to be
consistent.  I'll be happy either way, I just want us to make an informed
decision.

--sanders



From sanders@bsdi.com  Mon Dec  6 15:16:05 1993 -0600
Message-Id: <199312062116.PAA06547@austin.BSDI.COM>
Date: Mon, 06 Dec 1993 15:16:05 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: Redundant Web services? 

> The Gopher protocol provides a scheme for identifying a redundant
> service for a given document.  Believe it or not, this is in the

You are supposed to be able to list multiple HREF's in an
anchor and get the same effect.

> This seems straightforward and very useful.  To my knowledge, it's
> never been implemented.   Is there any chance that the Web community

I think that it's the same problem with WWW.  Anyone know if
any browsers support this?

--sanders



From ctrbdo%iapa.uucp@constellation.ecn.uoknor.edu  Mon Dec  6 14:00:46 1993 CST
Message-Id: <9312062000.AA03828@maple.iapa>
Date: Mon, 6 Dec 93 14:00:46 CST
From: ctrbdo%iapa.uucp@constellation.ecn.uoknor.edu (bryan oakley)
Subject: Mosaic 2.0 bug?

Anybody care to comment on how the following is rendered using Mosaic
2.0 for X?

<PRE>
    Notice that this block is indented four spaces.  Also notice
    that if a line has an &lt;EM&gt; which spans a line <EM>like this,
    the following line is improperly (?) indented</EM>.
</PRE>

At least on my system (SGI Indigo^2), the third line is indented only
about half as much as the other lines.  I'm guessing this is wrong.
If anything, I'd expect the line to be indented more because of the
spacing of the emphasized font.

---------------------------------------------------------------------
Instrument Approach Procedures Automation             DOT/FAA/AMI-230
---------------------------------------------------------------------
Bryan D. Oakley              ctrbdo%iapa@constellation.ecn.uoknor.edu
KENROB and Associates, Inc.              voice: (405) 954-7176 (work)
5909 NW Expwy Suite 209                         (405) 366-6248 (home)
Oklahoma City, Ok.  73132            



From timbl@dxcern.cern.ch  Mon Dec  6 22:54:16 1993 +0100 (MET)
Message-Id: <Pine.3.07.9312062213.E21230-c100000@dxcern.cern.ch>
Date: Mon, 6 Dec 1993 22:54:16 +0100 (MET)
From: timbl@dxcern.cern.ch (Timothy Berners-Lee)
Subject: Re: International Document Server Support 



On Mon, 6 Dec 1993, Tony Sanders wrote:

> 
> http://info.cern.ch/hypertext/WWW/Protocols/HTTP/HTRQ_Headers.html
> still says ISOXXX under Accept-Language.  I think that's where it was,
> can't reach the server to verify, darn it.

(try www0 instead of info. We'll switch them when the other
services are ready. Our first time with solaris 2 -- rough
if you were weaned on bsd)

> TimBL should make a ruling on this so we can all head in one direction:

I though I had -- in Accept-Langauge.  Until you metioned using
parameters to Accept:

> Someone else pointed out Accept-Language: but I think this is the wrong
> approch.  I think this information should be in the Accept: header along
> with the other client profile information.  I can see the arguments for
> special casing headers for some client profile but I would opt to be
> consistent.  I'll be happy either way, I just want us to make an informed
> decision.

There are a number of ways in which a documents can have variants.
One is data representation, unfortunately known in MIME as content-type.
Another orthogonal way is language. Another orthogonal way is
version.  I think we should keep these things independent.

	Accept		--	Content-Type
	Accept-Language	--	Content-Language
	(n/a)		--	Version

Note also the URI parameters are the same

URI: http://info.cern.ch/ vary=(content-type, content-language, version)

This is an attempt to rationalise the whole variant business
and I think it is the best bet so far.

Content-Language is being discussed on the rfc822 list.

It is also more practical to be orthogonal.Language preference
is NOT related to content-type. Suppose I wanted to give the list
of image and text types I can handle, already several dozen, and
had for each to specify two or three language versions?
Can you concieve of someone wanting to specify that if it
is postscript they prefer French, but in GIFs they only want
Japanese?

The spec currently defines it as Accept-Language and 
Content-Language. I'd like to keep it that way but I'm open
to argument of course as always.

Tim

> --sanders





From timbl@dxcern.cern.ch  Mon Dec  6 23:08:36 1993 +0100 (MET)
Message-Id: <Pine.3.07.9312062334.F21230-a100000@dxcern.cern.ch>
Date: Mon, 6 Dec 1993 23:08:36 +0100 (MET)
From: timbl@dxcern.cern.ch (Timothy Berners-Lee)
Subject: Re: Redundant Web services? 



On Mon, 6 Dec 1993, Tony Sanders wrote:

> > The Gopher protocol provides a scheme for identifying a redundant
> > service for a given document.  Believe it or not, this is in the
> 
> You are supposed to be able to list multiple HREF's in an
> anchor and get the same effect.

	What?  Where do you get that from?
	SGML does not allow multiple occurrences of the same
	attribute. I thought.

	I think that a short-term solution is to use
	multiple IP addresses (in fact on different machines)
	for the same server domain name.

	Anyone want to start talking about a practical
	URN scheme?  Interest? Someone got a project to do?
	Using DNS to find appropriate large index servers?
	
	Tim BL





From masinter@parc.xerox.com  Mon Dec  6 14:08:47 1993 PST
Message-Id: <93Dec6.140901pst.2732@golden.parc.xerox.com>
Date: Mon, 6 Dec 1993 14:08:47 PST
From: masinter@parc.xerox.com (Larry Masinter)
Subject: patch HTFTP.c to allow ftp://user:password@host/

nevermind the 'athost', that's part of the patches for allowing
connection through a Sun proxy service

*** libwww2/HTFTP.c	Mon Dec  6 14:04:01 1993
--- /import-writable/www/src/Mosaic-2.0/libwww2//HTFTP.c	Mon Dec  6 10:15:58 1993
***************
*** 286,292 ****
    char *password = 0;
    char  athost[250];
    int   hostlen;
!   
    if (!arg) 
      return -1;		/* Bad if no name sepcified	*/
    if (!*arg) 
--- 286,293 ----
    char *password = 0;
    char  athost[250];
    int   hostlen;
!   char dummy[MAXHOSTNAMELEN+8];
! 
    if (!arg) 
      return -1;		/* Bad if no name sepcified	*/
    if (!*arg) 
***************
*** 322,332 ****
  
      if (!username) 
        free(p1);
    }
    
    con = -1;
  
!   status = HTDoConnect (arg, "FTP", IPPORT_FTP, &con);
  
    if (status < 0)
      {
--- 323,336 ----
  
      if (!username) 
        free(p1);
+ 
+     /* copy hostname into dummy URL, since username:password@ might have been part of original */ 
+     sprintf(dummy, "ftp://%s", p1);
    }
    
    con = -1;
  
!   status = HTDoConnect (dummy, "FTP", IPPORT_FTP, &con);
  
    if (status < 0)
      {




From davis@dri.cornell.edu  Mon Dec  6 17:42:43 1993 -0500
Message-Id: <199312062242.AA05128@willow.tc.cornell.edu>
Date: Mon, 6 Dec 1993 17:42:43 -0500
From: davis@dri.cornell.edu (Jim Davis)
Subject: Re: International Document Server Support

> From timbl@dxcern.cern.ch Mon Dec  6 17:34:05 1993
> Can you concieve of someone wanting to specify that if it
> is postscript they prefer French, but in GIFs they only want
> Japanese?

Maybe my email has not reached you yet, but I gave an example
just like this.   Suppose my first preference is to hear spoken
english read aloud (because as a native speaker I can understand
it easily), but if the info is available only in dutch or spanish
I will still want it, but I want it in writing because I'll
need to consult a dictionary.





From sanders@bsdi.com  Mon Dec  6 17:42:09 1993 -0600
Message-Id: <199312062342.RAA07268@austin.BSDI.COM>
Date: Mon, 06 Dec 1993 17:42:09 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: International Document Server Support 

> 	Accept		--	Content-Type
> 	Accept-Language	--	Content-Language
> 	(n/a)		--	Version

At WWWWW you (TimBL) said that client profile information should be in
the Accept: header, I thought that was the way we were heading (and when
I wrote the Client Profile proposal there wasn't an Accept-language).

I think it's pretty clear that version should be associated with the
representation and since language doesn't *have* to be orthogonal to
content-type I don't see why we should special case it.

> Can you concieve of someone wanting to specify that if it
> is postscript they prefer French, but in GIFs they only want
> Japanese?
You never know when you will have an ancient egyption on the net:
    Accept: stone/tablet;language="hg_AE", text/plain;language="en_US"

Why not be as flexible as possible?  It doesn't cost you anything up front.

--sanders



From rik@rdt.monash.edu.au  Tue Dec  7 10:51:24 1993 +1100
Message-Id: <199312062351.KAA05140@daneel.rdt.monash.edu.au>
Date: Tue, 07 Dec 93 10:51:24 +1100
From: rik@rdt.monash.edu.au (Rik Harris)
Subject: Re: Mosaic 2.0 bug? 

Andreas Gehmeyr <gehmeyr@forwiss.uni-passau.de> wrote:
> Anybody care to comment on how the following is rendered using Mosaic
> 2.0 for X?
> 
> <PRE>
>     Notice that this block is indented four spaces.  Also notice
>     that if a line has an &lt;EM&gt; which spans a line <EM>like this,
>     the following line is improperly (?) indented</EM>.
> </PRE>
> 
> At least on my system (SGI Indigo^2), the third line is indented only
> about half as much as the other lines.  I'm guessing this is wrong.
> If anything, I'd expect the line to be indented more because of the
> spacing of the emphasized font.

I have mentioned this to the bugs address for Mosaic, but I guess
they're too busy to do anything with it at the moment.  The HTML spec
says:

   Within a PRE element, 
                    .
                    .
                    .
      Anchor elements and character highlighting elements may be used.
                    .
                    .
                    .
  NOTE: HIGHLIGHTING
  
   Within a preformatted element,  the constraint that the rendering must be on
   a fixed horizontal character pitch may limit or prevent the ability of the
   renderer to render highlighting elements specially. 


This suggests to me that if you can't provide fixed-width characters,
then it is better not to do any highlighting within the <PRE> section.

My situation is similar.  I am formatting tables for the man2html
converter, and it is convenient to use <PRE> to do this formatting.
If one column is bolded, though, you end up with jagged columns, due
to the differing widths of the bold characters.

<PRE>
  <B>WW</B>    some information about WW
  <B>ii</B>    some information about ii
</PRE>

Keep up the good work, NCSA,
rik.
--
Rik Harris - rik.harris@vifp.monash.edu.au              || Systems Programmer
+61 3 560-3265 (AH) +61 3 565-3227 (BH)                 || and Administrator
Fac. of Computing & Info.Tech., Monash Uni, Australia   || Vic. Institute of
http://www.vifp.monash.edu.au/people/rik.html           || Forensic Pathology



From robm@ncsa.uiuc.edu  Mon Dec  6 18:09:23 1993 -0600
Message-Id: <9312070009.AA06856@void.ncsa.uiuc.edu>
Date: Mon, 6 Dec 1993 18:09:23 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: International Document Server Support

/*
 * Re: International Document Server Support  by Tony Sanders (sanders@bsdi.com)
 *    written on Dec  6,  5:42pm.
 *
 * You never know when you will have an ancient egyption on the net:
 *     Accept: stone/tablet;language="hg_AE", text/plain;language="en_US"
 */

That made me crack up for a few minutes. Thanks, Tony.

--Rob



From koblas@netcom.com  Mon Dec  6 07:26:10 1993 -0800
Message-Id: <199312061526.HAA20862@mail.netcom.com>
Date: Mon, 6 Dec 1993 07:26:10 -0800
From: koblas@netcom.com (David Koblas)
Subject: International Document Server Support


Has anyone given this any thought, here is my problem/idea?

What I'm trying to do is create a WWW server that has multiple language
versions version of the same documents (ie. a top.html in both English
and Norwegian).  What would be nice to do is display the English version
by default, and the Norwgian to people interested in it.)  I would
prefer not having to do this via the Kiosk method of "click on your flag".

Now how to solve this problem;  I would think the best way to solve this
is to have a clients post a message that they accept:
        language/norwegian
        language/english
is this reasonable, or should there be a better way?

Thanks,
--koblas@netcom.com



From decoux@moulon.inra.fr  Tue Dec  7 08:21:38 1993 +0100
Message-Id: <9312070721.AA09924@moulon.moulon.inra.fr>
Date: Tue, 7 Dec 93 08:21:38 +0100
From: decoux@moulon.inra.fr (ts)
Subject: CGI/1.0: last call


   From: jern@spaceaix.jhuapl.edu
   Date: Mon, 6 Dec 1993 14:13:51 -0500 (EST)
   X-Mailer: ELM [version 2.4 PL21]
   Mime-Version: 1.0
   Content-Type: text/plain; charset=US-ASCII
   Content-Transfer-Encoding: 7bit
   Content-Length: 1363
   X-Lines: 26

   sanders@BSDI.COM writes:> 
   > bobj  <jern@spaceaix.jhuapl.edu> writes:
   > > Authentication must be the responsibility of the script writer.  While
   > 
   > Authentication must be the responsibility of the server.  If you want to
   > easily extend the possible authentication schemes then define a spec for
   > authentication scripts, but they should remain seperate from normal scripts,
   > which should not have to deal with authentication, that would be a HUGE
   > security hole.
   Of course this is right.  In the context of the original message,
   passwords for accessing Oracle were the question but my response to
   that used language that was too general.  To try to put my comment
   in context, assuming that the incoming query has traversed the network,
   gained access to the machine, is granted access to the scripts and is
   attempting to access an Oracle database, the *Oracle authentication*
   is the responsibility of the person writing the Oracle access script.  It
   would seem unreasonable to pass Oracle authentication requirements up
   a layer or two into httpd.  It could be done but then httpd would
   end up with and application/authentication-scheme token for each  
   application requiring authentication. Ne c'est pas?  

   I merely propose that application be done without:
   1.  a user:password token
   2.  an application/authentication-scheme in the www server daemon.

  __________________________________________________________________

 You have in 
       ftp://net.tamu.edu/pub/security/TAMU/sra.ps 

 the description for a "Secure RPC Authentication for TELNET and FTP
Version 1.3" 

 A brief description is : 

> This package provides drop in replacements for telnet and ftp client
> and server programs, which use Secure RPC code to provide encrypted
> authentication across the network, so that plaintext passwords are not
> used.  The clients and servers negotiate the availability of SRA so
> that they work with unmodified versions.  These programs require no
> external keyserver or ticket server, and work equally well for local or
> internet wide connections.
 
 For non US sites, you have a source for the DES encryption library in :

  ftp://chalmers.se/pub/unix/des/des-2.2.tar.Z

 Copyright file for this source is :
 _____________________________________________________________________________
 
                        DES SOFTWARE PACKAGE
                            Version 2.2
 
                                       _
Copyright (c) 1990,1991,1992,1993 Stig Ostholm.
All Rights Reserved
 
 
The author takes no responsibility of actions caused by the use of this
software package and does not guarantee the correctness of the functions.
 
This software package may be freely distributed for non-commercial purpose
as long as the copyright notice is kept. Any changes made should be
accompanied by a comment indicating who made the change, when it was made
and what was changed.
 
This software package, or any parts of it, may not be used or in any way
re-distributed for commercial purpose without the authors permission.
The author keeps the right to decide between of what is commercial and
what is non-commercial purpose.
 
Restrictions due to national laws governing the use, import or export of
cryptographic software is the responsibility of the software user/importer/
exporter to follow.
 
 
                                             _
                                        Stig Ostholm
                                        Chalmers University of Technology
                                        Department of Computer Engineering
                                        S-412 96 Gothenburg
                                        Sweden
                                        ----------------------------------
                                        Email: ostholm@ce.chalmers.se
                                        Phone: +46 31 772 1703
                                        Fax:   +46 31 772 3663
 _____________________________________________________________________________


Guy Decoux




From jern@spaceaix.jhuapl.edu  Mon Dec  6 08:56:01 1993 -0500 (EST)
Message-Id: <9312061356.AA18393@sdrmis.jhuapl.edu>
Date: Mon, 6 Dec 1993 08:56:01 -0500 (EST)
From: jern@spaceaix.jhuapl.edu (jern@spaceaix.jhuapl.edu)
Subject: Re: CGI/1.0: last call

Rob writes:
> 
> /*
>  * Re: CGI/1.0: last call  by ts (decoux@moulon.inra.fr)
>  *    written on Dec  5,  1:40pm.
>  *
>  * > No.  Password should be kept inside the server for security reasons.
>  * > The environment variable REMOTE_USER is only defined if user has
>  * > successfully authenticated himself.  This should be enough.
>  * 
>  *  I *need* a password to open an Oracle database,  I don't want to write
>  * a cracker to retrieve it from password file.
>  * 
>  *  username:password can be send in stdin.
>  */
> 
> The problem is that the username:password style doesn't work with future PEM
> and Kerberos based authentication schemes. 
> 
> I don't know if I agree with Ari's security objection, but making the
> unencrypted passwords places a large amount of trust between script writers
> and system administrators (not necessarily in your case, but in general when
> scripts are commonly available software). This is really the only reason I
> can see for not making the password available to the script. Have I missed
> something?
> 
> I would ask that you reconsider how you are planning to do this, perhaps you
> should maintain your own simple password file and grab the user's Oracle
> password from this file. This way, people do not have their Oracle passwords
> sent across the net, only their HTTP passwords, and in the future, only an
> encrypted request. The drawback is that you have to maintain two password
> files.
> 
> If this is completely unacceptable, or I have missed something, please let
> me know. I'll consider making the Authorization: line available to the
> script, but I am objected to it.
> --Rob
Authentication must be the responsibility of the script writer.  While
httpd provides a measure of security that security is not adequate for
the script writer.  Headers containing authentication information might
assist the script writer in selecting an authentication method but
abdicating the responsibility, i.e., relying on httpd to provide methods
for, say Oracle access, would be a mistake.  Passing username:password
over a network certainly does not constitute safe security practices.  If
security is a concern, as it should be in updating databases, the script
writer has methods other that the username:password anachronism.

--bobj 




From dsr@hplb.hpl.hp.com  Tue Dec  7 11:41:38 1993 GMT
Message-Id: <9312071141.AA10450@manuel.hpl.hp.com>
Date: Tue, 7 Dec 93 11:41:38 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: International Document Server Support 

How should we support switching between laguages and character sets
within documents?

I am including an optional CHARSET attribute in nearly all elements in
the next revision to the HTML+ DTD. This will allow browsers to switch
char sets for a paragraph etc,  e.g. <P charset="ISO-2022-JP"> ....
as described in RFC 1468 which is used for Japanese character encoding
for email and network news.

Should I also include a LANGUAGE attribute for the ISO3316 language codes?

-- Dave

BTW the new DTD will infer missing <P> elements following headers etc.
and so remove worries for once and for all as to whether they are
containers or separators.



From ctrbdo%iapa.uucp@constellation.ecn.uoknor.edu  Tue Dec  7 08:04:32 1993 CST
Message-Id: <9312071404.AA04551@maple.iapa>
Date: Tue, 7 Dec 93 08:04:32 CST
From: ctrbdo%iapa.uucp@constellation.ecn.uoknor.edu (bryan oakley)
Subject: inline sounds

Ok, we have inline graphics in Mosaic, why not inline sounds?  Many of
the same rules/concepts/controls would apply (such as the ability to
defer the playing of inlined sounds).  I think it would be great to
have an automatic, audible "Welcome to the FOO company" on a home
page.  Hmmmm.... could I do this with server side include files, or
perhaps an /htbin script?  Better to have it as part of the HTML+
spec.  Perhaps an <SND SRC="URL"> tag?

Other uses might be to place a subtle beep at the end of a long
document so that you know when it has finished loading, or perhaps at
the start of a document to let you know it was found and is in the
process of being retrieved.  Of course, the question then becomes, is
the sound played whenever the sound tag exists in the viewable part of
the document, or just when the document is loaded.  And, is it
replayed if you scroll (or jump) back to the document that has been
cached?

I guess if I had to vote (and why not, this is my posting, eh?) I
would play the sound on-the-fly as the surrounding text is being
rendered for the screen, AND place a little sound icon where the tag
is in the text so that the user can replay at will.  The rule would be
that whenever the icon has to be rendered for display it would be
played as well (unless deferred playing is turned on)


---------------------------------------------------------------------
Instrument Approach Procedures Automation             DOT/FAA/AMI-230
---------------------------------------------------------------------
Bryan D. Oakley              ctrbdo%iapa@constellation.ecn.uoknor.edu
KENROB and Associates, Inc.              voice: (405) 954-7176 (work)
5909 NW Expwy Suite 209                         (405) 366-6248 (home)
Oklahoma City, Ok.  73132            



From fielding@simplon.ics.uci.edu  Tue Dec  7 07:10:59 1993 -0800
Message-Id: <9312070711.aa04183@paris.ics.uci.edu>
Date: Tue, 07 Dec 1993 07:10:59 -0800
From: fielding@simplon.ics.uci.edu (Roy T. Fielding)
Subject: Re: RFC: Multi-Owner Maintenance robot (MOMspider) 

>> <!ELEMENT HEAD - -  ( TITLE?  & ISINDEX?  & NEXTID?  & LINK* 
>>                              & BASE?     & OWNER?   & EXPIRES? )>
>> <!ELEMENT OWNER - -  CDATA    -- Alias name for document owner -->
>> <!ELEMENT EXPIRES - -  CDATA  -- Expiration date in RFC850 format -->
> 
> Your suggestion for a multi-owner maintenance robot (MOMspider) seems
> a good one, and I like the idea for making the owner and expiry date
> part of the document HEAD. I never did like the <LINK REL="MADE" HREF=...">
> notation. Perhaps we ought to stipulate the OWNER should be an email address?

I believe that owner/author privacy will become an important issue 
as large-scale information resources are added to the Web.  Therefore,
I prefer to use a level of indirection such that the owner's alias name
can be used (by MOMspider or other scripts) to look-up the real owner's
e-mail address(es) and perform actions tailored to that owner.  For instance,
a {htbin-post | cgi-bin}/mail_owner script could be written which examines
a table of author aliases at that site and determines both whether or not the
owner wants to receive e-mail and what the true e-mail address is.

This also provides a simple mechanism for a single real owner to be
represented by multiple aliases.  For instance, this would be useful for
webmasters who are responsible for multiple, semi-independent webs.
It also makes it easier for ownership to change hands.

> When viewing a document with markup errors, or broken links, who should
> the reader  mail - the author or the admin staff, e.g. www-admin@host?
> The author may want responsibility, or the document may have been produced
> automatically. Perhaps we should use an additional attribute, what do you
> think?

That is why I used the term "owner" rather than author -- I assumed the
owner would be the one with administrative responsibility for that
document.  If the owner wants such e-mail to be directed to some other
admin type, then they would simply specify that admin-type's e-mail
address in the look-up table for the mail_owner script.

> I will be happy to include this in the revised HTML+ spec - so long
> as there isn't vociferous feelings against the idea on the net.

In testing this this morning, I discovered that using a CDATA type
causes existing clients like Mosaic to treat the text between the ignored
<OWNER> and </OWNER> tags as actual printed text -- this is very bad
for backwards compatibility.  Therefore, perhaps it would be better
to define the OWNER and EXPIRES elements as EMPTY with argument lists.
That would also allow us to add options in the future.


....Roy Fielding   ICS Grad Student, University of California, Irvine  USA
                   (fielding@ics.uci.edu)



From Jon.Tetzchner@nta.no  Tue Dec  7 17:17:17 1993 +0100
Message-Id: <199312071617.AA27074@bang.nta.no>
Date: Tue, 7 Dec 1993 17:17:17 +0100
From: Jon.Tetzchner@nta.no (Jon.Tetzchner@nta.no)
Subject: Re:  [rik@rdt.monash.edu.au: Re: Mosaic 2.0 bug? ] Re: Mosaic 2.0 bug?

	From ivars Tue Dec  7 11:43:05 1993
	Received: from haydn.nta.no by hal.nta.no with SMTP id AA16498
	  (5.65c/IDA-1.4.4 for <jons>); Tue, 7 Dec 1993 11:43:04 +0100
	Message-Id: <199312071043.AA16498@hal.nta.no>
	Received: by haydn.nta.no (4.1/SMI-4.1)
		id AA03556; Tue, 7 Dec 93 11:43:03 +0100
	To: jons
	Subject: [rik@rdt.monash.edu.au: Re: Mosaic 2.0 bug? ]
	X-Authentication-Warning: daneel.rdt.monash.edu.au: Host localhost didn't use HELO protocol
	To: www-talk@nxoc01.cern.ch
	Subject: Re: Mosaic 2.0 bug? 
	In-Reply-To: Your message of "Mon, 06 Dec 93 14:00:46 CST."
	             <9312062000.AA03828@maple.iapa> 
	Date: Tue, 07 Dec 93 10:51:24 +1100
	From: Rik Harris <rik@rdt.monash.edu.au>
	X-Mts: smtp
	Status: RO

	Andreas Gehmeyr <gehmeyr@forwiss.uni-passau.de> wrote:
	> Anybody care to comment on how the following is rendered using Mosaic
	> 2.0 for X?
	> 
	> <PRE>
	>     Notice that this block is indented four spaces.  Also notice
	>     that if a line has an &lt;EM&gt; which spans a line <EM>like this,
	>     the following line is improperly (?) indented</EM>.
	> </PRE>
	> 
	> At least on my system (SGI Indigo^2), the third line is indented only
	> about half as much as the other lines.  I'm guessing this is wrong.
	> If anything, I'd expect the line to be indented more because of the
	> spacing of the emphasized font.

	I have mentioned this to the bugs address for Mosaic, but I guess
	they're too busy to do anything with it at the moment.  The HTML spec
	says:

	   Within a PRE element, 
	                    .
	                    .
	                    .
	      Anchor elements and character highlighting elements may be used.
	                    .
	                    .
	                    .
	  NOTE: HIGHLIGHTING
	  
	   Within a preformatted element,  the constraint that the rendering must be on
	   a fixed horizontal character pitch may limit or prevent the ability of the
	   renderer to render highlighting elements specially. 


	This suggests to me that if you can't provide fixed-width characters,
	then it is better not to do any highlighting within the <PRE> section.

	My situation is similar.  I am formatting tables for the man2html
	converter, and it is convenient to use <PRE> to do this formatting.
	If one column is bolded, though, you end up with jagged columns, due
	to the differing widths of the bold characters.

	<PRE>
	  <B>WW</B>    some information about WW
	  <B>ii</B>    some information about ii
	</PRE>

	Keep up the good work, NCSA,
	rik.
	--
	Rik Harris - rik.harris@vifp.monash.edu.au              || Systems Programmer
	+61 3 560-3265 (AH) +61 3 565-3227 (BH)                 || and Administrator
	Fac. of Computing & Info.Tech., Monash Uni, Australia   || Vic. Institute of
	http://www.vifp.monash.edu.au/people/rik.html           || Forensic Pathology


I am having the same problem with tables generated by my frame2html filter.
The result is that I have all character formatting removed. I have also noted
that Mosaic for Windows will render preformatted text with pictures differently
from the X version.

	Jon.



From montulli@stat1.cc.ukans.edu  Tue Dec  7 10:47:40 1993 CST
Message-Id: <9312071647.AA21750@stat1.cc.ukans.edu>
Date: Tue, 7 Dec 93 10:47:40 CST
From: montulli@stat1.cc.ukans.edu (Lou Montulli)
Subject: Re: RFC: Multi-Owner Maintenance robot (MOMspider)

> 
> >> <!ELEMENT HEAD - -  ( TITLE?  & ISINDEX?  & NEXTID?  & LINK* 
> >>                              & BASE?     & OWNER?   & EXPIRES? )>
> >> <!ELEMENT OWNER - -  CDATA    -- Alias name for document owner -->
> >> <!ELEMENT EXPIRES - -  CDATA  -- Expiration date in RFC850 format -->
> > 
> > Your suggestion for a multi-owner maintenance robot (MOMspider) seems
> > a good one, and I like the idea for making the owner and expiry date
> > part of the document HEAD. I never did like the <LINK REL="MADE" HREF=...">
> > notation. Perhaps we ought to stipulate the OWNER should be an email address?
> 
> I believe that owner/author privacy will become an important issue 
> as large-scale information resources are added to the Web.  Therefore,
> I prefer to use a level of indirection such that the owner's alias name
> can be used (by MOMspider or other scripts) to look-up the real owner's
> e-mail address(es) and perform actions tailored to that owner.  For instance,
> a {htbin-post | cgi-bin}/mail_owner script could be written which examines
> a table of author aliases at that site and determines both whether or not the
> owner wants to receive e-mail and what the true e-mail address is.
> 
<Link Rel="made" href...> does not preclude the use of indirection.

There are many other uses for the owners address than just MOMspider
so hideing the owners address inside a comment when a defined structure
for that information already exists is foolish.  

Also, the EXPIRES information you are looking for already has a 
predefined method definition.  The information is passed back as
an HTTP header that looks like "Expires: DATE".

:lou



From dsr@hplb.hpl.hp.com  Tue Dec  7 17:53:39 1993 GMT
Message-Id: <9312071753.AA13742@manuel.hpl.hp.com>
Date: Tue, 7 Dec 93 17:53:39 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: RFC: Multi-Owner Maintenance robot (MOMspider) 

> I believe that owner/author privacy will become an important issue 
> as large-scale information resources are added to the Web.  Therefore,
> I prefer to use a level of indirection such that the owner's alias name
> can be used (by MOMspider or other scripts) to look-up the real owner's
> e-mail address(es) and perform actions tailored to that owner.  For instance,
> a {htbin-post | cgi-bin}/mail_owner script could be written which examines
> a table of author aliases at that site and determines both whether or not the
> owner wants to receive e-mail and what the true e-mail address is.

> This also provides a simple mechanism for a single real owner to be
> represented by multiple aliases.  For instance, this would be useful for
> webmasters who are responsible for multiple, semi-independent webs.
> It also makes it easier for ownership to change hands.

I see the elements in the document head being used by the HTTP server
to generate HTTP headers. This way you can have a general purpose interface
for agents like MOMspider which also works for non-HTML formats like GIF
or plain text.

How about the following for the HTML+ document HEAD:

    <!-- this element may often be implied by HTTP header info -->
    <!ELEMENT DATE - O EMPTY>
    <!ATTLIST DATE
        created     CDATA   #IMPLIED  -- RFC 850 Date format --
        expires     CDATA   #IMPLIED  -- RFC 850 Date format -->

    <!ELEMENT OWNER - O EMPTY>
    <!ATTLIST OWNER
        owner       CDATA   #IMPLIED  -- name of owner --
        contact     CDATA   #IMPLIED  -- email address as URL -->

These two elements wouldn't cause any problems for existing browsers.
The OWNER element can have either the owner or contact attributes or both.
Sometimes it might be nice to specify the owner by a hypertext link to a
page giving an autobiography, affiliation, contact details etc. The owner
attribute is as you suggest and can be used as an indirection to look up
the real owner's e-mail address by programs privy to that information.
An alternative to OWNER is two new relationship types for LINK. The OWNER
element seems marginally cleaner.

Dave Raggett



From vinay@eit.COM  Tue Dec  7 10:10:39 1993 PST
Message-Id: <9312071810.AA18839@eit.COM>
Date: Tue, 7 Dec 93 10:10:39 PST
From: vinay@eit.COM (Vinay Kumar)
Subject: slideshow-1.4 now available

"ss" or slideshow ver1.4 is now available by anonymous ftp from:

		ftp 192.100.58.2
under
		/pub/share/ss1.4.tar.Z

CHANGES from previous version include:

- Handles "q" (Quit) option better than before.
- Notifies on STDOUT the next URL to be displayed in the list as Mosaic
  sequences through the slides.
- Added support for time-based URL slideshow (including number of times
  to loop thru the URL file).
- Mosaic gets spawned off if not already running, otherwise not.
- Checks for URL syntax.

The distribution contains a Unix man page explaining use of "ss".

Try it, and feel free to send your experiences/feedback to me at:
						vinay@eit.com

--
  Vinay Kumar
vinay@eit.com




From WIGGINS@msu.edu  Tue Dec  7 13:28:46 1993 EST
Message-Id: <9312071845.AA22629@dxmint.cern.ch>
Date: Tue, 07 Dec 93 13:28:46 EST
From: WIGGINS@msu.edu (Rich Wiggins)
Subject: Re: inline sounds

>I guess if I had to vote (and why not, this is my posting, eh?) I
>would play the sound on-the-fly as the surrounding text is being
>rendered for the screen, AND place a little sound icon where the tag
>is in the text so that the user can replay at will.  The rule would be
>that whenever the icon has to be rendered for display it would be
>played as well (unless deferred playing is turned on)

This may not be such a good idea.  You might want to have a bunch
of "inline" sounds throughout a document.  For instance, a
colleague once commented on an article I'd written via Nextmail,
which presents a lip icon showing each inline sound.  The icon
is precisely adjacent to the passage where it was placed by
the author.  This is important, so that the sounds match up
with the text they are associated with.  Yes, the reader/listener
must click to hear each sound, but this is not onerous.

If you did it any other way, the timing of the playing of a sound
would be subject to vagaries such as how large your window is and
how fast your workstation renders the intervening text and images.
You'd effectively be limited to one inline sound per page.

In a somewhat different context I suggested it'd be nice to have
the ability to deliver an HTML-marked up storyboard, implying
the need to include pauses between relevant sections, but the
response was that should be driven by a workstation-resident script.
You either need to have the user invoke the playing of the next
sound, or you need a guranteed minimum timeout between selections.

/Rich Wiggins, CWIS Coordinator, Michigan State U



From atotic@ncsa.uiuc.edu  Tue Dec  7 13:05:42 1993 -0600 (CST)
Message-Id: <9312071905.AA23142@void.ncsa.uiuc.edu>
Date: Tue, 7 Dec 1993 13:05:42 -0600 (CST)
From: atotic@ncsa.uiuc.edu (Alexsander Totic)
Subject: Re: International Document Server Support

> I am including an optional CHARSET attribute in nearly all elements in
> the next revision to the HTML+ DTD. This will allow browsers to switch
> char sets for a paragraph etc,  e.g. <P charset="ISO-2022-JP"> ....
> as described in RFC 1468 which is used for Japanese character encoding
> for email and network news.
> 
> Should I also include a LANGUAGE attribute for the ISO3316 language codes?

Are these character sets all 8bit sets, or is there support for
multi-byte characters. I am not familiar with the way things work on X,
but on a Mac, Chinese and some other languages use 2-byte characters.

How is the parsing going to be done for character sets where all the 
characters are used? Current parser depends on special characters, such
as '<', and '&'. In different character sets, I do not think that we can
depend on this.

Aleks




From phillips@cs.ubc.ca  Mon Dec  7 12:14:00 1993 -0800
Message-Id: <7009*phillips@cs.ubc.ca>
Date: 7 Dec 93 12:14 -0800
From: phillips@cs.ubc.ca (George Phillips)
Subject: CGI/1.0 tweaks

So here I sit implementing my x-exec: URL scheme which I wish to make
compliant with CGI/1.0.  Naturally, I've run into a few problems.
First the no-brainer:  HTTP_ACCEPT -- since HTTP is going to change
to the proper MIME field separator (either , or ;), so should CGI.

I ran into a slightly stickier problem which doesn't necessarily
affect the spec but does have some implications for script writers.
It's the business about self-referencing URLs.  Think of a gateway
which serves some abstract URL sub-tree.  The gateway can do
absolute references in that tree with URLs of the form:

(1)	$SCRIPT_NAME/gateway/sub/tree

Now, we also have SERVER_NAME and SERVER_PORT so the gateway could
say:

(2)	//$SERVER_NAME:$SERVER_PORT$SCRIPT_NAME/gateway/sub/tree

if it wanted to be pedantic.  So why the extra variables?  Because
gopher requests need them in order to do self-references.  In other
words, they're useless unless your SERVER_PROTOCOL is "gopher".

What should the spec say?  Well, we could drop them or we could
say they're only set if the protocol is "gopher".  Either way
is fine by me.  What I feel is necessary is that (1) be _the_
method for self-referencing URLs.  That way, gateway scripts
can be used nicely as x-exec: scripts with 0 changes.

			-- George



From robm@ncsa.uiuc.edu  Wed Dec  8 02:49:13 1993 -0600
Message-Id: <9312080849.AA04619@void.ncsa.uiuc.edu>
Date: Wed, 8 Dec 1993 02:49:13 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: CGI/1.0: authentication


I have added YAEV, Yet Another Environment Variable to the CGI spec: AUTH_TYPE.
This is the protocol-specific method used to authenticate the user. The value
of this variable would determine what is in the AUTH_USER variable (for
instance, if it was public key authentication, this may be the user's public
key). 

Any problems with this?

--Rob



From robm@ncsa.uiuc.edu  Wed Dec  8 02:46:39 1993 -0600
Message-Id: <9312080846.AA04590@void.ncsa.uiuc.edu>
Date: Wed, 8 Dec 1993 02:46:39 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI/1.0 tweaks

/*
 * CGI/1.0 tweaks  by George Phillips (phillips@cs.ubc.ca)
 *    written on Dec  7, 12:14pm.
 *
 * So here I sit implementing my x-exec: URL scheme which I wish to make
 * compliant with CGI/1.0.  Naturally, I've run into a few problems.
 * First the no-brainer:  HTTP_ACCEPT -- since HTTP is going to change
 * to the proper MIME field separator (either , or ;), so should CGI.
 * 
 * I ran into a slightly stickier problem which doesn't necessarily
 * affect the spec but does have some implications for script writers.
 * It's the business about self-referencing URLs.  Think of a gateway
 * which serves some abstract URL sub-tree.  The gateway can do
 * absolute references in that tree with URLs of the form:
 * 
 * (1)	$SCRIPT_NAME/gateway/sub/tree
 * 
 * Now, we also have SERVER_NAME and SERVER_PORT so the gateway could
 * say:
 * 
 * (2)	//$SERVER_NAME:$SERVER_PORT$SCRIPT_NAME/gateway/sub/tree
 * 
 * if it wanted to be pedantic.  So why the extra variables?  Because
 * gopher requests need them in order to do self-references.  In other

 * words, they're useless unless your SERVER_PROTOCOL is "gopher".

Not necessarily. Each of the items could be of value to some scripts. For
instance, if I have a specialized server running on port 9999 which uses the
same scripts the one on port 80 does, then the port number may be important.
The same goes for SERVER_NAME. 

 * What should the spec say?  Well, we could drop them or we could
 * say they're only set if the protocol is "gopher".  Either way
 * is fine by me.  What I feel is necessary is that (1) be _the_
 * method for self-referencing URLs.  That way, gateway scripts
 * can be used nicely as x-exec: scripts with 0 changes.
 */

Hang on, you're confusing me. If it's a self-referencing *URL*, then you
should be able to include port and hostname any way since it is a URL. In
what context are you building these self-referencing URLs? For the Location:
header? For HTML links?

The problem I see here is not that there are extra variables, it's that
sending back URLs to non-HTTP clients won't usually work. This is a serious
problem, and is a possible red flag for making CGI work for non-HTTP servers.

I can thus see two solutions, both are ugly:
1. Make the scripts ensure that they are running from an HTTP server when
returning URLs.
2. Make the non-URL servers (basically everything non-HTTP) handle URLs
coming back from scripts.

Unfortunately both are ugly. I would prefer (2), but that's probably only
because I'm not the one who has to implement it. It would make scripts a lot
simpler, though. John? Ideas?

--Rob




From dsr@hplb.hpl.hp.com  Wed Dec  8 09:57:48 1993 GMT
Message-Id: <9312080957.AA16660@manuel.hpl.hp.com>
Date: Wed, 8 Dec 93 9:57:48 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: inline sounds

>I guess if I had to vote (and why not, this is my posting, eh?) I
>would play the sound on-the-fly as the surrounding text is being
>rendered for the screen, AND place a little sound icon where the tag
>is in the text so that the user can replay at will.  The rule would be
>that whenever the icon has to be rendered for display it would be
>played as well (unless deferred playing is turned on)

My wish would be for an ability to play a sound sequence as an
accompanyment to following a normal hypertext link. This way the
music/speech is synchronised to the change in the document display.
This is not the same as playing a sound sequence when first displaying
a document, since the link might have been to another section within
the same document.

To get this to work, we need an additional URL attribute in the <A>
and <LINK> elements. How about something like:

    <A HREF="#prologue" PLAY="fanfare.au">The Prologue</A>

I have used PLAY here rather than say SOUND since we may want to invoke
some animation e.g. a talking head in front of the main document rather
than just a simple sound sequence.

Another idea is to extend the LINK element to cause the browser to "turn
the page" after a specified time-out, e.g.

    <LINK HREF="next_doc" AFTER=10>

The AFTER attribute specifies a delay of 10 seconds after which, if the
user hasn't done anything, the browser will follow the link specified with
the HREF attribute.

Dave Raggett



From decoux@moulon.inra.fr  Wed Dec  8 11:07:32 1993 +0100
Message-Id: <9312081007.AA15937@moulon.moulon.inra.fr>
Date: Wed, 8 Dec 93 11:07:32 +0100
From: decoux@moulon.inra.fr (ts)
Subject: CGI/1.0: authentication



> I have added YAEV, Yet Another Environment Variable to the CGI spec: AUTH_TYPE.
> This is the protocol-specific method used to authenticate the user. The value
> of this variable would determine what is in the AUTH_USER variable (for
> instance, if it was public key authentication, this may be the user's public
> key). 

> Any problems with this?

 To give an example for public key authentication.

 Actually to simplify, I distinguish :

  - communication between browser and "httpd" 
  - communication between "httpd" and script

 I suppose than "httpd" have all informations and it must send these
informations to the script.

 "httpd" can determine :
   1) if the script is protected
   2) if the script is callable (with the pathname of the script or any
other methods). For me, it is the responsability of the webmaster to verify
all callable scripts on the server.

 With this method, you drop the disadvantage in page 2 :
 "The server does validate the user's identity, but the client does not
perform server authentication"
(WARNING : in my example "server" is the script, and client is "httpd")


 When httpd know that it is a callable and protected script, you have two
possibilities for communications :

 1) "httpd" send "AUTH" and receive "AUTH OK"

 communication is

     httpd                script

            ============> AUTH
    AUTH OK <===========
            ============> PKA
        PKB <============
            ============> KAB(U)
            ============> KAB(P)
    ACC/REJ <============
                ...

  2) "httpd" send "AUTH" and don't receive "AUTH OK"

     a) "httpd" can send URL or can close the communication, but it *don't*
send PKA

     b) script can accept the URL or reject it.

        
 Any comments, please

Guy Decoux




From dsr@hplb.hpl.hp.com  Wed Dec  8 10:28:19 1993 GMT
Message-Id: <9312081028.AA16856@manuel.hpl.hp.com>
Date: Wed, 8 Dec 93 10:28:19 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: International Document Server Support

> Are these character sets all 8bit sets, or is there support for
> multi-byte characters. I am not familiar with the way things work on X,
> but on a Mac, Chinese and some other languages use 2-byte characters.

These can be multi-byte character sets. See RFC 1468 and also
see http://www.ntt.jp/japan/note-on-JP/ which explains how NTT has
patched the WWW library to work with the 7 bit ISO-2022-JP, which is
widely used for email and network news.

Basically, ISO-2022-JP uses escape sequences to switch between
ASCII and JIS X 208. The latter is a two byte character set including
Kanji, Hiragana, Katakana and some other symbols and characters.

        ESC ( B         ASCII
        ESC $ B         JIS X 0208-1983

NTT have patched libwww to only recognise markup in ASCII text. This
is a simple change and only effects SGML.c. This approach allows one
to use the full range of 8-bit character sets, but for portability it
is essential that we stick to the ISO registered escape sequences and
character sets.

If browsers use the Accept-Language: header correctly, then we can
avoid the problem where the browser doesn't have any fonts for the
designated character set. The change needed to Mosaic to support this
scheme isn't bad, and there are already patched versions of

        tkWWW browser/editor for X11
        emacs browser
        line mode browser
        X Mosaic 1.2 for X11 (in alpha version)

Marc Andreessen writes:

> You know, there's not a chance in hell we'll be able to support this
> in the forseeable future...

I think it is important that we don't take an English-centric view of the
world. The escape sequence mechanism and support for Accept-Language and
multi-byte character sets seem like a good step in the right direction.

Dave Raggett



From fielding@simplon.ics.uci.edu  Wed Dec  8 04:12:45 1993 -0800
Message-Id: <9312080412.aa02028@paris.ics.uci.edu>
Date: Wed, 08 Dec 1993 04:12:45 -0800
From: fielding@simplon.ics.uci.edu (Roy T. Fielding)
Subject: Re: RFC: Multi-Owner Maintenance robot (MOMspider) 

Sorry for the delay in responding -- I seem to have overloaded
(or overdosed?) on information....

> On Mon, 6 Dec 1993, Roy T. Fielding wrote:
>> Each maintained HTML file would include an HTML comment of the following
>> format as the first line of the file:
>> 
>> <!-- MOM Owner="AnyAuthorAlias" Expires="31 Dec 1993" -->
>> 
> ...
>> Note that since this added line is a comment, it will have no effect on
>> existing servers or clients.
> 
> I agree with your later classification of this as a kludge, and
> would much prefer to use either the existing LINK element
> or new elements. Note that the HTML spec requires browsers to
> ignore elements they do not understand -- that is, to treat
> them as though the tags were not there. As this would leave
> the contents within the HEAD of a message, it seems reasonable
> to interpret this to mean that the contents (which would not
> otherwise be allowed in the HEAD part) should be ignored.

Unfortunately, Mosaic 2.0 for X (the only client I have tested this on)
just ignores the elements and displays the content as normal text.

> This gives you a transition path from trying it out on a small
> scale to standardising on it -- without breaking anything on the way.

That's definitely a good idea -- the initial suggestion of the comment was
just to make it easy for me to hack my local server.  I think I'll go with
Dave Raggett's last suggestion instead.

> ...
> I would like to draw your attention to the comments in the HTTP spec
> about WWW_Link: and the isomorphism between HTTP object header feilds
> and HTML head elements.  There it is suggested that a formal
> relationship be made, automatically defining one set in terms of
> the other.

I've read that stuff several times, and just checked it again to be sure.
Has any decision been reached (by anyone) as to whether the "WWW-" prefix
should be used?  Has this been implemented in CERN httpd? (I know it hasn't
in NCSA httpd).

Personally, I think the prefix should not be used for headers which are
applicable beyond HTML (as is the case for Expires and Owner).

> The next point is that, although the two specs have the
> metainformation in common, they should be kept separate.
> This separation should include the MOMspider design.
> Remember that GIFs have owners too -- and expiry dates, etc.
> 
> Suppose we specify this metainformation in HTTP. I think that
> it is really useful, and will put it in unless anyone objects.
> Owner, that is, as Expires: is already in. You have to leave it
> up to a server owner as to how he generates that field.
> Nowhere does the HTTP spec say anything about how the feilds
> are generated, only what they mean. For example, one could
> take the uid or gid fields as a good guide. It is rather system
> dependent.
> 
> So as a separate issue, we can add the fields for HTML, which
> would probably be used by most servers (server admins) to generate
> the HTTP headers.

Yes, that's exactly what I am proposing.  Thanks.

>> ...
>> Similarly, the HTTP response would include that metainformation as
>> appropriate headers (note that this has already been suggested for
>> the Expires header but I haven't seen any mention of how the expire
>> date would be obtained from normal HTML files).
> 
> Again, it could be done in bulk, for example by specifying that
> anything in /internet-drafts expires 6 months after its creation date.

It can?  I have not seen that anywhere outside netnews.  I would then 
suggest that the server (or whatever controlled that) should have an
option for which date (the one in the file or the one for the directory)
takes precedence.  But, as you said, that is server-specific and not HTTP.

> A question: Suppose we have this info duplicated in the HTTP
> headers and in HTML. What happens when a client PUTs a document
> with conflicting information? Suppose the server stored all the
> metainformation in a database.  Why ask the server to raed HTML
> files all the way through, when for anything else (GIF, sound) etc
> the server can just soak up the HTTP headers and treat the HTTP
> body as opaque data?   Sounds to me as though the client
> could be the one responsible for copying the metadata into the
> HTML HEAD.  The HTTP metatdata (however it is stored) would be
> the more fundamental.

That's an interesting suggestion, but, it seems to me, it would be 
difficult to maintain consistency between the metainformation and
the body contents if they are stored separately.

As far as clients like MOMspider are concerned, all they need is for
the metainformation to be placed in the headers (it doesn't matter
how they get there) and some means by which authors (or admins) can
specify the contents of that metainformation for a particular object.

>> One point which I think may spark discussion is whether we should
>> specify the Owner as a LINK relationship rather than as its own
>> element.  I decided not to do so for reasons of efficiency and
>> understandability. 
> 
> I'll play devil's advocate here.

That's what I was hoping for  ;).

>> If the owner was specified as a LINK, MOMspider
>> (and any similar clients) would have to parse through all the fields
>> of every LINK header in order to find an owner relationship.
> 
> Hey, come on, it has to read all the header lines anyway to
> look for OWNER. No more sweat for a machine to look for
> LINK REL="OWNS"

Marginal sweat -- the Owner: would be at the beginning of a line
(like any good header), whereas the REL="OWNS" (or REV="OWNS") could
be anywhere in any one of the Link: header lines.  No big deal, I guess.

>> Furthermore, the document author would have to build a contrived
>> reverse LINK relationship with fields normally used for document
>> references
> 
> Not at all -- the LINK element is not normally used for document
> references (the A element is usd for that normally).  The LINK
> element was designed to define any two-ended relationship,
> or binary predicate.  It was designed for relationships like
> 
> 	Jack loves Jill
> 	Jill loves Jack
> 	Jack likes pie
> 	Jill makes pie
> 	Jack eats pie
> 	Jack adicted to pie
> 	Jack needs pie
> 	Jack needs Jill
> 	Jack demands pie
> 	Jill fears Jack
> 	Jack fears "Jack needs Jill"
> 	Jack hates Jill
> 
> Check out all the stuff on semantics in hypertext, like
> the hairspray (keeps your ideas in places but I can't remember
> which brand) from Halasz &co at PARC.

I was talking syntax, not semantics.  The Link field names are the same
as those used by anchors and thus evoke the same psychological reaction
when a reader tries to interpret the semantics.  Furthermore, I have yet
to see an instance where links like the above would be useful in an
information resource database.  ;-)

>>  -- a concept which is counter to understandability and
>> everything I know about software engineering.
> 
> From that point of vire, the useful thing about overloading LINK
> is that a MOMspider (or anyone else) knows that a LINK has 
> a parameter which is an object URI, and so can do quite a lot
> with general machinery for all links. We can have general
> routines like "find me all B such that A o B" rather than
> special routnes "find me all B such that A owns B".

That's exactly what I would want to avoid.  There are some times when
"gee, wouldn't it be neat if we could do recursive indirection through
a URL to a script to ...." is the last thing you want to allow.
Simplicity in the headers is essential for fast servers and simple
clients like MOMspider.

>>  I believe that the
>> notion of document ownership is encountered frequently enough to
>> justify a special HTML element for that purpose.
> 
> Yes, we can, and maybe we will, but doesn't defining a special case
> because one form of a general one is used frequently enough run counter
> to everything you know about software engineering? :-)

Nope.  Generality is only as good as the abstraction upon which it is based.
I would say that broadening the document-document relationship abstraction
to include person-document and person-person relationships is not justified
by the application requirements (WWW) and creates unnecessary complexity.

> There is the case for generality. I agree it looks horrid.

But that's just it!  I consider links to be good for representing
relationships between documents, but horrid for representing relationships
between humans and documents.  Further, I think they are geared more towards
automatic creation than they are to being authored by humans.  Thus, authors
just avoid using them and the relationships they are intended to represent
cease to be meaningful.

In contrast, special HTML elements are easy to understand and remember by
authors and thus will be used more frequently and with better consistency.

>> ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
>> 
>> Well, that should be enough to generate some healthy debate.
> 
> Yes.  It has brought up the general and important issue of what
> to do about metadata, which is useful too.
> 
> Here is a final idea.  The HTML spec can be user-friendly
> as people see it more often than the HTTP. So let the
> HTTP have a general relationship field.  Then specify an
> architectural form  (am I kidding?) to allow any DTD to
> specify the semantics of a relationship element in terms of the
> underlying relationship model.

Crikey!  It took me ten minutes just to understand what you meant
by that last sentence.  That would be an excellent way to maintain
both document understandability (for authors) and HTTP simplicity.
Is SGML flexible enough to allow definition of the semantics of an
element relationship within the DTD itself?  Such a thing would be
fine for clients (providing the server output remained consistent),
but would the server implementors want to do the translation?

> Tim

Thanks for being the devil's advocate ;).  And, while I'm at it, thanks
for the rest of your WWW work as well.


....Roy Fielding   ICS Grad Student, University of California, Irvine  USA
                   (fielding@ics.uci.edu)



From hitoaki@mahler.ntt.jp  Wed Dec  8 21:25:54 1993 +0900
Message-Id: <9312081225.AA00822@mahler.ntt.jp>
Date: Wed, 08 Dec 1993 21:25:54 +0900
From: hitoaki@mahler.ntt.jp (Hitoaki Sakamoto)
Subject: Re: International Document Server Support 


  I am much interested in information systems(e.g. WWW,
gopher,wais..etc). But I think , many Japanese have
difficulties in reading/writing English. (Of course, me
too :-)

  Toshihiro, Shin-ya, and I think ,how to use Japanese
(and other languages) in information systems. It is
important to provide/get information in the world, we
think.  Please see as follows.
	http://www.ntt.jp/japan/note-on-JP/
	http://www.ntt.jp/Mosaic-l10n/

  Now, We are prepared a pointer button for switching
languages , if current document has some languages
version(e.g. English and Japanese). Radio Japan,
broadcast information is extreme case.
    http://www.ntt.jp/japan/NHK/broad/intro/ 

It has 15 languages(2 language is provide by GIF images).

-----
Hitoaki Sakamoto (hitoaki@mahler.ntt.jp)
Communication Swithing Systems Laboratories.
Nippon Telegraph and Telephone Corporation.



From Guido.van.Rossum@cwi.nl  Wed Dec  8 13:42:32 1993 +0100
Message-Id: <9312081242.AA00719=guido@voorn.cwi.nl>
Date: Wed, 08 Dec 1993 13:42:32 +0100
From: Guido.van.Rossum@cwi.nl (Guido.van.Rossum@cwi.nl)
Subject: Re: inline sounds 

> My wish would be for an ability to play a sound sequence as an
> accompanyment to following a normal hypertext link. This way the
> music/speech is synchronised to the change in the document display.
> This is not the same as playing a sound sequence when first displaying
> a document, since the link might have been to another section within
> the same document.
> 
> To get this to work, we need an additional URL attribute in the <A>
> and <LINK> elements. How about something like:
> 
>     <A HREF="#prologue" PLAY="fanfare.au">The Prologue</A>
> 
> I have used PLAY here rather than say SOUND since we may want to invoke
> some animation e.g. a talking head in front of the main document rather
> than just a simple sound sequence.

This would mean that if you wanted to change the accompanying effects
you would have to change all pointers.  Perhaps what we really need is
URLs that point to a group of files which should be fetched and
presented simultaneously (a "compound node" in the terminology of the
Dexter hypertext reference model).  I don't know enough about HTTP,
but possibly a variant of Content-type: multipart could be used here?

--Guido van Rossum, CWI, Amsterdam <Guido.van.Rossum@cwi.nl>



From fielding@simplon.ics.uci.edu  Wed Dec  8 04:43:38 1993 -0800
Message-Id: <9312080443.aa03028@paris.ics.uci.edu>
Date: Wed, 08 Dec 1993 04:43:38 -0800
From: fielding@simplon.ics.uci.edu (Roy T. Fielding)
Subject: Re: RFC: Multi-Owner Maintenance robot (MOMspider) 


I wrote:

>> I believe that owner/author privacy will become an important issue 
>> as large-scale information resources are added to the Web.  Therefore,
>> I prefer to use a level of indirection such that the owner's alias name
>> can be used (by MOMspider or other scripts) to look-up the real owner's
>> e-mail address(es) and perform actions tailored to that owner.  For instance,
>> a {htbin-post | cgi-bin}/mail_owner script could be written which examines
>> a table of author aliases at that site and determines both whether or not the
>> owner wants to receive e-mail and what the true e-mail address is.
>> 

Lou Montulli <montulli@stat1.cc.ukans.edu> writes:

> <Link Rel="made" href...> does not preclude the use of indirection.

It doesn't preclude anything, nor does it provide the author with any
guidance for consistency (i.e. the field names do not make sense).  Further,
there is a significant semantic difference between the OWNS relationship
(described in Tim's reply) and the MADE relationship.

> There are many other uses for the owners address than just MOMspider
> so hideing the owners address inside a comment when a defined structure
> for that information already exists is foolish.  

First of all, comments are not hidden -- they can be seen in the source.
Second, it is important to provide a means of indirection AND stating the
expected use up-front so that future tool-writers can avoid assuming that
it is an e-mail address and, if necessary, take advantage of the alias
feature.  Third, of course it's foolish -- that is the nature of a kludge.

> Also, the EXPIRES information you are looking for already has a 
> predefined method definition.  The information is passed back as
> an HTTP header that looks like "Expires: DATE".

It exists as an HTTP header but there is no defined means for providing
that information to the server for HTML files.  Thus, some form of
HTML element is needed.


....Roy Fielding   ICS Grad Student, University of California, Irvine  USA
                   (fielding@ics.uci.edu)



From fielding@simplon.ics.uci.edu  Wed Dec  8 05:21:37 1993 -0800
Message-Id: <9312080521.aa04544@paris.ics.uci.edu>
Date: Wed, 08 Dec 1993 05:21:37 -0800
From: fielding@simplon.ics.uci.edu (Roy T. Fielding)
Subject: Re: RFC: Multi-Owner Maintenance robot (MOMspider) 

Dave Raggett writes:

> I see the elements in the document head being used by the HTTP server
> to generate HTTP headers. This way you can have a general purpose interface
> for agents like MOMspider which also works for non-HTML formats like GIF
> or plain text.
> 
> How about the following for the HTML+ document HEAD:
> 
>     <!-- this element may often be implied by HTTP header info -->
>     <!ELEMENT DATE - O EMPTY>
>     <!ATTLIST DATE
>         created     CDATA   #IMPLIED  -- RFC 850 Date format --
>         expires     CDATA   #IMPLIED  -- RFC 850 Date format -->
> 
>     <!ELEMENT OWNER - O EMPTY>
>     <!ATTLIST OWNER
>         owner       CDATA   #IMPLIED  -- name of owner --
>         contact     CDATA   #IMPLIED  -- email address as URL -->
> 
> These two elements wouldn't cause any problems for existing browsers.
> The OWNER element can have either the owner or contact attributes or both.
> Sometimes it might be nice to specify the owner by a hypertext link to a
> page giving an autobiography, affiliation, contact details etc. The owner
> attribute is as you suggest and can be used as an indirection to look up
> the real owner's e-mail address by programs privy to that information.
> An alternative to OWNER is two new relationship types for LINK. The OWNER
> element seems marginally cleaner.

That is an excellent solution.  However, I have a couple nits to pick.

I would prefer:

      <!ATTLIST OWNER
          name        CDATA   #IMPLIED  -- name (or alias) of owner  --
          email       CDATA   #IMPLIED  -- email address of owner    --
          href        %URL;   #IMPLIED  -- URL for biographical info -->

as it more directly reflects what you describe.  Obviously, it would be
easy for a server to translate this into 

      <LINK rev="OWNS" title="name (email)" href="href">

and thus follow Tim's suggestion as well.


....Roy Fielding   ICS Grad Student, University of California, Irvine  USA
                   (fielding@ics.uci.edu)



From A.C.Holtham@exeter.ac.uk  Wed Dec  8 14:29:32 1993 GMT
Message-Id: <4013.9312081429@olib>
Date: Wed, 8 Dec 93 14:29:32 GMT
From: A.C.Holtham@exeter.ac.uk (A.C.Holtham@exeter.ac.uk)
Subject: Indexes in HTML


I am trying to set up and index search in an HTML document but am
unsure of what the document should hold (I am trying to search on
product)
i.e.

<ISINDEX>
<HEAD>
<TITLE>Test List</TITLE>
</HEAD>
<BODY>
<H1>Test List</H1>
<XMP>
Product         Description
</XMP>

Perl            Shell scripting language
C               C compiler


Can someone please tell me th esyntax -- I can'f find it in the
documentation or on the Web

Thanks in advance,


   Tony Holtham
   aholtham@cen.ex.ac.uk






From dsr@hplb.hpl.hp.com  Wed Dec  8 13:51:24 1993 GMT
Message-Id: <9312081351.AA17111@manuel.hpl.hp.com>
Date: Wed, 8 Dec 93 13:51:24 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: inline sounds

>>     <A HREF="#prologue" PLAY="fanfare.au">The Prologue</A>

> This would mean that if you wanted to change the accompanying effects
> you would have to change all pointers.  Perhaps what we really need is
> URLs that point to a group of files which should be fetched and
> presented simultaneously (a "compound node" in the terminology of the
> Dexter hypertext reference model).  I don't know enough about HTTP,
> but possibly a variant of Content-type: multipart could be used here?

The MIME spec includes multipart/parallel which is defined as:

   "This type is syntactically identical to multipart/mixed, but the
    semantics are different. In particular, in a parallel entity, all
    of the parts are intended to be presented in parallel, i.e.,
    simultaneously, on hardware and software that are capable of doing
    so. Composing agents should be aware that many mail readers will
    lack this capability and will show the parts serially in any event."

So all we need is to make PLAY specify a URL for a multipart/parallel
document, and to enthuse browser writers about the idea.

Dave Raggett



From ira@linus.mitre.org  Wed Dec  8 10:39:21 1993 -0500
Message-Id: <9312081539.AA20877@ellington.mitre.org>
Date: Wed, 8 Dec 93 10:39:21 -0500
From: ira@linus.mitre.org (ira@linus.mitre.org)
Subject: presentations



We implemented interactive presentations in mosaic by adding
extensions to HTML similar to ones that have been suggested. Our point
of view was that mosaic needed to have interactive capabilities similar
to those available from commercial packages such as Macromedia
Director and Authorware. While we have not achieved that yet, I think
we have added some basic capabilities in that direction that bear
consideration by the WWW community.

I think the WWW community should debate carefully the desired "grand
scheme" in active presentations before implementing alot of little
pieces which may limit extensibility down the road.  For a more
complete view of the needed capabilities, we should look more at what
Kaleida's Script-X, and similar scripting languages will do.

Some useful ideas:

Firstly, once you adopt the metaphor of active presentations you may
want to add the capability of controlling them. The ability to alter
the flow of presentation interactively adds greatly to the possible
applications. For example, tutoring. Our implementation acheived this
by loading in alternative augmented-html scripts depending on the
reply to a query.

We also added pause/continue buttons, forward/backward and play audio
buttons.  This allowed us to browse through the presentation and
choose which segments to listen to. The display indicates page N of
TOTAL to let the user know where they are.

Secondly, the ability to alter the screen format is potentially
important. We added a <screenformat style#> command which altered the
mosaic window size, form factor, and display style. For example, Our
presentations used a mosaic window which covered the screen with a
backdrop so that the images could be viewed in an uncluttered
environment. The backdrop hid the normal mosaic document viewer
entirely. In other cases, we had images displayed on one side of the
terminal in conjunction with documents being displayed on the other.



Cheers,

Ira Smotroff
The MITRE Corporation
ira@mitre.org







From sundar@ai.mit.edu  Wed Dec  8 10:48:05 1993 EST
Message-Id: <9312081548.AA14801@rice-chex>
Date: Wed, 8 Dec 93 10:48:05 EST
From: sundar@ai.mit.edu (Sundar Narasimhan)
Subject: http query

Hi, I'd like to know if there's a simple, fast and easy way to find
out the size and type of files referenced by URL anchors in a
document. 

Can someone tell me why the Object meta-information in response
headers have been made optional? I would have thought this should be
mandatory. 

The reason I ask all this, is that I'd like to suggest a modification
to the UI of X-Mosaic and I'd like to find out if it is feasible at
all.



From davis@dri.cornell.edu  Wed Dec  8 11:13:55 1993 -0500
Message-Id: <199312081613.AA23699@willow.tc.cornell.edu>
Date: Wed, 8 Dec 1993 11:13:55 -0500
From: davis@dri.cornell.edu (Jim Davis)
Subject: comments on HTTP draft of 5 Nov 93

Having read the draft of 5 Nov 93 I have some comments.   First, it
is a good step forward, and I congratulate you on it.


1) It's still not clear to me where SPACEJUMP and TEXTSEARCH are used,
or rather, the descriptions confuse me.  As the text on page 7 makes
clear one does not send a SPACEJUMP message, one send GET, and encodes
the spatial indicies into the URL.  So where are SPACEJUMP and
TEXTSEARCH used?  If only in the output from SHOWMETHOD, then they should
not be called methods.  


2) It's not clear to me that  HTTP needs to specify the syntax
by which searches are encoded into URLs, as in the sections in 1.6.1 
GET (p 7) and 1.6.6 SPACEJUMP and 1.6.7 TEXTSEARCH (p 10).  Isn't the URL
syntax a level of abstraction above that of HTTP itself?  Or perhaps
it belongs in HTML, since it requires the cooperation of the client
program (interpreting ISMAP and/or FORM directives) and the server.

3) In my opinion, the specification contains a number of methods
and features  which are currently not sufficiently clearly defined.
I would guess that few, if any, have been implemented, and would
further guess that at least a few are of dubious utility (after
all, if they were truly needed, someone would be implemented them - look
how quickly ISMAP spread.)

They should be removed.  Specifically, I mean CHECKOUT and CHECKIN and SEARCH.
One could argue that LINK and UNLINK are too ill-defined right now,
since the very names have been called into question, and I have argued 
(above) that TEXTSEARCH and SPACEJUMP should be removed, although for
other reasons.

PUT and DELETE and POST and REPLY seem to be sufficiently well
defined that they could be used, but has anyone implemented them?

There are also a number of headers that are ill-defined, but I won't
speak about them here and now.

There is no benefit to the spec by providing them, in their current
ill-defined form.  There is some harm in providing them, since they
make the protocol seem vague.  There is no harm in deleting them,
since the protocol is extensible anyway.  If anyone wishes to experiment
with such new methods, they can write an experimental server to
test the ideas.  Omitting them from the spec does not prevent such
experimentation. 

Don't get me wrong - I am eager to see some of these become part 
of the spec, particularly the authorization stuff.

But it's not a good idea to use the spec as the site for design discussions.
We can do that better in in www-talk (or comp.infosystems.www), 
perhaps also with someone building a working trial implementation.

Remaining comments are keyed to specific sections in the spec:

Re: 1.0  ProtocolVersion is wrong, should be HTTP/1.0

Re: 1.6 Methods - lists five methods that are not further described,
that is, there's nothing in the table of contents about them.  They 
are HEAD, CHECKOUT, PUT, DELETE, CHECKIN.  Also the description of PUT
mentions "REPLY" but this method is not otherwise mentioned or defined.
Finally, the list should either be in alphabetic order or grouped
by semantic similarity  e.g.
GET HEAD POST REPLY DELETE, CHECKOUT CHECKIN, LINK UNLINK, 
TEXTSEARCH, SPACEJUMP,

Re: GET 1.6.1 says, with regard to query terms: "those search terms are first
stripped off".  Stripped by who?  the client?

Re: LINK and UNLINK  (1.6.2) - you are right, the names are no good when
the concept is generalized.  It seems to me that the right names
are SET and CLEAR, since one can think of the header of a document
as containing a set of variables, each of which may be assigned to.
You could also call it ASSIGN and UNASSIGN.  "BESTOW" has the connotation
of awarding a priviledge or access right, it's the wrong name.

Do we really need this feature in HTTP?

Re: SEARCH (1.6.4)  It's not the least bit clear to me what this thing does,
or why it MUST be in the HTTP spec.  Also the correspondance is
formatted funny, it's set in a courier typeface and the lines
are so long they fall off the right margin of the paper.

Re: ACCEPT 1.7.2  Is the order of content types significant?  I
hope so.

Also remember that the MIME spec uses semi-colon, not comma, to separate 
content-type from parameters, and that tokens in parameters can not
include the period character, so "floating point" numbers must be quoted.
I don't know whether space is allowed or not, someone should check.

Re: Accept-Language 1.7.4  Why not use the encoding used in Language
(2.4.12)?  Also, there must be a way to specify the "q" factor for
a language, just as for Accept.  Finally, there must be a specification
of how the q from Content Type and the q from Language interact.
(Multiplied?)

Re: 2.4.9 URI: 1*uri

what does the 1* mean here?

Last and least -- Typos et -- do you have spelling checker?  Would you
prefer I not send spelling corrections?  Maybe it's a waste of your time?

page 5 1.1 sentence 1 ends with two periods in a row, sentence 2 ends with space before period.

page 6 1.4 has an extra space before comma.  also "fromats" abnd "contenst"

page 7 "methos" "incldues" "seperated"; and the last sentence should read
"overwrites any preexisting title".

p 10 "spacified", "postcondidtion", "HTTP2"

p 11 "signifiance"

p 12 "filed" "unspecifies"

p 18 "dimensiosn"

p 19 "smae"  Also there is some kind of formatting glitch here
with the URL for url6.ps  "informatiiuon" "ofthe" 

p 21 "algoritm"

p 24 "resrverd"



From mueller@sc.zib-berlin.de  Wed Dec  8 16:54:32 1993 +0100
Message-Id: <9312081554.AA02200@ave.ZIB-Berlin.DE>
Date: Wed, 8 Dec 93 16:54:32 +0100
From: mueller@sc.zib-berlin.de (Peter Mueller)
Subject: HTML(+)-editor available?

Hi,

I've followed the list for some months, and, though it seems that my 
request is not very well placed in here, I would like to ask for an
easy-to-use HTML(+)-editor.

We at Konrad-Zuse-Zentrum (ZIB) would like to offer most of our
documentation in WWW. But almost all of our main document
writers don't want to hack raw HTML(+). 

As I am a main maintainer for distributed information systems, I hope
you can give me some interest references. (Yes I know, HTML+ is currently
under specification.) I need them to push the ZIB into WWW ...

Cheers,

Peter Mueller



From FisherM@is3.indy.tce.com  Wed Dec  8 11:50:00 1993 PST
Message-Id: <2D063245@MSMAIL.INDY.TCE.COM>
Date: Wed, 08 Dec 93 11:50:00 PST
From: FisherM@is3.indy.tce.com (Fisher Mark)
Subject: HTML Editors on PC Windows?


What editors exist for HTML on PC/Microsoft Windows?  Although I have 
written HTML by hand, I hate to ask my customer base to do that.  Are there 
any editors other than the NextStep HTML editor?
======================================================================
Mark Fisher                            Thomson Consumer Electronics
fisherm@tcemail.indy.tce.com           Indianapolis, IN

"Just as you should not underestimate the bandwidth of a station wagon
traveling 65 mph filled with 8mm tapes, you should not overestimate
the bandwidth of FTP by mail."




From dsr@hplb.hpl.hp.com  Wed Dec  8 17:09:13 1993 GMT
Message-Id: <9312081709.AA17224@manuel.hpl.hp.com>
Date: Wed, 8 Dec 93 17:09:13 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: HTML(+)-editor available?

> I've followed the list for some months, and, though it seems that my 
> request is not very well placed in here, I would like to ask for an
> easy-to-use HTML(+)-editor.

You may find the best route is to author in another format and convert
to HTML, e.g. with Framemaker, MS Word or even LaTeX. There are a number
of conversion programs available on the net.

I am working to ensure that standard SGML authoring tools can be
used for HTML/HTML+. A freeware version is available for emacs, but
there are several commercial versions e.g. Intellitag from WordPerfect.
I think that there is also an emacs-based browser/editor for HTML which
will insert the markup elements for you. This is definitely worth trying.

Given the simplicity of HTML you will soon find it an easy task to author
documents using an ordinary text editor. Preferably one offering wordwrap.
HTML+ is marginally more complicated, but menu driven insertion of markup
via macros will take the tedium out of typing in elements. As the web takes
off, I expect we will see people develop wysiwyg style editors, but this
takes more resources than a grad student working for a few weeks, part time.

Dave Raggett



From montulli@stat1.cc.ukans.edu  Wed Dec  8 11:16:02 1993 CST
Message-Id: <9312081716.AA21574@stat1.cc.ukans.edu>
Date: Wed, 8 Dec 93 11:16:02 CST
From: montulli@stat1.cc.ukans.edu (Lou Montulli)
Subject: Re: RFC: Multi-Owner Maintenance robot (MOMspider)

> 
> Lou Montulli <montulli@stat1.cc.ukans.edu> writes:
> 
> > <Link Rel="made" href...> does not preclude the use of indirection.
> 
> It doesn't preclude anything, nor does it provide the author with any
> guidance for consistency (i.e. the field names do not make sense).  Further,
> there is a significant semantic difference between the OWNS relationship
> (described in Tim's reply) and the MADE relationship.

I don't care if its OWNS or MADE. (actually I wanted OWNER a year ago
when this was first discussed)  But we should discuss this and
implement it as a standard up front rather than hacking in a
quick solution.  The "OWNS" information is exactly what every browser
needs to provide a direct channel between the user/viewer and the
person(s) responsible for the information.
> 
> > There are many other uses for the owners address than just MOMspider
> > so hideing the owners address inside a comment when a defined structure
> > for that information already exists is foolish.  
> 
> First of all, comments are not hidden -- they can be seen in the source.
> Second, it is important to provide a means of indirection AND stating the
> expected use up-front so that future tool-writers can avoid assuming that
> it is an e-mail address and, if necessary, take advantage of the alias
> feature.  Third, of course it's foolish -- that is the nature of a kludge.

They are for all intents and purposes hidden from the browser so they
are hidden.  There is no reason to put this info in a comment when
link exists.  Browsers will ignore link attributes that are unknown.

> 
> > Also, the EXPIRES information you are looking for already has a 
> > predefined method definition.  The information is passed back as
> > an HTTP header that looks like "Expires: DATE".
> 
> It exists as an HTTP header but there is no defined means for providing
> that information to the server for HTML files.  Thus, some form of
> HTML element is needed.
> 
There are a thousand ways of doing it besides a header within the HTML
file.  You could use a database system, cap files, lookup tables, etc. 
Putting it in the HTML file is resonable, but only if the _server_
parses out the info and sends it as the "Expires:" header.

:lou
-- 
  **************************************************************************
  *           T H E   U N I V E R S I T Y   O F   K A N S A S              *
  *         Lou  MONTULLI @ Ukanaix.cc.ukans.edu                           *
  *                         Kuhub.cc.ukans.edu      ACS Computing Services *
  *     913/864-0436        Ukanvax.bitnet             Lawrence, KS 66044  *
  *             UNIX! Cool! I know that!  Jurassic Park - The Movie        *
  **************************************************************************



From vinay@eit.COM  Wed Dec  8 09:31:33 1993 PST
Message-Id: <9312081731.AA29633@eit.COM>
Date: Wed, 8 Dec 93 09:31:33 PST
From: vinay@eit.COM (Vinay Kumar)
Subject: Re: inline sounds

Fully second this approach. Until this idea gets incorporated into browsers 
and servers, use external clients (say, metamail, or...) to handle such 
presentations ! Ofcourse this may not satisfy most of us, but will work for
short term !
--
  Vinay Kumar
vinay@eit.com

-----------------------
> From: Dave_Raggett <dsr@hplb.hpl.hp.com>
>
> The MIME spec includes multipart/parallel which is defined as:
> 
>    "This type is syntactically identical to multipart/mixed, but the
>     semantics are different. In particular, in a parallel entity, all
>     of the parts are intended to be presented in parallel, i.e.,
>     simultaneously, on hardware and software that are capable of doing
>     so. Composing agents should be aware that many mail readers will
>     lack this capability and will show the parts serially in any event."
> 
> So all we need is to make PLAY specify a URL for a multipart/parallel
> document, and to enthuse browser writers about the idea.
> 
> Dave Raggett
> 



From alanb@ncsa.uiuc.edu  Wed Dec  8 11:29:10 1993 CST
Message-Id: <9312081729.AA09672@void.ncsa.uiuc.edu>
Date: Wed, 8 Dec 93 11:29:10 CST
From: alanb@ncsa.uiuc.edu (Alan Braverman)
Subject: HTML Editors on PC Windows?

Fisher Mark writes:
> What editors exist for HTML on PC/Microsoft Windows?  Although I have 
> written HTML by hand, I hate to ask my customer base to do that.  Are there 
> any editors other than the NextStep HTML editor?
> ======================================================================
> Mark Fisher                            Thomson Consumer Electronics
> fisherm@tcemail.indy.tce.com           Indianapolis, IN
> 
> "Just as you should not underestimate the bandwidth of a station wagon
> traveling 65 mph filled with 8mm tapes, you should not overestimate
> the bandwidth of FTP by mail."

Check the Mosaic FAQ: Other WWW/Mosaic Software.

  http://www.ncsa.uiuc.edu/SDG/Software/Mosaic/Docs/faq-software.html

--
Alan Braverman
Software Development Group
National Center for Supercomputing Applications
alanb@ncsa.uiuc.edu



From sanders@bsdi.com  Wed Dec  8 11:41:44 1993 -0600
Message-Id: <199312081741.LAA00354@austin.BSDI.COM>
Date: Wed, 08 Dec 1993 11:41:44 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: comments on HTTP draft of 5 Nov 93 

> 1) It's still not clear to me where SPACEJUMP and TEXTSEARCH are used,
> or rather, the descriptions confuse me.  As the text on page 7 makes
> clear one does not send a SPACEJUMP message, one send GET, and encodes
> the spatial indicies into the URL.  So where are SPACEJUMP and
> TEXTSEARCH used?  If only in the output from SHOWMETHOD, then they should
> not be called methods.  
They are used when returning an object in the Public: or Allowed: headers.
They indicate to the browser that the object can be searched and what form
that search should take.  TEXTSEARCH means use the http:...?query format
and SPACEJUMP means clicking (or other means of spatial selection) should
be used to index into the data and return the relative coordinates of the
selection.

> 3) In my opinion, the specification contains a number of methods
> and features  which are currently not sufficiently clearly defined.
> I would guess that few, if any, have been implemented, and would
> further guess that at least a few are of dubious utility (after
> all, if they were truly needed, someone would be implemented them - look
> how quickly ISMAP spread.)
I think it's a good idea to have the future mapped out so people don't
invent square wheels when someone has already figured out how to make
round ones.  If you remove them then people will implement alternative
solutions that don't fit the model.  This is already a problem as
it stands.

Of course, the official RFC is a different story.  For that I agree with you.

> Don't get me wrong - I am eager to see some of these become part 
> of the spec, particularly the authorization stuff.
There are already implementations of the authorization stuff.

> Re: ACCEPT 1.7.2  Is the order of content types significant?  I
> hope so.
No, the ranking is done with the `q' attribute.

> Re: Accept-Language 1.7.4  Why not use the encoding used in Language
> (2.4.12)?  Also, there must be a way to specify the "q" factor for
> a language, just as for Accept.  Finally, there must be a specification
> of how the q from Content Type and the q from Language interact.
> (Multiplied?)
This is why I voted that Accept-language was the wrong approach.  It
should be an attribute associated with the Accept content-type like all
the other client-profile information is.

--sanders



From waterbug@epims1.gsfc.nasa.gov  Wed Dec  8 13:11:36 1993 +0500
Message-Id: <9312081811.AA03567@epims1>
Date: Wed, 8 Dec 1993 13:11:36 +0500
From: waterbug@epims1.gsfc.nasa.gov (Steve Waterbury)
Subject: Re: HTML(+)-editor available?


Dave Raggett writes,

> I am working to ensure that standard SGML authoring tools can be
> used for HTML/HTML+.... 

I am just curious for more details on this -- do you just mean that 
you are working on making sure that HTML/HTML+ conform to the 
SGML standard, or are there other things you are doing (like 
talking to the tool vendors, etc. -- which I have done and I 
would encourage others to do!).  

I recently got the SoftQuad SGML Author/Editor and Rules Builder, 
and I hope to use the Author/Editor for HTML/HTML+ authoring.  
Does anyone have experience with this?  I don't have any specific 
problems yet because I haven't installed them yet! ... but I 
assume I can just load the HTML/HTML+ DTD's and flail away.

Steve Waterbury
NASA/GSFC
NASA Parts Project Office



From fielding@simplon.ics.uci.edu  Wed Dec  8 10:40:59 1993 -0800
Message-Id: <9312081041.aa19368@paris.ics.uci.edu>
Date: Wed, 08 Dec 1993 10:40:59 -0800
From: fielding@simplon.ics.uci.edu (Roy T. Fielding)
Subject: Re: RFC: Multi-Owner Maintenance robot (MOMspider) 

> Putting it in the HTML file is reasonable, but only if the _server_
> parses out the info and sends it as the "Expires:" header.

Isn't that what we've been talking about?

Look, let's put this issue to rest.  I will hack my local server to
read the HTML headers for (as per Dave's suggestion) something like:

<OWNER name="AliasName" email="owner@domain.edu" href="http:/People/owner.html">
<DATE created="date1_in_rfc850_format" expires="date2_in_rfc850_format">

and have the HTTP headers spit out as:

Owner: name="AliasName"; email="owner@domain.edu"; href="http:/People/owner.html"
Created: date1_in_rfc850_format
Expires: date2_in_rfc850_format

for the first version of MOMspider.  Once we have a working example,
we can decide exactly what to call the headers and whether to use
Link: instead of Owner:.


....Roy Fielding   ICS Grad Student, University of California, Irvine  USA
                   (fielding@ics.uci.edu)



From davis@dri.cornell.edu  Wed Dec  8 13:30:42 1993 -0500
Message-Id: <199312081830.AA24980@willow.tc.cornell.edu>
Date: Wed, 8 Dec 1993 13:30:42 -0500
From: davis@dri.cornell.edu (Jim Davis)
Subject: Re: comments on HTTP draft of 5 Nov 93

To continue the discussion on SPACEJUMP and TEXTSEARCH.  I thank
Tony Sanders for clarifying the role of SPACEJUMP and TEXTSEARCH.

If nothing else, the RFC should be changed to include his words,
or something similar.

But it would seem that SPACEJUMP and TEXTSEARCH are not "methods"
at all, but rather a pair of keywords that inform us of the
capabilities of a particular server or document.  

The meaning of these keywords is that server is prepared to
accept URLs with particular syntaxes and interpret them according
to a set of shared conventions.  

As I see it, there are three such conventions currently in use.
All of them use a question mark to separate the "main" portion
of the URL from the search or index parameters.  They differ in
the form of the parameters

1) ISINDEX: parameters are a list of keywords, separated by +

2) ISMAP: parameters are X and Y coordinates, separated by comma

3) FORM: parameters are pairs of NAME=VALUE, separated by ampersand.

It seems to me that TEXTSEARCH means ISINDEX will work, and SPACEJUMP
means ISMAP will work, and there is no way to say that FORM will work.

So here follow a whole slew of criticisms

1) The names are wrong - they should be changed to reflect the function,
i.e. indicating what kinds of indexing are allowed.  Possible names are
INDEX_KEYWORDS, INDEX_2D, INDEX_FORM

2) The association with GET is wrong.  It seems to me that just as one
could use spatial indexing to GET a document one could use spatial
indexing to POST (or PUT) a document.  Have you seen the world map demo,
which shows a point for each site that's queried the server?  Might
one not want to implement this by POSTing to the X Y coordinates?

So I am trying to argue here that "SPACEJUMP" and "TEXTSEARCH" are
really trying to tell you something about the document, not about
GET per se.

3) It is very unlikely that these two keywords convey useful information,
because most likely, the way you do a GET is by first pulling some
other document from the server.  Do we really expect it to happen
that someone will obtain a URL, then do a HEAD on it (to find out
whether they can use ISMAP syntax to address it), and then do a GET?
Isn't it much more likely that they will obtain the URL through
a client, and be seeing e.g. a map or a picture, along with instructions
to click on it?  And besides that, unless you know the interpretation
of the spatial dimensions, how could you even know what coordinates to send?

Imagine it:  I tell you that I have a URL you can index with an X Y coordinate,
lets even say that I tell you it's a map.  How do you know what X and Y
to pick, until you display it on a browser?

In summary - SPACEJUMP and TEXTSEARCH don't convey useful information,
have the wrong names for the meanings that they do have, and should
not be considered methods.  They should be removed.


 



From FisherM@is3.indy.tce.com  Wed Dec  8 13:32:00 1993 PST
Message-Id: <2D06486A@MSMAIL.INDY.TCE.COM>
Date: Wed, 08 Dec 93 13:32:00 PST
From: FisherM@is3.indy.tce.com (Fisher Mark)
Subject: Re: HTML(+)-editor available?


Dave, could you be so kind as to list some of these conversion programs and 
their locations, esp. the WinWord -> HTML converter, for those of us with 
only mail access to the Internet?  FTP-by-mail is so tedious (but it DOES 
work)...
======================================================================
Mark Fisher                            Thomson Consumer Electronics
fisherm@tcemail.indy.tce.com           Indianapolis, IN

"Just as you should not underestimate the bandwidth of a station wagon
traveling 65 mph filled with 8mm tapes, you should not overestimate
the bandwidth of FTP by mail."



From masinter@parc.xerox.com  Wed Dec  8 11:39:11 1993 PST
Message-Id: <93Dec8.113920pst.2732@golden.parc.xerox.com>
Date: Wed, 8 Dec 1993 11:39:11 PST
From: masinter@parc.xerox.com (Larry Masinter)
Subject: Re: inline sounds

Oh, please! Talk about guilding the lilly!

Why not use the method having the link be multipart/parallel where the
first part is the sound, and the second part is the URL to follow?

It would require making metamail be able to call back to mosaic to
display the URL you're following, perhaps in the same way that
slideshow does.

But don't invent new mechanisms when we haven't really explored the
applications of the old.






From sanders@bsdi.com  Wed Dec  8 14:14:36 1993 -0600
Message-Id: <199312082014.OAA01036@austin.BSDI.COM>
Date: Wed, 08 Dec 1993 14:14:36 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: comments on HTTP draft of 5 Nov 93 

> But it would seem that SPACEJUMP and TEXTSEARCH are not "methods"
> at all, but rather a pair of keywords that inform us of the
> capabilities of a particular server or document.  
> 
> The meaning of these keywords is that server is prepared to
> accept URLs with particular syntaxes and interpret them according
> to a set of shared conventions.  
Agreed.  We need an extensible attribute scheme.  Of course, you could
just use headers but that tends to be too unstructured.

> It seems to me that TEXTSEARCH means ISINDEX will work, and SPACEJUMP
> means ISMAP will work, and there is no way to say that FORM will work.
I think that's because a FORM is an attribute of the document contents,
not the document itself.

> So I am trying to argue here that "SPACEJUMP" and "TEXTSEARCH" are
> really trying to tell you something about the document, not about
> GET per se.
Mostly correct.  It's actually telling you something about the OBJECT in
question.  Not all objects are documents.  However, it also implies
what you can *do* with the object and how it is to be done.  Therefore
it helps defines the interface to the object.

> 3) It is very unlikely that these two keywords convey useful information,
> because most likely, the way you do a GET is by first pulling some
> other document from the server.  Do we really expect it to happen
> that someone will obtain a URL, then do a HEAD on it (to find out
> whether they can use ISMAP syntax to address it), and then do a GET?
No, the browser GET's the URL and says to itself "hey, I can search
using this URL and this method".  Then it changes the user interface
so the user also knows this fact.

> In summary - SPACEJUMP and TEXTSEARCH don't convey useful information,
> have the wrong names for the meanings that they do have, and should
> not be considered methods.  They should be removed.
You are forgetting a very important fact here.  Not all objects returned
by HTTP are HTML.  This information *MUST* be allowed in the object
meta-information (aka the HTTP header) because not all data types allow
ISINDEX and ISMAP!

Perhaps the design should be changed a bit but SPACEJUMP and TEXTSEARCH
should *NOT* be removed in spirit.  I see the names as a pretty arbitrary
since only software ever sees them.

--sanders



From phillips@cs.ubc.ca  Mon Dec  8 13:09:00 1993 -0800
Message-Id: <7017*phillips@cs.ubc.ca>
Date: 8 Dec 93 13:09 -0800
From: phillips@cs.ubc.ca (George Phillips)
Subject: Re: CGI/1.0 tweaks

Rob sez:
>Hang on, you're confusing me. If it's a self-referencing *URL*, then you
>should be able to include port and hostname any way since it is a URL. In
>what context are you building these self-referencing URLs? For the Location:
>header? For HTML links?

I was narrow-mindedly thinking that the gateway would only wish to
reference itself in HTML output where saying <A HREF=/foo/bar>link</A>
is sufficient because the client will fill in "http://a.machine:port".
I had forgotten "Link:" and other headers which need "complete" URLs.
My use of URL was incorrect.

>The problem I see here is not that there are extra variables, it's that
>sending back URLs to non-HTTP clients won't usually work.

Right.  However, I'm not expecting that you can simply write a gateway
script which can spit HTML and have that translated by the server into
gopherese.  I think it's sufficient to solve the problem that gateway
scripts can only self-reference themselves if they assume they're
being accessed via HTTP.  How about this:  drop SERVER_PORT and
expand SERVER_NAME to include the URL scheme, hostname and port.
A script then can create self-referencing URLs by saying:

	$SERVER_NAME$SCRIPT_NAME$PATH_INFO

This will solve the problem in the x-exec: scheme and will have the
benefit of letting the scripts operate as long as whatever protocol
they're using gives them a URL and will understand their MIME object
output.  Here's how a few URLs might break down:

	SERVER_NAME	SCRIPT_NAME	PATH_INFO

http://a.host:99	/htbin/finger	/phillips/cs/ubc/ca
x-exec://\bin\wrn			/newsgroups/comp.sources.misc
dec-http://decnetaddr	/htbin/finger	/phillips/cs/ubc/ca

The only down-side to this is CGI scripts which wish to output
something that isn't HTML or WWW-MIME like.  They're going to
have to work harder in parsing the SERVER_NAME so they can spit
out, say, a gopher directory.  I see this as acceptable --
especially since it very nicely abstracts the access protocol.

Now, you might ask about SERVER_PROTOCOL.  Well, I'd argue that's
independent of SERVER_NAME.  Certainly x-exec: will tell you
the SERVER_PROTOCOL is HTTP/1.0 -- no reason not to since x-exec:
will give you the extra information on a POST and it will accept
full HTTP/1.0 repsonses.  I'm sure the same would be true of
the hypothetical dec-http: scheme -- just the transport is different.
In that way, SERVER_PROTOCOL is a bit of a misnomer, but I
certainly can't think of a better name.

			-- George




From altis@ibeam.jf.intel.com  Wed Dec  8 14:58:16 1993 -0800
Message-Id: <m0p7Xod-0003XmC@ibeam.intel.com>
Date: Wed, 8 Dec 1993 14:58:16 -0800
From: altis@ibeam.jf.intel.com (Kevin Altis)
Subject: HTML comments removed from spec.?

Tim,
I must have missed this decision, but in
<http://info.cern.ch/hypertext/WWW/MarkUp/NonStandard.html> Comments are
listed as obsolete to be replaced later. Is there no acceptable way to do
comments in an HTML file now that works across all clients? What was wrong
with <!-- --> Isn't that SGML?

ka





From davis@dri.cornell.edu  Wed Dec  8 17:58:27 1993 -0500
Message-Id: <199312082258.AA27270@willow.tc.cornell.edu>
Date: Wed, 8 Dec 1993 17:58:27 -0500
From: davis@dri.cornell.edu (Jim Davis)
Subject: Re: comments on HTTP draft of 5 Nov 93


> From sanders@BSDI.COM Wed Dec  8 15:14:52 1993
> No, the browser GET's the URL and says to itself "hey, I can search
> using this URL and this method".  Then it changes the user interface
> so the user also knows this fact ... .  Not all objects returned
> by HTTP are HTML.  This information *MUST* be allowed in the object
> meta-information (aka the HTTP header) because not all data types allow
> ISINDEX and ISMAP!

Oh!  I get it.  In the old days, the browser saw an ISINDEX
HTML tag, and that made the "Search Keywords" field activate.
But this could only work for HTML documents.  So the idea
is to put the information (that the object is searchable
in such-and-such way) into the object header instead of the
content.

If that's the real and true reason, then the RFC should explain
that.

But my argument about ISMAP still makes sense doesn't it?  It's
one thing to "blindly" search a document with text keywords,
it's another to submit a pair of X Y coordinates.

And I certainly see the need for this information now.  But
tell me, do the existing browsers check for these methods in
the header?  My server certainly is not returning them at present,
and things still work, but perhaps that's because they are not
needed when the data is HTML.






From henrich@crh.cl.msu.edu  Wed Dec  8 18:39:51 1993 -0500 (EST)
Message-Id: <9312082339.AA27477@crh.cl.msu.edu>
Date: Wed, 8 Dec 1993 18:39:51 -0500 (EST)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: Browser handling of URL's with '?' in them

Okay a number of folks of the NCSA For Macintosh browser have pointed out that
the Macintosh browser find's the first question mark in a URL and lops off
everything after it.  As a result of which my interactive weather stuff does
not work.  I havent been able to find any definitive word on this in the specs,
while Mosaic for X only remove's what it appends on subsequent queries (as I
think it should).  So the question is this, whats the definitive behavior for a
browser when it encounters a URL like:

http://somehost/somedoc?item

and is clickable (i.e ismap).  When someone enter's clicks should the resulting
URL be:

http://somehost/somedoc?item?x,y (as mosaic for X handles it)

or

http://somehost/somedoc?x,y

as in the case of the Mosaic for Mac's?

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                     http://rs560.msu.edu/~henrich/



From sanders@bsdi.com  Wed Dec  8 18:31:09 1993 -0600
Message-Id: <199312090031.SAA03435@austin.BSDI.COM>
Date: Wed, 08 Dec 1993 18:31:09 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: comments on HTTP draft of 5 Nov 93 

> > so the user also knows this fact ... .  Not all objects returned
> > by HTTP are HTML.  This information *MUST* be allowed in the object
> > meta-information (aka the HTTP header) because not all data types allow
> > ISINDEX and ISMAP!
> 
> Oh!  I get it.  In the old days, the browser saw an ISINDEX
bingo.

> If that's the real and true reason, then the RFC should explain that.
It does, just not very well :-)

> But my argument about ISMAP still makes sense doesn't it?  It's
> one thing to "blindly" search a document with text keywords,
> it's another to submit a pair of X Y coordinates.
You aren't searching the document though.  You are using the URL to initate
a search of "something" and that "something" is defined by the server not
the client.  It might be a WAIS database, like:
    http://httptest.bsdi.com/plexus-3.0/plexus.html
or it might be a graphical index into some other data space, etc.

> And I certainly see the need for this information now.  But
> tell me, do the existing browsers check for these methods in
> the header?
Nope, not yet.

> My server certainly is not returning them at present,
> and things still work, but perhaps that's because they are not
> needed when the data is HTML.
Right.   Also note that SPACEJUMP would not be an attribute of the
document, but rather would be returned when you retrieved the
URL that points to the image itself (indicating that the URL can
be used as a spatial index vs. a textual index for TEXTSEARCH).
Thus the names.

Pretty neat eh?

I still agree that there should be another way to indicate the attributes
of an object instead of them being methods.  It's also highly likely that
they should allow options, e.g.,

    WWW-object-attr: SPACEJUMP;dimensions=3, TEXTSEARCH;style="wais"

--sanders



From fwilliam@ccs.carleton.ca  Wed Dec  8 20:39:03 1993 EST
Message-Id: <9312090139.AA06363@superior.YP.nobel>
Date: Wed, 8 Dec 93 20:39:03 EST
From: fwilliam@ccs.carleton.ca (Fred Williams)
Subject: RE: comments on HTTP draft of 5 Nov 93

Subject: RE: comments on HTTP draft of 5 Nov 93
To: davis@dri.cornell.edu
Date: Wed, 8 Dec 93 19:59:51 EST
Cc: www_talk_request@dxcern.cern.ch
X-Mailer: ELM [version 2.3 PL11]

Jim Davies writes
> They should be removed.  Specifically, I mean CHECKOUT and CHECKIN
  and SEARCH.
> One could argue that LINK and UNLINK are too ill-defined right now,
> since the very names have been called into question, and I have
  argued 
> (above) that TEXTSEARCH and SPACEJUMP should be removed, although
  for
>other reasons.

The method SEARCH is intended to allow for the searching of items that do not
easily lend themselves to a textual representation and as such do not fit the
current method of specifying search terms using GET.  By specifying the SEARCH
method and including the search terms within the MIME envelope any information
can be searched (within the capabilities of the server).  This would allow for
the following (example) searches to be done:
 
    All sound clips that contain this passage
    All pictures that contain this element
    etc.
    and other searches not yet explored within the MultiMedia enviroment.

> Re: SEARCH (1.6.4)  It's not the least bit clear to me what this
  thing does,
> or why it MUST be in the HTTP spec.  Also the correspondance is
> formatted funny, it's set in a courier typeface and the lines
> are so long they fall off the right margin of the paper.

It should be in the HTTP specification as it represents a generalized way to 
search information.  I realize that the specification may not represent all the
intent of the idea but it is really a `chicken or egg' type problem. 

The formatting of the text is a decision left to the author of the document.  

I would be happy to detail out the functionality of this method, if requested,
now that my academic obligations are complete.

Fred Williams

fwilliam@ccs.carleton.ca



From guenther.fischer@hrz.tu-chemnitz.de  Thu Dec  9 07:18:53 1993 +0100 (MET)
Message-Id: <9312090618.AA05622@etzel.hrz.tu-chemnitz.de>
Date: Thu, 9 Dec 1993 07:18:53 +0100 (MET)
From: guenther.fischer@hrz.tu-chemnitz.de (Guenther Fischer)
Subject: WWW_http_GATEWAY definition?

I'm on the way to give www as a base service to our users. All the
unixes with X works fine with Mosaic (thanks to NCSA ...). Mosaic
for Windows too but I need the WWW_http_GATEWAY - feature for
(X)Mosaic - how can I do this or isn't it avialable. (For MacMosaic
the same question).
I've setup a HTTP-Cache-Server for with help of the WWW_http_GATEWAY
feature of Mosaic.

Last: We have many PC's without window - are there good solutions?

	~Thanks for help
-- 
Name:      Guenther Fischer
Institute: TU Chemnitz, Universitaetsrechenzentrum
Phone:     0371 668 361
mail:      fischer@hrz.tu-chemnitz.de



From rik@rdt.monash.edu.au  Thu Dec  9 17:23:15 1993 +1100
Message-Id: <199312090623.RAA00684@daneel.rdt.monash.edu.au>
Date: Thu, 09 Dec 93 17:23:15 +1100
From: rik@rdt.monash.edu.au (Rik Harris)
Subject: Re: Browser handling of URL's with '?' in them 

Charles Henrich <henrich@crh.cl.msu.edu> wrote:
> Okay a number of folks of the NCSA For Macintosh browser have pointed out that
> the Macintosh browser find's the first question mark in a URL and lops off
> everything after it.  As a result of which my interactive weather stuff does
> not work.  I havent been able to find any definitive word on this in the specs,
> while Mosaic for X only remove's what it appends on subsequent queries (as I
> think it should).  So the question is this, whats the definitive behavior for
> a
> browser when it encounters a URL like:
> 
> http://somehost/somedoc?item
> 
> and is clickable (i.e ismap). When someone enter's clicks should the resulting
> URL be:
> 
> http://somehost/somedoc?item?x,y (as mosaic for X handles it)
> 
> or
> 
> http://somehost/somedoc?x,y
> 
> as in the case of the Mosaic for Mac's?

I've had problems with this too, except the other way.  I'd like to be
able to have the document returned from a search, also searchable,
using the same search as the original document.  

I like the way forms are submitted.  Would it be possible to set
the head of the URL returned as the search as part of the <ISINDEX>, 
like maybe <ISINDEX ACTION="http://...."> like the forms.

Does that make sense?

rik.
--
Rik Harris - rik.harris@vifp.monash.edu.au              || Systems Programmer
+61 3 560-3265 (AH) +61 3 565-3227 (BH)                 || and Administrator
Fac. of Computing & Info.Tech., Monash Uni, Australia   || Vic. Institute of
http://www.vifp.monash.edu.au/people/rik.html           || Forensic Pathology



From dsr@hplb.hpl.hp.com  Thu Dec  9 10:11:19 1993 GMT
Message-Id: <9312091011.AA17870@manuel.hpl.hp.com>
Date: Thu, 9 Dec 93 10:11:19 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: HTML(+)-editor available?

>> I am working to ensure that standard SGML authoring tools can be
>> used for HTML/HTML+.... 

> I am just curious for more details on this -- do you just mean that 
> you are working on making sure that HTML/HTML+ conform to the 
> SGML standard, or are there other things you are doing (like 
> talking to the tool vendors, etc. -- which I have done and I 
> would encourage others to do!).  

The easy first step was to ensure that the DTD is parsed without errors
by sgmls 1.1 (the latest version). The next and harder step is to ensure
that test examples work as well, and that this is true for other sgml
parsers. Thus Intellitag doesn't seem to respect the resource limits
specified by the DTD's <!SGML> prelude. Getting the revised HTML+ DTD
to work effectively with commonly available SGML authoring tools is my
current goal.

> I recently got the SoftQuad SGML Author/Editor and Rules Builder, 
> and I hope to use the Author/Editor for HTML/HTML+ authoring.  
> Does anyone have experience with this?  I don't have any specific 
> problems yet because I haven't installed them yet! ... but I 
> assume I can just load the HTML/HTML+ DTD's and flail away.

Thats the short term goal! In the longer run, though, I expect that
editors designed with the web in mind will be easier to use.

Dave Raggett



From dsr@hplb.hpl.hp.com  Thu Dec  9 12:08:47 1993 GMT
Message-Id: <9312091208.AA22032@manuel.hpl.hp.com>
Date: Thu, 9 Dec 93 12:08:47 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: HTML(+)-editor available?

> Dave, could you be so kind as to list some of these conversion programs and 
> their locations, esp. the WinWord -> HTML converter, for those of us with 
> only mail access to the Internet?  FTP-by-mail is so tedious (but it DOES 
> work)...

Rich Brandwein rhb@hotsand.att.com has collected info on converter/filter
software, see http://info.cern.ch/hypertext/WWW/Tools/Filters.html

I will summarise his data for word processors (he has data for other
filters as well, including program language filters, man page, FAQ and
Mail filters).

To get an HTML document via email, e.g.

    http://info.cern.ch/hypertext/WWW/Tools/Filters.html

You should email listserv@info.cern.ch with a message which looks like:

    SEND http://info.cern.ch/hypertext/WWW/Tools/Filters.html
    STOP

Make sure the first line starts with the SEND command (no leading spaces).
There is a 1000 line limit on any returned file and please don't abuse
this facility.

-----------------------------------------------------------------------------

MS Word RTF :

    rtftohtml (cjh@cray.com) [[excellent - requires ...]]
        ftp://ftp.cray.com/src/cjh/RTF

    rtftohtml (cshotton@oac.hsc.uth.tmc.edu) [[outdated?]]
        http://info.cern.ch/hypertext/WWW/Tools/HTMLGeneration/rtf2html.html

Word Perfect :

    mcr@spiff.carleton.ca [[word perfect 5.1 filter]]
        http://info.cern.ch/hypertext/WWW/Tools/WP2HTML.html

FrameMaker MIF :

    jons@nta.no
        ftp://bang.nta.no/pub/fm2html.tar.Z

    more info at http://info.cern.ch/hypertext/WWW/Tools/fm2html.html

TROFF :
    oscar@cui.unige.ch [[good]]

    http://cui_www.unige.ch/ftp/PUBLIC/oscar/scripts/ms2html

LATEX :
    nikos@cbl.leeds.ac.uk [[state of the art in filters]]

    http://cbl.leeds.ac.uk/nikos/tex2html/doc/latex2html/latex2html.html

Texinfo :
    cons@dxcern.cern.ch

    http://asis01.cern.ch/infohtml/texi2html.html



From mcclanah@dlgeo.cr.usgs.gov  Thu Dec  9 06:27:14 1993 -0600
Message-Id: <9312091227.AA22176@dlgeo.cr.usgs.gov>
Date: Thu, 9 Dec 1993 06:27:14 -0600
From: mcclanah@dlgeo.cr.usgs.gov (mcclanah@dlgeo.cr.usgs.gov)
Subject: Found this on an educational listserver this morning

Found this on the kidsphere listserver this morning, just
thought I would pass it along - more good press for Mosiac and WWW


------------------------------Forwarded message-----------------------------
Date: Thu, 9 Dec 1993 00:01:17 EST
From: KIDSPHERE Mailing List <kidsphere@vms.cis.pitt.edu>
Subject: MOSAIC-"Killer App" for education? (from alt.education.distance,comp.infosystems.www,sci.space,misc.education)
To: KIDSPHERE Subscribers <kidsphere@vms.cis.pitt.edu>
Warnings-To: <kidsphere-request@vms.cis.pitt.edu>
Reply-To: <KIDSPHERE@vms.cis.pitt.edu>
Content-Type: text
Content-Length: 1725

Keywords: mosaic,ncsa
From: ccat@netcom.com (Chris Beaumont)
Subject: MOSAIC-"Killer App" for education?
Newsgroups: alt.education.distance,comp.infosystems.www,sci.space,misc.education
Date: 8 Dec 93 18:47:16 GMT
Organization: Morningdew Associates
Xref: ophelia.phyast.pitt.edu alt.education.distance:1048 comp.infosystems.www:4194 sci.space:40538 misc.education:10791

It strikes me that the new program for accessing the WWW (World Wide Web)
"MOSAIC" could serve as the catalyst that makes kids interested in science 
again,particularly space science.. Read the article on the front page of
todays New York Times about this program and you'll see what I mean,if 
you arent already familiar with it.(the program is available from
ftp.ncsa.uiuc.edu and requires an Internet link.) For those who feel
that the American education system is faltering and needs something to 
get science education (and really all kinds of education) back on 
track,look no further.I think that all elementary and secondary 
schools,as well as colleges,should develop Mosaic resourses immediately.
Dont let the huge corporations derail cooperative solutions like this and 
try to sell their proprietary products.Mosaic is already a de-facto system
for turning kids on to science.Teachers,take note.
Scientists, also take note.Funding for NASA could be dramatically increased
by means of Mosaic. (The accessibility of space images and datasets 
through Mosaic could make it possible for millions of youngsters to actually
_participate_ in space study and research.) If the scientific community 
doesnt grab this and run with it,you are missing out on  a huge opportunity.
Go for it. dont let the corporations steal the future.
-Chris Beaumont.



--------------------------------End of Forwarded message---------------------


Pat McClanahan		Internet:mcclanah@dlgeo.cr.usgs.gov
EROS Data Center 		 mcclanah@edcserver1.cr.usgs.gov
Sioux Falls, SD
605-361-4607



From davis@dri.cornell.edu  Thu Dec  9 09:54:11 1993 -0500
Message-Id: <199312091454.AA06218@willow.tc.cornell.edu>
Date: Thu, 9 Dec 1993 09:54:11 -0500
From: davis@dri.cornell.edu (Jim Davis)
Subject: RE: SEARCH (was: comments on HTTP draft of 5 Nov 93)

Dear Fred (and WWW) - At time time I wrote the letter
I did not understand what SEARCH was supposed to do. 

Now I think I do -  it allows one to encode the search information
in the message body instead of the URL, right?  This allows one to do searches
that can't be expressed in a URL either because they are too long
or because they are not textual, e.g. one could use a picture
as a query.)

Now that I understand it, I recognize that it would be VERY useful.
I have an application that requires it in fact.  I want it.

But I still think it should go out of the spec until it's
well defined.  It's not a judgement about the value of the idea,
only about the chaos in the document.  You want proof that the
current description is confusing?  Here it is:  I was confused.
I could not tell what the thing was supposed to do, much less
how it was supposed to do it.  A spec is supposed to tell you
how to implement a complying client or server.  The current
spec does not do that.  So the meta-point here, the one that
is logically prior, is "Should the HTTP spec say anything at
all about features which are neither mandatory nor fully designed?"

We have not heard from Tim on this topic - and it is he
who owns the document.   If he wants it to contain such
partial designs, it is his right and priviledge. Tim, are you there? 

As for SEARCH itself - I need and want this feature.
I would be grateful were you to devote
the time to bring the design to completion.  I would be pleased
to help anyway I can.  I will support it in my server.  I am already
thinking of how to make a client to use it.
 

PS I will also volunteer to Tim to help edit the specification  (to
remove or improve ill-defined features) if you are too busy to do that.


best wishes,
jim




From P.Lister@cranfield.ac.uk  Thu Dec  9 14:27:40 1993 GMT
Message-Id: <9312091427.AA03689@xdm039.ccc.cranfield.ac.uk>
Date: Thu, 09 Dec 93 14:27:40 GMT
From: P.Lister@cranfield.ac.uk (Peter Lister, Cranfield Computer Centre)
Subject: Re: HTML(+)-editor available?

I have a basic but useful DECwrite to HTML PERL script.

ftp://ftp.cranfield.ac.uk/source/info-tools/WWW/decw2html

Peter Lister                             Email: p.lister@cranfield.ac.uk
Computer Centre, Cranfield University    Voice: +44 234 754200 ext 2828
Cranfield, Bedfordshire MK43 0AL UK        Fax: +44 234 750875
--- Widget. It's got a widget. A lovely widget. A widget it has got. ---

#!/usr/local/bin/perl
# Author:
#   Peter Lister                                    p.lister@cranfield.ac.uk
#   Computer Centre,
#   Cranfield Institute of Technology,        Voice: +44 234 754200 ext 2828
#   Cranfield, Bedfordshire MK43 0AL England    Fax: +44 234 750875
#
# This script copes with SGML output from DECwrite. It should cope with basic
# documents in Example, General, Slide, Technical Manual styles, which are the
# ones I happen to have used.
# It ignores some tags, translates others, and leaves any it doesn't know
# alone.
# Specifically, it
#   Removes ! tags. If I understood SGML, maybe I could make sense of them.
#   Directly converts:
#     Headings
#     Paragraphs
#     Page breaks
#   Parses and does groovy stuff with
#     Tables of Contents
#     Numbered and Bulleted lists and sublists
#     Footnotes
# Wish list:
#   Document references
#   Pictures
# If you use this script please let me know. If you add bits to cope with
# other styles and local preferences, please send me the a copy of what you
# did. 



From montulli@stat1.cc.ukans.edu  Thu Dec  9 10:18:09 1993 CST
Message-Id: <9312091618.AA50916@stat1.cc.ukans.edu>
Date: Thu, 9 Dec 93 10:18:09 CST
From: montulli@stat1.cc.ukans.edu (Lou Montulli)
Subject: Re: WWW_http_GATEWAY definition?

> 
> I'm on the way to give www as a base service to our users. All the
> unixes with X works fine with Mosaic (thanks to NCSA ...). Mosaic
> for Windows too but I need the WWW_http_GATEWAY - feature for
> (X)Mosaic - how can I do this or isn't it avialable. (For MacMosaic
> the same question).
> I've setup a HTTP-Cache-Server for with help of the WWW_http_GATEWAY
> feature of Mosaic.
> 
> Last: We have many PC's without window - are there good solutions?
> 
Two solutions, one you can use now, the other in a few months.
Run Lynx on a UNIX or VMS box and have your non-windows dos machines
telnet and use Lynx.

In the near future you will be able to use the all new PC Lynx
which is currently under development.

:lou
-- 
  **************************************************************************
  *           T H E   U N I V E R S I T Y   O F   K A N S A S              *
  *         Lou  MONTULLI @ Ukanaix.cc.ukans.edu                           *
  *                         Kuhub.cc.ukans.edu      ACS Computing Services *
  *     913/864-0436        Ukanvax.bitnet             Lawrence, KS 66044  *
  *             UNIX! Cool! I know that!  Jurassic Park - The Movie        *
  **************************************************************************



From atotic@ncsa.uiuc.edu  Thu Dec  9 11:50:23 1993 -0600 (CST)
Message-Id: <9312091750.AA24353@void.ncsa.uiuc.edu>
Date: Thu, 9 Dec 1993 11:50:23 -0600 (CST)
From: atotic@ncsa.uiuc.edu (Alexsander Totic)
Subject: Re: Browser handling of URL's with '?' in them7

> think it should).So the question is this, whats the definitive behavior for a
> browser when it encounters a URL like:
> http://somehost/somedoc?item
> and is clickable (i.e ismap).  When someone enter's clicks should the resulting
> URL be:
> http://somehost/somedoc?item?x,y (as mosaic for X handles it)
> or
> http://somehost/somedoc?x,y
> as in the case of the Mosaic for Mac's?

In the URL's specs, '?' is defined as the separator between the document
name and the search string. I have understood this to mean that only a 
single question mark is allowed. This behavior works well for <ISINDEX>
pages,  and I think that we should not make ISMAP an exception.

Aleks



From montulli@stat1.cc.ukans.edu  Thu Dec  9 13:35:28 1993 CST
Message-Id: <9312091935.AA28690@stat1.cc.ukans.edu>
Date: Thu, 9 Dec 93 13:35:28 CST
From: montulli@stat1.cc.ukans.edu (Lou Montulli)
Subject: Re: PC Lynx

> 
> Lou,
> 
> > In the near future you will be able to use the all new PC Lynx
> > which is currently under development.
> 
> Sounds great, will it work in a 640K machine for all those folks
> with old machines (sounds of "real world" echoing in distance)?

That's the idea.  Well let NCSA & Cornell do all the fancy stuff and
KU can fill in those unsightly gaps in between :)

> 
> It would also be neat if it worked with a modem, but without SLIP.
> I spent some time thinking about this, and decided that one could
> easily run the networking stuff as a program on the "mainframe",
> with a cache etc. given that error correction is handled by modems.

Yes that would be an option once it's stable.

> 
> This approach gives you much better scrolling speeds than just
> running Lynx under a terminal emulator, plus the ability to save
> locally and to use a local printer. Borland's C++ package takes
> away the pain of having to deal with different display types.

We are using turbo vision to give a psuedo windowing capibility,
mouse control, pull down windows, and an overall nice apperance.

> p.s. I am beavering away on the revised DTD, and hope to publish it
> soon as I get test cases to work well on SGML authoring tools.
> 
Looking forward to it.

:lou
-- 
  **************************************************************************
  *           T H E   U N I V E R S I T Y   O F   K A N S A S              *
  *         Lou  MONTULLI @ Ukanaix.cc.ukans.edu                           *
  *                         Kuhub.cc.ukans.edu      ACS Computing Services *
  *     913/864-0436        Ukanvax.bitnet             Lawrence, KS 66044  *
  *             UNIX! Cool! I know that!  Jurassic Park - The Movie        *
  **************************************************************************



From Lillian.Elam@eng.sun.com  Thu Dec  9 16:55:17 1993 PST
Message-Id: <9312100055.AA04786@bayside.Eng.Sun.COM>
Date: Thu, 9 Dec 93 16:55:17 PST
From: Lillian.Elam@eng.sun.com (Lile Elam)
Subject: Please add me to this mailing alias...


I have 2 address.

lile@eng.sun.com
and
lile@netcom.com

thanks,

-lile



From marca@ncsa.uiuc.edu  Fri Dec 10 17:37:07 1993 -0800
Message-Id: <9312110137.AA22251@wintermute.ncsa.uiuc.edu>
Date: Fri, 10 Dec 93 17:37:07 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: info re sgml product

From: newsbytes@clarinet.com
Newsgroups: clari.nb.general
Subject: SGML '93: Rainbow "SGML Enabler" Available On Internet 12/10/93
Keywords: Bureau-BOS
Date: 10 Dec 93 20:54:05 GMT

BOSTON, MASSACHUSETTS, U.S.A., 1993 DEC 10 (NB) -- Electronic
Book Technologies (EBT) has announced that Rainbow (RB), a
new "public technology platform" for easing the transition from
proprietary word processor (WP) data to Standard Generalized
Markup Language (SGML), is now available free of charge over the
Internet. 

David Sklar, senior application developer at EBT and leader of a
team of SGML tool vendors that created Rainbow, told Newsbytes
that the new approach specifies a single Document Type Definition
(DTD) for use as an "enabler" between proprietary word processor
data formats and SGML. DTDs are used to designate rules for
SGML, an emerging standard for publication and delivery of
electronic information.

The DTD specified under Rainbow represents a variety of
proprietary word processor formats, said Sklar, in a meeting with
Newsbytes at SGML '93. The tool makers have also developed
"Rainbow Makers" for converting the proprietary WP information
into the Rainbow DTD. 

Once a document is represented in basic Rainbow format, "Rainbow
Transformers" and other new tools can be used to extract the
richer SGML structures required by various industry-specific
DTDs, such as DocBook, J2008, RefBook, HTML, and AAP.
                                       ^^^^

Sklar explained that SGML is gaining momentum in the
marketplace as organizations with large bodies of information --
such as technical manuals, maintenance procedures, catalogs, and
price lists -- begin to stabilize their data by converting to a
standard, vendor- and application-neutral format.

"(But) proprietary word processing formats are typically poorly
documented, highly idiosyncratic, and subject to change without
notice. Maintaining conversion tools that recognize such formats
is thus a very expensive endeavor. The goal of Rainbow is to
provide a stable data format to feed conversion tools, making the
path to SGML much more affordable and increasing the shelf-life
of such tools," he added. 

Rainbow has obtained strong support from a number of leading SGML
tool vendors, including SoftQuad, Exoterica, ArborText, and
Database Publishing Systems, according to Sklar.

Rainbow Makers are currently available for several word
processing formats, including Windows RTF (Rich Text Format),
Interleaf, and Frame, Newsbytes was told. "But we are issuing a
call to the industry for greater involvement in the Rainbow
effort," Sklar told Newsbytes.

To obtain free copies of Rainbow Makers and the annotated Rainbow
DTD anonymously via the Internet, use FTP server ftp.ebt.com. 
Rainbow data is located in pub/outgoing/rainbow.

To receive notification of Rainbow DTD updates and events, as
well as information on the status of Rainbow Makers, subscribe to
the Rainbow information service. You can contact the information
service by sending electronic mail to rainbow@ebt.com.

(Jacqueline Emigh/19931210/Reader contact: EBT, tel
401-421-9550; Press contacts: Kent Summers, EBT, tel
401-421-9550; Paul Lamoureux, Miller Communications for EBT, tel
617-536-0470)




From janssen@parc.xerox.com  Fri Dec 10 18:35:24 1993 PST
Message-Id: <Ah2H7gsB0KGW1Gkkpf@holmes.parc.xerox.com>
Date: Fri, 10 Dec 1993 18:35:24 PST
From: janssen@parc.xerox.com (Bill Janssen)
Subject: Re: Synchronized...

Wouldn't HyTime be the right format to use?

Bill



From janssen@parc.xerox.com  Fri Dec 10 18:48:51 1993 PST
Message-Id: <sh2HIHQB0KGWNGkllD@holmes.parc.xerox.com>
Date: Fri, 10 Dec 1993 18:48:51 PST
From: janssen@parc.xerox.com (Bill Janssen)
Subject: Re: CGI/1.0: last call

Excerpts from ext.WorldWideWeb: 6-Dec-93 Re: CGI/1.0: last call Peter
Lister@cranfield.a (661)

> > Authentication must be the responsibility of the script writer.  While

Interesting.  I just returned from a meeting where various security
experts impressed on me just how bad an idea that is, as it increases
the amount of code in the "Trusted Computing Base" unmanageably.  They
felt that such a system could never be rated secure.

> What he said. Any authentication mechanism must allow for any
> authentication data to be passed to the server. I want to write HTML
> front ends to various Kerberos authenticated doobreys, and I MUST be
> able to pass a ticket to the server, and preferably also encrypted data
> using the Kerberos session key.

Well, perhaps as an option.

Bill



From janssen@parc.xerox.com  Fri Dec 10 18:54:43 1993 PST
Message-Id: <Mh2HNnYB0KGW1GkmEp@holmes.parc.xerox.com>
Date: Fri, 10 Dec 1993 18:54:43 PST
From: janssen@parc.xerox.com (Bill Janssen)
Subject: Re: inline sounds

multipart/hytime, anyone?

Bill



From marca@ncsa.uiuc.edu  Fri Dec 10 23:17:28 1993 -0800
Message-Id: <9312110717.AA23315@wintermute.ncsa.uiuc.edu>
Date: Fri, 10 Dec 93 23:17:28 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Re: inline sounds

Bill Janssen writes:
> multipart/hytime, anyone?
> 
> Bill

Sure -- can't wait to see the spec.

Cheers,
Marc




From decoux@moulon.inra.fr  Sat Dec 11 11:50:39 1993 +0100
Message-Id: <9312111050.AA02536@moulon.moulon.inra.fr>
Date: Sat, 11 Dec 93 11:50:39 +0100
From: decoux@moulon.inra.fr (ts)
Subject: CGI/1.0: last call


> Interesting.  I just returned from a meeting where various security
> experts impressed on me just how bad an idea that is, as it increases
> the amount of code in the "Trusted Computing Base" unmanageably.  They
> felt that such a system could never be rated secure.

 You are right. But the problem is : authentication protocol of WWW (a la
un*x) is perhaps good enough for HTTP/0.9, but is not adapted for HTTP/1.0
particulary for method PUT, POST, DELETE.

 Actually I prefer write a script with a better authentication rather than
use WWW to do it.

 Put under "/htauth" specific scripts for authentication and don't use
this basic authentication protocol.

Guy Decoux





From marca@ncsa.uiuc.edu  Sat Dec 11 20:42:36 1993 -0800
Message-Id: <9312120442.AA26163@wintermute.ncsa.uiuc.edu>
Date: Sat, 11 Dec 93 20:42:36 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: NCSA Mosaic for X 2.1 available

NCSA Mosaic for X 2.1 is now available.

...ftp.ncsa.uiuc.edu in /Mosaic:

  o Source in /Mosaic/Mosaic-source.

  o Binaries for SunOS 4.1.3, AIX 3.2.4 with X11R5, IRIX 4.x,
    DEC Alpha (OSF/1), DEC Ultrix, and HP/UX 9.x (700-series) in
    /Mosaic/Mosaic-binaries.

  o Source diffs in /Mosaic/Mosaic-source/diffs.

As always, thanks for all the feedback -- 2.1 fixes many user-reported
bugs.

If you have any comments, questions, or problems with Mosaic 2.1,
please send mail to mosaic-x@ncsa.uiuc.edu.  Also please drop us a
note if you enjoy using Mosaic or if you are using it in any
interesting projects or applications -- we love to hear from our
users!

Changes from version 2.0 to version 2.1 include:

 o Remote control users and script writers take note: control filename
   changed from /tmp/xmosaic.pid to /tmp/Mosaic.pid. This
   is the final such change, forever. 
 o Transparent uncompression over HTTP/1.0 is working -- Plexus
   3.0i-beta is known to handle the server-side aspects, and the first
   release of NCSA httpd after 1.0a5 will. Only content encodings
   "x-compress" and "x-gzip" are currently handled. 
 o Transparent uncompression for local files is now working. 
 o Mail sending from within Mosaic is redone. Notably: 
    o mailCommand resource is now totally obsolete. 
    o sendmailCommand resource is now expected to point to
      your system's sendmail binary; default is 
      /usr/lib/sendmail. Assumption is made that this
      program accepts command-line arguments specifying
      addresses to which message should be mailed, and accepts other
      headers and message text from stdin. 
    o Mailed messages are now MIME-compliant, including use of
      proper content-types. 
    o Additional header X-URL is used to indicate the URL of a
      mailed document to the recipient. 
    o A BASE directive is added to mailed HTML documents to
      allow inlined images and relative hyperlinks to work on the
      other end. 
 o Mosaic 1.2's multiline FTP response fixes (courtesy John
   Ockerbloom) merged in, and tweaks made. 
 o Added support for freeWAIS 0.202's URL type in native WAIS code. 
 o Added support for "204 NoResponse" responses in HTTP/1.0. When
   such a response is received, Mosaic will not go to a new document or
   an error message but will completely disregard the results of the
   connection. 
 o Status line now displays "xx of yy bytes" when talking to an HTTP/1.0
   server that tells it content-length. (For small transfers this may not
   happen, which is to be expected, as header and entire data block
   transfer will be very close together.) 
 o Worked around BadWindow crash under Ultrix with Edit Hotlist
   window. 
 o Worked around BadWindow crash under Ultrix with ISINDEX forms
   and text entry areas. 
 o Glitch with formatting long lines in some cases fixed. 
 o Fixed rare coredump opportunity in SELECT/OPTION handling. 
 o Fixed rare uninitialized memory read in widget selection code. 
 o Fixed another coredump opportunity in inlined image loading. 
 o Fixed coredump opportunity in client-side authentication code with
   long (>48 character) realm names. 
 o Mosaic no longer tries to pick up final reply from FTP servers, to
   thwart those servers that don't seem to be responding to the final reply
   read. Also should make FTP performance a little better. This may be
   an evil thing to do (since Mosaic may now tear down the socket before
   the FTP server has finished writing to it); I'm not sure. 
 o Rob says: "It appears on first glance that Mosaic 2.0 is ignoring
   anchors in redirected URLs." He was right, and it's now fixed. 
 o Made a few fixes in PostScript printing code: corrected header
   generation, and fixed width handling (thanks to Gustaf Neumann). 
 o Tweaked reloading code to avoid strange error message. 
 o Mosaic now assumes that text documents beginning with string
   "<BASE" or "<base" are HTML -- this makes it easy to use Mosaic
   as a metamail viewer for HTML documents mailed from this version
   of Mosaic. 
 o Merged in donated fixes for 6-bit and 16-bit displays. These aren't
   guaranteed to work as we have no way to test them. 
 o Fixed missing closing ADDRESS tag in news articles. 
 o Fixed condition in WAIS source parser that caused it to lose track of
   its state if escapted characters were inside quotes (thanks to Larry
   Masinter). 
 o Fixed FTP code to allow ftp://username:password@host/
   URLs (thanks to Larry Masinter). 
 o This version of Mosaic supports the GIF89 transparent color
   extension. You can create GIFs with a transparent background color
   with the latest beta of netpbm and its ppmtogif filter (you can
   FTP that from ftp.cs.ubc.ca in /ftp/archive/netpbm if
   you're desperate). 
 o Merged in SOCKS modifications from Ying-Da Lee
   (ylee@syl.dl.nec.com); for the version of SOCKS needed to compile
   with SOCKS support enabled, see here; note that SOCKS and the SOCKS
   code now in Mosaic are NOT supported by NCSA.
 o Fixed memory problem with trackFullURLs set to false (that
   option still doesn't work in all cases, but at least it does something
   reasonable now). 
 o Tweaks for compilation on various platforms. 

Cheers,
Marc & Eric

--
Marc Andreessen & Eric Bina
Software Development Group
National Center for Supercomputing Applications
marca@ncsa.uiuc.edu & ebina@ncsa.uiuc.edu




From kevinh  Sun Dec 12 03:25:27 1993 PST
Message-Id: <9312121125.AA01211@eit.COM>
Date: Sun, 12 Dec 93 03:25:27 PST
From: kevinh (Kevin 'Kev' Hughes)
Subject: Work on EIT's Web beginning


	Just so everyone knows, I'll be starting a major overhaul of
EIT's web server. I'm copying it to a remote work area where I'll redo it,
it'll then take the place of the old site in one piece when I'm done.
	For this reason, please do not make changes or add links to
anything in the /usr/local/www directory. I'll inform everyone when I'm
through - this may take a few weeks.
	The server directory will be reorganized and redone as well.
Please email me re: any customized programs or code you may wish to keep
in /usr/local/httpd and its subdirectories.

	-- Kevin




From robm@ncsa.uiuc.edu  Mon Dec 13 00:04:38 1993 -0600
Message-Id: <9312130604.AA17772@void.ncsa.uiuc.edu>
Date: Mon, 13 Dec 1993 00:04:38 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: NCSA httpd 1.0

NCSA httpd 1.0 is now available at URL http://hoohoo.ncsa.uiuc.edu/docs/ or
via FTP from ftp.ncsa.uiuc.edu in /Web/ncsa_httpd/httpd_1.0.

This is the first non-alpha release, which explains why the version number
is actually readable. If you have been waiting to upgrade your server,
this should be the release to do it with.

Several minor things have changed since 1.0a5, please see the
upgrade notes at http://hoohoo.ncsa.uiuc.edu/docs/Upgrade.html if you are
upgrading a server. 

Really quickly: 

   o the htbin stuff is no longer distributed, CGI/1.0 versions of your old
     favorites are included instead 

   o the NCSA script interface (htbin) is still supported via
     OldScriptAlias, with the default ScriptAlias pointing to CGI scripts.

   o A CGI version of imagemap is included, the only differences
     being that you have to manually set the config. file location if your
     ServerRoot is not /usr/local/etc/httpd, and that the file references in
     *.map are virtual instead of physical now. 
     
   o The AddType directive now works
   
   o NCSA POST scripts have REMOTE_HOST set


As usual, comments/questions to httpd@ncsa.uiuc.edu

--Rob





From robm@ncsa.uiuc.edu  Mon Dec 13 00:26:43 1993 -0600
Message-Id: <9312130626.AA18099@void.ncsa.uiuc.edu>
Date: Mon, 13 Dec 1993 00:26:43 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: CGI scripts archive


I would like to set up a CGI scripts archive at ftp.ncsa.uiuc.edu in
/Web/ncsa_httpd/cgi. If you write a CGI script, and would like to submit it to
the archive, upload it to /incoming/cgi on ftp.ncsa.uiuc.edu and send mail to
robm@ncsa.uiuc.edu.

Currently, the archive is very sparse and contains only the default scripts for
NCSA httpd.

--Rob



From assar@nada.kth.se  Mon Dec 13 07:40:12 1993 +0100
Message-Id: <9312130640.AA03296@kai.nada.kth.se>
Date: Mon, 13 Dec 93 07:40:12 +0100
From: assar@nada.kth.se (assar@nada.kth.se)
Subject: ALEX support in libwww2 (Mosaic)

> Has anyone hacked mosaic to use Alex?
> 
> A couple users have pointed out that it would be very nice
> to have a flag to tell mosaic to use /alex for FTPable
> files.
> 
> Mosaic does not cache files and does not seem to even 
> cache open FTP connections.
> 
>   -- Vince

Here are patches to use Alex in libwww2 (which is used by Mosaic)

This patch is also ftp-able as
file://ftp.nada.kth.se/pub/Mosaic-2.1.alex.patch

After applying this patch all URLs with file: will go through Alex and
all ftp: will use normal FTP.

(Alex is a transparent way of doing anonymous FTP with caching. FTP to
alex.sp.cs.cmu.edu for more information and source.)

All comments, bugreports and fixes are welcome.

------------------------------ cut here ------------------------------
Index: Makefile
===================================================================
RCS file: /afs/nada.kth.se/misc/projects/mosaic/MASTER/Mosaic/Makefile,v
retrieving revision 1.1.1.1
diff -c -r1.1.1.1 Makefile
*** 1.1.1.1	1993/12/13 01:50:48
--- Makefile	1993/12/13 04:41:11
***************
*** 150,156 ****
  #### . If you want to define the default Mosaic documentation directory
  ####   (should be a URL), set -DDOCS_DIRECTORY_DEFAULT=\\\"url\\\"
  #### . Other things you can define are spelled out in src/mosaic.h.
! customflags =
  
  
  
--- 150,156 ----
  #### . If you want to define the default Mosaic documentation directory
  ####   (should be a URL), set -DDOCS_DIRECTORY_DEFAULT=\\\"url\\\"
  #### . Other things you can define are spelled out in src/mosaic.h.
! customflags = -DALEX
  
  
  
***************
*** 203,209 ****
  
  libwww2::
  	@echo --- Building libwww2
! 	cd libwww2; make CC=$(CC) RANLIB=$(RANLIB) CFLAGS="$(CFLAGS) $(knrflag) $(waisflags)"
  
  src::
  	@echo --- Building src
--- 203,209 ----
  
  libwww2::
  	@echo --- Building libwww2
! 	cd libwww2; make CC=$(CC) RANLIB=$(RANLIB) CFLAGS="$(CFLAGS) $(knrflag) $(waisflags) $(customflags)"
  
  src::
  	@echo --- Building src
Index: libwww2/HTFile.c
===================================================================
RCS file: /afs/nada.kth.se/misc/projects/mosaic/MASTER/Mosaic/libwww2/HTFile.c,v
retrieving revision 1.1.1.1
diff -c -r1.1.1.1 HTFile.c
*** 1.1.1.1	1993/12/13 01:51:41
--- HTFile.c	1993/12/13 04:44:24
***************
*** 833,839 ****
--- 833,899 ----
  }
  		
  
+ #ifdef ALEX
  
+ #define ALEX_PREFIX "/alex/"
+ 
+ /*
+ ** Return an alexified version of the nodename.
+ */
+ 
+ PRIVATE char * alexifynode ARGS1 (CONST char *, nodename)
+ {
+   char * result = malloc(strlen(nodename) + 1);
+   char * ournode;
+   char * dot;
+ 
+   StrAllocCopy(ournode, nodename);
+   result[0] = '\0';
+ 
+   while(dot = strrchr(ournode, '.')) {
+     strcat(result, dot+1);
+     strcat(result, "/");
+     *dot = '\0';
+   }
+   strcat(result, ournode);
+   free(ournode);
+   return result;
+ }
+ 
+ /* Convert an address to alex.
+ **
+ */
+ 
+ PRIVATE char * HTAlexName
+ ARGS1 (
+   char *,			addr
+ )
+ {
+   char * newname;
+   char * filename;
+   char * nodename;
+   char * newaddr;
+   char * alexnode;
+ 
+   StrAllocCopy(newname, addr);
+   filename=HTParse(newname, "", PARSE_PATH|PARSE_PUNCTUATION);
+   nodename=HTParse(newname, "", PARSE_HOST);
+   free(newname);
+   alexnode = alexifynode(nodename);
+   free(nodename);
+   newaddr = malloc(strlen(ALEX_PREFIX) 
+ 		   + strlen(alexnode) + strlen(filename) + 1);
+   strcpy(newaddr, ALEX_PREFIX);
+   strcat(newaddr, alexnode);
+   strcat(newaddr, filename);
+   free(alexnode);
+   free(filename);
+   return newaddr;
+ }
+ 
+ 
+ #endif /* ALEX */
+ 
  /*	Load a document
  **	---------------
  **
***************
*** 860,865 ****
--- 920,926 ----
      char * newname=0;	/* Simplified name of file */
      HTAtom * encoding;	/* @@ not used yet */
      int compressed;
+     int alexp;
      extern char *HTgeticonname(HTFormat, char *);
      
  /*	Reduce the filename to a basic form (hopefully unique!)
***************
*** 895,901 ****
      }
  #else
  
-     free(filename);
      
  /*	For unix, we try to translate the name into the name of a transparently
  **	mounted file.
--- 956,961 ----
***************
*** 907,916 ****
--- 967,988 ----
  	 
      {		/* try local file system */
  	char * localname = HTLocalName(addr);
+ 	char * officialname = localname;
  	struct stat dir_info;
  
          if (!localname)
+ #ifdef ALEX
+ 	  {
+ 	    alexp = 1;
+ 	    free(localname);
+ 	    localname = HTAlexName(addr);
+ 	    officialname = filename;
+ 	  }
+ #else
            goto suicide;
+ #endif /* ALEX */
+ 	else
+ 	  free(filename);
  	
  #ifdef GOT_READ_DIR
  
***************
*** 1106,1111 ****
--- 1178,1188 ----
  
                  HT = HText_new();
                  HText_beginAppend(HT);
+ #ifdef ALEX
+ 		if(alexp)
+ 		  HText_appendText(HT, "<H1>Alex Directory ");
+ 		else
+ #endif /* ALEX */
                  HText_appendText(HT, "<H1>Local Directory ");
                  HText_appendText(HT, localname);
                  HText_appendText(HT, "</H1>\n");
***************
*** 1130,1138 ****
  
                      if(strcmp(dataptr,"..") == 0)
                          {
!                         if(strcmp(localname,"/") != 0)
                              {
!                             strcpy(buffer,localname);
  
                              ptr = strrchr(buffer, '/');
  
--- 1207,1215 ----
  
                      if(strcmp(dataptr,"..") == 0)
                          {
!                         if(strcmp(officialname,"/") != 0)
                              {
!                             strcpy(buffer,officialname);
  
                              ptr = strrchr(buffer, '/');
  
***************
*** 1163,1169 ****
                      if(stat(filepath, &statbuf) == -1) continue;
       
                      HText_appendText(HT,"<DD><A HREF=\"");
!                     HText_appendText (HT, localname);
  
                      if(localname[strlen(localname)-1] != '/') 
                          {
--- 1240,1246 ----
                      if(stat(filepath, &statbuf) == -1) continue;
       
                      HText_appendText(HT,"<DD><A HREF=\"");
!                     HText_appendText (HT, officialname);
  
                      if(localname[strlen(localname)-1] != '/') 
                          {
***************
*** 1265,1270 ****
--- 1342,1348 ----
  /*	Now, as transparently mounted access has failed, we try FTP.
  */
    suicide:
+     free(filename);
      return HTFTPLoad(addr, anchor, format_out, sink);
  }
  



From kevinh@eit.COM  Sun Dec 12 23:52:02 1993 -0800
Message-Id: <199312130752.XAA01172@kmac.eit.com>
Date: Sun, 12 Dec 1993 23:52:02 -0800
From: kevinh@eit.COM (Kevin 'Kev' Hughes)
Subject: Re: Work on EIT's Web beginning

Jay-C writes:

> Bottom line:  we're all excited about you overhauling the web stuff, but
> you'll need to work around the fact that many of us are knowledgeable and
> active in it too.  EIT system administration is rarely dictatorial!  Instead,
> you might want to just make responsibilities clearer, e.g., by leaving
> /usr/local/www/demos/asiceda owned and maintained by me.

	No problem, by no means do I wish to be dictatorial! It would be
a good thing for those involved in the site to have a meeting to discuss
things like:

	* the creation of a list of things I shouldn't modify/update.
	* the creation of a list of things I should regularly modify/update -
          perhaps my "webmaster" role needs to be more clearly defined.
          What sort of latitude do I have in rearranging services,
	  information and graphics?
	* who is doing what to the site (who has responsibility for what
          pages/programs, what projects to they go under, etc.) The more
          I and others know what's on the site, the better I can do my job.
	* the creation of a Web posting policy - some method of defining
          whose approval must be asked before certain information is put
          on the site.
        * brainstorming on what features people might like to see on the
          site - interactive tours, WAIS indexing, other gateways...?

	What does everyone think? I certainly don't want to give you guys
the impression that I'm taking over everything!

	-- Kev



From pasquier@icdc-u1.icdc.fr  Mon Dec 13 10:31:30 1993
Message-Id: <755775090.11117.0@icdc.fr>
Date: 13 Dec 93 10:31:30+0100
From: pasquier@icdc-u1.icdc.fr (pasquier@icdc-u1.icdc.fr)
Subject: subscribe claude pasquier

subscribe claude pasquier





From decoux@moulon.inra.fr  Mon Dec 13 10:26:18 1993 +0100
Message-Id: <9312130926.AA09804@moulon.moulon.inra.fr>
Date: Mon, 13 Dec 93 10:26:18 +0100
From: decoux@moulon.inra.fr (ts)
Subject: ACeDB, Oracle


 ACEDB
 =====
  source for CGI 1.0 and ACEDB is in :
    ftp://moulon.inra.fr/pub/www-acedb/www-acedb.cgi.tar.Z

  executable for sun4/SunOS 4.1.3
    ftp://moulon.inra.fr/pub/www-acedb/nph-acedb.sun.Z

  documentation is :
    http://moulon.inra.fr/acedb_conf_eng.html

 Oracle
 ======
  source for CGI 1.0 and Oracle :
    ftp://moulon.inra.fr/pub/www-oracle/nph-oracle.tar.Z     C version
    ftp://moulon.inra.fr/pub/www-oracle/nph-oraperl.tar.Z    perl version

  documentation is :
    http://moulon.inra.fr/oracle/another.html


Guy Decoux




From Guido.van.Rossum@cwi.nl  Mon Dec 13 13:18:25 1993 +0100
Message-Id: <9312131218.AA13970=guido@voorn.cwi.nl>
Date: Mon, 13 Dec 1993 13:18:25 +0100
From: Guido.van.Rossum@cwi.nl (Guido.van.Rossum@cwi.nl)
Subject: who has a pointer to the CWI logo in their html file?

From the logs of our http server I notice that there are many GET
requests for our institute's logo (http://www.cwi.nl/cwi/cwi_logo.gif)
from sites all over the world that don't send any other requests to
it.  From this I deduce (maybe incorrectly?) that there's another site
which has a link pointing to our logo.  Out of curiosity, I would like
to know which site that is...

BTW, CWI's http server has finally settled down.  Its address is (for
now and forever):

	http://www.cwi.nl/

--Guido van Rossum, CWI, Amsterdam <Guido.van.Rossum@cwi.nl>



From dolesa@smtp-gw.spawar.navy.mil  Mon Dec 13 10:42:14 1993 EDT
Message-Id: <9311137558.AA755808134@smtp-gw.spawar.navy.mil>
Date: Mon, 13 Dec 93 10:42:14 EDT
From: dolesa@smtp-gw.spawar.navy.mil (Andre Doles)
Subject: Re: NCSA httpd 1.0


     If anybody gets this running under A/UX, I'd love to know how you do 
     it.  Likewise for the 2.1 X-Mosaic...  Or anything else for that 
     matter!!! Need I say more?
     
                        Andre' Doles
                        Space & Naval Warfare Systems Command HQ
                        dolesa@smtp-gw.spawar.navy.mil

______________________________ Reply Separator _________________________________
Subject: NCSA httpd 1.0
Author:  robm@ncsa.uiuc.edu (Rob McCool) at SMTP-GW
Date:    12/13/93 1:30 AM


NCSA httpd 1.0 is now available at URL http://hoohoo.ncsa.uiuc.edu/docs/ or 
via FTP from ftp.ncsa.uiuc.edu in /Web/ncsa_httpd/httpd_1.0.
     
This is the first non-alpha release, which explains why the version number 
is actually readable. If you have been waiting to upgrade your server, 
this should be the release to do it with.
     
Several minor things have changed since 1.0a5, please see the
upgrade notes at http://hoohoo.ncsa.uiuc.edu/docs/Upgrade.html if you are 
upgrading a server. 
     
Really quickly: 
     
   o the htbin stuff is no longer distributed, CGI/1.0 versions of your old
     favorites are included instead 
     
   o the NCSA script interface (htbin) is still supported via
     OldScriptAlias, with the default ScriptAlias pointing to CGI scripts.
     
   o A CGI version of imagemap is included, the only differences
     being that you have to manually set the config. file location if your 
     ServerRoot is not /usr/local/etc/httpd, and that the file references in 
     *.map are virtual instead of physical now. 
     
   o The AddType directive now works
     
   o NCSA POST scripts have REMOTE_HOST set
     
     
As usual, comments/questions to httpd@ncsa.uiuc.edu
     
--Rob
     
     
     



From JB%FRP7UN51.BITNET@cearn.bitnet  Mon Dec 13 19:48:11 1993 +0100
Message-Id: <01H6FYCHVCNM001PVW@paris7.jussieu.fr>
Date: Mon, 13 Dec 1993 19:48:11 +0100
From: JB%FRP7UN51.BITNET@cearn.bitnet (Jean-Baptiste)
Subject: subscribe



++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Jean-Baptiste        | Good girls write diaries.
JB@Paris7.Jussieu.Fr | Bad girls don't have the time!
++++++++++++++++++++++++++++++++++++++++++++++++++++++++



From tom@fatty.law.cornell.edu  Mon Dec 13 13:51:54 1993 -0500 (EST)
Message-Id: <9312131851.AA02210@fatty.law.cornell.edu>
Date: Mon, 13 Dec 1993 13:51:54 -0500 (EST)
From: tom@fatty.law.cornell.edu (Thomas R. Bruce)
Subject: "internal-gopher-image"?!?

Folks:

This question probably stems from being asleep at the switch as usual,
but what does
         <IMG SRC="internal-gopher-image">
mean, and what unexplored part of the HTML standard is it part of?

Best,
Tb.
-- 
+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+
|  Thomas R. Bruce                           trb2@cornell.edu |
|  Research Associate                                         |
|  Cornell Law School                     Voice: 607-255-1221 |
|  Myron Taylor Hall                        FAX: 607-255-7193 |
|  Ithaca, NY 14853                                           |
+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+



From gyula@multim.elte.hu  Mon Dec 13 19:55:27 1993 +0100
Message-Id: <9312131855.AA09201@multim.elte.hu>
Date: Mon, 13 Dec 93 19:55:27 +0100
From: gyula@multim.elte.hu (gyula@multim.elte.hu)
Subject: CGI specification

Where can I find the complette CGI 1.0 specification?
I would like to have PostScript and HTML both.

Thanks 
	Gyula Mentler



From J.Larmouth@iti.salford.ac.uk  Mon Dec 13 14:19:00 1993
Message-Id: <9312132027.AA25451@dxmint.cern.ch>
Date: 13 Dec 93 14:19
From: J.Larmouth@iti.salford.ac.uk (J.Larmouth@iti.salford.ac.uk)
Subject: On languages and character repertoires and all that

=========================================================================
E-mail from: Prof J Larmouth              J.Larmouth @ ITI.SALFORD.AC.UK
             Director                       Telephone: +44 61 745 5657
             IT Institute                         Fax: +44 61 745 8169
             University of Salford              Telex: 668680 (Sulib)
             Salford M5 4WT
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

To:     www-talk @ info.cern.ch

Subject:      On languages and character repertoires and all that

Hope this is not going over too much old ground.

It is clear that a Japanese text can be supported by an appropriate G-set
in the ISO 2022 framework.   However,  a marked-up Japanese text is no
longer a Japanese text,  and requires additional G-sets.  A clear
separation of "language" (eg "Japanese with mark-up" versus "Japanese")
from the character repertoires needed to support that "language" is
important.

More generally,  the discussions I have been hearing recently on this
list seem to be focussed entirely on ISO 2022.   ISO 2022 is a kludge on
ISO 646 which has done a fair (only fair) job for the last decade or so,
but the character standard for the next decade/century will be ISO 10646.

It may be right to base the HTML+ work on ISO 2022,  as it is here now
(tho' personally I disagree),  but it is certainly wrong to ignore ISO
10646.

Use of ISO 2022 to support "Japanese with mark-up" will require frequent
uses of escape sequences,  and generally there is not a lot of computer
software around that does a good job with ISO 2022.   By contrast,  ISO
10646 with a "selected subset" of KATAKANA provides a much cleaner
solution for most languages.  Moreover,  I think most computer vendors
are working on or already have provided support for ISO 10646 16-bit
encodings.  (Note that for some way-out (?) languages the BMP of ISO
10646 will not suffice,  and a 32-bit encoding may be needed.)

However,  once we determine that a particular character repertoire is
needed,  the choice of ISO 2022 or ISO 10646 as the encoding mechanism
(and the choice of encodings within 10646) is just the same as the choice
of GIF or JPEG for an image,  and should be negotiated by HTTP in the
same way.

Turning now to user level requirements for languages,  it seems to me
that the model should be that an HTML document is anglic (by default) or
one of a listed set of languages (plus markup,  and the tags are of
course not translated).   The http: URL should identify the language if
it is not the default,  but we should also allow the identification to be
"multiple".   In this case the document is available in multiple
languages,  and RUN-TIME NEGOTIATION using HTTP negotiation can be used
to determine which one is to be fetched.

I envisage that a browser would support the selection of a "preferred
language" for use in the negotiation,  but would also allow the
"preferred language" to be UNSET,  in which case the user is told the
languages available for a particular document and asked which one he
wants it in.

I am not sure the current proposals provide quite this functionality?

John L




From robm@ncsa.uiuc.edu  Mon Dec 13 14:45:33 1993 -0600
Message-Id: <9312132045.AA28596@void.ncsa.uiuc.edu>
Date: Mon, 13 Dec 1993 14:45:33 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: a brief explanation of CGI


I'm currently in the middle of finals this week, so I don't have time to answer
all of the mail I'm getting about CGI. Hopefully, a quick summary will
suffice until later in the week.

CGI is the next generation of the script interface. It provides the exact
capabilities that the NCSA script interface (/htbin) provided, and a whole
lot more. In addition, it is not an NCSA-only feature as it was developed by
several server authors and script writers.

The basic differences between CGI and /htbin are cosmetic. Instead of
getting query arguments on the command line, they now come in environment
variables. 

If you have used NCSA httpd 1.0a5, and have scripts which were written for
/htbin or /htbin-post, use OldScriptAlias to point to them instead of
ScriptAlias.

Hopefully within a few days I will have time to write a short ``What the
hell is Rob babbling about'' page and a tutorial for writing CGI scripts (as
well as upgrading your old ones).

--Rob




From marca@ncsa.uiuc.edu  Mon Dec 13 15:55:35 1993 -0800
Message-Id: <9312132355.AA03730@wintermute.ncsa.uiuc.edu>
Date: Mon, 13 Dec 93 15:55:35 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: "internal-gopher-image"?!?

Thomas R. Bruce writes:
> This question probably stems from being asleep at the switch as usual,
> but what does
>          <IMG SRC="internal-gopher-image">
> mean, and what unexplored part of the HTML standard is it part of?

It's an internal feature in Mosaic for X, to get cute icons in Gopher
menus (and now FTP menus).  We have not documented it nor intended it
for general use, but some people (USGS) have been using it in
generally available documents anyway... sigh...

The bitmaps themselves are in the Mosaic source code (src/bitmaps), in
xbm format.

Cheers,
Marc




From ams  Mon Dec 13 16:53:51 1993 PST
Message-Id: <9312140053.AA09912@eit.COM>
Date: Mon, 13 Dec 93 16:53:51 PST
From: ams (Allan M Schiffman)
Subject: Web posting policy

Your message today suggested that we have a meeting to discuss, among
other things:
	"the creation of a Web posting policy - some method
	 of defining whose [sic] approval must be asked
	 before certain information is put on the site."

I think the rule is, if it hasn't been "published" before in SOME
form,  material put on the web requires prior approval by Steve.

Section 14 ("Signoffs"), paragraph 2 of the EIT policy and procedures
statement require prior approval of the President and/or CEO for
"papers and/or articles".  Paragraph 1 of the section requires signoff
by the President for any "written document which solicits additional
work for EIT".

I'm sure there's no reason to make the policy for "publication" via
the web any less (or more) stringent than paper publication.

-Allan



From phillips@cs.ubc.ca  Mon Dec 13 17:36:07 1993 -0800
Message-Id: <199312140136.AA12547@grolsch.cs.ubc.ca>
Date: Mon, 13 Dec 1993 17:36:07 -0800
From: phillips@cs.ubc.ca (George Phillips)
Subject: Annoucement: Local Browser Execution

Have you ever wanted your WWW browser to run a program and display
it's output?  Have you ever wanted to post news from your WWW
browser?  If so, then I think you'll definitely be interested
in the rest of this message.  If not, well, you'll probably still be
interested.

I've been working on a new URL scheme called "x-exec:" which directs
the WWW browser to execute a program locally.  For full details
on how it works, upgrade patches to Mosaic 2.1 and Lynx 2-0-12, and
some sample scripts open:

	http://www.cs.ubc.ca/doc/world/exec/intro

I'll describe the system only briefly here.  The new URL scheme
looks like:

	x-exec://program/path/information

When it sees that, the browser will look for a program called "program"
to run.  What local programs may be run is configurable by the installer
and the user (default: nothing).  If everything is cool, the browser
runs the program using the Common Gateway Interface
(see http://hoohoo.ncsa.uiuc.edu/cgi/interface.html) which is just
a way of telling the program about the URL that activated it and
what the program should output (generally speaking, environment
variables on the way in, a MIME-like object on stdout).

For example, if you one of my example scripts installed, opening:

	x-exec://urnw/rn/unread/group/comp.infosystems.www

Will have your browser pop up a display of the subject lines of the
last 10 unread articles in comp.infosystems.www.  If you open:

	x-exec://postnews/?newsgroups=misc.test

You'll get a form to fill with an article to post to misc.test.

Go grab the patches, re-compile your browser, try the sample scripts
and start writing your own.  Who knows, if it becomes popular
enough, x-exec: could become a standard.

One last thing.  I'm certainly interested in discussing viable
alternatives to x-exec: and suggestions for improving it.  Flames
about it being "a bad thing" and/or "the wrong thing" will be
accepted in the same cheerful spirit as Mosaic Motif flames.



From henrich@crh.cl.msu.edu  Mon Dec 13 20:44:44 1993 EST
Message-Id: <9312140144.AA06085@crh.cl.msu.edu>
Date: Mon, 13 Dec 93 20:44:44 EST
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: 

I have a delimma folks.  Im looking at the constraints my previous message
has put on me about using multiple ?'s in a url, and I cant seem to solve
this problem.  This is what I need to accomplish,

On my interactive weather browser
(http://rs560.cl.msu.edu/weather/interactive.html) I have both a search field
(isindex) and a ismap image.  When you first enter the page the following ismap
reference is attached to the map:

http://rs560.cl.msu.edu/weather/interactive.html?nodisp

When a user clicks on the map the Mosaic for X browser submits this query:

http://rs560.cl.msu.edu/weather/interactive.html?nodisp?x,y

A small program peel's off the "nodisp" field and the "x,y" field.  If the x,y
isnt present nothing special happens.  If it is present, and the nodisp field
is present the current textual weather information for the location is
returned.

When a user enter's a search, the query is sent to the server using this url:

http://rs560.cl.msu.edu/weather/interactive.html?search_query

Which is then peel'd off by the same small little program and attached to the
ismap reference like so:

http://rs560.cl.msu.edu/weather/interactive.html?search_query

so when the user clicks on the map I can peel off the search_query (which
specifies a display name) and draw the user a map for the given x,y
coordinates.  Its apparent that this is achieved by a small quirk in Mosaic for
X that allows me to remember search queries between mouse clicks.  However,
several browsers do not do the same thing, notably Mosaic for Mac.  There is
also no special characters I can embed at the end of the URL that the server
will ignore, that I can use to remember previous actions.  So guys, whats the
solution here?  Is what im doing un-doable?  All comments appreciated!

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                     http://rs560.msu.edu/~henrich/




From joe@MIT.EDU  Mon Dec 13 21:40:35 1993 -0500
Message-Id: <9312140240.AA24732@theodore-sturgeon.MIT.EDU>
Date: Mon, 13 Dec 93 21:40:35 -0500
From: joe@MIT.EDU (joe@MIT.EDU)
Subject: tkWWW 0.10 pre 3 is out


I've uploaded tkWWW 0.10 pre3 into /pub/incoming/joe on info.cern.ch.
It should migrate to /pub/www/dev in a few days.  Also in those directories
is a patch you can pipe into "patch -p" to update your tkWWW 0.10 pre2
sources.

The main change is that I'm improved the configuration scripts, "make
install" should work correctly.  I've also included some fixes that
fixed seg faults on the HP/UX.

One thing that I didn't do was to make any changes that would involve
the WWW core libraries.  In particular, some systems require a
NO_GETCWD flag to be set in tcp.h that isn't.  I've reported these bugs
to CERN and they should get fixed in the next addition.

My thanks to everyone who submitted a bug report.  Unfortunately, I
was innudated with them, and haven't had a chance to reply personally.

Also, I will be off the net for a few weeks, so I won't be able to
release the next prerelease until after the new year.

As usual, please remember that this is a prerelease and so probably 
won't work without a great deal of tinkering.  :-) :-) :-) :-)



From kevinh  Mon Dec 13 19:31:34 1993 PST
Message-Id: <9312140331.AA11627@eit.COM>
Date: Mon, 13 Dec 93 19:31:34 PST
From: kevinh (Kevin Hughes)
Subject: First draft of Web "puncher"


	OK, for those webbers (and weber) :), I've made the second
beta Web punch interface, based on Jason's work. It's at

	http://www/htbin/puncher

	If anyone is willing to hack wwwpunch to allow it to accept
all the other normal punch commands (unpunch, timesheet, etc.), I
will add it to the interface - or if anyone else wants to hack it,
source is /usr/local/httpd/htbin/src/puncher.c
	Aloha,

	-- Kev



From Axel.Belinfante@cs.utwente.nl  Tue Dec 14 06:07:10 1993 +0100
Message-Id: <9312140507.AA26872@utis179.cs.utwente.nl>
Date: Tue, 14 Dec 93 06:07:10 +0100
From: Axel.Belinfante@cs.utwente.nl (Axel Belinfante)
Subject: 

Charles Henrich <henrich@crh.cl.msu.edu> writes:
> I have a delimma folks.  Im looking at the constraints my previous message
> has put on me about using multiple ?'s in a url, and I cant seem to solve
> this problem.  This is what I need to accomplish,

I'm not sure that i understand what you need, it could be possible
that you can do what you need, without using forms.
When you use forms it is relatively easy to keep state information.

The ISMAP mechanism allows you to specify a 'root' URL for the
ISMAP result that can be different from the URL of the page that
contains the ISMAP, which means that you can store info in the
ISMAP 'definition' - you are using this right now.

The ISINDEX query mechanism _does not_ allow you to specify that 'root'
URL - the result is that all queries from a page will have the same
'root', which thus cannot be used to store 'state' information.

Forms, however, allow you to do things similar to ISINDEX, and much more
relevant to your problem: they allow you to specify the 'root' URL of a
form in a way similar to the ISMAP mechanism.

The idea is that you use should be able to have all URLs that start with 
	http://rs560.cl.msu.edu/weather/interactive/
executed/interpreted by your little program.

  (i don't know how easy it is to do that with your server - i use
   plexus, where it is not very hard to do so. I would suppose that it
   would be realtively easy once the CGI is supported by all servers)

The URL above should/could represent the 'default' - as it is before
any user 'given' info is added to it.
The user information that you want to remember can now be added to the
end of the 'default' URL, and used as 'root' for the ISMAP.

Note:
This information is 'reset' when the user does not click on the map,
to use the result of the query, but instead issues another query - 
it is reset in the same way as it is in the current situation.
However, if you would use forms, you can also keep that information.

The idea is now that this
	http://rs560.cl.msu.edu/weather/interactive/
is your 'basic' URL, and the state information is added to the end of it;
the query gets attached to the end of that.
I'll give the corresponding URLs with your explanation below.

> On my interactive weather browser
> (http://rs560.cl.msu.edu/weather/interactive.html) I have both a search field
> (isindex) and a ismap image.  When you first enter the page the following
> ismap reference is attached to the map:
> 
> http://rs560.cl.msu.edu/weather/interactive.html?nodisp

http://rs560.cl.msu.edu/weather/interactive/nodisp

> When a user clicks on the map the Mosaic for X browser submits this query:
> 
> http://rs560.cl.msu.edu/weather/interactive.html?nodisp?x,y

http://rs560.cl.msu.edu/weather/interactive/nodisp?x,y

> A small program peel's off the "nodisp" field and the "x,y" field.  If the
> x,y isnt present nothing special happens. If it is present, and the nodisp
> field is present the current textual weather information for the location is
> returned.
> 
> When a user enter's a search, the query is sent to the server using this url:
> 
> http://rs560.cl.msu.edu/weather/interactive.html?search_query

http://rs560.cl.msu.edu/weather/interactive/?search_query

> Which is then peel'd off by the same small little program and attached to the
> ismap reference like so:
> 
> http://rs560.cl.msu.edu/weather/interactive.html?search_query

http://rs560.cl.msu.edu/weather/interactive/search_query

> so when the user clicks on the map I can peel off the search_query (which
> specifies a display name) and draw the user a map for the given x,y
> coordinates.  Its apparent that this is achieved by a small quirk in Mosaic
> for X that allows me to remember search queries between mouse clicks.
> However, several browsers do not do the same thing, notably Mosaic for Mac.
> There is also no special characters I can embed at the end of the URL that
> the server will ignore, that I can use to remember previous actions.
> So guys, whats the solution here? Is what im doing un-doable?
> All comments appreciated!

In a way, i use the last / in the URL i proposed as a special character:
everything that follows it is part of the arguments for the
'weather-interactive' program.


I hope the above makes sense, and is of some help... it has gotten a bit
late (early? :-) here in the meantime...


In the newest addition to my 'esperanto demo' i use forms to keep
'query'-like information. The esperanto lesson contains a small
interactive exercise and i use forms to pass info from one exercise 
part' to another.
Using forms, i store the 'state' information in the url, the query
(result of a submitted form) gets attached to the URL (including that info)
when the form gets executed.
Without forms it would be harder, but not impossible - but the user
interface would be less nice: i would need probably an additional page
between the 'exercises' of the lesson: instead of returning the feedback
to the previous exercise on the same page as the new one, i would have to
return a feedback page that contains the link to the next exercise -
this link would contain the information i want to 'keep'.

The esperanto exercise prototype is at

 http://utis179.cs.utwente.nl:8001/esperanto/hypercourse/voorzetsels_ekz.html

It still is a bit in rough shape - i want to make the state info more
'opaque'. Right now, if you look at the URL that is passed on during the
exercise you can see the info change (and you can cheat, too  :-)
(by the way, it is bilingual, sort of.. (both dutch and english))

Something that cost me some time just before i started this email was
the following: right now i represent the 'state' as a number of
name=value bindings, linked together by & separators.
I made the mistake of using a 'name' lt, and trying to add another
name=value binding in front of the lt=value binding, which gave me
a FORM like (shortened for clarity):

<FORM METHOD="GET" ACTION="/ekz/esp/hyp/lang=nl&lt=value&rt=value2">
some text: <inPUT NAME="entry">
<inPUT TYPE="submit" NAME="action" VALUE="Return">
</FORM>

which after submitting got mapped onto
http://host:port/ekz/esp/hyp/lang=nl<=value&rt=value2?entry=ff

It took a while before i understood where the < came from, and
worked around the problem:
    ACTION="/ekz/esp/hyp/lt=value&lang=nl&rt=value2">
works fine.

Regards,
Axel.

<Axel.Belinfante@cs.utwente.nl>   tel. +31 53 893774   fax. +31 53 333815
     University of Twente, Tele-Informatics & Open Systems Group
       P.O. Box 217    NL-7500 AE Enschede      The Netherlands
     "ili ne sciis ke estas neebla do ili simple faris" -- Loesje




From sanders@bsdi.com  Mon Dec 13 23:55:22 1993 -0600
Message-Id: <199312140555.XAA02665@austin.BSDI.COM>
Date: Mon, 13 Dec 1993 23:55:22 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: 

> When a user clicks on the map the Mosaic for X browser submits this query:
> 
> http://rs560.cl.msu.edu/weather/interactive.html?nodisp?x,y
Get or make a smarter server and use:
  http://rs560.cl.msu.edu/weather/interactive.html/nodisp?x,y

--sanders



From sanders@BSDI.COM  Mon Dec 13 23:52:40 1993 -0600
Message-Id: <199312140552.XAA02630@austin.BSDI.COM>
Date: Mon, 13 Dec 1993 23:52:40 -0600
From: sanders@BSDI.COM (Tony Sanders)
Subject: Re: Annoucement: Local Browser Execution 

> I've been working on a new URL scheme called "x-exec:" which directs
...
> One last thing.  I'm certainly interested in discussing viable
> alternatives to x-exec: and suggestions for improving it.  Flames
> about it being "a bad thing" and/or "the wrong thing" will be
> accepted in the same cheerful spirit as Mosaic Motif flames.

Ok, define a content type application/x-exec that returns some data for
you to deal with.  This doesn't require *ANY* changes to the browser and
at some point down the road you will be able to authenticate the data
instead of being forced to trust just anyone.  Same effect, much more
flexible, and it doesn't clutter the URL space.

--sanders



From henrich@crh.cl.msu.edu  Tue Dec 14 01:19:31 1993 -0500 (EST)
Message-Id: <9312140619.AA06805@crh.cl.msu.edu>
Date: Tue, 14 Dec 1993 01:19:31 -0500 (EST)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: CGI SPec change

Okay guys, I got an idea.  (That will solve my problem :) and hopefully make
everyone's life easier in handling "state" information.

I propose that when a server see's a URL like so:

http://URL;hello there;bob

It returns the document http://URL and then passes the whole thing to the
called scripts.  State information can be cleanly preserved that way.

Robm?  Tony?

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                     http://rs560.msu.edu/~henrich/



From marca@ncsa.uiuc.edu  Tue Dec 14 00:36:32 1993 -0800
Message-Id: <9312140836.AA05769@wintermute.ncsa.uiuc.edu>
Date: Tue, 14 Dec 93 00:36:32 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Re: Annoucement: Local Browser Execution 

Tony Sanders writes:
> > I've been working on a new URL scheme called "x-exec:" which directs
> ...
> > One last thing.  I'm certainly interested in discussing viable
> > alternatives to x-exec: and suggestions for improving it.  Flames
> > about it being "a bad thing" and/or "the wrong thing" will be
> > accepted in the same cheerful spirit as Mosaic Motif flames.
> 
> Ok, define a content type application/x-exec that returns some data for
> you to deal with.  This doesn't require *ANY* changes to the browser and
> at some point down the road you will be able to authenticate the data
> instead of being forced to trust just anyone.  Same effect, much more
> flexible, and it doesn't clutter the URL space.
> 
> --sanders

George and Tony --

What if there were an attribute to given MIME types, specifiable in
one's .mailcap, called "receiveoutput" or something similar?  This
would be similar to how mailcaps are also supposed to be able to
supports "needsterminal" attributes and the like.  E.g.:

application/x-csh-exec; my-csh-exec %s; receiveoutput

When the browser fetches a data object of type application/x-csh-exec
it runs my-csh-exec and, due to the presence of "receiveoutput", pulls
the output of my-csh-exec back into the browser as an HTTP/1.0
object...

What am I missing (i.e. what do you want to do with x-exec that that
wouldn't support)?

Cheers,
Marc




From phillips@cs.ubc.ca  Mon Dec 13 23:22:00 1993 -0800
Message-Id: <7053*phillips@cs.ubc.ca>
Date: 13 Dec 93 23:22 -0800
From: phillips@cs.ubc.ca (George Phillips)
Subject: Re: Annoucement: Local Browser Execution 

Tony says:
>Ok, define a content type application/x-exec that returns some data for
>you to deal with.  This doesn't require *ANY* changes to the browser and
>at some point down the road you will be able to authenticate the data
>instead of being forced to trust just anyone.  Same effect, much more
>flexible, and it doesn't clutter the URL space.

As near as I can tell with Mosaic, you'd still have to make some
changes.  Unless the content type is text/html, it just doesn't
get displayed on the document window.  Even so, I think you're still
a far stretch from having the same effect as x-exec.  For instance,
you need at least a server to drop these application/x-exec
documents on the browser.

I could be wrong, but I certainly can't figure out how to replace
x-exec: with application/x-exec.  If you know how, please show
me.



From phillips@cs.ubc.ca  Mon Dec 13 23:22:00 1993 -0800
Message-Id: <7053*phillips@cs.ubc.ca>
Date: 13 Dec 93 23:22 -0800
From: phillips@cs.ubc.ca (George Phillips)
Subject: Re: Annoucement: Local Browser Execution 

Tony says:
>Ok, define a content type application/x-exec that returns some data for
>you to deal with.  This doesn't require *ANY* changes to the browser and
>at some point down the road you will be able to authenticate the data
>instead of being forced to trust just anyone.  Same effect, much more
>flexible, and it doesn't clutter the URL space.

As near as I can tell with Mosaic, you'd still have to make some
changes.  Unless the content type is text/html, it just doesn't
get displayed on the document window.  Even so, I think you're still
a far stretch from having the same effect as x-exec.  For instance,
you need at least a server to drop these application/x-exec
documents on the browser.

I could be wrong, but I certainly can't figure out how to replace
x-exec: with application/x-exec.  If you know how, please show
me.



From kevinh@eit.COM  Mon Dec 13 23:54:13 1993 -0800
Message-Id: <199312140754.XAA01478@kmac.eit.com>
Date: Mon, 13 Dec 1993 23:54:13 -0800
From: kevinh@eit.COM (Kevin 'Kev' Hughes)
Subject: Re:  Web posting policy

ams writes:

> Your message today suggested that we have a meeting to discuss, among
> other things:
> ...
> I'm sure there's no reason to make the policy for "publication" via
> the web any less (or more) stringent than paper publication.

	That's fine; but could there be any fundamental differences
in the way information is put on the Web (or the Internet, for that matter)
to warrant any further policy making? That is, not for network "publishing"
in the traditional sense, but for general updating/addition of timely
information, such as corporate calendars, employee databases, fact sheets,
and other such information. Things that are normally circulated and
printed but don't require official approval.
	Should a system be set up where Martha can send regular information
to the Web site? Perhaps Brian and I could work over these questions to
find some solution that will work well with the way EIT has traditionally
distributed its corporate information.

	-- Kev



From phillips@cs.ubc.ca  Mon Dec 13 23:46:00 1993 -0800
Message-Id: <7054*phillips@cs.ubc.ca>
Date: 13 Dec 93 23:46 -0800
From: phillips@cs.ubc.ca (George Phillips)
Subject: Re: Annoucement: Local Browser Execution 

Marc says:
>What if there were an attribute to given MIME types, specifiable in
>one's .mailcap, called "receiveoutput" or something similar?  This
>would be similar to how mailcaps are also supposed to be able to
>supports "needsterminal" attributes and the like.  E.g.:
>
>application/x-csh-exec; my-csh-exec %s; receiveoutput
>
>When the browser fetches a data object of type application/x-csh-exec
>it runs my-csh-exec and, due to the presence of "receiveoutput", pulls
>the output of my-csh-exec back into the browser as an HTTP/1.0
>object...
>
>What am I missing (i.e. what do you want to do with x-exec that that
>wouldn't support)?

That covers the script's output, you're just missing the input.
How would information from the URL get to the script?  For example,
in x-exec: you can say "x-exec://program/some/path" and "program"
will get "/some/path" as PATH_INFO.  If it wants itself to be
run with "/foo/bar" as PATH_INFO it outputs <A HREF=x-exec:/foo/bar>.
How does the similar event happen with a the MIME type?  The
best I can see is that the URL has to bounce off an HTTP server
which outputs the appropriate HTTP/1.0 object with the
application/x-csh-exec output type or somesuch.

In other words, how does the script reference itself in an anchor?

If you can solve that, then I don't think there's any problem
with other stuff like different methods (POST) and extra data
on stdin (for application/x-www-form-urlencoded or whatever).



From kevinh@eit.COM  Tue Dec 14 00:10:16 1993 -0800
Message-Id: <199312140810.AAA01537@kmac.eit.com>
Date: Tue, 14 Dec 1993 00:10:16 -0800
From: kevinh@eit.COM (Kevin 'Kev' Hughes)
Subject: Using multiple ?'s


Charles Henrich <henrich@crh.cl.msu.edu> writes:
> 
> I have a delimma folks.  Im looking at the constraints my previous message
> has put on me about using multiple ?'s in a url, and I cant seem to solve
> this problem.  This is what I need to accomplish,

	I'm not sure if this will help, but I came across a similar
problem in making the interactive map at http://www.hcc.hawaii.edu/htbin/plotd.
If you want to send a value as well as an ismap x,y coordinate to a
server both at once, perhaps using an intermediate forms page can do the
trick. For instance, say I go to this URL by clicking on an ISMAP image:

	http://server/htbin/mapthing?x,y

	"mapthing" generates or shows a form where I can specify my
options, and when I submit it, it can have extra options as well as the
x, y coordinates. Something like:

	http://server/htbin/mapthing?option1=yes&option2=no&x=23&y=42

	and you can make the same server "mapthing" realize when it's
been passed just the coordinates only as well as name=value pairs, and
do the right thing in each case.
	It's not great, but it works. Hope that helps!

	-- Kevin



From robm@ncsa.uiuc.edu  Tue Dec 14 02:08:36 1993 -0600
Message-Id: <9312140808.AA05227@void.ncsa.uiuc.edu>
Date: Tue, 14 Dec 1993 02:08:36 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI SPec change

/*
 * CGI SPec change  by Charles Henrich (henrich@crh.cl.msu.edu)
 *    written on Dec 14,  1:19am.
 *
 * Okay guys, I got an idea.  (That will solve my problem :) and hopefully make
 * everyone's life easier in handling "state" information.
 * 
 * I propose that when a server see's a URL like so:
 * 
 * http://URL;hello there;bob
 * 
 * It returns the document http://URL and then passes the whole thing to the
 * called scripts.  State information can be cleanly preserved that way.
 */

The specification already allows this... in extra path information.

That means that if you have a script called /foo/interactive.html, and your
user accesses it with /foo/interactive.html/nodisp?100,100, you would get

/nodisp in PATH_INFO
100,100 in QUERY_STRING

Is this similar to what you have in mind?

--Rob



From dsr@hplb.hpl.hp.com  Tue Dec 14 11:20:47 1993 GMT
Message-Id: <9312141120.AA06898@manuel.hpl.hp.com>
Date: Tue, 14 Dec 93 11:20:47 GMT
From: dsr@hplb.hpl.hp.com (Dave_Raggett)
Subject: Re: HTML(+)-editor available?

> I read your mail from the www-talk line from Thu, 9 Dec 93. I'm working on
> an HTML-editor for NeXTstep at the moment and I'm very interested in all  
> information about problems or solvings anybody has made in trying it, too.
> For me the most important problem is parsing an HTML-text. I'm going to use 
> sgmls as far as possible, because the libwww is a very ugly code and  
> incomplete, too.
> So, if you've got some experiences in writing an HTML-editor, please tell me.

My design for an HTML editor (it hasn't reach the coding stage yet ...)
presents the user with a toolbar including a style dropdown and some
accelerator buttons. The available styles depend on the position of the
text cursor. The Return (Enter) key ends the current paragraph.

The toolbar has the following buttons:

    End         -- Ends current element

    Header      -- start new header

    List        -- start new list
    Item        -- start new item

    Term        -- start DT element
    Def         -- start DD element

    Literal     -- start preformatted text

    Emphasis    -- select from full range of character emphasis
    Italic      -- start italic or set emphasis of highlighted text
    Bold        -- start bold or set emphasis of highlighted text
    Underline   -- start underline or set emphasis of highlighted tex

    Link        -- link highlighted text to specified URL

For the Header, List and Emphasis buttons, the style is selected in
neighboring status windows which drop down to allow users to change
the current selection. The current element name is shown in a larger
status window on the left (pops down to show nesting of current elements).

All elements can be terminated by clicking the end button, although in
some cases the context will cause this to be implied, e.g. clicking
Header while in a list will terminate all current list elements.

Nested lists may cause some confusion. Clicking the List button will
start a nested list and imply an initial list element. To start a new
list at the same level as the current one, you need to first click
End and then the List button.

You can always highlight text by dragging the mouse pointer over it.
The editor is smart enough to insert start/end tags when necessary,
including removing empty emphasis or adjacent end,start tags of the
same type.

When moving the cursor out of an unfinished element, the editor
will automatically terminate any open elements. An alternative is
to insert start and end tags at the same time. Users can choose to
see markup elements explicitly or not as their prefer. This isn't
an all or nothing choice - one could show just the tag names in
a suitable font/colour without the attributes.

It would be neat to be able to display several documents at once. This
would allow users to make links using a point and click mechanism.

I hope that gives you the general feel of my as yet half-baked ideas.

Dave Raggett



From philipp@res.enst.fr  Tue Dec 14 13:53:18 1993 +0100
Message-Id: <9312141353.ZM13836@clarke.res.enst.fr>
Date: Tue, 14 Dec 93 13:53:18 +0100
From: philipp@res.enst.fr (Philippe-Andre Prindeville)
Subject: Re: Annoucement: Local Browser Execution

On Dec 13, 17:36, George Phillips wrote:
> Subject: Annoucement: Local Browser Execution

> One last thing.  I'm certainly interested in discussing viable
> alternatives to x-exec: and suggestions for improving it.  Flames
> about it being "a bad thing" and/or "the wrong thing" will be
> accepted in the same cheerful spirit as Mosaic Motif flames.

I'm not saying it is a "bad" or "wrong" thing.  But it has to be
pointed out that the possibility for Trojan Horses here is
mind-boggling.  One of the students here had FTP'd a shar file
from a BBS that he thought contained pornographic images.  When
he ran it, it archived and encrypted his directory and told him
where you could send $50 to get the password to unencrypt his files.

Serves him right, I said to myself (not because I'm a moralist
crusading against pornography -- just because you have to be
pretty bleeding daft to run an untrusted shar file in your home
directory).

So, does your patch try to use a restricted shell?  If so, what
commands do you limit the agent to?  Do you chroot to a temporary
directory?

-Philip



From wade@cs.utk.edu  Tue Dec 14 09:49:24 1993 -0500
Message-Id: <9312141449.AA09571@honk.cs.utk.edu>
Date: Tue, 14 Dec 1993 09:49:24 -0500
From: wade@cs.utk.edu (Reed Wade)
Subject: Re: Annoucement: Local Browser Execution 


>On Dec 13, 17:36, George Phillips wrote:
>
>I'm not saying it is a "bad" or "wrong" thing.  But it has to be
>pointed out that the possibility for Trojan Horses here is
>mind-boggling.  One of the students here had FTP'd a shar file


There will soon be a version of TCL/TK which includes a 'safe'
operating mode. It is mainly intended for active email but
would provide a very good operating environment for untrusted
scripts gotten via WWW.

We intend to use it quite heavily to provide more services via 
the WWW client we're working on.  

Reed Wade
wade@cs.utk.edu




From guenther.fischer@hrz.tu-chemnitz.de  Tue Dec 14 15:47:10 1993 +0100 (MET)
Message-Id: <9312141447.AA18345@etzel.hrz.tu-chemnitz.de>
Date: Tue, 14 Dec 1993 15:47:10 +0100 (MET)
From: guenther.fischer@hrz.tu-chemnitz.de (Guenther Fischer)
Subject: Re: "internal-gopher-image"?!?

> 
> Folks:
> 
> This question probably stems from being asleep at the switch as usual,
> but what does
>          <IMG SRC="internal-gopher-image">
> mean, and what unexplored part of the HTML standard is it part of?
> 

You can address the inlined images of Mosaic in such a way - I think
there was one answer to  this.

The good one is: No image data has to be transfered.
The bad one: Whats with other browsers ?

Because of that the question about standard is right. Because of that
I put my question about such thinks here again:

To the www gurus:

I see some nive icons in Mosaic (inlined icons), but have no way to refer
to them from my documents. I mean such as for ftp or gopher URLs.

It would save much traffic over the lines if we could have a
standard set of icons on the client site I could refer from the server site
(I will say from the documents on a server).

My vote:

<IMG SRC=/INLINE/icon01.gif>

The path component INLINE is reserved to be interpreted by the clients.
If client found INLINE the next component is interpreted as one of
a welldefined set of icons - nothing to transfer.

If the client hasn't this feature he could transfer as till now.
Because of that the server should have these "Standard-Icons" in the
INLINE directory too.

Could this be a area of standardization? - It would be so nice.

It could also help to get a "real" WWW look and feel ...

        ~Guenther


-- 
Name:      Guenther Fischer
Institute: TU Chemnitz, Universitaetsrechenzentrum
Phone:     0371 668 361
mail:      fischer@hrz.tu-chemnitz.de



From adreyer@uni-paderborn.de  Tue Dec 14 17:45:29 1993 +0100
Message-Id: <199312141645.AA02842@euler.uni-paderborn.de>
Date: Tue, 14 Dec 1993 17:45:29 +0100
From: adreyer@uni-paderborn.de (Achim Dreyer)
Subject: httpd1.0

Hallo,

I just got the new NCSA httpd1.0 und found the following problem :

I've got a file http://math-www.uni-paderborn.de/~adreyer/index.html 
with the URL-link to <A HREF="private.html"> placed in the same directory.
Under version httpd_1.0a5 the corresponding file was served correctly,
but with the new version I only get :

<HEAD><TITLE>404 Not Found</TITLE></HEAD>
<H1>404 Not Found</H1><BODY>
The requested URL /private.html was not found on this server.<P>
</BODY>

an in logs/error_log I get :

[Tue Dec 14 17:36:01 1993] httpd: access to /mathsoft/WWW/http_root_dir/private.html failed for euler-bb, reason: file does not exist


where :      ServerRoot /mathsoft/WWW/httpd
             DocumentRoot /mathsoft/WWW/http_root_dir
             UserDir public_html
             DirectoryIndex index.html

===> which means he is trying to fetch the document from the
document root of the server and not from my directory.

Have I configured something wrong ( I just copied the most parts ..) ??

Ciao,
        Achim

----------------------------------------------------------------
   
   Achim Dreyer, SunGuru MathDepartment, Uni/GH Paderborn, Germany
   UUCP:      adreyer@uni-paderborn.de
   BITNET:    adreyer%pbinfo.uucp@unido.BITNET
   X.400:     C=de;ADMD=" ";PRMD=uni-paderborn;S=adreyer
                           



From adreyer@uni-paderborn.de  Tue Dec 14 18:11:13 1993 +0100
Message-Id: <199312141711.AA03128@euler.uni-paderborn.de>
Date: Tue, 14 Dec 1993 18:11:13 +0100
From: adreyer@uni-paderborn.de (Achim Dreyer)
Subject: Mosaic for X version 2.1  -  <HR>Tag

Hallo,

Just got the new version .. It's great ;-))))

But what happend to the <HR>-Ruler in the postscript output ?
It just disappeared when I saved/printed a html-document as a
postscript file.. Under 2.0 it just made a line - but now there's
just a little gap.
My Question : Was it intended or is it dropped ?

Ciao,
        Achim

----------------------------------------------------------------
   
   Achim Dreyer, SunGuru MathDepartment, Uni/GH Paderborn, Germany
   UUCP:      adreyer@uni-paderborn.de
   BITNET:    adreyer%pbinfo.uucp@unido.BITNET
   X.400:     C=de;ADMD=" ";PRMD=uni-paderborn;S=adreyer
                           



From masinter@parc.xerox.com  Tue Dec 14 09:53:44 1993 PST
Message-Id: <93Dec14.095357pst.2732@golden.parc.xerox.com>
Date: Tue, 14 Dec 1993 09:53:44 PST
From: masinter@parc.xerox.com (Larry Masinter)
Subject: Re: "internal-gopher-image"?!?

> I see some nive icons in Mosaic (inlined icons), but have no way to refer
> to them from my documents. I mean such as for ftp or gopher URLs.

> It would save much traffic over the lines if we could have a
> standard set of icons on the client site I could refer from the server site
> (I will say from the documents on a server).

> My vote:

> <IMG SRC=/INLINE/icon01.gif>

> The path component INLINE is reserved to be interpreted by the clients.
> If client found INLINE the next component is interpreted as one of
> a welldefined set of icons - nothing to transfer.

> If the client hasn't this feature he could transfer as till now.
> Because of that the server should have these "Standard-Icons" in the
> INLINE directory too.

> Could this be a area of standardization? - It would be so nice.

Here's another proposal:
	Invent a new kind of reference.
	Call it a `name' instead of a `location'.
	MMM, how about URN instead of URL.

	Use the URNs of frequently used icons instead of URLs.

	Some clients might even have built into them 
	*copies* of resources that are really frequently
	used (like common inline images).

	Others might retrieve them every time and just cache them
	for a short time.

	Others might have different caching schemes.

This could be a new area of standardization.



From ams  Tue Dec 14 10:42:22 1993 PST
Message-Id: <9312141842.AA19459@eit.COM>
Date: Tue, 14 Dec 93 10:42:22 PST
From: ams (Allan M Schiffman)
Subject: Re:  Web posting policy

You're right that where timeliness is important, meeting the "prior approval"
standard makes things difficult.

But the attitude that should be adopted, I think, is that the default is
NOT to publish.  Corporate calendars and employee databases are a case
in point. IMHO, neither (in the general sense) should be exposed to public
view.

In practice, it might be enough to get prior approval for a general class
of information.  For example, we might adopt the principal that project
reports are immediately publishable, or that MADE project reports, in
particular are.

-Allan




From phillips@cs.ubc.ca  Mon Dec 14 10:43:00 1993 -0800
Message-Id: <7058*phillips@cs.ubc.ca>
Date: 14 Dec 93 10:43 -0800
From: phillips@cs.ubc.ca (George Phillips)
Subject: Re: Local Browser Execution

Philippe-Andre Prindeville says:
>So, does your patch try to use a restricted shell?  If so, what
>commands do you limit the agent to?  Do you chroot to a temporary
>directory?

You should really read the documentation
(http://www.cs.ubc.ca/doc/world/exec/intro).  x-exec does not,
repeat, does not just feed arbitrary commands to a shell.
It takes an abstract program name, checks to see if that
program is on a list of allowed programs and runs the
program only if it is on that list.

Obviously there is still the possibility of abuse, but if you're
careful about what programs you have run, there's no problem.

Reed Wade says:
>There will soon be a version of TCL/TK which includes a 'safe'
>operating mode. It is mainly intended for active email but
>would provide a very good operating environment for untrusted
>scripts gotten via WWW.

Again, x-exec: doesn't execute just anything.  I do think a
"safe" interpreter would be interesting, though.  Are such
scripts allowed to write any files?  Some x-exec: scripts
depend heavily on cache files for performance.  Some x-exec:
scripts use files to keep track of history, like the newsreading
stuff.



From gak@eit.COM  Tue Dec 14 11:06:33 1993 PST
Message-Id: <9312141906.AA19765@eit.COM>
Date: Tue, 14 Dec 93 11:06:33 PST
From: gak@eit.COM (Glenn A. Kramer)
Subject: Web posting policy


    But the attitude that should be adopted, I think, is that the default is
    NOT to publish.  Corporate calendars and employee databases are a case
    in point. IMHO, neither (in the general sense) should be exposed to public
    view.

I thought "publish" in this context meant for EIT only, not for the
public. 



From ams  Tue Dec 14 11:24:58 1993 PST
Message-Id: <9312141924.AA19848@eit.COM>
Date: Tue, 14 Dec 93 11:24:58 PST
From: ams (Allan M Schiffman)
Subject: Re: Web posting policy

Sorry, I thought it was clear from the context that I was discussing
materials made available to the public at large.  Internal EIT
documents (on paper or in digital form) do not require "publications
clearance", and I don't consider them "published".

OK?

-Allan



From rivero@sol.unizar.es  Tue Dec 14 20:30:27 1993 +0000 (GMT)
Message-Id: <9312142030.AA21278@sol.cie.unizar.es>
Date: Tue, 14 Dec 1993 20:30:27 +0000 (GMT)
From: rivero@sol.unizar.es (Alejandro Rivero)
Subject: Re: Local Browser Execution (speaking of troyans)



Hmm, now I think of, I would like to get some files from the client 
included in the reply to a FORM html... Hey, I was thinking 
only in the .gopherrc and or some other .'wwwclient'rc :-)

Seriusly, it could be a good method, to get statistics, post 
files etc. Can it be done within current standards?


				Alejandro



From fielding@simplon.ICS.UCI.EDU  Tue Dec 14 15:38:04 1993 -0800
Message-Id: <9312141538.aa05116@paris.ics.uci.edu>
Date: Tue, 14 Dec 1993 15:38:04 -0800
From: fielding@simplon.ICS.UCI.EDU (Roy T. Fielding)
Subject: Re: HTML(+)-editor available? 

I was thinking about the design of such an editor as well, although
I know I won't have the time to write one.  So, I'll just add a suggestion
on to Dave's design list ;).

I would like to have the editor work with two parallel views of the
document: one with a full text view of the HTML source and the other
with a view of how the text should be displayed (similar to a Mosaic
display widget).  Both windows should be editable and the insertion/
deletion of printable characters should appear simultaneously in both
windows as appropriate to the context in which they are typed.  The
difficult thing will be to get the display-widget to read partially-formed
HTML text and interpret the results in a reasonable manner.  Naturally,
I'll leave that up to someone else to figure out.


....Roy Fielding   ICS Grad Student, University of California, Irvine  USA
                   (fielding@ics.uci.edu)



From brock@netmanage.com  Tue Dec 14 17:27:13 1993 PST
Message-Id: <Chameleon.3.11-AC.931214173010.brock@>
Date: Tue, 14 Dec 93 17:27:13 PST
From: brock@netmanage.com (Kevin Brock)
Subject: HTTP draft comment

I was looking over the HTTP draft dated 
5 Nov 93 and I noticed that one of the 
references was RFC850... This has been
obsoleted by RFC1036.  Is the reference 
to RFC850 an error, or is there something
there which is not in RFC1036?

Kevin Brock
brock@netmanage.com




From timbl@www3.cern.ch  Wed Dec 15 10:24:16 1993 +0100
Message-Id: <9312150924.AA04440@www3.cern.ch>
Date: Wed, 15 Dec 93 10:24:16 +0100
From: timbl@www3.cern.ch (Tim Berners-Lee)
Subject: EDI and WWW

>From: sdw@meaddata.com (Stephen Williams)
>To: Multiple recipients of list <ietf-edi@byu.edu>

I cross-post this to www-talk, as WWW should be aware of EDI.

For wwwwizads:  There is discussion
in ietf-edi for doing EDI (electronic commercial transactions) over
the Internet.  EDI seems to be like using forms with email submission,
with a forms language which HTML+  _ought_ to be able to subsume.
I suggest someone get hold of the specs and write a DTD which is
equivalent.  Whether you like the look of the EDI format or not
(if you are a WWWWizard I can hazard a guess ;-) there is an established  
community using this stuff and so the standards must reflact needs in
some way at least. A good test of a new, general, system, is that it
can represent other things without pausing for breath.  This is what
WWW rather specialises in.  First thing is to get hold of X.435....
We will soon have apparatus for interactive transactions with forms
operating in I suspect a largs scale on the Internet for applications
which are not legally and financially critiacal. Forms with HTTP are
much faster and neater than anything email or even "fast batch"
as they say in EDI. PEM on top of HTTP will introduce the security,
and then there will suddenly be a complete Internet solution for EDI
as a spin off of what we have now.  We don't want then that there is
some basica incompatibility with EDI.  That's why I suggest someone
check out the specs.  I suspect Dave Raggett won't have time soon,
so is there a volunteer?

Now to the message I quote:

>> David [Crocker] said:
>> 

>> >Do people (on this list specifically, but in the industry  in general, if 

>> >they've thought about it) think that X.435 and "internet edi" are in 

>> >competition, or that they are just two of many approaches to electronic 

>> >commerce?
>
Stephen Williams said:
 >They are going to interoperate, if I have to write the software myself...  
:-)

	Aaaagh, the Internet spirit!

>> In the commercial setting, it is definitely competition.  The X.400 VANs
>> already offer non-X.435 EDI and have promised X.435 upgrades.  They can  
show
>> working, off-the-shelf software.[...] businesses are placing
>> their efforts on X.400 and the INTERNET has lost this race even before  
they
>> entered it, except for those organizations that are already on the  
INTERNET.
>
>Only until we create it and standardize on it.
>
>We really should have done this long ago.  Can anyone provide us with
>stipped down X.400/X.435 code/specs?  The X.400 stuff should be
>available from the pp/isode distributions.  The X.435 could probably
>be attained just by typing in the ASN.1 specs.

	I would be interested in a copy -- anyone prepared to fax
	it to me even if its not online? Or is there an ECMA
	equivalent number for this ANSI spec?
	
[...]
>I submit that we should get an X.435 message packer/unpacker package
>together with no transport mechanism bound in and then decide how to
>map that onto MIME.  If it's exactly compatible, we should be able to
>catch up quickly.

	HTTP is a bit ahead of MIME with the forms DTD here --
	as HTTP uses MIME for messages (just does them interactively)
	it shouldn't make a lot of difference.
	
>Adding encryption/signatures, etc. might give us an edge also, ala
>cypherpunks.  Remailer techniques could even be used for
>non-repudiation, auditing, or anon support.
>
>What are the requirements for 'fast-batch'?  SMTP is pretty fast,
>especially if you run a few parallel sessions (my experience is
>watching the wire with cslip to Internet).

	Just watch HTTP.

>> EDI deliver will also have an interesting (IMHO) influence on IIN.  The
>> network that can readily carry the commerce of the nation will be the
>> network that the government will want to see grow...

	Aside from that, do we really want to draw the line and say that
	a particular information item is commercial, and therfore
	shough use one paradigm, set of protocols, etc, and another
	is not really commercial so will use the same pardigm as
	the web, news, and mail?  Of course not.  Such lines do not
	exist. We want to put the features, such as security and
	common formats, in in a totally orthogonal way, so that they
	can all be blissfully used together. And it shouldn't be
	difficult.  :-)

>> Bob
>sdw
timbl



__________________________________________________________
Tim Berners-Lee                       timbl@info.cern.ch
World Wide Web development leader	
CERN, CN Division                     Tel: +41(22)767 3755
1211 Geneva 23, Switzerland           Fax: +41(22)767 7155







From masinter@parc.xerox.com  Wed Dec 15 01:33:13 1993 PST
Message-Id: <93Dec15.013323pst.2732@golden.parc.xerox.com>
Date: Wed, 15 Dec 1993 01:33:13 PST
From: masinter@parc.xerox.com (Larry Masinter)
Subject: Re: Annoucement: Local Browser Execution 

I think x-exec: is an ugly hack. I'm about to propose something that
at first glance looks like an uglier hack, but maybe after you think
about it for a bit you won't shoot me:

Right now, you're taking something 'x-exec:blah blah' and treating it
as a URL that executes something special.

Why not, instead of searching for "x-exec:", search for
"http://cs.ubc.ca/exec/".  That is, build *into your client* the
special case that if you see "http://cs.ucb.ca/exec/blah blah",
instead of sending http protocol somewhere, you execute "blah blah" as
a shell command.

This doesn't clutter the URL space either. You might think it is
rather special purpose to put such an odd special case in your
software, but in fact it is fairly general. 

#define DUMMY_HTTP_EXEC_SERVER "cs.ucb.ca"

if you like.

You'll get all the features you wanted with x-exec, and you'll also
get pages that function when you browse them with clients that don't
have any special purpose extensions.



From timbl@www3.cern.ch  Wed Dec 15 11:30:29 1993 +0100
Message-Id: <9312151030.AA04479@www3.cern.ch>
Date: Wed, 15 Dec 93 11:30:29 +0100
From: timbl@www3.cern.ch (Tim Berners-Lee)
Subject: WWW and EDI: The need


I just had to forward this one too! - tim

Date: Tue, 14 Dec 1993 08:33:52 -0700

I just returned from the interim meeting of X12 Subcommittee J, Technical
Assessment, in Scottsdale.  The health care industry is really pushing
interactive EDI, which they characterize as real-time, immediate response
 rather as opposed to normal, batch EDI.  The rationale:

"Providers of health care are demanding immediate access to clinical
histories as well as payer coverage and delivery rules that effect how they
might deliver or be reimbursed for services rendered.  Payers desire
the ability to manage patient access to available health care services
by requiring justification for services before they are delivered.
Patients expect that their insurance coverage will afford them immediate
access to the care they require.  When they enter the provider's office,
patients expect that questions of coverage and reimbursement will not
delay delivery of the care they need...."

The health care industry has submitted to Subcommitte J business
scenarios involving requestor (provider), service intermediary, and
responder all linked through a dial-up connection, leased line, or a
virtual private circuit.  This industry believes immediate response EDI
will be used not only by providers of health care, but the Health Care
Finance Administration (HCFA); Medicaid; commercial payors, third-
party administrators and Blue Cross/Blue Shield; and property and
casualty companies.

The health care industry is now developing X12 guidelines for
interactive EDI through Subcommittees N and C.  I believe this subject
may have a significant impact on the education community and its
current and future EDI applications.

Betsy Bainbridge
AACRAO EDI Coordinator





From hgs@research.att.com  Wed Dec 15 08:03:46 1993 EST
Message-Id: <9312151304.AA13944@dxmint.cern.ch>
Date: Wed, 15 Dec 93 08:03:46 EST
From: hgs@research.att.com (Henning G. Schulzrinne)
Subject: Re: Annoucement: Local Browser Execution

> From research!dxcern.cern.ch!www-talk-request Wed Dec 15 05:16:12 1993
> To: phillips@cs.ubc.ca
> 
> I think x-exec: is an ugly hack. I'm about to propose something that
> at first glance looks like an uglier hack, but maybe after you think
> about it for a bit you won't shoot me:
> 
> Right now, you're taking something 'x-exec:blah blah' and treating it
> as a URL that executes something special.
> 
> Why not, instead of searching for "x-exec:", search for
> "http://cs.ubc.ca/exec/".  That is, build *into your client* the
> special case that if you see "http://cs.ucb.ca/exec/blah blah",
> instead of sending http protocol somewhere, you execute "blah blah" as
> a shell command.

I believe this solution to be far superior. One of the nicer things
about URLs is that you don't necessarily know or care whether something
returned to you has been generated dynamically or exists as a file.
Conceptually, both are the same: In either case, you provide a 
string that maps into some output, to be returned. For file retrieval,
the mapping is done by the filesystem, for a shell command it is done
by some special program. You might even decide to switch between the
two, e.g., if the range of arguments provided is small enough that
they can easily be mapped into files.

Henning
---
Henning Schulzrinne (hgs@research.att.com)
AT&T Bell Laboratories  (MH 2A-244)
600 Mountain Ave; Murray Hill, NJ 07974
phone: +1 908 582-2262; fax: +1 908 582-5809



From jern@spaceaix.jhuapl.edu  Wed Dec 15 08:41:52 1993 -0500 (EST)
Message-Id: <9312151341.AA20936@sdrmis.jhuapl.edu>
Date: Wed, 15 Dec 1993 08:41:52 -0500 (EST)
From: jern@spaceaix.jhuapl.edu (jern@spaceaix.jhuapl.edu)
Subject: Re: WWW and EDI: The need

The whole business of EDI and Internet is more of a problem than
might be expected.  Many business managers are convinced that
technical business problems must have a *commercial* solution.  COS,
Commercial Off the Shelf, is the keyword.  Also known as 'cover
your ass'(CYA) or keep someone in the wings to sue if it doesn't work.
Freeware is to be avoided at all costs.  I recently saw a EDI
system implemented with commercial products when the two computers
being connected via modems were both on the Internet with fiber-optic
local nets.  Frankly, if I were in the business of supplying
commercial network products I'd be scared as hell at the moment.
With HTTP I don't need SQL*Net or the EDI products.  Meeting the
EDI specs is a piece of cake.

Keep up the good work everyone.

bob jernigan



From muenkel@tnt.uni-hannover.de  Wed Dec 15 15:10:35 1993 +0100
Message-Id: <9312151410.AA29239@helios.tnt.uni-hannover.de>
Date: Wed, 15 Dec 93 15:10:35 +0100
From: muenkel@tnt.uni-hannover.de (Heiko Muenkel)
Subject: New version of the HTML-mode for the lemacs

Hello,


I've written a new version (3.0) of my extensions to the html-mode from Marc
Andreessen for the Lucid Emacs (lemacs). The name of the package is
	hm--html-menus-3.0.tar.gz
You can find it on the following ftp server:
	info.cern.ch in /pub/www/contrib
	sunsite.unc.edu in /pub/Linux/apps/editors/emacs/
			or /pub/Linux/Incoming
	and in a few days on:
	ftp.rrzn.uni-hannover.de in /pub/unix/editors/lemacs/contrib

The package has now a lot of functions for HTML+ and for special features
of the NCSA http daemons like forms and server side include commands.

It provides functions to insert the following stuff in html-pages:
1. Anchors:
	html link, info link, gopher link, file link;
	ftp link, news link, mail link, wais (direct) link,
	wais (gateway) link;
	proggate link, local proggate link, general link;
	link target;
2. Frame elements:
	full html frame with html, head, body, title, header and signature
	elements or only the single elments;
	html 'created'- and 'changed'- comments;  
	the current date in the title; 
3. Structure elements:
	menu or list item, menu, unordered list, ordered list, directory list;
	description list, description title, description entry;
	new paragraph, new line, horizontal rule;
4. for preformated text:
	without links, with links, blockquote, listing;
5. formatting:
	bold, italic, underline, typewriter,
	emphasized, strong, code, sample, keyboard, variable, definition,
	citation, html comment;
6. include:
	top aligned image, middle aligned image, bottom aligned image;
	server side include commands for files, commands and commands
	with parameter;
7. forms:
	form;
	text and password fields, checkbox, radio, submit and reset buttons;
	option menus, scrolled lists and option entries;
	textarea;

If it makes sense, the functions worked also on selected regions. Therefore 
I've used the same menu items and the same keystrokes. So you don't need to
learn different menus or keys for similar functions.
You can choose the popup menus between an expert menu, an novice menu and
the menu from Marc Andreessen interactive.
With the pulldown menu, you can do the following things:
- select the pulldown menu
- change the highlighting of html tags
- quotify hrefs
- reload the config files
- load html templates from a template directory (one template is included
  in the package)
- preview html documents with the xmosaic
- preview html documents with the w3 package for the lemacs

You can configure the html mode with a special configuration file for your site
and with another file specific for a user.

The html is under developement and therefore also this package is under
developement. So, if you have any ideas to extend the package, feel free to
email them to muenkel@tnt.uni-hannover.de.


Heiko







From Axel.Belinfante@cs.utwente.nl  Wed Dec 15 15:14:23 1993 +0100
Message-Id: <9312151414.AA18443@utis179.cs.utwente.nl>
Date: Wed, 15 Dec 93 15:14:23 +0100
From: Axel.Belinfante@cs.utwente.nl (Axel Belinfante)
Subject: Re: Annoucement: Local Browser Execution 

Inspired by all this I'm trying to do something similar - using what is
available right now, without hacking the client.

In my _server_ i have a mapping from
	http://host:port/exec/blah blah
into a HTTP/1.0 MIME document of type: application/x-exec with contents
blah blah
Probably the document should also contain some information about the
document BASE.

In my .mailcap i have a mapping:
	application/x-exec; x_exec %s

The x_exec program is what i'm currently working on. It should execute
the commands in the file it receives, but not blindly: it should check
whether the commands are considered 'safe' (eg. by checking if they are
in a directory that contains (links to) the 'safe' commands), and it
should probably filter out shell meta-symbols to avoid trickery
(or maybe we can handle this in a different way).

It should catch the standard output of the commands in a (tmp)file, and
be ready to give this file to Mosaic via the remote control feature.
This is where the information about the document BASE will be needed:
the stdout of the command is supposed to be HTML, which might contain
relative links. I think that the Mosaic feature recently added to
handle mailed documents will solve/handle this.

One remaing problem: how/when do we remove the tmp-file that contains
the standard output?

What do people think? Could this be made to work? I'll try anyway.. :-)

Regards,
Axel.

In message <9312151304.AA13944@dxmint.cern.ch> 
hgs@research.att.com (Henning G. Schulzrinne) writes:
> > From research!dxcern.cern.ch!www-talk-request Wed Dec 15 05:16:12 1993
> > To: phillips@cs.ubc.ca
> > 
> > I think x-exec: is an ugly hack. I'm about to propose something that
> > at first glance looks like an uglier hack, but maybe after you think
> > about it for a bit you won't shoot me:
> > 
> > Right now, you're taking something 'x-exec:blah blah' and treating it
> > as a URL that executes something special.
> > 
> > Why not, instead of searching for "x-exec:", search for
> > "http://cs.ubc.ca/exec/".  That is, build *into your client* the
> > special case that if you see "http://cs.ucb.ca/exec/blah blah",
> > instead of sending http protocol somewhere, you execute "blah blah" as
> > a shell command.
> 
> I believe this solution to be far superior. One of the nicer things
> about URLs is that you don't necessarily know or care whether something
> returned to you has been generated dynamically or exists as a file.
> Conceptually, both are the same: In either case, you provide a 
> string that maps into some output, to be returned. For file retrieval,
> the mapping is done by the filesystem, for a shell command it is done
> by some special program. You might even decide to switch between the
> two, e.g., if the range of arguments provided is small enough that
> they can easily be mapped into files.

<Axel.Belinfante@cs.utwente.nl>   tel. +31 53 893774   fax. +31 53 333815
     University of Twente, Tele-Informatics & Open Systems Group
       P.O. Box 217    NL-7500 AE Enschede      The Netherlands
     "ili ne sciis ke estas neebla do ili simple faris" -- Loesje




From nilsson@dxcern.cern.ch  Wed Dec 15 15:45:22 1993 +0100
Message-Id: <9312151445.AA06635@dxcern.cern.ch>
Date: Wed, 15 Dec 1993 15:45:22 +0100
From: nilsson@dxcern.cern.ch (Bjorn S. Nilsson)
Subject: Mosaic 2.0 VMS version, more fixes

Just in case you did not see this somewhere else:

This morning I uploaded another set of fixes to my VMS port of
Mosaic 2.0 to info.cern.ch, directory pub/www/bin/vms. These
fixes have also been submitted to ftp.ncsa.uiuc.edu and should
appear in Mosaic/Mosaic-contrib in due time.

Short description:
    4. A nice icon pixmap contributed by Kevin Oberman.
    5. Changes to setup of external viewers etc.
    6. Changes to the TCP/IP interface. Important improvements
       to the code version using UCX. Support for AXP machines
       running MultiNet.
    7. Code for interfacing Mosaic to CMU-OpenVMS/IP contributed
       by Mike O'Malley.

Like the previous changes these ones are in the format of VMS diff
files. I hope you find them useful.

Bjorn S. Nilsson, ALEPH, CERN, 14-Dec-1993
nilsson@alws.cern.ch
http://alephinfo.cern.ch/@ALWHO?nilsson




From swb@nr-tech.cit.cornell.edu  Wed Dec 15 09:33:23 1993 -0500
Message-Id: <199312151433.JAA15087@mitchell.cit.cornell.edu>
Date: Wed, 15 Dec 1993 09:33:23 -0500
From: swb@nr-tech.cit.cornell.edu (Scott W Brim)
Subject: Re: HTML(+)-editor available?

  >I would like to have the editor work with two parallel views of the
  >document: one with a full text view of the HTML source and the other
  >with a view of how the text should be displayed (similar to a Mosaic
  >display widget)

I was thinking of asking the folks who did Lightning Textures for the
Mac to take on an (at least) HTML editor, since this is exactly what
they do for latex, and they do it very nicely.  Unfortunately Textures
costs about $500, which is more than I can justify, and this would
probably cost the same.





From davis@dri.cornell.edu  Wed Dec 15 10:22:32 1993 -0500
Message-Id: <199312151522.AA14611@willow.tc.cornell.edu>
Date: Wed, 15 Dec 1993 10:22:32 -0500
From: davis@dri.cornell.edu (Jim Davis)
Subject: HTTP date format: RFC 850 or RFC 1036

As has been pointed out, the HTTP draft specifies that dates
are to expressed in RFC 850 format, but RFC 850 has been
replaced by RFC 1036.

I wish to point out that RFC 1036 has a different format for dates
than RFC 850. Although neither RFC says so explicitly, the differences
seems to be that RFC 1036 uses a space to separate day, month, and year,
where 850 uses a dash; and 1036 uses three-letter forms of the day
name.  

Example of 850:        Weekday, DD-Mon-YY HH:MM:SS TIMEZONE
Example of 1036:       Wdy, DD Mon YY HH:MM:SS TIMEZONE

By the way, I can't resist pointing out that neither RFC provides an
explicit syntax for dates, other than to say that it must be
"acceptable both in RFC-822 and to the getdate(3) routine that is
provided with the Usenet software."  This is in keeping with the Unix
practise of defining "standards" by saying "it's whatever the
such-and-such routine accepts".  I don't see so much as a man page for
the getdate(3) routine, so who knows that the syntax really is.
Judging from the most recent usenet message I have seen, the dayname
(and comma and space) are optional.

Anyway, we need to make a clear decision which RFC to follow, since
there are incompatible differences.

Does anyone implement Date (or Last-Modified) response headers yet?
I do, and for now I am going with the new RFC.




From J.Larmouth@iti.salford.ac.uk  Mon Dec 15 15:01:00 1993
Message-Id: <9312151513.AA29473@dxmint.cern.ch>
Date: 15 Dec 93 15:01
From: J.Larmouth@iti.salford.ac.uk (J.Larmouth@iti.salford.ac.uk)
Subject: Re caching of frequently used pages

=========================================================================
E-mail from: Prof J Larmouth              J.Larmouth @ ITI.SALFORD.AC.UK
             Director                       Telephone: +44 61 745 5657
             IT Institute                         Fax: +44 61 745 8169
             University of Salford              Telex: 668680 (Sulib)
             Salford M5 4WT
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -

To:     www-talk @ info.cern.ch

Subject:      Re caching of frequently used pages

It can happen that at any one site many people are more or less
simultaneously (within days of each other) browsing around the "popular"
pages of the web.  This is particularly true for undergraduate courses
that introduce them to the web,  and to "open day" demonstrations of the
web.

If we are thinking about more support for caching,  a LAN-cache server
would be a better idea than caching in a personal client:   you configure
the client to say you have a LAN-cache server and thereafter it always
accesses the net through that server,  allow it to deliver cached
material and/or to cache material fetched for you.

Of course,  any greater use of caching must raise the issue of an
"expected frequency of update" value to be held with each document,  in
order to assist the LAN-cache server in knowing how long to keep things.

John L

PS This idea arose in discussions with Peter Mills of Manchester.




From Gisle.Aas@nr.no  Wed Dec 15 17:41:08 1993 +0100
Message-Id: <9312151641.AA11330@nora.nr.no>
Date: Wed, 15 Dec 93 17:41:08 +0100
From: Gisle.Aas@nr.no (Gisle.Aas@nr.no)
Subject: Re: Annoucement: Local Browser Execution

Axel.Belinfante@cs.utwente.nl writes:
> It should catch the standard output of the commands in a (tmp)file, and
> be ready to give this file to Mosaic via the remote control feature.
> This is where the information about the document BASE will be needed:
> the stdout of the command is supposed to be HTML, which might contain
> relative links. I think that the Mosaic feature recently added to
> handle mailed documents will solve/handle this.
> 
> One remaing problem: how/when do we remove the tmp-file that contains
> the standard output?
> 
> What do people think? Could this be made to work? I'll try anyway.. :-)

I have tried it and it works:

----------------------------------------------cut here----------
#!/local/bin/perl

$allowed = "(imaker|cal|ls)$";  # only programs that match this regex are allowed to run

$file = shift || &usage;
open(F, "$file") || die;
$cmd = <F>;
chop($cmd);
#print "<$cmd>\n"; exit;
@ARGV = split(/ /, $cmd);

if ($ARGV[0] =~ /^-/) {
   $how = shift;
   grep($_ eq $how, "-html", "-text", "-xterm", "-null") || &usage;
};
$how = "-html" unless defined $how;
die "Not allowed to run this program \"$ARGV[0]\""
    unless $ARGV[0] =~ /$allowed/;


if ($how eq "-text" || $how eq "-html")
{
   open(PIDFILE, "$ENV{'HOME'}/.mosaicpid") || die "No mosaic is running";
   $pid = <PIDFILE>;
   close(PIDFILE);

   $tmpfile = "/tmp/out-$$";
   $tmpfile .= ".txt"  if $how eq "-text";
   $tmpfile .= ".html" if $how eq "-html";
   open(STDOUT, ">$tmpfile");
}
if ($how eq "-null")
{
   open(STDOUT, ">/dev/null");
   open(STDERR, ">/dev/null");
}
if ($how eq "-xterm")
{
   @xterm = ("xterm", "-e");
}

open(STDIN, "/dev/null");

system @xterm,@ARGV;

if ($how eq "-text" || $how eq "-html")
{
   open(CONTROL,"> /tmp/Mosaic.$pid");
   
   print CONTROL "goto\n";
   print CONTROL "file://localhost$tmpfile\n";

   close(CONTROL);

   kill "USR1",$pid;
   system "(sleep 5; rm -f $tmpfile)&"
}



sub usage
{
   die "Usage: mosaic-run [-text|-html|-xterm|-null] command args...\n";
}



From sanders@bsdi.com  Wed Dec 15 11:08:22 1993 -0600
Message-Id: <199312151708.LAA07620@austin.BSDI.COM>
Date: Wed, 15 Dec 1993 11:08:22 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: HTTP date format: RFC 850 or RFC 1036 

> Does anyone implement Date (or Last-Modified) response headers yet?
> I do, and for now I am going with the new RFC.
Both Plexus and the NCSA HTTPD (v1.0) use RFC850 style dates:
    Last-modified: Monday, 06-Dec-93 23:48:09 GMT

Changing this for no reason is a bad idea.  We should specify the date
format in the HTTP RFC by value instead of by reference.

If we change this then browsers will have to support both formats forever.

--sanders



From bainbridgel%aacrao.decnet.cern.ch@NCHEMAIL.nche.edu  Wed Dec 15 09:33:17 1993 -0800
Message-Id: <9312151733.AA13516@interval.interval.com>
Date: Wed, 15 Dec 1993 09:33:17 -0800
From: bainbridgel%aacrao.decnet.cern.ch@NCHEMAIL.nche.edu (Lysbeth Bainbridge, EDI Coordinator)
Subject: EDI and the Internet

     *************************************************************************

     For Immediate Release                                    December 4, 1993


          A Call to Action:  Internet and Electronic Data Interchange

     "Come on in, the water's fine!" invited the speaker at a recent workshop,
     summoning all those interested in helping to develop a standardized way
     to use the Internet for electronic data interchange (EDI).  Internet
     standards development requires collaboration and grass-roots partici-
     pation.  The education community is now providing opportunities for open
     discussion on EDI and the Internet. The result will likely have signifi-
     cant consequences for current and future users of the Internet.

     Over the past ten years, business and government have depended
     increasingly on EDI as a fast, economical, and dependable way to conduct
     business transactions.  Computer-to-computer communication is replacing
     such paper forms as purchase orders, court conviction records, and
     mortgage credit reports.  Commercial value-added networks (VANs) have
     been the traditional carriers of EDI messages.  Now the education
     community is pioneering efforts to take advantage of widespread Internet
     availability to reap the benefits of EDI while addressing issues of
     authentication, access control, data integrity, and confidentiality.

     The American Association of Collegiate Registrars and Admissions Officers
     (AACRAO) sponsored a mid-October Vancouver workshop attended by some 250
     users of EDI formats for student records.  Two speakers on Internet
     issues were invited to share their expertise.  Kelly McDonald is a member
     of the Westnet Steering Committee, and David Crocker is a member and area
     director of the Internet Engineering Task Force (IETF).  Both experts are
     enthusiastic about the possibility of using Internet for EDI.

     Crocker put forward an initial proposal for using EDI over the Internet.
     He outlined the steps needed to finalize such a standard.  Key to this
     process is putting together a work group that has the passion, skill, and
     time to pursue the topic.  The remaining components are:

          --   establishing a listserv for discussion of this topic
          --   drafting a proposal for comment
          --   inviting open discussion on the proposal
          --   revising the proposal according to the discussion
          --   submitting the proposal to the IETF for approval

     AACRAO's SPEEDE/ExPRESS Project, the driving force behind the workshop
     and this development effort, has issued a call to action directed at
     potential users of this standard.  Brigham Young University hosts the
     listserv established for this topic.  To subscribe send an e-mail message
     to:  LISTSERV@BYU.EDU.  The text of the message should only contain the
     following:

          sub ietf-edi <your-name>

     Messages may be sent to IETF-EDI@BYU.EDU

     For information contact:  Lysbeth Bainbridge, AACRAO EDI Coordinator,
     (202) 293-7383 or BAINBRIDGEL@AACRAO.NCHE.EDU.

     *************************************************************************






From guenther.fischer@hrz.tu-chemnitz.de  Wed Dec 15 18:43:48 1993 +0100 (MET)
Message-Id: <9312151743.AA25564@etzel.hrz.tu-chemnitz.de>
Date: Wed, 15 Dec 1993 18:43:48 +0100 (MET)
From: guenther.fischer@hrz.tu-chemnitz.de (Guenther Fischer)
Subject: Re: Re caching of frequently used pages

> E-mail from: Prof J Larmouth              J.Larmouth @ ITI.SALFORD.AC.UK
> 
> Subject:      Re caching of frequently used pages
> 
> ...

> 
> Of course,  any greater use of caching must raise the issue of an
> "expected frequency of update" value to be held with each document,  in
> order to assist the LAN-cache server in knowing how long to keep things.
> 

I have an experimental cache server running based on Tony Sanders Plexus.
Users are connected per default to this server through the
WWW_http_GATEWAY environment variable for Mosaic (Unix). Mosaic for Windows
and Lynx will follow. (I hope soon ... - we need it).

setenv WWW_http_GAETWAY www.tu-chemnitz.de:8002

Then Mosaic gives all http://host:port/... URL to www.tu-chemnitz.de:8002 
in the form

GET /host:port/...

The main base of "my" caching is:
- Server is HTTP/1.0 and
- has the Last-Modified (L-M) value in its header.
- do not handle queries
- run as a simple gateway for servers not to cache

I can configure the cache server:
- list of servers to cache
- TIME_SHORT for html/text
- TIME_LONG for other (gifs etc.)

Algorithm implemented at now:

- If request not in cache: get it -> give it to client and cache
  (I store it with full header)
- If request in cache:
  - if NOW - cache files TIME < TIME_SHORT
      put it to client 
    else
      put it to client      and
      get the head from the server
      if L-M of cache == L-M from server
         utime the cache file to now
      else
         unlink the file and get it

For TIME_LONG files in the same manner.

I've also started a students work to clean and refresh the cache
without client (at night or weekend).

You can try my cache server:

www.novell.com and www.ncsa.uiuc.edu are on the list.

	~Guenther
-- 
Name:      Guenther Fischer
Institute: TU Chemnitz, Universitaetsrechenzentrum
Phone:     0371 668 361
mail:      fischer@hrz.tu-chemnitz.de



From phillips@cs.ubc.ca  Mon Dec 15 11:57:00 1993 -0800
Message-Id: <7069*phillips@cs.ubc.ca>
Date: 15 Dec 93 11:57 -0800
From: phillips@cs.ubc.ca (George Phillips)
Subject: Re: Annoucement: Local Browser Execution

Larry Masinter says:
>Why not, instead of searching for "x-exec:", search for
>"http://cs.ubc.ca/exec/".  That is, build *into your client* the
>special case that if you see "http://cs.ucb.ca/exec/blah blah",
>instead of sending http protocol somewhere, you execute "blah blah" as
>a shell command.

If what you're getting at is that it is better to use an HTTP server
than x-exec:, then I agree, but only when you can use a server.
And there are two cases of that.  First, there are lots of people
who can't set up a server (not priviledged enough, no network, etc).
For them, "x-exec:" gives them access to server-only features like
search queries, forms and gateways.  It makes a web browser just
that much better of a tool for their use.

Second, if your x-exec: script has side effects, the equivalent
HTTP server implementation is much harder.  Take the news-reading
with history example.  My x-exec: script writes cache files and
the user's .newsrc.  So the server will have to authenticate the
connection as a particular user and, under UNIX, become that user.
That means it must run as root.  All this can be done, but I
think the security implications are much worse -- now you have
a world-accessible port to which anyone can try to crack security
on.  I just wouldn't put that on to my server with just the "basic"
authentication.

I do agree that having a server which lets me do things like read
news from anywhere in the world I can get a WWW browser and an
internet connection would be wonderful.  The authentication
technology is not quite there yet (but it will be).  At any rate,
it doesn't help my first point -- you still have to have the
ability to set up the server to do it.  In fact, it gets worse
because you have to set up a server that does all the careful
authentication.  You move from a situation where any old user
can get the x-exec: news browser running to something to a
situation where only a high-level server guru can do the
job for you.  Sure the server guru has given you something
much more and that's good, but why go to all that extra work
if you don't particularly care about running the news browser
anywhere but your local site?

And with x-exec:, once the authentication is strong enough
to trust you'll be able to drop your scripts right into your
server since x-exec: uses the CGI.  In the mean time, I'll use my
ugly hack and explore what can be done.




From njw@cs.city.ac.uk  Wed Dec 15 21:03:42 1993 +0000 (GMT)
Message-Id: <Ih3riiW__5g9M68EgO@cs.city.ac.uk>
Date: Wed, 15 Dec 1993 21:03:42 +0000 (GMT)
From: njw@cs.city.ac.uk (Nick Williams)
Subject: Re: HTML(+)-editor available?

I wrote and alpha released a vanilla HTML editor a while back, using the
Andrew Toolkit, giving it a wysiwyg feel.  Works pretty well, however I
haven't got around to implementing the http access (the editor was only
for local files), as I decided that should be implemented at a different
level. Since then, HTML+ has hit the scene, which my editor doesn't know
about.  No, it's not an SGML based thing, but a pure hack on HTML.  I'd
like to continue working on this: updating it for HTML+ and adding http
support but I'm not sure if I have the time.  If anyone else is
interested (perhaps some of the people who picked up the htmltext might
like to give me some feedback...?) in cooperating, I'd be happy to hear
from you.

The almost-wysiwyg aspect is very desirable.  We now use the editor for
almost all document creation here and not having to see the raw html
entities is many orders of magnitude better than "vi", no matter how
simple people claim html is.

Nick Williams                          E-mail: njw@cs.city.ac.uk (MIME and ATK)
Systems Architecture Research Centre,  Tel: +44 71 477 8551
London, EC1V 0HB                       Fax: +44 71 477 8587



From fielding@simplon.ics.uci.edu  Wed Dec 15 15:09:14 1993 -0800
Message-Id: <9312151509.aa15878@paris.ics.uci.edu>
Date: Wed, 15 Dec 1993 15:09:14 -0800
From: fielding@simplon.ics.uci.edu (Roy T. Fielding)
Subject: Re: HTTP date format: RFC 850 or RFC 1036 

>> Does anyone implement Date (or Last-Modified) response headers yet?
>> I do, and for now I am going with the new RFC.
> Both Plexus and the NCSA HTTPD (v1.0) use RFC850 style dates:
>     Last-modified: Monday, 06-Dec-93 23:48:09 GMT
> 
> Changing this for no reason is a bad idea.  We should specify the date
> format in the HTTP RFC by value instead of by reference.
> 
> If we change this then browsers will have to support both formats forever.

NO NO NO NO!!!!!!

The date format MUST be RFC822 compliant (as is the new RFC1036) and
can be seen in every Date: field generated by NNTP and mail.
RFC 850 was obsolete long ago.  I sent the following to httpd@ncsa
when httpd_1.0 came out, but I'm not sure if it got there because my
mail server went down at the same time.  Anyways, here is THE format:


     5.  DATE AND TIME SPECIFICATION

     5.1.  SYNTAX

     date-time   =  [ day "," ] date time        ; dd mm yy
                                                 ;  hh:mm:ss zzz

     day         =  "Mon"  / "Tue" /  "Wed"  / "Thu"
                 /  "Fri"  / "Sat" /  "Sun"

     date        =  1*2DIGIT month 2DIGIT        ; day month year
                                                 ;  e.g. 20 Jun 82

     month       =  "Jan"  /  "Feb" /  "Mar"  /  "Apr"
                 /  "May"  /  "Jun" /  "Jul"  /  "Aug"
                 /  "Sep"  /  "Oct" /  "Nov"  /  "Dec"

     time        =  hour zone                    ; ANSI and Military

     hour        =  2DIGIT ":" 2DIGIT [":" 2DIGIT]
                                                 ; 00:00:00 - 23:59:59

     zone        =  "GMT"                ; Universal Time


whereas the output from httpd_1.0 is like:

----------------------------------------------------------
% telnet www.ics.uci.edu 80
Trying 128.195.13.1 ...
Connected to www.ics.uci.edu.
Escape character is '^]'.
HEAD /ICShome.html HTTP/1.0

HTTP/1.0 200 OK
Date: Monday, 13-Dec-93 12:12:33 GMT
Server: NCSA/1.0
MIME-version: 1.0
Content-type: text/html
Last-modified: Thursday, 09-Dec-93 16:20:08 GMT
Content-length: 1817

Connection closed by foreign host.
----------------------------------------------------------

which matches the RFC850 example but does not match the 
format required by netnews and mail.  To be a conformant
arpanet message, the output should be:

----------------------------------------------------------
% telnet www.ics.uci.edu 80
Trying 128.195.13.1 ...
Connected to www.ics.uci.edu.
Escape character is '^]'.
HEAD /ICShome.html HTTP/1.0

HTTP/1.0 200 OK
Date: Mon, 13 Dec 93 12:12:33 GMT
Server: NCSA/1.0
MIME-version: 1.0
Content-type: text/html
Last-modified: Thu, 9 Dec 93 16:20:08 GMT
Content-length: 1817

Connection closed by foreign host.
----------------------------------------------------------


....Roy Fielding   ICS Grad Student, University of California, Irvine  USA
                   (fielding@ics.uci.edu)



From marca@ncsa.uiuc.edu  Wed Dec 15 17:37:49 1993 -0800
Message-Id: <9312160137.AA17338@wintermute.ncsa.uiuc.edu>
Date: Wed, 15 Dec 93 17:37:49 -0800
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Mosaic for X development/support disclaimer

Hi folks,

As is to be expected, the support and feature request load for Mosaic
for X (and, of course, NCSA httpd and the other versions of Mosaic) is
still increasing exponentially.  In the meantime, several things are
happening: (a) Eric's on a well-deserved vacation, (b) Alan, Rob, and
I are in the middle of finals and thence on to Christmas break, and
(c) as of January I'll be gone from NCSA and hacking away at a company
everyone on this list has no doubt heard of: EIT.

So the upshot is that support and maintenance for Mosaic for X will
probably not be proceeding at a fast pace for the next few weeks -- so
if you don't hear from us or if we don't fix a critical bug
immediately :-), you'll know why..... but, as usual, we'll do what we
can in the time we have.

Cheers,
Marc




From sanders@bsdi.com  Wed Dec 15 19:30:39 1993 -0600
Message-Id: <199312160130.TAA09527@austin.BSDI.COM>
Date: Wed, 15 Dec 1993 19:30:39 -0600
From: sanders@bsdi.com (Tony Sanders)
Subject: Re: HTTP date format: RFC 850 or RFC 1036 

> NO NO NO NO!!!!!!
> 
> The date format MUST be RFC822 compliant (as is the new RFC1036) and
> can be seen in every Date: field generated by NNTP and mail.
Is that so... Hmmm... a quick sample (from comp.mail.headers!) reveals no
less than six (6) different Date formats in current use:
    Date: 1 Dec 1993 15:40:28 -0000
    Date: 15 Dec 1993 18:00:37 GMT
    Date: 4 Dec 93 23:53:10 GMT
    Date: Tue, 14 Dec 1993 21:29:02 GMT
    Date: Wed, 8 Dec 93 07:51:39 GMT
    Date: Mon, 06 Dec 93 22:05:22 +1000 (AEST)
And this is from a sample size of only 7 messages!

In other groups I found some really amazing stuff:
    Date: Monday 13 April, 1992 09:30:00 PDT
    Date: Monday, March 3, 12:59:00 CDT
    Date: Monday May 24 23:01:34.34 CDT 1993
    Date: Thu, 2 Dec 1993 12:53:49
    Date: Wed, 15 Dec 1993 13:36:54 UNDEFINED
I have just as many email examples also.  So much for "MUST" and "every".

Guess what else.  Every RFC850-like date format I could find was consistent!
    Date: Friday, 24-Sep-93 20:38:06 GMT
If you had a full dayname or you had hypens between the date section
you had a valid RFC850 date.  Amazing (even to me).

Now, do you have any valid arguments for *why* we should break hundreds
of HTTP servers?  It is VERY VERY important that HTTP software agree on
the date format, and that it not change weekly.  This isn't so with News
and Mail (as is obvious by the lack of a real standard in those cases).

Clearly having a full year (instead of just two digits) is not optimial
but neither is it a major problem (not until 2070 or so anyway).

If we do end up changing then this is clearly the best format:
    Date: Tue, 04 Dec 1993 21:29:02 GMT

--sanders



From robm@ncsa.uiuc.edu  Wed Dec 15 20:14:46 1993 -0600
Message-Id: <9312160214.AA27562@void.ncsa.uiuc.edu>
Date: Wed, 15 Dec 1993 20:14:46 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: HTTP date format: RFC 850 or RFC 1036

/*
 * HTTP date format: RFC 850 or RFC 1036  by Jim Davis (davis@dri.cornell.edu)
 *    written on Dec 15, 10:22am.
 *
 * Does anyone implement Date (or Last-Modified) response headers yet?
 * I do, and for now I am going with the new RFC.
 * 
 */

Tony Sanders and I both have it implemented, for Plexus and NCSA httpd
respectively. We currently use 850 (Weekday, dd-mmm-yy hh:mm:ss) to format
dates...

--ROb



From robm@ncsa.uiuc.edu  Wed Dec 15 21:54:46 1993 -0600
Message-Id: <9312160354.AA28628@void.ncsa.uiuc.edu>
Date: Wed, 15 Dec 1993 21:54:46 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Upgrading /htbin scripts to CGI


I have written a quick primer on upgrading your /htbin scripts to CGI scripts
at http://hoohoo.ncsa.uiuc.edu/cgi/from-htbin.html

This document briefly discusses what has changed between httpd 1.0a5's script
interface and the CGI interface. Hopefully this will avoid some confusion. 

This document is linked from the upgrade notes at
http://hoohoo.ncsa.uiuc.edu/docs/Upgrade.html.

--Rob



From fielding@simplon.ICS.UCI.EDU  Wed Dec 15 20:19:15 1993 -0800
Message-Id: <9312152019.aa00974@paris.ics.uci.edu>
Date: Wed, 15 Dec 1993 20:19:15 -0800
From: fielding@simplon.ICS.UCI.EDU (Roy T. Fielding)
Subject: Re: HTTP date format: RFC 850 or RFC 1036 

>> The date format MUST be RFC822 compliant (as is the new RFC1036) and
>> can be seen in every Date: field generated by NNTP and mail.
> Is that so... Hmmm... a quick sample (from comp.mail.headers!) reveals no
> less than six (6) different Date formats in current use:
>     Date: 1 Dec 1993 15:40:28 -0000
>     Date: 15 Dec 1993 18:00:37 GMT
>     Date: 4 Dec 93 23:53:10 GMT
>     Date: Tue, 14 Dec 1993 21:29:02 GMT
>     Date: Wed, 8 Dec 93 07:51:39 GMT
>     Date: Mon, 06 Dec 93 22:05:22 +1000 (AEST)
> And this is from a sample size of only 7 messages!
> 
> In other groups I found some really amazing stuff:
>     Date: Monday 13 April, 1992 09:30:00 PDT
>     Date: Monday, March 3, 12:59:00 CDT
>     Date: Monday May 24 23:01:34.34 CDT 1993
>     Date: Thu, 2 Dec 1993 12:53:49
>     Date: Wed, 15 Dec 1993 13:36:54 UNDEFINED
> I have just as many email examples also.  So much for "MUST" and "every".

Of the 603 mail messages and 197 news posts I have stored, every single
date header is RFC822 compliant with the exception that roughly half use
a four digit year (which I prefer) instead of two.  The fact that there
exists non-compliant servers out there does not justify making HTTP servers
non-compliant.

> Now, do you have any valid arguments for *why* we should break hundreds
> of HTTP servers?  It is VERY VERY important that HTTP software agree on
> the date format, and that it not change weekly.  This isn't so with News
> and Mail (as is obvious by the lack of a real standard in those cases).

Break?  The output format of the date makes no difference to the HTTP
server -- only to the clients (like the one I'm building).  As for a change,
the NCSA httpd server just changed its date format to supposedly be RFC822
(see the announcement) and the fact that it is not should be pointed out.

Here is the one line change required to make NCSA httpd_1.0 compliant with
RFC822 and RFC1036 with the exception of the four-digit year:
----------------------------------------------------------------------
% diff -c save/util.c util.c
*** save/util.c Wed Dec 15 19:43:30 1993
--- util.c      Wed Dec 15 19:44:28 1993
***************
*** 24,30 ****
  
      t = gmtime(&sec);
      /* check return code? */
!     strftime(ts,MAX_STRING_LEN,"%A, %d-%h-%y %T GMT",t);
      return ts;
  }
  
--- 24,30 ----
  
      t = gmtime(&sec);
      /* check return code? */
!     strftime(ts,MAX_STRING_LEN,"%a, %d %h %Y %T GMT",t);
      return ts;
  }

----------------------------------------------------------------------
> 
> Clearly having a full year (instead of just two digits) is not optimial
> but neither is it a major problem (not until 2070 or so anyway).
> 
> If we do end up changing then this is clearly the best format:
>     Date: Tue, 04 Dec 1993 21:29:02 GMT

Which is what the above change does.  I would be surprised if other
servers were any harder to change.  What is important is that we don't
have a special date format for every protocol, resulting in a nightmare
for gateways and clients.


....Roy Fielding   ICS Grad Student, University of California, Irvine  USA
                   (fielding@ics.uci.edu)



From fielding@simplon.ics.uci.edu  Wed Dec 15 22:08:44 1993 -0800
Message-Id: <9312152208.aa05167@paris.ics.uci.edu>
Date: Wed, 15 Dec 1993 22:08:44 -0800
From: fielding@simplon.ics.uci.edu (Roy T. Fielding)
Subject: Re: Annoucement: Local Browser Execution 

> ... One of the nicer things
> about URLs is that you don't necessarily know or care whether something
> returned to you has been generated dynamically or exists as a file.
> Conceptually, both are the same: In either case, you provide a 
> string that maps into some output, to be returned. For file retrieval,
> the mapping is done by the filesystem, for a shell command it is done
> by some special program. You might even decide to switch between the
> two, e.g., if the range of arguments provided is small enough that
> they can easily be mapped into files.

The one problem with all these conceptual similarities is that it
makes writing a web-roaming robot (spider) very difficult.  A spider
(or human) that specifically wants to avoid scripts or dynamically
created documents needs to be able to determine whether or not the
URL points to a script.

Also, there are times when it is better for the browser client to
exec the desired command rather than having some HTTP server
(possibly at a remote site) do the execution.


....Roy Fielding   ICS Grad Student, University of California, Irvine  USA
                   (fielding@ics.uci.edu)



From m.koster@nexor.co.uk  Thu Dec 16 09:23:27 1993 +0000
Message-Id: <9312160924.AA27864@dxmint.cern.ch>
Date: Thu, 16 Dec 1993 09:23:27 +0000
From: m.koster@nexor.co.uk (Martijn Koster)
Subject: Re: Annoucement: Local Browser Execution


Roy Fielding wrote:

> The one problem with all these conceptual similarities is that it
> makes writing a web-roaming robot (spider) very difficult. 

I'm convinced WWW-wide spiders are a pretty bad idea anyway, for more
reasons than the infinite dynamic page problem.
If you run the spider on your own server you know what URL's to avoid,
so there is no problem.

> A spider
> (or human) that specifically wants to avoid scripts or dynamically
> created documents needs to be able to determine whether or not the
> URL points to a script.

I really don't see why a human cares? And I can imagine that spiders
don't always care either. Say I have a welcome page that is dynamic 
and displays the date and local time or whatever, I'd still want my
robot to use it. And most ISINDEX servers can be regarded as dynamic
too. 

-- Martijn
__________
Internet: m.koster@nexor.co.uk
X-400: C=GB; A= ; P=Nexor; O=Nexor; S=koster; I=M
X-500: c=GB@o=NEXOR Ltd@cn=Martijn Koster
WWW: http://web.nexor.co.uk/mak/mak.html



From aqeel@isip2.water.ca.gov  Thu Dec 16 13:21:07 1993 -0800
Message-Id: <199312162121.AA12906@isip2.water.ca.gov>
Date: Thu, 16 Dec 1993 13:21:07 -0800
From: aqeel@isip2.water.ca.gov (Asghar Aqeel)
Subject: Mosaic client

Hello, 

I like to know if somebody has compiled the NCSA Mosaic for X Window System 
client on the Intergraph CLIX systems.  If so, would you share information 
regarding the Mosaic client on the Intergraph systems. 
Please e-mail info at aqeel@isip2.water.ca.gov.

Thanks 
bye
Asghar Aqeel



From jer@bagheera.jax.org  Thu Dec 16 16:46:59 1993 EST
Message-Id: <9312162146.AA02158@bagheera.jax.org>
Date: Thu, 16 Dec 93 16:46:59 EST
From: jer@bagheera.jax.org (Joel Richardson)
Subject: Attaching docs, Virtual images


Can anyone help me with the following two problems?

1. In a forms application that we're developing, the bulk of what the
user must enter usually exists in a text file already. The form can
include a textarea, of course, but then the user either has to retype
the data or cut and paste. Neither is particularly attractive. Is there
a better way to do this currently? (Something like <INPUT TYPE="attach" ...>
suggests itself, but far be it from me to suggest yet another feature ! :-)

2. Another thing I'm trying to do is to generate embedded images on the
fly, i.e., to create virtual image maps the way we now create virtual
documents. We want to allow the user to explore a database graphically,
so the images and the mappings have to be generated dynamically. Seems
like all the necessary mechanisms are there, so...

I began by simply trying to return a GIF image from a script. (We're
using httpd 1.0) A document contains <IMG SRC="/cgi-bin/getgif" ISMAP>.
The script "getgif" spits out the mime header "Content-type: image/gif"
then cats a sample GIF image. I can see from the logs that that Mosaic
is issuing the GETs, but the image load is unsuccessful (I get the default
NCSA icon). I also tried a script the just issues a "Location: <path>",
where <path> pointed to the GIF file. Same result. Obviously, I am
doing something wrong. Can anyone clue me in? Marc? Rob?

Thanks,
Joel Richardson



From alanb@ncsa.uiuc.edu  Thu Dec 16 16:05:28 1993 CST
Message-Id: <9312162205.AA10555@void.ncsa.uiuc.edu>
Date: Thu, 16 Dec 93 16:05:28 CST
From: alanb@ncsa.uiuc.edu (Alan Braverman)
Subject: Mosaic client

Asghar Aqeel writes:
> Hello, 
> 
> I like to know if somebody has compiled the NCSA Mosaic for X Window System 
> client on the Intergraph CLIX systems.  If so, would you share information 
> regarding the Mosaic client on the Intergraph systems. 
> Please e-mail info at aqeel@isip2.water.ca.gov.
> 
> Thanks 
> bye
> Asghar Aqeel

We have not heard anything about a port to that particular system.  The ports
we do know of are listed in the online FAQ under Machines and Systems.  If you
cannot access that, check ftp.ncsa.uiuc.edu in /Mosaic/Mosaic-contrib.

--
Alan Braverman
Software Development Group
National Center for Supercomputing Applications
alanb@ncsa.uiuc.edu



From jbluming@chivalry.eit.COM  Thu Dec 16 14:38:59 1993 -0800
Message-Id: <9312162247.AA10991@eit.COM>
Date: Thu, 16 Dec 1993 14:38:59 -0800
From: jbluming@chivalry.eit.COM (Jason B. Bluming)
Subject: Re: Attaching docs, Virtual images 

>I began by simply trying to return a GIF image from a script. (We're
>using httpd 1.0) A document contains <IMG SRC="/cgi-bin/getgif" ISMAP>.
>The script "getgif" spits out the mime header "Content-type: image/gif"
>then cats a sample GIF image. I can see from the logs that that Mosaic
>is issuing the GETs, but the image load is unsuccessful (I get the default
>NCSA icon). I also tried a script the just issues a "Location: <path>",
>where <path> pointed to the GIF file. Same result. Obviously, I am
>doing something wrong. Can anyone clue me in? Marc? Rob?
>
>Thanks,
>Joel Richardson

I'll pick up the second for you.  Your problem seems to be not on the
idea, but on the choice for implementation.  While you could try
and force the document down the line, I'd suggest a simple 
workaround of having your form action generate a temporary file for
the gif, then return a html page with an <img src> tag to the file.
Your resulting text page will contain the image you want, and to keep
things clean, you can have the "ok" button at the bottom of the returned
page call a script to clean up the gensym-ed (temp named) file.

Granted, there are more elegant ways to work this, however, I did some
brief playing with generating graphs on the fly and found I almost
always wanted text/anchors at the bottom anyway, so why fight to get 
around what you will probably use anyway.

Hope that helps.

	-Jason

=========================================================
			Jason Bluming
	     Enterprise Integration Technologies
                      jbluming@eit.com

(415) 617 - 8018 (office)    |    459 Hamilton Avenue
      617 - 8019 (fax)       |    Palo Alto, CA 94301
========================================================= 




From phillips@cs.ubc.ca  Mon Dec 16 14:29:00 1993 -0800
Message-Id: <7077*phillips@cs.ubc.ca>
Date: 16 Dec 93 14:29 -0800
From: phillips@cs.ubc.ca (George Phillips)
Subject: Attaching docs, Virtual images

Joel Richardson asks:
>1. In a forms application that we're developing, the bulk of what the
>user must enter usually exists in a text file already.

Check out http://www.cs.ubc.ca/ftp/local/www/x-exec/examples/type/postnews

It's a sorta-CGI script that does the same kind of thing you want.
Basically, it takes the PATH_INFO it has and opens a file which it dumps
into a dynamically created <TEXTAREA> form element.

>I began by simply trying to return a GIF image from a script. (We're
>using httpd 1.0) A document contains <IMG SRC="/cgi-bin/getgif" ISMAP>.
>The script "getgif" spits out the mime header "Content-type: image/gif"
>then cats a sample GIF image. I can see from the logs that that Mosaic
>is issuing the GETs, but the image load is unsuccessful (I get the default
>NCSA icon). I also tried a script the just issues a "Location: <path>",
>where <path> pointed to the GIF file. Same result. Obviously, I am
>doing something wrong. Can anyone clue me in? Marc? Rob?

You have to be careful that you output "Content-type: image/gif\r\n\r\n".
You can test it by telnetting to your server -- if it spits
binary crap at you, it should be working.  My guess is that it isn't
and you'll just see some error message.

The only trick with the Location: stuff is that it points to a "virtual"
file on your server and not a UNIX file.

			-- George



From robm@ncsa.uiuc.edu  Thu Dec 16 16:59:32 1993 -0600
Message-Id: <9312162259.AA11411@void.ncsa.uiuc.edu>
Date: Thu, 16 Dec 1993 16:59:32 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: CGI server indexing with WAIS


Hi, gang, I've taken Tony Sanders' PERL script which uses freeWAIS to search
an index of a server and ported it to CGI. What this means is that if you
index your HTTP server with wais, you can use this script to search it.

For a demonstration, try http://hoohoo.ncsa.uiuc.edu/cgi-bin/wais.pl. The
script source and HTML instructions for its setup can be found in the CGI
archive at ftp.ncsa.uiuc.edu in /Web/ncsa_httpd/cgi.

--Rob




From sanders@BSDI.COM  Thu Dec 16 18:09:15 1993 -0600
Message-Id: <199312170009.SAA17371@austin.BSDI.COM>
Date: Thu, 16 Dec 1993 18:09:15 -0600
From: sanders@BSDI.COM (Tony Sanders)
Subject: Re: Attaching docs, Virtual images 

> >using httpd 1.0) A document contains <IMG SRC="/cgi-bin/getgif" ISMAP>.
> >The script "getgif" spits out the mime header "Content-type: image/gif"
The HTTP header looks like this (between the "cut here" parts):
-------- cut here --------
HTTP/1.0 200 Document follows
MIME-version: 1.0
Content-type: image/gif

GIFDATA...
-------- cut here --------

The blank line is required after the header info.

> I'll pick up the second for you.  Your problem seems to be not on the
> idea, but on the choice for implementation.  While you could try
Using a temp file for this is a very ugly kludge and has many problems.
It's very simple and elegant to just return the image on the fly
when it's requested.  That way you don't have to worry about the
numerous cases when people request the document but don't request
the image (like delayed image loading, or browsers that don't support
images).

--sanders



From jbluming@chivalry.eit.COM  Thu Dec 16 16:32:06 1993 -0800
Message-Id: <9312170040.AA11825@eit.COM>
Date: Thu, 16 Dec 1993 16:32:06 -0800
From: jbluming@chivalry.eit.COM (Jason B. Bluming)
Subject: Re: Attaching docs, Virtual images 


>> I'll pick up the second for you.  Your problem seems to be not on the
>> idea, but on the choice for implementation.  While you could try
>Using a temp file for this is a very ugly kludge and has many problems.
>It's very simple and elegant to just return the image on the fly
>when it's requested.  That way you don't have to worry about the
>numerous cases when people request the document but don't request
>the image (like delayed image loading, or browsers that don't support
>images).

I don't think we're disagreeing on these issues.  I was just pointing
out that before you decide upon a particular implementation, it would
be beneficial to consider how it is being used.  For example, say I
want to generate a graph of server utilization for the past 24 hrs --
for any arbitrarily complex figure being generated, it is not unreasonable
to assume that the file generation (and associated data compilation)
may be non-trivial, and separating the access time from the generation
time might be less irritating to the user (ie. by activating delayed image 
loading if THEY so choose).  In either case, I won't argue with 
advocating an elegant solution, as long as it addresses the problem being
asked.

	-Jason



From t93502yy@sfc.keio.ac.jp  Fri Dec 17 18:00:33 1993 +0900
Message-Id: <9312170900.AA20485@cs0.sfc.keio.ac.jp>
Date: Fri, 17 Dec 93 18:00:33 +0900
From: t93502yy@sfc.keio.ac.jp (Vivian&Yuki)
Subject: I would join

Hi,my name is Yukihiko Yoshida.I would like to join this mailing list.

      YUKIHIKO YOSHIDA t93502yy.sfc.keio.ac.jp  
      Project  MultiMediaModeling,EISOC,and so on.
               Virtual City Planner



From roeber@axcrnc.cern.ch  Fri Dec 17 10:46:14 1993 +0100
Message-Id: <9312170946.AA02071@dxmint.cern.ch>
Date: Fri, 17 Dec 1993 10:46:14 +0100
From: roeber@axcrnc.cern.ch (Frederick G.M. Roeber)
Subject: Re: Attaching docs, Virtual images

>Using a temp file for this is a very ugly kludge and has many problems.
>It's very simple and elegant to just return the image on the fly
>when it's requested.  That way you don't have to worry about the
>numerous cases when people request the document but don't request
>the image (like delayed image loading, or browsers that don't support
>images).

One idea I was mulling over awhile ago would be to add libwww handling
for MIME "multipart/mumble" data, where the first would be the text/html
file, and the later part(s) the referred-to images, sounds, etc.

Then, since (in my case) I was creating both the text and image on the 
fly, I only had to create one thing: no hiding of information in the
URL, and the server remains stateless.

<hr><a href="http://info.cern.ch/roeber/fgmr.html">Frederick</a>



From robm@ncsa.uiuc.edu  Fri Dec 17 04:51:43 1993 -0600
Message-Id: <9312171051.AA17686@void.ncsa.uiuc.edu>
Date: Fri, 17 Dec 1993 04:51:43 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: HTTP date format: RFC 850 or RFC 1036

/*
 * Re: HTTP date format: RFC 850 or RFC 1036  by "Roy T. Fielding" (fielding@simplon.ICS.UCI.EDU)
 *    written on Dec 15,  8:19pm.
 *
 * Break?  The output format of the date makes no difference to the HTTP
 * server -- only to the clients (like the one I'm building).  As for a change,
 * the NCSA httpd server just changed its date format to supposedly be RFC822
 * (see the announcement) and the fact that it is not should be pointed out.
 */

I got the RFC number wrong in the announcement; I used Tony's server as a
model of what the HTTP protocol specifes since it was faster than looking
through the RFC, and it encouraged consistency (if Plexus outputs that way,
now NCSA does the same). Sorry.

--Rob



From robm@ncsa.uiuc.edu  Fri Dec 17 05:03:33 1993 -0600
Message-Id: <9312171103.AA17773@void.ncsa.uiuc.edu>
Date: Fri, 17 Dec 1993 05:03:33 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI server indexing with WAIS

/*
 * Re: CGI server indexing with WAIS  by Tony Sanders (sanders@BSDI.COM)
 *    written on Dec 16,  6:14pm.
 *
 * > Hi, gang, I've taken Tony Sanders' PERL script which uses freeWAIS to search
 * > an index of a server and ported it to CGI. What this means is that if you
 * > index your HTTP server with wais, you can use this script to search it.
 * Neat, please mail me a copy (of your wais.pl).

Attached. I'm not a serious perl user so my techniques may not be the best,
but it appears to work.

 * I'll pick up 1.0 soon and take a peek at it.  Hopefully sometime early
 * next year I'll have more free time to hack on Plexus and make it
 * CGI compliant.  Great work BTW.  I'm glad we did this early on
 * so folks will have plug-and-play servers for many things.

I'm hoping it takes off. I wish I had some time to go and update the
documentation; I'm getting truckloads of confused questions because the CGI
spec assumes a fair bit of previous knowledge.

 * One of my first projects when I get back to is to make a perl package
 * of support functions for people to use to write CGI compliant scripts
 * in perl (you probably have the same thing for C).  Basically this
 * just means packaging up a lot of the funnctions I already have and
 * making some minor changes.
 */

I just got a reference to a perl cgi library from someone, I haven't gotten
a chance to look at it. It's at http://www.bio.cam.ac.uk/cgi-src/cgi-lib.pl

--Rob

#!/usr/local/bin/perl
#
# wais.pl -- WAIS search interface
#
# $Id$
#
# Tony Sanders <sanders@bsdi.com>, Nov 1993
#
# Example configuration (in local.conf):
#     map topdir wais.pl &do_wais($top, $path, $query, "database", "title")
#

$waisq = "/usr/local/bin/waisq";
$waisd = "/u/Web/wais-sources";
$src = "www";
$title = "NCSA httpd documentation";

sub send_index {
    print "Content-type: text/html\n\n";
    
    print "<HEAD>\n<TITLE>Index of ", $title, "</TITLE>\n</HEAD>\n";
    print "<BODY>\n<H1>", $title, "</H1>\n";

    print "This is an index of the information on this server. Please\n";
    print "type a query in the search dialog.\n<P>";
    print "You may use compound searches, such as: <CODE>environment AND cgi</CODE>\n";
    print "<ISINDEX>";
}

sub do_wais {
#    local($top, $path, $query, $src, $title) = @_;

    do { &'send_index; return; } unless defined @ARGV;
    local(@query) = @ARGV;
    local($pquery) = join(" ", @query);

    print "Content-type: text/html\n\n";

    open(WAISQ, "-|") || exec ($waisq, "-c", $waisd,
                                "-f", "-", "-S", "$src.src", "-g", @query);

    print "<HEAD>\n<TITLE>Search of ", $title, "</TITLE>\n</HEAD>\n";
    print "<BODY>\n<H1>", $title, "</H1>\n";

    print "Index \`$src\' contains the following\n";
    print "items relevant to \`$pquery\':<P>\n";
    print "<DL>\n";

    local($hits, $score, $headline, $lines, $bytes, $type, $date);
    while (<WAISQ>) {
        /:score\s+(\d+)/ && ($score = $1);
        /:number-of-lines\s+(\d+)/ && ($lines = $1);
        /:number-of-bytes\s+(\d+)/ && ($bytes = $1);
        /:type "(.*)"/ && ($type = $1);
        /:headline "(.*)"/ && ($headline = $1);         # XXX
        /:date "(\d+)"/ && ($date = $1, $hits++, &docdone);
    }
    close(WAISQ);
    print "</DL>\n";

    if ($hits == 0) {
        print "Nothing found.\n";
    }
    print "</BODY>\n";
}

sub docdone {
    if ($headline =~ /Search produced no result/) {
        print "<HR>";
        print $headline, "<P>\n<PRE>";
# the following was &'safeopen
        open(WAISCAT, "$waisd/$src.cat") || die "$src.cat: $!";
        while (<WAISCAT>) {
            s#(Catalog for database:)\s+.*#$1 <A HREF="/$top/$src.src">$src.src</A>#;
            s#Headline:\s+(.*)#Headline: <A HREF="$1">$1</A>#;
            print;
        }
        close(WAISCAT);
        print "\n</PRE>\n";
    } else {
        print "<DT><A HREF=\"$headline\">$headline</A>\n";
        print "<DD>Score: $score, Lines: $lines, Bytes: $bytes\n";
    }
    $score = $headline = $lines = $bytes = $type = $date = '';
}

eval '&do_wais';



From robm@ncsa.uiuc.edu  Fri Dec 17 05:53:07 1993 -0600
Message-Id: <9312171153.AA18023@void.ncsa.uiuc.edu>
Date: Fri, 17 Dec 1993 05:53:07 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: sorry about last message Re: CGI server indexing with WAIS


The previous message was not supposed to go to the entire list, I did not
look at the Reply-to header on Tony's message. Sorry for any confusion.

--Rob



From jer@bagheera.jax.org  Fri Dec 17 09:00:41 1993 EST
Message-Id: <9312171400.AA02369@bagheera.jax.org>
Date: Fri, 17 Dec 93 09:00:41 EST
From: jer@bagheera.jax.org (Joel Richardson)
Subject: Re: Attaching docs, Virtual images


> -------- cut here --------
> HTTP/1.0 200 Document follows
> MIME-version: 1.0
> Content-type: image/gif
>
> GIFDATA...
> -------- cut here --------

Tony's suggestion did the trick. Thanks!

Joel



From Axel.Belinfante@cs.utwente.nl  Fri Dec 17 17:20:15 1993 +0100
Message-Id: <9312171620.AA08734@utis179.cs.utwente.nl>
Date: Fri, 17 Dec 93 17:20:15 +0100
From: Axel.Belinfante@cs.utwente.nl (Axel Belinfante)
Subject: Re: Annoucement: Local Browser Execution 

Gisle.Aas@nr.no writes:
> Axel.Belinfante@cs.utwente.nl writes:
> > It should catch the standard output of the commands in a (tmp)file, and
> > be ready to give this file to Mosaic via the remote control feature.
> > This is where the information about the document BASE will be needed:
> > the stdout of the command is supposed to be HTML, which might contain
> > relative links. I think that the Mosaic feature recently added to
> > handle mailed documents will solve/handle this.
> > 
> > One remaing problem: how/when do we remove the tmp-file that contains
> > the standard output?
> > 
> > What do people think? Could this be made to work? I'll try anyway.. :-)
> 
> I have tried it and it works:
[script deleted]


Thanks!
I was already hacking my own version when i received your message,
but some ideas (the -xterm, -html etc features) were too nice to ignore :-)

I have now a new (prototype - comments welcome!) version of the script,
it looks for a BASE href passed in its input.
(it tries to be paranoia about the commands it is given to run, pointers
 are welcome if someone has something similar - i remember seeing
 something about a secure tcl interpreter ):
	http://utis179.cs.utwente.nl:8001/export/x_exec

and a server that does the necessary mapping  (it includes the BASE href)
(in principle there is only need for one 'gateway' in the Web that does
 the URL-to-MIME-document mapping):
	http://utis179.cs.utwente.nl:8001/x-exec/

I think this can make the x-exec: URL scheme functionality available
to those who don't want/can hack the Mosaic client - all you need is the
x_exec script (or something similar), and in your ~/.mailcap a line:
	application/x-exec; x_exec %s
and then it should be (more or less?) 'plug compatible' with the x-exec:
scripts (the xprog script does contains some additonal tests that
are moved to the x_exec script) (my version of the xprog script:
	http://utis179.cs.utwente.nl:8001/export/xprog
to test, try
(after putting the x_exec and xprog scripts somewhere where they will
 be found, and adding the ~/.mailcap line mentioned above):
	http://utis179.cs.utwente.nl:8001/x-exec/xprog

Please note: the x_exec script is experimental, just to test the idea...
 
Regards,
Axel.

<Axel.Belinfante@cs.utwente.nl>   tel. +31 53 893774   fax. +31 53 333815
     University of Twente, Tele-Informatics & Open Systems Group
       P.O. Box 217    NL-7500 AE Enschede      The Netherlands
     "ili ne sciis ke estas neebla do ili simple faris" -- Loesje




From cheung@eplrx7.es.dupont.com  Fri Dec 17 12:30:43 1993 EST
Message-Id: <9312171730.AA22305@eplrx7.es.duPont.com>
Date: Fri, 17 Dec 93 12:30:43 EST
From: cheung@eplrx7.es.dupont.com (Bryan Cheung)
Subject: Mosaic + innd = Nuthin

Is anyone out there using Mosaic to access news services from an innd news
server?? I am trying to use Mosaic (X,Mac,Win) to access internet news
using innd 1.4 as an nntp server on an AIX 3.2.4 box. I am having a problem
using all versions of mosaic to access the news server. In every case I get
back 
     X:       "No articles in this group"
     Mac:     "No articles in this range"
     Windoze: "HTACCESS: Error accessing "my_local_group": Error Num -1"
The newsgroups in question are local newsgroups which are heavily
populated. Cello accesses the same innd-based news groups without any
problems. I am guessing that there are some differences in the NNTP
conversations expected by innd and the Mosaics (they have no problems
accessing CNEWS servers). Has anyone else run into this problem?? Any
pointers or info is greatly appreciated.

                Thanks in advance,

                              -- Bryan Cheung
                                 cheung@eplrx7.es.dupont.com





From montulli@stat1.cc.ukans.edu  Fri Dec 17 14:36:37 1993 CST
Message-Id: <9312172036.AA28039@stat1.cc.ukans.edu>
Date: Fri, 17 Dec 93 14:36:37 CST
From: montulli@stat1.cc.ukans.edu (Lou Montulli)
Subject: Release of Lynx ver 2.1

Ho ho ho, Merry Christmas:

Lynx Ver. 2.1 is now available for anonymous ftp from
 FTP2.cc.ukans.edu    as   /pub/lynx/lynx2-1.tar.Z
                     and   /pub/lynx/lynx2-1.zip

( ftp://ftp2.cc.ukans.edu/pub/lynx/lynx2-1.tar.Z )
( ftp://ftp2.cc.ukans.edu/pub/lynx/lynx2-1.zip )

Lynx is a distributed hypertext browser with full World Wide Web
capibilities.  For an explanation of features and a demo, 
telnet to "www.cc.ukans.edu" and login as "www".

This release of Lynx has been compiled by me on the following platforms:

 o  IBM (AIX 3.2)
 o  DEC Ultrix
 o  DEC Alpha OSF/1
 o  Sun 4
 o  NeXT (Mine is an older version of NeXTStep, but it should work 
          with newer ones too.)
 o  VMS (Multinet)
 o  OpenVMS for Alpha AXP (Multinet)

This release is rumored to compile on the following platforms:
 o  HP-UX (snake)
 o  Solaris 2
 o  SVR4
 o  VMS (UCX)
 o  LINUX
 o  SGI 
 o  SUN 3
 o  AIX 3.1
 o  NeXTStep 3.x

Binaries for the following platforms are available:

 o  IBM (AIX 3.2, will work with 3.1 as well)
 o  Ultrix
 o  Alpha OSF/1
 o  Sun 4
 o  VMS (Multinet)
 o  OpenVMS for Alpha AXP (Multinet)
 
A listserv list exists for the distribution of
Lynx related information and updates.
  o  Lynx-Dev@ukanaix.cc.ukans.edu
 
Send a subscribe request to listserv@ukanaix.cc.ukans.edu to
be added to the list.  All new releases will be anounced on this
list.  Please do not send subscribe requests to the the Lynx-Dev
list directly.

    The following new features have been added/changed:

* massive rewrite.  Removed all Lynx internal format code and 
  restructured all the source files.  Every piece of Lynx
  code was rewritten or restructured or both.  Enhanced
  architecture and obtained modest increase in speed.
* The Lynx Bookmark file is now interpreted as an HTML document.  
  Old Lynx bookmark files must be converted using the lynx2html
  program or deleted.
* HTML+ forms as implemented by XMosaic now work. 
  Fill in the empty spaces and press the submit button to
  submit the form. (fun, fun, fun!)
* The <textarea> tag isn't done yet.  It will currently only
  give a one line text area.  The next version of Lynx will
  include a true textarea implementation once I figure out a
  reasonable interface.
* Incorporated WWWlib 2.14 and fixed up the descrip.mms files.
  Foteos Macrides made VMS port changes and wrote a really nice
  build.com script to make compilation on VMS systems really easy.
  Foteos also ported Lynx to OpenVMS for alpha axp systems. 
* 's' now only means search a searchable indexed document through the
  server, and can no longer be used to search for strings within
  the displayed document.
* '/' now only searches through the current displayed document for
  strings and can not be used for server searching searchable index documents.
* Capital 'Q' now quits without asking for confirmation.
* 'm' for Main Menu now askes for confirmation and does NOT clear
  the history stack.
* Blockquote style changed slightly.
* Verbose Gopher option removed, verbose gopher functionality
  is now set permenantly on.
* Default editor is now configurable in the lynx.cfg file.
* Default bookmark file is now configurable in the lynx.cfg file.
* ownership is no longer inherited.
* <link rev="owner" href="mailto:ADDRESS"> now accepted as well as
  <link rev="made" href="mailto:ADDRESS"> to define the URL of the
  owner or person responsible for the info.
* 's' now only searches <isindex> server documents.
* '/' always means search within the document.
* anonymous users cannot change the bookmark page!  (security hole)
* added &nbsp; (non-breaking space), &ensp; and &emsp;
* fixed bug with <a> and other tags messing up formatting
  withing <PRE> segments.

:lou



From cailliau@www1.cern.ch  Fri Dec 17 22:17:50 1993 +0100
Message-Id: <9312172122.AB12434@www1.cern.ch>
Date: Fri, 17 Dec 1993 22:17:50 +0100
From: cailliau@www1.cern.ch (Robert Cailliau)
Subject: WWW Conference

This is to announce the


   First International Conference on the World-Wide Web

                   May 25-26-27, 1994
                      CERN, Geneva
                       Switzerland


The Conference will include tutorials, topical workshops, panels,
presentations of formal papers on WWW technology and theory, user and
provider experiences,
and a series of special sessions for delegates from business and
non-academic organisations.

We are working out a detailed schedule, which will appear on the Web early
in January. Today only the place, the dates and the title are firm
(conference rooms and infrastructure availability.)

Suggestions for tutorials, workshops and panels are welcome now.


           Robert Cailliau
        World-Wide Web Project             | phone:  +41 22 767 5005
              C E R N                      | fax:    +41 22 767 8730
European Laboratory for Particle Physics   | e-mail: cailliau@www1.cern.ch
         CH - 1211 Geneve 23               | diary:  http://www1.cern.ch/
           (Switzerland)                   |  CERN/Admin/Diaries/Robert.html





From kevina@clark.net  Fri Dec 17 17:32:03 1993 +0000
Message-Id: <9312172227.AA15490@explorer.clark.net>
Date: Fri, 17 Dec 1993 17:32:03 +0000
From: kevina@clark.net (Kevin Atkinson)
Subject: Release of Lynx ver 2.1

Thought you might be intersted in this:

It is always a good idea to keep your programs up to date:

---------------

Ho ho ho, Merry Christmas:

Lynx Ver. 2.1 is now available for anonymous ftp from
 FTP2.cc.ukans.edu    as   /pub/lynx/lynx2-1.tar.Z
                     and   /pub/lynx/lynx2-1.zip

( ftp://ftp2.cc.ukans.edu/pub/lynx/lynx2-1.tar.Z )
( ftp://ftp2.cc.ukans.edu/pub/lynx/lynx2-1.zip )

Lynx is a distributed hypertext browser with full World Wide Web
capibilities.  For an explanation of features and a demo, 
telnet to "www.cc.ukans.edu" and login as "www".

This release of Lynx has been compiled by me on the following platforms:

 o  IBM (AIX 3.2)
 o  DEC Ultrix
 o  DEC Alpha OSF/1
 o  Sun 4
 o  NeXT (Mine is an older version of NeXTStep, but it should work 
          with newer ones too.)
 o  VMS (Multinet)
 o  OpenVMS for Alpha AXP (Multinet)

This release is rumored to compile on the following platforms:
 o  HP-UX (snake)
 o  Solaris 2
 o  SVR4
 o  VMS (UCX)
 o  LINUX
 o  SGI 
 o  SUN 3
 o  AIX 3.1
 o  NeXTStep 3.x

Binaries for the following platforms are available:

 o  IBM (AIX 3.2, will work with 3.1 as well)
 o  Ultrix
 o  Alpha OSF/1
 o  Sun 4
 o  VMS (Multinet)
 o  OpenVMS for Alpha AXP (Multinet)
 
A listserv list exists for the distribution of
Lynx related information and updates.
  o  Lynx-Dev@ukanaix.cc.ukans.edu
 
Send a subscribe request to listserv@ukanaix.cc.ukans.edu to
be added to the list.  All new releases will be anounced on this
list.  Please do not send subscribe requests to the the Lynx-Dev
list directly.

    The following new features have been added/changed:

* massive rewrite.  Removed all Lynx internal format code and 
  restructured all the source files.  Every piece of Lynx
  code was rewritten or restructured or both.  Enhanced
  architecture and obtained modest increase in speed.
* The Lynx Bookmark file is now interpreted as an HTML document.  
  Old Lynx bookmark files must be converted using the lynx2html
  program or deleted.
* HTML+ forms as implemented by XMosaic now work. 
  Fill in the empty spaces and press the submit button to
  submit the form. (fun, fun, fun!)
* The <textarea> tag isn't done yet.  It will currently only
  give a one line text area.  The next version of Lynx will
  include a true textarea implementation once I figure out a
  reasonable interface.
* Incorporated WWWlib 2.14 and fixed up the descrip.mms files.
  Foteos Macrides made VMS port changes and wrote a really nice
  build.com script to make compilation on VMS systems really easy.
  Foteos also ported Lynx to OpenVMS for alpha axp systems. 
* 's' now only means search a searchable indexed document through the
  server, and can no longer be used to search for strings within
  the displayed document.
* '/' now only searches through the current displayed document for
  strings and can not be used for server searching searchable index documents.
* Capital 'Q' now quits without asking for confirmation.
* 'm' for Main Menu now askes for confirmation and does NOT clear
  the history stack.
* Blockquote style changed slightly.
* Verbose Gopher option removed, verbose gopher functionality
  is now set permenantly on.
* Default editor is now configurable in the lynx.cfg file.
* Default bookmark file is now configurable in the lynx.cfg file.
* ownership is no longer inherited.
* <link rev="owner" href="mailto:ADDRESS"> now accepted as well as
  <link rev="made" href="mailto:ADDRESS"> to define the URL of the
  owner or person responsible for the info.
* 's' now only searches <isindex> server documents.
* '/' always means search within the document.
* anonymous users cannot change the bookmark page!  (security hole)
* added &nbsp; (non-breaking space), &ensp; and &emsp;
* fixed bug with <a> and other tags messing up formatting
  withing <PRE> segments.

:lou
                                                         >>> Kevina <<<
                                                       




From jamie@explorer.clark.net  Fri Dec 17 17:32:04 1993 -0500 (EST)
Message-Id: <Pine.3.87.9312171704.A9806-0100000@explorer>
Date: Fri, 17 Dec 1993 17:32:04 -0500 (EST)
From: jamie@explorer.clark.net (Jamie H. Clark)
Subject: Re: Release of Lynx ver 2.1

On Fri, 17 Dec 1993, Kevin Atkinson wrote:

> Thought you might be intersted in this:
> 
> It is always a good idea to keep your programs up to date:

Yes, great!!! Let's get 'em and install here!

> 
> ---------------
> 
> Ho ho ho, Merry Christmas:
> 
> Lynx Ver. 2.1 is now available for anonymous ftp from
>  FTP2.cc.ukans.edu    as   /pub/lynx/lynx2-1.tar.Z
>                      and   /pub/lynx/lynx2-1.zip
> 
> ( ftp://ftp2.cc.ukans.edu/pub/lynx/lynx2-1.tar.Z )
> ( ftp://ftp2.cc.ukans.edu/pub/lynx/lynx2-1.zip )
> 
> Lynx is a distributed hypertext browser with full World Wide Web
> capibilities.  For an explanation of features and a demo, 
> telnet to "www.cc.ukans.edu" and login as "www".
> 
> This release of Lynx has been compiled by me on the following platforms:
> 
>  o  IBM (AIX 3.2)
>  o  DEC Ultrix
>  o  DEC Alpha OSF/1
>  o  Sun 4
>  o  NeXT (Mine is an older version of NeXTStep, but it should work 
>           with newer ones too.)
>  o  VMS (Multinet)
>  o  OpenVMS for Alpha AXP (Multinet)
> 
> This release is rumored to compile on the following platforms:
>  o  HP-UX (snake)
>  o  Solaris 2
>  o  SVR4
>  o  VMS (UCX)
>  o  LINUX
>  o  SGI 
>  o  SUN 3
>  o  AIX 3.1
>  o  NeXTStep 3.x
> 
> Binaries for the following platforms are available:
> 
>  o  IBM (AIX 3.2, will work with 3.1 as well)
>  o  Ultrix
>  o  Alpha OSF/1
>  o  Sun 4
>  o  VMS (Multinet)
>  o  OpenVMS for Alpha AXP (Multinet)
>  
> A listserv list exists for the distribution of
> Lynx related information and updates.
>   o  Lynx-Dev@ukanaix.cc.ukans.edu
>  
> Send a subscribe request to listserv@ukanaix.cc.ukans.edu to
> be added to the list.  All new releases will be anounced on this
> list.  Please do not send subscribe requests to the the Lynx-Dev
> list directly.
> 
>     The following new features have been added/changed:
> 
> * massive rewrite.  Removed all Lynx internal format code and 
>   restructured all the source files.  Every piece of Lynx
>   code was rewritten or restructured or both.  Enhanced
>   architecture and obtained modest increase in speed.
> * The Lynx Bookmark file is now interpreted as an HTML document.  
>   Old Lynx bookmark files must be converted using the lynx2html
>   program or deleted.
> * HTML+ forms as implemented by XMosaic now work. 
>   Fill in the empty spaces and press the submit button to
>   submit the form. (fun, fun, fun!)
> * The <textarea> tag isn't done yet.  It will currently only
>   give a one line text area.  The next version of Lynx will
>   include a true textarea implementation once I figure out a
>   reasonable interface.
> * Incorporated WWWlib 2.14 and fixed up the descrip.mms files.
>   Foteos Macrides made VMS port changes and wrote a really nice
>   build.com script to make compilation on VMS systems really easy.
>   Foteos also ported Lynx to OpenVMS for alpha axp systems. 
> * 's' now only means search a searchable indexed document through the
>   server, and can no longer be used to search for strings within
>   the displayed document.
> * '/' now only searches through the current displayed document for
>   strings and can not be used for server searching searchable index documents.
> * Capital 'Q' now quits without asking for confirmation.
> * 'm' for Main Menu now askes for confirmation and does NOT clear
>   the history stack.
> * Blockquote style changed slightly.
> * Verbose Gopher option removed, verbose gopher functionality
>   is now set permenantly on.
> * Default editor is now configurable in the lynx.cfg file.
> * Default bookmark file is now configurable in the lynx.cfg file.
> * ownership is no longer inherited.
> * <link rev="owner" href="mailto:ADDRESS"> now accepted as well as
>   <link rev="made" href="mailto:ADDRESS"> to define the URL of the
>   owner or person responsible for the info.
> * 's' now only searches <isindex> server documents.
> * '/' always means search within the document.
> * anonymous users cannot change the bookmark page!  (security hole)
> * added &nbsp; (non-breaking space), &ensp; and &emsp;
> * fixed bug with <a> and other tags messing up formatting
>   withing <PRE> segments.
> 
> :lou
>                                                          >>> Kevina <<<
>                                                        
> 

-----
Jamie Clark, jamie@clark.net| ClarkNet Public Access Internet, info@clark.net,
Dial-up shell, SLIP/PPP & UUCP, Modem (410) 730-9786, login guest | "Knowledge
is power; the ability to acquire knowledge at will is more powerful."  (Jamie)





From fielding@simplon.ICS.UCI.EDU  Sat Dec 18 02:58:02 1993 -0800
Message-Id: <9312180258.aa22020@paris.ics.uci.edu>
Date: Sat, 18 Dec 1993 02:58:02 -0800
From: fielding@simplon.ICS.UCI.EDU (Roy T. Fielding)
Subject: What should happen when you HEAD a CGI script?

While poking around in the NCSA httpd_1.0 source code, I noticed that
the CGI script interface does not treat the HEAD method differently
than the GET method.  Unlike the older htbin interface, performing a

HEAD /cgi-bin/script HTTP/1.0

will return exactly the same result (including body contents) as the

GET /cgi-bin/script HTTP/1.0

request.  There is no mention of HEAD responses in the initial CGI spec.

Is this just a simple oversight?  Or is it a feature?

My preference would be for HEAD to check the existance, authorization,
and executability of the script and just return the response headers.
Am I missing something (besides sleep)?


....Roy Fielding   ICS Grad Student, University of California, Irvine  USA
                   (fielding@ics.uci.edu)



From robm@ncsa.uiuc.edu  Mon Dec 20 01:13:40 1993 -0600
Message-Id: <9312200713.AA09201@void.ncsa.uiuc.edu>
Date: Mon, 20 Dec 1993 01:13:40 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: What should happen when you HEAD a CGI script?

/*
 * What should happen when you HEAD a CGI script?  by "Roy T. Fielding" (fielding@simplon.ICS.UCI.EDU)
 *    written on Dec 18,  2:58am.
 *
 * While poking around in the NCSA httpd_1.0 source code, I noticed that
 * the CGI script interface does not treat the HEAD method differently
 * than the GET method.  Unlike the older htbin interface, performing a
 * 
 * HEAD /cgi-bin/script HTTP/1.0
 * 
 * will return exactly the same result (including body contents) as the
 * 
 * GET /cgi-bin/script HTTP/1.0
 * 
 * request.  There is no mention of HEAD responses in the initial CGI spec.
 * 
 * Is this just a simple oversight?  Or is it a feature?

Originally it was intended that scripts could check if REQUEST_METHOD is
HEAD, then they could perform the action themselves. However, the server
should probably limit their output in order to keep scripts small. I'll fix
it.

 * My preference would be for HEAD to check the existance, authorization,
 * and executability of the script and just return the response headers.
 * Am I missing something (besides sleep)?
 */

It wouldn't be able to return content-type.

--Rob



From robm@ncsa.uiuc.edu  Mon Dec 20 02:15:09 1993 -0600
Message-Id: <9312200815.AA09926@void.ncsa.uiuc.edu>
Date: Mon, 20 Dec 1993 02:15:09 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Additions to the CGI archive


An INCREDIBLE forms-based (but not required) archie gateway has been written
by Guy Brooker, guy@jw.estec.esa.nl, for CGI compliant servers. It's similar
to the ArchiePlex package by Martijn Koster.

The package itself can be found at ftp.ncsa.uiuc.edu in
/Web/ncsa_httpd/cgi/archie.tar.Z, and a demonstration of its function can be
found at http://hoohoo.ncsa.uiuc.edu/archie.html. It's a must see.

The package only requires the Bourne shell, awk, and the archie client.

--Rob




From decoux@moulon.inra.fr  Mon Dec 20 14:10:36 1993 +0100
Message-Id: <9312201310.AA00390@moulon.moulon.inra.fr>
Date: Mon, 20 Dec 93 14:10:36 +0100
From: decoux@moulon.inra.fr (ts)
Subject: WWW-ACEDB



 gateway WWW-ACEDB
 =================

 For these releases you must have a CGI server (Common Gateway Interface),
like NCSA "httpd_1.0".

 ACEDB 2.0
 ---------
  source : ftp://moulon.inra.fr/pub/www-acedb/www-ace2.cgi.tar.Z
  demo : "http://moulon.inra.fr:8001/acedb/acedb.html" ACeDB

 ACEDB 3.0
 ---------
  source : ftp://moulon.inra.fr/pub/www-acedb/www-ace3.cgi.tar.Z
  demo : "http://moulon.inra.fr:8001/acedb/igd.html" Integrated Genome Database

 Common characteristics
 ----------------------
  * mimimal configuration : you just have to put an URL in a document and
create a helpfile.
  * bibliography
  * table maker
  * map : genetic map, multi map, ...
If you have a client which accept tag <FORM> (like Lynx and Mosaic), you can
select columns for genetic and features maps.
  * DNA dump

 Problem 
 -------
  * don't implement class "_VImage"

 More explanations are given in "http://moulon.inra.fr/acedb_conf_eng.html"


Guy Decoux



From ZAPANTIS@uvphys.phys.UVic.CA  Mon Dec 20 09:45:19 1993 -0800 (PST)
Message-Id: <931220094519.24a022b4@uvphys.phys.UVic.CA>
Date: Mon, 20 Dec 1993 9:45:19 -0800 (PST)
From: ZAPANTIS@uvphys.phys.UVic.CA (Nik Zapantis, UVic Physics, Victoria BC)
Subject: How do I specify a WHOIS scheme?

Hi,
I would like to have an option in my home page that connects to my WHOIS
server. I have tried putting something like
    <UL>   <A HREF="whois://my-node.domain/">WHOIS server</A>
in my welcome.html file, but it does not work.
I need to be able to prompt for input and have it piped to the WHOIS utility.
My WHOIS utility is the regular INET WHOIS that is part of most TCPIP packages.
If this is a FAQ, please bear with me, since I've just started experimenting
with WWW servers and clients (Mosaic) and I am still on the learning curve.
An example would be most welcome.

thank you in advance,
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
| Nik Zapantis                  | zapantis@uvphys     (BITNET)  |
| Dept. of Physics & Astronomy  | 45393::zapantis(HEPnet/SPAN)  |
| University of Victoria        | zapantis@uvphys.phys.UVic.CA  |
| Victoria, BC                  | Phone: (604)721-7729          |
| V8W 3P6                       | FAX:   (604)721-7715          |
+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
 



From rivero@sol.unizar.es  Mon Dec 20 20:59:05 1993 +0000 (GMT)
Message-Id: <9312202059.AA08407@sol.unizar.es>
Date: Mon, 20 Dec 1993 20:59:05 +0000 (GMT)
From: rivero@sol.unizar.es (Alejandro Rivero)
Subject: Web wanderers?

Hi,

Which is the current status of web wanderers? Is there anyone?
I have heard of an experimental one running under Python, but I dont
know if it is operative.

I would like to make a shallow wandering (say, up to four jumps
deep) and get the output in some tree or net format... 

Any suggestions?


				Alejandro Rivero
				Zaragoza Univ, Spain
ps: I have heard something about calling mosaic from other program.
     How does this work? is there some explanation in the web?



From warnock@Hypatia.gsfc.nasa.gov  Mon Dec 20 17:32:58 1993 EST
Message-Id: <9312202232.AA02339@Hypatia.gsfc.nasa.gov>
Date: Mon, 20 Dec 93 17:32:58 EST
From: warnock@Hypatia.gsfc.nasa.gov (Archie Warnock)
Subject: American Astronomical Society WWW Server online

The American Astronomical Society now has a World Wide Web server
running.  It contains information on the Society, meeting schedules,
meeting abstracts (in HTML), staff directory and an HTML version of the
AAS Job Register.  The URL for the home page document is:

http://blackhole.aas.org/AAS-homepage.html

Refer questions to webmaster@aas.org.
_______________________________________________________________________
-- Archie Warnock              Internet:  Archie.Warnock@gsfc.nasa.gov
-- Hughes STX                  "WAIS is the engine, WWW is the track"
-- NASA/GSFC                   Project STELAR: WAIS to do science




From CSP1DWD@MVS.OAC.UCLA.EDU  Mon Dec 20 17:07:00 1993 PST
Message-Id: <9312210107.AA00552@dxmint.cern.ch>
Date: Mon, 20 Dec 93 17:07 PST
From: CSP1DWD@MVS.OAC.UCLA.EDU (Denis DeLaRoca)
Subject: Xmosaic 2.1 and gopher://amanda.physics.misc.edu

It times out trying to access the above gopher server... it used to
work in previous versions.

The Passau clickable map at

 http://httpserver.forwiss.uni-passau.de/passau/stadt/plan/uebersicht

has also stopped working, end up with BAD FILE REQUEST error msgs from
Xmosaic... an out of date http server perhaps?

-- Denis




From m.koster@nexor.co.uk  Tue Dec 21 10:29:41 1993 +0000
Message-Id: <9312211030.AA00853@dxmint.cern.ch>
Date: Tue, 21 Dec 1993 10:29:41 +0000
From: m.koster@nexor.co.uk (Martijn Koster)
Subject: Re: Additions to the CGI archive


> An INCREDIBLE forms-based archie gateway has been written...

Very nice indeed...

I incorporated its icons and extra functionality into ArchiePlex,
but it made me wonder about two things:

- Did the discussion on built-in IMG's result into anything
  for HTML+ ? If not, can we advance the discussion?
  Altough the 'internal-gopher-binary works' fine for
  Mosaic, I already find lots of problems in the logs, where 
  people are trying to retrieve these images from my server.
  Of course I can special-case for Mosaic, but I would be more
  comfortable with a general solution.

- Can a DT in a DL have multiple DD's? Mosaic copes nicely, 
  but HTML+ talsk about <B>pairs</B>...

-- Martijn
__________
Internet: m.koster@nexor.co.uk
X-400: C=GB; A= ; P=Nexor; O=Nexor; S=koster; I=M
X-500: c=GB@o=NEXOR Ltd@cn=Martijn Koster
WWW: http://web.nexor.co.uk/mak/mak.html



From guenther.fischer@hrz.tu-chemnitz.de  Tue Dec 21 13:54:15 1993 +0100 (MET)
Message-Id: <9312211254.AA29281@flash1.hrz.tu-chemnitz.de>
Date: Tue, 21 Dec 1993 13:54:15 +0100 (MET)
From: guenther.fischer@hrz.tu-chemnitz.de (Guenther Fischer)
Subject: Re: Additions to the CGI archive





From guenther.fischer@hrz.tu-chemnitz.de  Tue Dec 21 14:31:44 1993 +0100 (MET)
Message-Id: <9312211331.AA29547@flash1.hrz.tu-chemnitz.de>
Date: Tue, 21 Dec 1993 14:31:44 +0100 (MET)
From: guenther.fischer@hrz.tu-chemnitz.de (Guenther Fischer)
Subject: Re: Additions to the CGI archive

Martijn,
sorry about the last one ... :-)
> 
> 
> - Did the discussion on built-in IMG's result into anything
>   for HTML+ ? If not, can we advance the discussion?
>   Altough the 'internal-gopher-binary works' fine for
>   Mosaic, I already find lots of problems in the logs, where 
>   people are trying to retrieve these images from my server.
>   Of course I can special-case for Mosaic, but I would be more
>   comfortable with a general solution.
> 

YES - I`ve tried to contribute this with no response. The third try:

Inline images could be very nice. There should be a small set of
standardized images to give them to clients as well as to servers.

Clients could know and include them without tranfers. Servers should
have them at the server database - the name should be something like
IMG SRC=/inline/internal-gopher-binary

Then I can use this in my documents and I'm shure all clients
get them.

Such well defined images can also help to have a WWW look and feel.

At now the user see the fantasy of the document writer for such
simple things as icons to navigate or diectories or ...

	~Guenther
-- 
Name:      Guenther Fischer
Institute: TU Chemnitz, Universitaetsrechenzentrum
Phone:     0371 668 361
mail:      fischer@hrz.tu-chemnitz.de



From masinter@parc.xerox.com  Tue Dec 21 11:45:42 1993 PST
Message-Id: <93Dec21.114549pst.2732@golden.parc.xerox.com>
Date: Tue, 21 Dec 1993 11:45:42 PST
From: masinter@parc.xerox.com (Larry Masinter)
Subject: Re: Additions to the CGI archive

> YES - I`ve tried to contribute this with no response.

I did respond, although perhaps too humorously. My suggestion is
that you use the URNs of Frequently used icons instead of URLs.

Some clients might even have built into them copies of resources that
are really frequently used (like common inline images).

Others might retrieve them every time and just cache them for a short time.

You might argue that 'URNs aren't here yet', but defining a standard
for URNs really isn't harder than defining a standard for /inline/etc.
images. 




From rivero@sol.unizar.es  Tue Dec 21 21:03:06 1993 +0000 (GMT)
Message-Id: <9312212103.AA13669@sol.unizar.es>
Date: Tue, 21 Dec 1993 21:03:06 +0000 (GMT)
From: rivero@sol.unizar.es (Alejandro Rivero)
Subject: Which client is already supporting FIG?



Can anyone out there suggest a WWW client or HTML+ parser 
implementing FIG directive?

I find it more powerful that the ismap atribute, as there are 
no interaction with the server, and the figt and figa tags have
other important result: no source .gif is needed (except to
define size and proportion of the box, if the FIGD mechanism is not
implemented). If geografical maps are going to proliferate, it will
be a really needed tag.


					Alejandro



From ahmed@SDSC.EDU  Wed Dec 22 11:10:04 1993 -0800
Message-Id: <9312221910.AA09470@cassatt.sdsc.edu>
Date: Wed, 22 Dec 1993 11:10:04 -0800
From: ahmed@SDSC.EDU (ahmed@SDSC.EDU)
Subject: Workshop on Intelligent Access to On-line Digital Libraries

Please distribute. Thanks.
 
Please let me know if you need any additional details.

                Zahid Ahmed
                Project Sequoia 2000 
                San Diego Supercomputer Center
                University of California, San Diego, 0505
                9500 Gilman Drive
                La Jolla, CA 92093-0505

                Phone : (619)-534-5105
                FAX   : (619)-534-5113
                E-mail: ahmed@cassatt.sdsc.edu
**********************  CALL FOR PARTICIPATION  **********************


       Workshop on Intelligent Access to On-line Digital Libraries  
       ===========================================================


                           IEEE CAIA '94 
			 Marriott Riverwalk   
                         San Antonio, Texas

                       Tuesday, March 1, 1994  


The rate of information production in our global society is taking place
thousands of times faster than our population growth. The linkages of
high speed networks, fiberized telephone lines, and large capacity
information bases will facilitate creation of digital libraries which 
are expected to provide many kinds of information. Due to their widely 
distributed and diversified clientele, these emerging libraries will   
require intelligent management of information. The purpose of this workshop 
is to focus on how intelligent data management and intelligent presentation 
systems will allow better information services to end-users of next 
generation, mass-scale, robust information architectures. 

This workshop will attract researchers and designers of on-line 
digital libraries (DLs) that are being applied to data analysis problems,
educational and publication media, and entertainment services. Through  
a discussion of some generic issues that effect the design of digital  
libraries, it is the goal of the workshop to produce a reference model   
of such libraries based on the access, interface, and communication    
requirements of a small range of application domains. In line with this,      
the following is a list of possible topics for consideration at the 
workshop. 

I. Basic Architectural Issues. 

  - Comparing DLs with traditional libraries and data management systems 

  - Relationship between DL architecture and intended or expected use

  - Generality of retrieval models s.t. they are usable in multiple 
    domains, and for multiple DL clients. 
 
  - Basic DL building blocks and scaling issues

  - DL reference models - one or many?

  - Integrating DLs with other information processing elements, for
    example, data analysis tools, supercomputers, and end-user applications

II. Information Retrieval. 

   - Browsing approaches for large, distributed on-line libraries,
     including experience with Mosaic, WAIS, and other browsers     

   - Query language paradigms

   - Searching, filtering, summarizing of multimedia information

   - Knowbots, intelligent agents, intelligent gatekeepers

   - Personalized, interactive news and publication services

III. Information Organization.

   - Multimedia information models (hypertext, relational, etc.)

   - Indexing, classification and merging of information clips

   - Document management

IV. Information Presentation Mediums.

  - Intelligent, interactive data visualization systems

  - Dynamic, task-based multimedia interfaces

  - Dialogue management between DL client and DL server    

PARTICIPATION

Workshop participation will be limited to twenty people. It is
expected that all participants are active researchers, or are
interested in the design and development of digital libraries,    
information retrieval systems, or multimedia interfaces. Participants 
should submit position papers through electronic mail (preferred), 
regular mail or FAX by January 15, 1994.   
 
Position papers can be a review, original research contributions, 
extensions of previous work, or applications briefs. Participants
will be selected based on their position papers by the workshop  
organizers. Participants will have an opportunity to resubmit 
their papers for possible post-workshop publication.  Please
e-mail or send (4 copies, please) position papers to the workshop
chair at the address included below. 
 
The fee for a one-day workshop is $75 (only if you do not register
for the CAIA '94 conference), which includes breaks and lunch. 
Registration forms will be sent to participants by IEEE CAIA
(Conference on Artificial Intelligence for Applications) '94. 
For more information on IEEE CAIA '94, contact:

Peter Selfridge 
AT&T Bell Laboratories 
Murray Hill, NJ 07974 
Phone: 908-582-6801
pgs@research.att.com


WORKSHOP ORGANIZERS 

Zahid Ahmed, San Diego Supercomputer Center
Robert Akscyn, Knowledge Systems 
Nicholas Belkin, Rutgers University 
Edward Fox, Virginia Polytechnic Institute 
Thomas Kirk, AT&T Bell Laboratories 
Scott Stevens, Carnegie-Mellon University  

Workshop Chair:

Zahid Ahmed
San Diego Supercomputer Center
University of California, San Diego, 0505 
9500 Gilman Drive
La Jolla, CA 92093-0505

Phone : (619)-534-5105
FAX   : (619)-534-5113
E-mail: ahmed@cassatt.sdsc.edu  



From chen@cds001.cebaf.gov  Thu Dec 23 16:05:02 1993 -0500
Message-Id: <9312232105.AA24673@cds001.cebaf.gov>
Date: Thu, 23 Dec 93 16:05:02 -0500
From: chen@cds001.cebaf.gov (chen@cds001.cebaf.gov)
Subject: 

To all you out there:
	Is there any utilities which convert WordPerfect documents
to html files? Or is there a package which converts from anything to
html? 

	Regards,

--jie chen



From garylang@netcom.com  Thu Dec 23 13:17:03 1993 -0800 (PST)
Message-Id: <Pine.3.85.9312231303.A2423-0100000@netcom2>
Date: Thu, 23 Dec 1993 13:17:03 -0800 (PST)
From: garylang@netcom.com (Gary Lang)
Subject: Re: your mail

1. Save your WP files as RTF files
2. Use the RTF->HTML converter to get your HTML document.

-g




From khorkov@UNIVAX.FREE.NET  Fri Dec 24 21:16:36 1993 +0400
Message-Id: <0097782A.A0D9D8E0.8920@UNIVAX.FREE.NET>
Date: Fri, 24 Dec 1993 21:16:36 +0400
From: khorkov@UNIVAX.FREE.NET (Sergey N. Khorkov. UNICOR System manager)
Subject: What symbol refers to WWW port?

>>>
Dear friends!

I wrote WWW_UCX.EXE from gatekeeper.dec.com and now have some problem. I 
don't know how I can mean connection port. When I insert port number in 
http request WWW works ok. But when WWW try to link with second documents I 
have a error. 

In documentation I read that there is some symbol in system wich describe 
this port number. Please, tell me what symbol I must use?

We have a MicroVAX 3100 model 80 with VAX/VMS v5.5-2 and UCX v2.0.

Thank you for help.

		Sincerelly yours,
===============================================================================
					Sergey N. Khorkov
					Univercity's Knowledge Network
					System Manager.



From alanb@ncsa.uiuc.edu  Sun Dec 26 00:11:58 1993 CST
Message-Id: <9312260611.AA29851@void.ncsa.uiuc.edu>
Date: Sun, 26 Dec 93 00:11:58 CST
From: alanb@ncsa.uiuc.edu (Alan Braverman)
Subject: 

chen@cds001.cebaf.gov writes:
> 	Is there any utilities which convert WordPerfect documents
> to html files? Or is there a package which converts from anything to
> html? 

Check the online FAQ to Mosaic for X, under "Other Mosaic/WWW Software"

--
Alan Braverman
Software Development Group
National Center for Supercomputing Applications
alanb@ncsa.uiuc.edu



From pini@bgumail.bgu.ac.il  Sun Dec 26 16:10:50 1993 +0200 (IST)
Message-Id: <Pine.3.85.9312261650.C15480-0100000@bgumail.bgu.ac.il>
Date: Sun, 26 Dec 1993 16:10:50 +0200 (IST)
From: pini@bgumail.bgu.ac.il (Pini Albilia)
Subject: view and print the same image

 
Hello,
I scan a text paper in 300 DPI (2032 x 2976 pixels) and want to display the
image on my X-Terminal  (1024 x 1024 resoluton) by <iMG SRC="..."> method
and not by external viewer.
Is there a way to display the total width of the image within HTML document
from the 300 DPI image?
I do not want to keep the two images: one for printing and one for viewing.
What is, if any, the best format to handle images of text papers (GIF, TIFF,
JPEG, ...) ?
Waiting for any help ... Thank You.

-Pini.





From john@math.nwu.edu  Mon Dec 27 10:49:17 1993 -0600 (CST)
Message-Id: <9312271649.AA03002@hopf.math.nwu.edu>
Date: Mon, 27 Dec 1993 10:49:17 -0600 (CST)
From: john@math.nwu.edu (John Franks)
Subject: CGI suggestion


Now that I am seriously looking at implementing the CGI interface,
I find one part problematic.  This is the way that "state information"
or arguments to a script get encoded in a URL as a sort of pseudo-path
at the end.

Here are my objections:

1. It is not possible to fully parse the URL without knowledge of the
server's file hierarchy.  For example, without knowing something about
the file structure of the server I can't tell whether 

http://host.edu/foo1/foo2/foo3

means script /foo1/foo2 with parameter foo3 or script /foo1 with
parameter /foo2/foo3.  I am not sure that there won't at some point be
a need to get this information.  Maybe not, but in any case this syntax is
cumbersome to implement.

2. Assuming in the example above that the parameter is foo3 (or /foo3 ?)
then the URL actually refers to two files: root/foo1/foo2 and, say,
root/u/Web/foo3.  Inexperienced users will find this confusing and 
expect to find an actual file root/foo1/foo2/foo3.

3. This syntax overloads the '/' token so it has very different meanings
depending on context and does this in a situation where the context 
isn't readily visible.  In my experience this is conducive to errors.


SUGGESTION:

I would like to make it a CGI *requirement* that the PATH_INFO data
at the end of a URL contain an '=' and that this '=' be before the 
occurence of any '/' in this data.  

Here is what the example above might be like:

	/foo1/foo2/path=foo3

Other legal and useful URL's might end like

	/foo1/foo2/param1=value1&param2=value2

	/foo1/foo2/path=foo3/foo4&path2=foo5

URL's like this existing one from the xerox parc map server would be
perfectly legal.

	http://pubweb.parc.xerox.com/map/color=1/ht=30/lat=38.8/lon=-96

But I would encourage map/color=1&ht=30 etc. instead of using '/' as
the separator.  The main reason is that code to parse the '&' version
should be common since it is necessary for forms.

If the server knows that an '=' will occur at the begining of the
PATH_INFO data, (and that any ='s in the actual path are URL encoded)
then this information can be used to parse the URL without knowledge
of the server filesystem.  Also it is quite clear that expressions like
foo1/foo2/path=foo3 refer to two files not one.

The only significant change in the current CGI implementations that
this would require is the PATH_TRANSLATED environment variable.  I
would suggest that this be replaced by a variable containing a
directory name and then the script could create the translated path.
For example if the URL ended in

	/foo1/foo2/file1=foo3&file2=foo4/foo5

then the script could read the environment variable to get the directory,
say, "/u/Web" and could reconstruct the file names /u/Web/foo3 and
/u/Web/foo4/foo5.  Notice that this allows more than one file name
to be passed to the script which is not currently possible.

One final minor suggestion.  If the PATH_INFO data actually starts
with '=' as the first character, I would have the server strip this
character before putting the information in the environment variable.
This would be convenient for very simple scripts that shouldn't have
to do any parsing.  Thus a URL ending in

	/foo1/foo2/=foo3/foo4 

would have PATH_INFO set to "foo3/foo4".  You could also keep the 
PATH_TRANSLATED environment variable for this kind of URL and then
almost no changes would be necessary in current scripts.

What do you think?


John Franks 	Dept of Math. Northwestern University
		john@math.nwu.edu




From marca@ncsa.uiuc.edu  Tue Dec 28 08:31:47 1993 -0600
Message-Id: <9312281431.AA08977@wintermute.ncsa.uiuc.edu>
Date: Tue, 28 Dec 93 08:31:47 -0600
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: CGI suggestion

John Franks writes:
> Now that I am seriously looking at implementing the CGI interface,
> I find one part problematic.  This is the way that "state information"
> or arguments to a script get encoded in a URL as a sort of pseudo-path
> at the end.
> 
> Here are my objections:
> 
> 1. It is not possible to fully parse the URL without knowledge of the
> server's file hierarchy.  For example, without knowing something about
> the file structure of the server I can't tell whether 

Who is "I" in this context?  If I == the server, then the server's
file hierarchy is in fact known.  If I == some user, then it doesn't
matter one way or the other, does it (since the URL should be
considered opaque anyway)?  I'm probably missing something...

Cheers,
Marc


> 
> http://host.edu/foo1/foo2/foo3
> 
> means script /foo1/foo2 with parameter foo3 or script /foo1 with
> parameter /foo2/foo3.  I am not sure that there won't at some point be
> a need to get this information.  Maybe not, but in any case this syntax is
> cumbersome to implement.
> 
> 2. Assuming in the example above that the parameter is foo3 (or /foo3 ?)
> then the URL actually refers to two files: root/foo1/foo2 and, say,
> root/u/Web/foo3.  Inexperienced users will find this confusing and 
> expect to find an actual file root/foo1/foo2/foo3.
> 
> 3. This syntax overloads the '/' token so it has very different meanings
> depending on context and does this in a situation where the context 
> isn't readily visible.  In my experience this is conducive to errors.
> 
> 
> SUGGESTION:
> 
> I would like to make it a CGI *requirement* that the PATH_INFO data
> at the end of a URL contain an '=' and that this '=' be before the 
> occurence of any '/' in this data.  
> 
> Here is what the example above might be like:
> 
> 	/foo1/foo2/path=foo3
> 
> Other legal and useful URL's might end like
> 
> 	/foo1/foo2/param1=value1&param2=value2
> 
> 	/foo1/foo2/path=foo3/foo4&path2=foo5
> 
> URL's like this existing one from the xerox parc map server would be
> perfectly legal.
> 
> 	http://pubweb.parc.xerox.com/map/color=1/ht=30/lat=38.8/lon=-96
> 
> But I would encourage map/color=1&ht=30 etc. instead of using '/' as
> the separator.  The main reason is that code to parse the '&' version
> should be common since it is necessary for forms.
> 
> If the server knows that an '=' will occur at the begining of the
> PATH_INFO data, (and that any ='s in the actual path are URL encoded)
> then this information can be used to parse the URL without knowledge
> of the server filesystem.  Also it is quite clear that expressions like
> foo1/foo2/path=foo3 refer to two files not one.
> 
> The only significant change in the current CGI implementations that
> this would require is the PATH_TRANSLATED environment variable.  I
> would suggest that this be replaced by a variable containing a
> directory name and then the script could create the translated path.
> For example if the URL ended in
> 
> 	/foo1/foo2/file1=foo3&file2=foo4/foo5
> 
> then the script could read the environment variable to get the directory,
> say, "/u/Web" and could reconstruct the file names /u/Web/foo3 and
> /u/Web/foo4/foo5.  Notice that this allows more than one file name
> to be passed to the script which is not currently possible.
> 
> One final minor suggestion.  If the PATH_INFO data actually starts
> with '=' as the first character, I would have the server strip this
> character before putting the information in the environment variable.
> This would be convenient for very simple scripts that shouldn't have
> to do any parsing.  Thus a URL ending in
> 
> 	/foo1/foo2/=foo3/foo4 
> 
> would have PATH_INFO set to "foo3/foo4".  You could also keep the 
> PATH_TRANSLATED environment variable for this kind of URL and then
> almost no changes would be necessary in current scripts.
> 
> What do you think?
> 
> 
> John Franks 	Dept of Math. Northwestern University
> 		john@math.nwu.edu




From decoux@moulon.inra.fr  Tue Dec 28 14:04:03 1993 +0100
Message-Id: <9312281304.AA16663@moulon.moulon.inra.fr>
Date: Tue, 28 Dec 93 14:04:03 +0100
From: decoux@moulon.inra.fr (ts)
Subject: CGI suggestion


> Who is "I" in this context?  If I == the server, then the server's
> file hierarchy is in fact known.  If I == some user, then it doesn't
> matter one way or the other, does it (since the URL should be
> considered opaque anyway)?  I'm probably missing something...

 Actually you can't have a subdirectory under "/cgi-bin". Example :

 http://server/cgi-bin/subdir/script/extra_path

 With this URL server, actually, call "subdir" and not "subdir/script"


Guy Decoux



From dolesa@smtp-gw.spawar.navy.mil  Tue Dec 28 09:00:51 1993 EDT
Message-Id: <9311287570.AA757098051@smtp-gw.spawar.navy.mil>
Date: Tue, 28 Dec 93 09:00:51 EDT
From: dolesa@smtp-gw.spawar.navy.mil (dolesa@smtp-gw.spawar.navy.mil)
Subject: subscribe


     subscribe



From john@math.nwu.edu  Tue Dec 28 09:46:54 1993 -0600 (CST)
Message-Id: <9312281546.AA04784@hopf.math.nwu.edu>
Date: Tue, 28 Dec 1993 09:46:54 -0600 (CST)
From: john@math.nwu.edu (John Franks)
Subject: Re: CGI suggestion

> Marc Andreessen writes:
> > Who is "I" in this context?  If I == the server, then the server's
> > file hierarchy is in fact known.  If I == some user, then it doesn't
> > matter one way or the other, does it (since the URL should be
> > considered opaque anyway)?  I'm probably missing something...
> 

Well the "I" might be a server maintainer who is not fully cognizant
of the details of CGI, and would expect something which looks like
a path to a file to be one.  Such a maintainer may not, in the best
of all possible worlds, really *need* to know what is going on, but
that won't prevent mail to the developers saying "File /cgi-bin/foo1/foo2
is not in the distribution I got; where is it?"

Also is it really clear that no future caching mechanism will ever
need to parse the URL?


> Guy Decoux writes:
>  Actually you can't have a subdirectory under "/cgi-bin". Example :
> 
>  http://server/cgi-bin/subdir/script/extra_path
> 
>  With this URL server, actually, call "subdir" and not "subdir/script"
> 

This is something that was not clear to me from reading the spec.  I
did not realize that the name "cgi-bin" was in any way special. Is,
in fact, "cgi-bin" going to be a reserved word in http URL's?  If so
then my objection about parsing is not well founded.  This is easy
enough to parse -- it will still confuse some people though.  It also
seems like a rather artificial restriction.  Am I correct in my
understanding that this means that any subdirectory of cgi-bin is
inaccessible to a client querying the server?

Could we clarify the CGI spec some more?

1. Is "cgi-bin" a reserved directory name?
2. Can it be anyplace in the directory hierarchy?
3. Can a server have more than one cgi-bin?

and most importantly

4. Is it the case that in any URL containing "cgi-bin" everything
   from the second '/' after "cgi-bin" to the end of the URL is always
   path info, optionally followed by a ? and a query string?


If the answers to questions 1-4 are all "yes", then I will withdraw my 
suggestions. I still think this is a less than optimal syntax, but it
is usable.


John Franks 	Dept of Math. Northwestern University
		john@math.nwu.edu




From henrich@crh.cl.msu.edu  Tue Dec 28 11:07:23 1993 -0500 (EST)
Message-Id: <9312281607.AA17465@crh.cl.msu.edu>
Date: Tue, 28 Dec 1993 11:07:23 -0500 (EST)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: CGI Suggestion

I would like to propose that instead of (or if we must, as well as) allowing
the embedding of information in the path (which is really poor!) we should
special case the character ';' to mean end of URL for the client.  This would
allow folks to use

http://machine/documentpath;info that can be passed to programs.

In the above case the server would return the document /documentpath, but keep
the ';' information intact for scripts and programs. Forcing the server to have
to stat each directory level is an incredibly waste of resources, and thats
doubly so for AFS!

Thoughts?

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                     http://rs560.msu.edu/~henrich/



From decoux@moulon.inra.fr  Tue Dec 28 17:12:17 1993 +0100
Message-Id: <9312281612.AA18828@moulon.moulon.inra.fr>
Date: Tue, 28 Dec 93 17:12:17 +0100
From: decoux@moulon.inra.fr (ts)
Subject: CGI suggestion



> This is something that was not clear to me from reading the spec.  I
> did not realize that the name "cgi-bin" was in any way special. Is,
> in fact, "cgi-bin" going to be a reserved word in http URL's?  If so
> then my objection about parsing is not well founded.  This is easy
> enough to parse -- it will still confuse some people though.  It also
> seems like a rather artificial restriction.  Am I correct in my
> understanding that this means that any subdirectory of cgi-bin is
> inaccessible to a client querying the server?
> 
> Could we clarify the CGI spec some more?
> 
> 1. Is "cgi-bin" a reserved directory name?
> 2. Can it be anyplace in the directory hierarchy?
> 3. Can a server have more than one cgi-bin?
> 

 No, "cgi-bin" is not a reserved directory name. For example with NCSA
httpd_1.0 you must define in "conf/srm.conf" ScriptAlias, like :

 _____________________________________________________________________

 ...
# ScriptAlias: This controls which directories contain server scripts.
# Format: ScriptAlias fakename realname
 
ScriptAlias /cgi-bin/ /usr/local/etc/httpd/cgi-bin/

 _____________________________________________________________________


 You can define a ScriptAlias whith "/htbin/" for fakename (or any other
name), you can have several ScriptAliases directives, like :

 _____________________________________________________________________

 ...
# ScriptAlias: This controls which directories contain server scripts.
# Format: ScriptAlias fakename realname
 
ScriptAlias /cgi-bin/ /usr/local/etc/httpd/cgi-bin/
ScriptAlias /htbin/ /usr/local/etc/httpd/cgi-bin/exec

 _____________________________________________________________________


 Example if I want subdirectory "perl" and "csh" for script I must have
config file like this :

 _____________________________________________________________________

 ...
# ScriptAlias: This controls which directories contain server scripts.
# Format: ScriptAlias fakename realname
 
ScriptAlias /cgi-perl/ /usr/local/etc/httpd/cgi-bin/perl
ScriptAlias /cgi-csh/ /usr/local/etc/httpd/cgi-bin/csh

 _____________________________________________________________________

 URL are :
  http://server/cgi-perl/script/extra_path
  http://server/cgi-csh/script/extra_path

 I can't have :
  http://server/cgi-bin/perl/script/extra_path
  http://server/cgi-bin/csh/script/extra_path


Guy Decoux



From speyer@mcc.com  Tue Dec 28 10:29:34 1993 CST
Message-Id: <9312281629.AA22591@faith.mcc.com>
Date: Tue, 28 Dec 93 10:29:34 CST
From: speyer@mcc.com (Bruce Speyer)
Subject: Re: CGI Suggestion

Charles Henrich <henrich@crh.cl.msu.edu> writes:
>I would like to propose that instead of (or if we must, as well as) allowing
>the embedding of information in the path (which is really poor!) we should
>special case the character ';' to mean end of URL for the client.  This would
>allow folks to use
>
>http://machine/documentpath;info that can be passed to programs.
>
>In the above case the server would return the document /documentpath, but keep
>the ';' information intact for scripts and programs. Forcing the server to have
>to stat each directory level is an incredibly waste of resources, and thats
>doubly so for AFS!
>
>Thoughts?

A general solution can't avoid stat'ing/resolving at each directory level
unless scenarios like gateways accessed through gateways are disallowed.
This would be problematic.  Also, each gateway may require additional information
needed to stat/resolve which means information contained within pathnames
although the information may be notated as virtual directories.  For example:

  http://machine/Spanish/latest-config/documentpath;info

-Bruce




From john@math.nwu.edu  Tue Dec 28 10:52:23 1993 -0600 (CST)
Message-Id: <9312281652.AA04852@hopf.math.nwu.edu>
Date: Tue, 28 Dec 1993 10:52:23 -0600 (CST)
From: john@math.nwu.edu (John Franks)
Subject: Re: CGI Suggestion

According to Charles Henrich:

> I would like to propose that instead of (or if we must, as well as) allowing
> the embedding of information in the path (which is really poor!) we should
> special case the character ';' to mean end of URL for the client.  This would
> allow folks to use
> 
> http://machine/documentpath;info that can be passed to programs.

I think this is a much cleaner suggestion than the current scheme

> 
>In the above case the server would return the document /documentpath, but keep
>the ';' information intact for scripts and programs. Forcing the server to have
> to stat each directory level is an incredibly waste of resources, and thats
> doubly so for AFS!
> 

This was what I saw as problmatic also.  But, in fact, that isn't the way
that NCSA httpd, at least, works (as Guy Descoux pointed out).  What it
does is read some magic names (like "cgi-bin") from a configuration file
and assume that the first thing in the path after the magic name is a
script and anything else is info.  It is not necessary to stat anything.

This is workable, but less clean than either Charles suggestion or my
earlier one (the maintainer has to set up and maintain the magic
names, for example).  I also agree with Charles that embedding
information in a path is "really poor", primarily because it is
potentially confusing.



John Franks 	Dept of Math. Northwestern University
		john@math.nwu.edu




From rst@ai.mit.edu  Tue Dec 28 12:02:23 1993 EST
Message-Id: <9312281702.AA03437@volterra>
Date: Tue, 28 Dec 93 12:02:23 EST
From: rst@ai.mit.edu (Robert S. Thau)
Subject: CGI/1.0 --- what's wrong with the status quo?

As the de facto webmaster of a site (the MIT AI lab) which recently
upgraded to a somewhat modified (I'll get to that) NCSA httpd 1.0, in the
hopefully correct impression that server features, particularly the script
interface, were finally stable, I'm watching the discussion over
modifications with interest.  Here's a different perspective:

Franks, as far as I can tell, is objecting that with CGI as presently
implemented by (at least) NCSA, you can't tell whether a particular URL
will cause a script to be invoked or not, nor can you tell where the name
of the script ends and the parameters begin.  

For instance, consider an Info gateway.  As things stands, you can't tell
whether something like

  http://some-site.edu/info/rel/perl.info/Formats

will search a directory structure whose files contain translated Info nodes
or whether it will run a script to do the translation on the fly --- nor
whether the 'rel' is a parameter to the translator, or whether it selects
which of several alternative scripts to run.

My question is, what's wrong with this?  It doesn't confuse me --- I know
that 'info' is the script, 'rel' is a parameter, and the rest is info file/
node name --- that's the way I chose to set it up.  And as for clients, I
would tend to view these alternatives as implementation details which are
none of their business.  (Really picky observers may note that these aren't
quite the same as the URLs used by the info gateway I'm actually running
--- in particular, for back compatibility with an older hack, I'm covering
up the 'rel' parameter with a ScriptAlias, but this is a reflection of
what's actually going on under my hood).

In fact, I've found the status quo to be in some respects insufficiently
flexible.  For instance, it's awkward to have to put Guy Brooker's archie
script in a different directory from its coversheet, at potentially far
remove.  To deal with this, I've modified my NCSA httpd so that it is
capable of running scripts from (some of) the same directories it would
ordinarily search for files, under control of a RunScripts allow-option.
(The scripts are distinguished from ordinary files by a naming convention
which isn't visible to the clients, and PATH_INFO works --- as indicated
above, I'm using it.  BTW, I'd be willing to give the changes out as a
patch to anyone interested, and willing not to look a gift horse too close
in the mouth).

With this all in mind, my comments on the two changes which seem to be on
the table:

1) Having a magic character which delimits CGI script parameters ---

   I could live with this, although as I say, I really don't think it's
   much of the client's business.  However, it would require modifying
   every script out there which takes PATH_INFO --- and every invocation of
   one.  (That means every use of imagemap, among many others).

   BTW, with regard to the specific point that the status quo requires the
   daemon to do 'wasted' stats to discover where the script name ends, it's
   worth remembering that the daemon may be doing a lot of stats anyway for
   other purposes --- the NCSA daemon, for instance, walks the directory
   hierarchy repeatedly during access checks, looking for .htaccess files
   and symlinks.  In any case, compared with the load of running a Bourne
   shell script --- forking and execing a process which is likely to fork
   and exec many more --- these stats are pretty trivial.

2) As an alternative, requiring a fixed string at the name of any URL which
   might invoke a script ---

   This would set in stone the notion of separate, parallel directory
   hierarchies for scripts and everything else.  As indicated above, I
   don't like that notion much at all.

rst



From marca@ncsa.uiuc.edu  Tue Dec 28 14:44:16 1993 -0600
Message-Id: <9312282044.AA10003@wintermute.ncsa.uiuc.edu>
Date: Tue, 28 Dec 93 14:44:16 -0600
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: CGI Suggestion

Charles Henrich writes:
> I would like to propose that instead of (or if we must, as well as)
> allowing the embedding of information in the path (which is really
> poor!) we should special case the character ';' to mean end of URL
> for the client.  This would allow folks to use
> 
> http://machine/documentpath;info that can be passed to programs.
> 
> In the above case the server would return the document
> /documentpath, but keep the ';' information intact for scripts and
> programs. Forcing the server to have to stat each directory level is
> an incredibly waste of resources, and thats doubly so for AFS!

This isn't going to fly as a change for URLs per se; as far as URLs
go, everything after the third slash is opaque, which is as it should
be.  So if possible let's at least restrict this discussion to CGI.

Cheers,
Marc




From henrich@rs560.cl.msu.edu  Tue Dec 28 14:11:24 1993 -0500 (EST)
Message-Id: <9312281912.AA16756@rs560.cl.msu.edu>
Date: Tue, 28 Dec 1993 14:11:24 -0500 (EST)
From: henrich@rs560.cl.msu.edu (Charles Henrich)
Subject: Re: CGI Suggestion

> This isn't going to fly as a change for URLs per se; as far as URLs
> go, everything after the third slash is opaque, which is as it should
> be.  So if possible let's at least restrict this discussion to CGI.

The ;'s are meant only for the server (CGI) to interpret, not the client!

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                     http://rs560.msu.edu/~henrich/




From john@math.nwu.edu  Tue Dec 28 14:46:10 1993 -0600 (CST)
Message-Id: <9312282046.AA05074@hopf.math.nwu.edu>
Date: Tue, 28 Dec 1993 14:46:10 -0600 (CST)
From: john@math.nwu.edu (John Franks)
Subject: Re: CGI/1.0 --- what's wrong with the status quo?

According to Robert S. Thau:
> 
[Robert asks what's wrong with the status quo then says]
>
> In fact, I've found the status quo to be in some respects insufficiently
> flexible.  For instance, it's awkward to have to put Guy Brooker's archie
> script in a different directory from its coversheet, at potentially far
> remove.  To deal with this, I've modified my NCSA httpd so that it is
> capable of running scripts from (some of) the same directories it would
> ordinarily search for files, under control of a RunScripts allow-option.
> (The scripts are distinguished from ordinary files by a naming convention
> which isn't visible to the clients, and PATH_INFO works --- as indicated
> above, I'm using it.  BTW, I'd be willing to give the changes out as a
> patch to anyone interested, and willing not to look a gift horse too close
> in the mouth).
> 

Well, you ask what is wrong with the status quo and then tell us about
the modifications you have made to your server in order to get around
one of the problems which wouldn't exist if either of the suggestions
made by Charles Henrich and myself were adopted.  You are absolutely
right that there is no reason that the script and coversheet should
have to be in different directories.  There is also no reason that
directories containing scripts have to be listed in configuration
files and processed on server start up.  Or that scripts need to be
distinguished from ordinary files by a naming convention which the
server presumably decodes.  Adding unnecessary complexity to the
server is undesirable.  You have now added more code to your server
and you still don't have the functionality (much less the simplicity)
that a very minor change in the protocol would give.

> With this all in mind, my comments on the two changes which seem to be on
> the table:
> 
> 1) Having a magic character which delimits CGI script parameters ---
> 
>    I could live with this, although as I say, I really don't think it's
>    much of the client's business.

It is *none* of the client's business -- everyone agrees that the path
part of the URL is opaque to the client.  We are talking about making
the *servers* clean and simple and about making things clearer for human
maintainers.  All I am saying is SIMPLE IS GOOD.  Unnecessary complexity
is bad.

>    However, it would require modifying
>    every script out there which takes PATH_INFO --- and every invocation of
>    one.
> 

I have to plead guilty to starting this discussion at much too late a
date.  The suggestions should have been made several months ago when
the CGI standard was still in flux.  One possibility is that this
issue could be addressed in CGI/1.1.  I would point out that nothing
suggested requires any change in browsers and changes to scripts and
servers should be very minimal.  I think that relatively few scripts
currently use PATH_INFO.

I would be interested in hearing from server writers, like Rob McCool, Tony
Sanders and the CERN server author.  Also the views of script writers 
would be valuable.  Are there examples of widely used scripts that would
break?


John Franks 	Dept of Math. Northwestern University
		john@math.nwu.edu




From rst@ai.mit.edu  Tue Dec 28 17:32:55 1993 EST
Message-Id: <9312282232.AA03532@volterra>
Date: Tue, 28 Dec 93 17:32:55 EST
From: rst@ai.mit.edu (Robert S. Thau)
Subject: Re: CGI/1.0 --- what's wrong with the status quo?

> Well, you ask what is wrong with the status quo and then tell us about
> the modifications you have made to your server...

Perhaps I should have made it more clear that I was referring to the status
quo definition of the *protocol*.  The changes I have made to the server
don't affect *that* in the least --- it is already possible to mix scripts
and ordinary files indiscriminately from the client's perspective with the
stock NCSA httpd using ScriptAlias, with none of my hacks at all.

> ...in order to get around
> one of the problems which wouldn't exist if either of the suggestions
> made by Charles Henrich and myself were adopted.

Again, the changes I've made to the server have absolutely *nothing* to do
with the way scripts get their parameters (which is what your suggestion,
and Charles', would affect).  They have to do with the way that the daemon
finds the scripts in the first place --- in particular, which directories
it will search.  

Perhaps it was confusing to discuss these two separate issues in the same
note, but I was trying to use them to argue the same point, namely, that
from a user's perspective, it is better for the server software to become
*more* flexible rather than less.  (N.B. I'm counting script authors as
users in this context --- the author of a script is using the server).

> You are absolutely
> right that there is no reason that the script and coversheet should
> have to be in different directories.  There is also no reason that
> directories containing scripts have to be listed in configuration
> files and processed on server start up.

I'm glad we agree about these, but...

> Or that scripts need to be
> distinguished from ordinary files by a naming convention which the
> server presumably decodes.

I've got two comments on this:

First off --- CGI/1.0 already has a naming convention which some people
find at least irksome, the 'nph-' business.   Secondly --- if scripts and
ordinary files coexist in the same directories, and the server can't tell
them apart by the names, then how *can* it tell them apart?  How is the
server to know whether to read the file or to run it?

I suppose one could do something with file permissions, but I honestly
prefer suffixing the name with '.doit'.  The trouble with using permission
bits is that stray 'x' bits do occasionally get set on ordinary files.
With my server the way it is, this doesn't matter.  On the other hand, if
the server were using the x bits to tell whether to run the file, and a
stray 'x' bit landed on some gateway's conversheet, the server would
wind up trying to exec() a file full of HTML, fail, and return a '500
Server Error' which *really* confuses the hell out of some poor novice.
("The file is there.  Why can't the server read it?").

In short, the naming convention makes it obvious, simply by looking at a
file, whether it is a script which the server should run, or an ordinary
file which the server should just throw over the transom.  From a *user's*
perspective, that's simplicitly --- even if it takes ten more lines of code
in the server.  (This is not an exaggeration, BTW --- see below).

> Adding unnecessary complexity to the
> server is undesirable.  You have now added more code to your server
> and you still don't have the functionality (much less the simplicity)
> that a very minor change in the protocol would give.

I'm not sure what you're getting at.  What functionality don't I have?
Please be specific --- show me something I can't do.  As to simplicity,
that's a matter of perspective.  As the author of several scripts, I regard
your proposed changes as *adding* complexity, by giving me one more
inessential detail to keep track of.  Granted, the server code does become
perhaps a little simpler, but see below for more on how I see the
tradeoff...

In any case, the amount of code I have added to the server is *minimal* ---
the total number of lines changed or added is well under 200.  If I deleted
all of the code related to ScriptAlias (which I no longer actually use), I
think the server would actually shrink substantially.

> All I am saying is SIMPLE IS GOOD.  Unnecessary complexity
> is bad.

I suppose most people would agree with this in the abstract --- until you
get around to the tricky issues of what exactly is "complexity", and what
is "necessary", from whose perspective.  In particular, as I've said, you
are proposing to *add* complexity from the perspective of the script writer
--- in terms of requiring a fixed form for the parameters of their scripts,
which is one more inessential detail to keep track of and get right --- in
order to keep *your* code simple and clean:

> We are talking about making
> the *servers* clean and simple and about making things clearer for human
> maintainers.

The simplicification is in whatever routine in the server identifies the
PATH_INFO parameters to a CGI script.  In the distributed NCSA server, this
routine is 22 lines of code (get_path_info in http_script.c), two of which
are blank.  In my version, it's 62 lines, but I can shrink it to 29 by
reverting to the original code's K&R brace style, and stripping out blank
lines and comments.  (BTW, I'm counting these 33 lines of braces and
whitespace in the change count above.  Also, BTW, the extra nine lines of
executable code here are the ones that add the '.doit' and '.nph' suffixes
before checking for the existence of the script --- the naming convention
mentioned above.  We are not talking about an enormous amount of code to
implement *any* of this stuff).

The complication is in every CGI script that takes PATH_INFO.  At my site,
that includes 'imagemap' (which may well be the single most used CGI script
anyplace), my info gateway, and several scripts which form a community
hotlist system which I'm playing around with, along with a few more minor
experiments.

In short, I'm not at all sure I can see the tradeoff the same way you do
once the scripts, and the documents which already have links to them, are
put into the balance.

> I would be interested in hearing from server writers, like Rob McCool, Tony
> Sanders and the CERN server author.  Also the views of script writers 
> would be valuable.  

I've never written a whole server, but I have written several nontrivial
scripts.  You've got my opinion...

rst



From henrich@rs560.cl.msu.edu  Tue Dec 28 18:50:58 1993 -0500 (EST)
Message-Id: <9312282351.AA24924@rs560.cl.msu.edu>
Date: Tue, 28 Dec 1993 18:50:58 -0500 (EST)
From: henrich@rs560.cl.msu.edu (Charles Henrich)
Subject: Re: your mail

> Using Charles Henrich's suggested syntax, for example, URLs like
>
>     http://host/path/script;
>     http://host/path/script;foo
>     http://host/path/script;foo?bar
>
> would all be scripts.  I.e. the presence of the ';' indicates it is
> executable.  An trailing ';' just indicates an empty PATH_INFO.

Actually, no I wouldnt suggest using a ';' to represent executable.  The
current manner to determine if a script is a script is "good enough".  In fact
using the ';' to determine if a script was would disallow most of what Im
doing.  I use the inlined include facility of NCSA's server extensivly.  I want
the server to return

http://host/path/document

And then the document calls an inlined include which can then decipher the ';'
attributes, making  all sorts of interesting things possible.

I'd like to say, this syntax could be *in addition* to the current method, it
doesnt need to replace it.  Im finding a situation here where the forced
"stat'ing" of non-existant files to be distasteful, wasteful, and a very
potential problem with servers that are heavily utilized.

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                     http://rs560.msu.edu/~henrich/




From john@math.nwu.edu  Tue Dec 28 17:30:49 1993 -0600 (CST)
Message-Id: <9312282330.AA05364@hopf.math.nwu.edu>
Date: Tue, 28 Dec 1993 17:30:49 -0600 (CST)
From: john@math.nwu.edu (John Franks)
Subject: 

According to Robert S. Thau:
>
> First off --- CGI/1.0 already has a naming convention which some people
> find at least irksome, the 'nph-' business.   

I too find it irksome.  Not horrible, but irksome.

> Secondly --- if scripts and
> ordinary files coexist in the same directories, and the server can't tell
> them apart by the names, then how *can* it tell them apart?  How is the
> server to know whether to read the file or to run it?
> 

Using Charles Henrich's suggested syntax, for example, URLs like

	http://host/path/script;
	http://host/path/script;foo
	http://host/path/script;foo?bar

would all be scripts.  I.e. the presence of the ';' indicates it is
executable.  An trailing ';' just indicates an empty PATH_INFO.

> 
> > Adding unnecessary complexity to the
> > server is undesirable.  You have now added more code to your server
> > and you still don't have the functionality (much less the simplicity)
> > that a very minor change in the protocol would give.
> 
> I'm not sure what you're getting at.  What functionality don't I have?
> Please be specific --- show me something I can't do.  

OK, it is not a big deal, but I do think the current syntax has less
functionality and is less flexible than the one described above. If I
understand you correctly with your server you can't have a script with
an arbitrary path and an arbitrary name.  You must either have a magic
directory name like "cgi-bin" in the path above the script or the
script must have a name ending in a special suffix like ".doit".  On
my server, I have scripts which are both executed and served as text
documents.  Which of these is done depends on how the URL references
them.  In the syntax described above, for example, the script would be
executed if the URL ends with ';' and treated as a document
otherwise.  I know you can do the same thing by making a symbolic link
to your script with a doit-less name, but this is, as you put it,
just "one more inessential detail to keep track of".

> As to simplicity,
> that's a matter of perspective.  As the author of several scripts, I regard
> your proposed changes as *adding* complexity, by giving me one more
> inessential detail to keep track of.  Granted, the server code does become
> perhaps a little simpler, but see below for more on how I see the
> tradeoff...
> 

Now, could you explain, how the ';' mechanism is more complex than the
current syntax?  I find it hard to see how writing a script which
outputs

	http://host/path/script;info

is more complicated than one which outputs

	http://host/path/script/info

The value of the environmental variable PATH_INFO would be the same
with either syntax, so that couldn't make any difference.

Also could you explain why you find the ';' mechanism less flexible
than the current syntax.  I think the example above shows that the ;
mechanism is *more* flexible than the current one.  Since it would be
trivial to translate the ';' to a '/', I think it is clear that
Charles' suggested syntax contains at least as much information as the
current syntax and hence is at least as flexible.


John Franks 	Dept of Math. Northwestern University
		john@math.nwu.edu






From ushioda@tko.dec.com  Tue Dec 28 20:29:50 1993 PST
Message-Id: <9312290428.AA10060@enet-gw.pa.dec.com>
Date: Tue, 28 Dec 93 20:29:50 PST
From: ushioda@tko.dec.com (ushioda@tko.dec.com)
Subject: remove

Please remove me from your distribution list.

Thank you,
Kentaro.



From rst@ai.mit.edu  Wed Dec 29 13:46:09 1993 EST
Message-Id: <9312291846.AA03803@volterra>
Date: Wed, 29 Dec 93 13:46:09 EST
From: rst@ai.mit.edu (Robert S. Thau)
Subject: Re: CGI, semicolons, and so on...

John Franks says:

> Also could you explain why you find the ';' mechanism less flexible
> than the current syntax.  I think the example above shows that the ;
> mechanism is *more* flexible than the current one.  Since it would be
> trivial to translate the ';' to a '/', I think it is clear that
> Charles' suggested syntax contains at least as much information as the
> current syntax and hence is at least as flexible.
>
>	http://host/path/script;
>	http://host/path/script;foo
>	http://host/path/script;foo?bar
>
> would all be scripts.  I.e. the presence of the ';' indicates it is
> executable.  

You regard this as more flexible because 'GET /path/script;' runs the
script, while 'GET /path/script' returns it as a file.  I could actually do
pretty much the same thing --- to have 'GET /path/script' run the script,
while 'GET /path/script.doit' would return it as a file.  I don't, out of
sheer paranoia --- there is actually an extra line of code which I threw in
deliberately to *prevent* this from working.  To put it bluntly, if there's
a Bourne shell script on my machine which anyone in the world can run, I
don't want to let them read it as well without knowing I have done so.
Some of them are nasty, and some of the nasty ones know more about the
Bourne shell than I do.  But, if that extra line of code offends you, you
don't have to write it.

The flexibility that concerns me more is my flexibility to decide whether a
particular URL is going to run a script at all, or not --- and having made
that choice, to change my mind.  Suppose, for instance, that I have a
document which is frequently referenced, and I want to add something to it
for local eyes only.  One thing I could do, with my current setup, is to
turn it into a script, which only prints certain parts of the boilerplate
if the connection has come from inside the lab.  

Now, with your variant of Charles' proposal, this means changing the name
of it as well --- I'd have to add that extra semicolon.  Then, I'd have to
either track down and change all the references to the old name (a messy
chore), or add a Redirect line to srm.conf (which gets ugly when they start
to pile up).  And --- to return to an earlier point --- if I wasn't
extremely careful about how I wrote the script, then a client who left off
the semicolon would get to see the eyes-only matter anyway, and find out a
little about my security setup as an added bonus.  ("Oh, so he trusts the
nameserver? Hmmmm....")  Because the client can read the script, the whole
point of having a script there in the first place has been lost.  This sort
of thing is why I *don't* regard the free export of the code of the scripts
that I'm running as an "inessential" matter.

In short, what I mean by flexibility is the ability to make these kinds of
changes --- turning an ordinary file into a script, etc. --- without having
to track down all the references and change *those* as well.  Requring
special syntax to invoke a script denies me this flexibility; it makes what
*ought* to be local changes into global ones.

So much for my "flexible".  Now, I'm still confused by your "functional"
--- since, as we seem to agree, there is no script which *couldn't* be
written to work either way, it seems to me that there is no difference in
functionality whatever.  It's just that (aside from the question of
changing a "standard" after it was promulgated), one thing is, IMHO, rather
easier to keep secure and to administer.

rst



From rst@ai.mit.edu  Wed Dec 29 13:54:53 1993 EST
Message-Id: <9312291854.AA03807@volterra>
Date: Wed, 29 Dec 93 13:54:53 EST
From: rst@ai.mit.edu (Robert S. Thau)
Subject: Re: your mail

Charles Henrich writes ...

> In fact using the ';' to determine if a script was would disallow most of
> what Im doing.  I use the inlined include facility of NCSA's server
> extensivly.  I want the server to return
> 
> http://host/path/document
> 
> And then the document calls an inlined include which can then decipher
> the ';' attributes, making all sorts of interesting things possible.

Hmmm... You have a point.  Still, scripts run from NCSA's server includes
don't actually get the CGI variables set yet.  Even if they did, it
wouldn't be too hard to make the current PATH_INFO mechanism do the job ---
when presented with

  GET /path/document/parameter/and-another-one

the server would find the prefix which refers to an actual file (i.e.
'/translated-path/document'), and leave the rest as PATH_INFO for potential
includes.  This leaves aside the question of efficiency, of course, to
which I'll return.

As a side note --- there are other ways to skin the same cat.  For
instance, on my server as currently configured, I can create a script
called 'document' which looks like this:

 #! /usr/local/bin/perl

 print<<EOF;
 <title> blah blah blah </title>
 ...
 EOF

 &play_with ($ENV{'PATH_INFO"});

 print<<EOF;
 <H1>More grunge here</H1>
 <H2>Nirvana in Buddhist thought as related to Christian Eschatology</H2>
 gubbish gubbish gubbish...
 EOF

Retrievals on http://host/path/document/params/here would then do what you
want.  This is arguably a little more awkward than server includes; it may
be more or less efficient (certainly less efficient if the includes simply
include other ordinary files; probably more efficient if there are several
includes which fork off child processes whose work could have been done by
the single perl script, without further process spawning).

> I'd like to say, this syntax could be *in addition* to the current method, it
> doesnt need to replace it.  Im finding a situation here where the forced
> "stat'ing" of non-existant files to be distasteful, wasteful, and a very
> potential problem with servers that are heavily utilized.

First off, with regard to aesthetics, de gustibus non disputandum est.  My
personal 'aesthetic' objection to the semicolon syntax is that it keeps me
from changing directories to scripts-with-path_info and back without making
the change in status visible in the URLs and making me change all the
references.  (I don't think this is a totally wild idea --- I've been
chewing over turning the 'people' directory on my server into a script
which redirects to ~.../public_html areas if they exist for the user in
question, and makes up a default home page if they don't).  

Still, so long as I can turn an ordinary *file* into a script and back
without having to find and change everything that cites it (which can be a
real pain in the butt) or doing an Alias or Redirect in srm.conf (which
could get ugly if they started to add up), this isn't a *major* issue.  If
the new syntax is an optional alternative, I have no real objection (though
somebody else might --- two ways of specifying PATH_INFO does add a little
complication to the server).  I'm frankly more hung up on the notion of
incompatible changes to something which has been announced as a standard,
over what I see as quite minor efficiency concerns.

This efficiency argument is apparently the nub of the dispute --- I just
don't find it easy to see how these few extra stat() calls, which needn't
occur unless PATH_INFO is present, can possibly amount to a potentially
serious problem, in the context of all the other things the server does
when processing a request.

To try to put this in context, I've appended a system-call trace of my
(hacked) httpd processing the request 'GET /cgi-bin/fortune'.  The trace
was collected from a server running as 'ServerType inetd', so to keep
things fair I've deleted all the initialization, opening of the logs, and
so forth, and picked up where it actually starts to process the request.
For convenience, I've pointed out the PATH_INFO search in the middle of it.
It amounts to one stat() --- it would have been five with the stock httpd
(Rob goes top down, I go bottom up); there also would have been a little
more monkey business if the script had been run out of a normal directory
instead of cgi-bin, if I had FollowSymLinks disabled (which makes the
daemon walk the pathname looking for symlinks to see if it should deny
access), or if PATH_INFO were actually present.

Due to limitations of the tracer, this count excludes housekeeping system
calls done by the daemon child process which exec()s the script.  More to
the point, it excludes the load put on the system by the CGI script itself,
beginning with the exec(), which is hardly cheap when individual stat()s
are in the balance.  The most trivial possible C program --- 'main () {}',
generates 43 lines of system-call trace when I run it dynamically linked
under SunOS (mostly due to the shared library mechanism), including 23
opens, reads, and mmaps.  In the particular example here, of course, the
overhead would amount to far more --- the NCSA 'fortune' gateway is a shell
script, and you can barely turn around and sneeze in Bourne shell without
spawning off a child process or two, and doing more stat()s for searches
along $PATH than anyone would care to shake a stick at.

Leaving all that aside, and looking at the system calls executed in the
body of the daemon itself, we find a total of 148 system calls.  Because of
the way the trace was collected (see above), this count does not include
the overhead associated with accepting the connection in the first place,
which (for a standalone server) would amount to at least an accept(), a
fairly hefty fork(), and a bit of housekeeping.  Against this background, I
find it difficult to see how another stat() or two, or even ten, done only
for URLs which happen to invoke a script in the first place, could make
enough of a difference to matter.

rst

The system-call trace follows, picking up after the daemon opens the log
files and enters its process_request() routine:

...
getsockname (1, 0xf7fffea0, 0xf7fffe9c) = 0
getpeername (0, 0xf7ff5e30, 0xf7ff5e2c) = 0
getpid () = 3748
open ("/var/yp/binding/ai.mit.edu.2", 0, 036736176136) = 5
flock (5, 06) = -1 EWOULDBLOCK (Operation would block)
mmap (0x361e0, 14, 0x1, 0x80000001, 5, 0) = 0xf76f0000
close (5) = 0
socket (2, 2, 0) = 5
bind (5, "".., 16) = -1 EADDRINUSE (Address already in use)
close (5) = 0
gettimeofday (0xf7ff5ae8, 0) = 0
getpid () = 3748
socket (2, 2, 17) = 5
getpid () = 3748
bind (5, "".., 16) = -1 EACCES (Permission denied)
ioctl (5, 0x8004667e, 0xf7ff5ab4) = 0
fcntl (5, 02, 0x1) = 0
bind (5, "".., 16) = 0
getsockname (5, 0xf7ff5b5c, 0xf7ff5b7c) = 0
sendto (5, "".., 88, 0, 0x362e0, 16) = 88
getdtablesize () = 64
select (64, 0xf7ff5bc0, 0, 0, 0xf7ff5c30) = 1
recvfrom (5, "".., 1600, 0, 0xf7ff5bac, 0xf7ff5bbc) = 52
gettimeofday (0xf7ff5d48, 0xf7ff5d40) = 0
sigblock (0x2000) = 0
sigvec (14, 0xf7ff5dd4, 0xf7ff5dc8) = 0
sigvec (14, 0xf7ff5d5c, 0) = 0
sigsetmask (0) = 0x2000
sigblock (0x2000) = 0
sigvec (14, 0xf7ff5dd4, 0) = 0
sigvec (14, 0xf7ff5d5c, 0) = 0
sigsetmask (0) = 0x2000
setitimer (0, 0xf7ff5dd0, 0xf7ff5dc0) = 0
read (0, "G", 1) = 1
read (0, "E", 1) = 1
read (0, "T", 1) = 1
read (0, " ", 1) = 1
read (0, "/", 1) = 1
read (0, "c", 1) = 1
read (0, "g", 1) = 1
read (0, "i", 1) = 1
read (0, "-", 1) = 1
read (0, "b", 1) = 1
read (0, "i", 1) = 1
read (0, "n", 1) = 1
read (0, "/", 1) = 1
read (0, "f", 1) = 1
read (0, "o", 1) = 1
read (0, "r", 1) = 1
read (0, "t", 1) = 1
read (0, "u", 1) = 1
read (0, "n", 1) = 1
read (0, "e", 1) = 1
read (0, "\r", 1) = 1
read (0, "\n", 1) = 1
setitimer (0, 0xf7ff5dd0, 0xf7ff5dc0) = 0
sigblock (0x2000) = 0
sigvec (14, 0xf7ff5dd4, 0xf7ff5dc8) = 0
sigvec (14, 0xf7ff5d5c, 0) = 0
sigsetmask (0) = 0x2000
gettimeofday (0xf7ff5d68, 0) = 0
open ("/usr/share/lib/zoneinfo/localtim".., 0, 0) = 6
read (6, "".., 4136) = 746
close (6) = 0
ioctl (3, 0x40125401, 0xf7ff4eac) = -1 ENOTTY (Inappropriate ioctl for device)
fstat (3, 0xf7ff4f20) = 0
write (3, "localhost [Wed Dec 29 10:18:28 1".., 58) = 58
close (3) = 0
>>>> PATH_INFO stat ("/com/doc/web-support/cgi-bin/for".., 0xf7ff5968) = 0 <<<<
open ("/.htaccess", 0, 0666) = -1 ENOENT (No such file or directory)
open ("/com/.htaccess", 0, 0666) = -1 ENOENT (No such file or directory)
open ("/com/doc/.htaccess", 0, 0666) = -1 ENOENT (No such file or directory)
open ("/com/doc/web-support/.htaccess", 0, 0666) = -1 ENOENT (No such file or directory)
open ("/com/doc/web-support/cgi-bin/.ht".., 0, 0666) = -1 ENOENT (No such file or directory)
pipe (0xf7ff5dc0) = 3
fork () = 3749
close (6) = 0
getdtablesize () = 64
sigblock (0x2000) = 0
sigvec (14, 0xf7ff5424, 0xf7ff5418) = 0
sigvec (14, 0xf7ff53ac, 0) = 0
sigsetmask (0) = 0x2000
setitimer (0, 0xf7ff5420, 0xf7ff5410) = 0
read (3, "C", 1) = 1
read (3, "o", 1) = 1
read (3, "n", 1) = 1
read (3, "t", 1) = 1
read (3, "e", 1) = 1
read (3, "n", 1) = 1
read (3, "t", 1) = 1
read (3, "-", 1) = 1
read (3, "t", 1) = 1
read (3, "y", 1) = 1
read (3, "p", 1) = 1
read (3, "e", 1) = 1
read (3, ":", 1) = 1
read (3, " ", 1) = 1
read (3, "t", 1) = 1
read (3, "e", 1) = 1
read (3, "x", 1) = 1
read (3, "t", 1) = 1
read (3, "/", 1) = 1
read (3, "p", 1) = 1
read (3, "l", 1) = 1
read (3, "a", 1) = 1
read (3, "i", 1) = 1
read (3, "n", 1) = 1
read (3, "\n", 1) = 1
setitimer (0, 0xf7ff5420, 0xf7ff5410) = 0
sigblock (0x2000) = 0
sigvec (14, 0xf7ff5424, 0xf7ff5418) = 0
sigvec (14, 0xf7ff53ac, 0) = 0
sigsetmask (0) = 0x2000
sigblock (0x2000) = 0
sigvec (14, 0xf7ff5424, 0xf7ff5418) = 0
sigvec (14, 0xf7ff53ac, 0) = 0
sigsetmask (0) = 0x2000
setitimer (0, 0xf7ff5420, 0xf7ff5410) = 0
read (3, "\n", 1) = 1
setitimer (0, 0xf7ff5420, 0xf7ff5410) = 0
sigblock (0x2000) = 0
sigvec (14, 0xf7ff5424, 0xf7ff5418) = 0
sigvec (14, 0xf7ff53ac, 0) = 0
sigsetmask (0) = 0x2000
sigblock (0x2000) = 0
sigvec (14, 0xf7ff5134, 0xf7ff5128) = 0
sigvec (14, 0xf7ff50bc, 0) = 0
sigsetmask (0) = 0x2000
sigblock (0x1000) = 0
sigvec (13, 0xf7ff5134, 0xf7ff5128) = 0
sigvec (13, 0xf7ff50bc, 0) = 0
sigsetmask (0) = 0x1000
setitimer (0, 0xf7ff5130, 0xf7ff5120) = 0
ioctl (3, 0x40125401, 0xf7ff4fcc) = -1 EOPNOTSUPP (Operation not supported on socket)
fstat (3, 0xf7ff5040) = 0
read (3, "Kiss me twice.  I'm schizophreni".., 4096) = 35
read (3, "", 4096) = 0
ioctl (1, 0x40125401, 0xf7ff4fcc) = -1 EOPNOTSUPP (Operation not supported on socket)
- SIGCHLD (20)
fstat (1, 0xf7ff5040) = 0
write (1, "Kiss me twice.  I'm schizophreni".., 35) = 35
close (3) = 0
wait4 (3749, 0, 0, 0) = 3749
close (0) = 0
close (1) = 0
close (2) = 0
close (4) = 0
exit (0) = ?



From cardeci@lysator.liu.se  Wed Dec 29 20:18:45 1993 +0100
Message-Id: <199312291918.UAA00322@dell.lysator.liu.se>
Date: Wed, 29 Dec 1993 20:18:45 +0100
From: cardeci@lysator.liu.se (cardeci@lysator.liu.se)
Subject: UNsubscribe

Could you please unsubscribe me?
(Yes, I have mailed to www-talk-request first, and as a result
 I got my mail back..........)



From john@math.nwu.edu  Wed Dec 29 14:24:12 1993 -0600 (CST)
Message-Id: <9312292024.AA00540@hopf.math.nwu.edu>
Date: Wed, 29 Dec 1993 14:24:12 -0600 (CST)
From: john@math.nwu.edu (John Franks)
Subject: Re: CGI, semicolons, and so on...

Look, this discussion has wandered far away from the point I wanted to
make initially.  I am not unhappy with the functionality or the
flexibility of the current PATH_INFO syntax.  I am unhappy with the
design of that syntax because it is inelegant, cumbersome to
implement, and conducive to misunderstanding by people who are only
marginally familiar with the protocol.

Let me mention the syntax used by the Minnesota gopher server for a
similar function.  It is fairly similar to URL syntax.  The path part
of the URL looks like

	exec:args:/path/script

I am NOT advocating that this be adopted as part of CGI.  I offer it
only as an existence proof that it is not too difficult to design a
syntax whose server implementation will have several important
properties:

1) It is simple and clear.  I don't think I even need to explain it;
   its meaning should be self evident.  THE FACT THAT THIS PART OF THE
   URL IS OPAQUE DOES NOT MEAN IT SHOULD BE OBSCURE.

2) It is easy and efficient to parse.  It is not necessary to stat any
   files or directories in order to parse it. 

3) It is not necessary to maintain a configuration file which is read
   and processed each time a server starts up.  

4) It uses no magic directory names like "cgi-bin" and no magic 
   extensions like ".doit".  You can name files, scripts and directories
   whatever you like and mix files and scripts in any directory.

I believe that WWW community can do at least as well as the gopher
designers.  That's all I wanted to say.  I concede that it is late in
the game to be requesting changes.  If it is too late, so be it.
Maybe I am just old-fashioned in my belief that programs (and
protocols) should try to be simple, clear, concise and if at all
possible elegant.

Robert Thau points out that it is possible to modify the NCSA server
so that some of these properties are achieved within the current
protocol.  Fine.  But IMHO, if we had had a better protocol to begin
with the original implementation would have been better and his
modifications would never have been necessary.

Interestingly, the gopher syntax does not address the issue raised by
Charles Henrich who, quite reasonably, suggests that putting PATH_INFO
in the environment should be independent of indicating that a file is
executable.  I would agree.

It seems to me now that there are (at least) three pieces of
information which need to be contained in the path part of a URL:

1) Name and path of the file/script
2) string to be put in PATH_INFO environment variable (if any)
3) Is this file/script to be executed or treated as text

I would suggest as an important design criterion that these three
pieces of information should be orthogonal, i.e. the value of one
should not restrict the possible values of the others.  For example,
as Charles Henrich pointed out, my suggestion to make the existence of
PATH_INFO data be the indicator that the file should be executed is
not a good idea.  Likewise, I would contend that it is not a good idea
to have the fact that a file is intended to be executed restrict
either its possible name or possible path.  It is certainly not
technically difficult to have such a design.  The question is, is it
too late.


John Franks 	Dept of Math. Northwestern University
		john@math.nwu.edu






From henrich@crh.cl.msu.edu  Wed Dec 29 16:51:34 1993 -0500 (EST)
Message-Id: <9312292151.AA20618@crh.cl.msu.edu>
Date: Wed, 29 Dec 1993 16:51:34 -0500 (EST)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: Re: CGI, semicolons, and so on...

> only as an existence proof that it is not too difficult to design a
> syntax whose server implementation will have several important
> properties:

I agree wholeheartedly, my original intent was to make the scheme cleaner and
allow for a more efficent implementation.  the stat() call on local unix
systems is a waste of resources, and on a AFS system a whole lot of wasted
resources.  (We run AFS all over here)

My scheme was simply to have the server ignore everything beyond the first
semicolon found in the URL.  That information would then be passed (in any
number of ways) to the scripts that get called.  This format works quite well
in satisfying the following parameters:

> 1) Name and path of the file/script

Initial part of the URL

> 2) string to be put in PATH_INFO environment variable (if any)

The text beyond the semicolon

> 3) Is this file/script to be executed or treated as text

The srm.conf file.  Or heaven forbid the execute bit on the file, after all,
unix has been using the EXECUTE bit to mean that the file is EXECUTABLE (go
figure) for the longest of times..

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                     http://rs560.msu.edu/~henrich/



From rst@ai.mit.edu  Wed Dec 29 18:59:14 1993 EST
Message-Id: <9312292359.AA03913@volterra>
Date: Wed, 29 Dec 93 18:59:14 EST
From: rst@ai.mit.edu (Robert S. Thau)
Subject: Re: CGI, semicolons, and so on...

John Franks' note is very helpful in making the disagreements between us
clear --- and, unfortunately, making it clear that a resolution is rather
less than likely, since the disagreements are largely over matters of
style.  For instance, if I were to come up with a list of desiderata for a
CGI-like interface, it would probably have somewhere on it, that:

n) There should not be any indication within the URL, selector string,
   etc., as to whether or not a retrieval will cause a script to be
   invoked.

Unfortunately, as near as I can tell, there is no way to reconcile this
desideratum with John's.

The reason I want it is that having put something up as a file, or
collection of files, I may want to turn it into a script, without having to
track down all the references to it and change them as well --- which I
would necessarily have to do if the script/file distinction were explicit
in the URL (selector, whatever).  The 'eyes-only document hack' provides, I
think, one fairly reasonable example of where one might like to do this.

Conversely, I might also want to take something that I've put up as a
script, and replace it with a collection of files --- as in the case of
replacing my on-the-fly info gateway with the output of a batch translator.
I want to be able to do this without having to find and change every
reference to an info node anywhere on my server.

Now, in order to satisfy the goal above, you need some way of
distinguishing the scripts from the ordinary files, other than selector
syntax.  In other words, you need a mechanism for typing the files.

Like it or not, most of the existing servers already have such a mechanism
--- to tell what type a file is (in order to report the proper MIME type),
they discriminate on the basis of the name.  If you put a GIF file up under
the name 'foo.au', or even just plain 'foo', then (with the stock NCSA
server, and Plexus and CERN as well, I believe), the wrong MIME type will
be reported back to the client, and things fall apart.  If you want to get
rid of arbitrary naming conventions, this may be the best place to start.
Scripts could easily piggy-back on any solution to the file-typing problem
--- just type them as application/x-cgi-run-it-here, and make the server
give special treatment to that type (as the NCSA server already does for
text/html with Charles' server includes).

But, supposing the script type is different enough from other types that we
want some completely different mechanism for indicating files of that type.
For instance, we could use the 'x' bit.  Now, 'x' bits sometimes do get set
where they aren't meant to be --- typos happen.  Generally, this doesn't
matter much.  A C source file with an 'x' bit is still a perfectly useful C
source file.  However, with this scheme, an 'x' bit on a data file in the
server arena makes it impossible to retrieve the file.

For instance, suppose some novice slips up with chmod, and the 'x' bit gets
set on a form coversheet --- his fingers ran away with him, and instead of
'chmod foo', he typed 'chmod foo*'.  Then, when the luser attempts to
retrieve the coversheet, the server sees the 'x' bit on it, and tries to
run it as code.  When this fails, the poor guy sees:

  500 Server error.

  The script '...' failed to produce output...

From the server's perspective, there's no more to say --- it was supposed
to run the thing, and it couldn't.  But the novice will likely assume that

  a) it was trying to run the script, and not the coversheet.
     (After all, it makes no sense to try to run the coversheet).

  b) It tried and failed to run the script.  Therfore, the script is
     somehow broken, even though it seems to work just fine
     when tested from the command line.

This is the setup for a major wild goose chase.

Better error messages might ameliorate the problem --- but it would be
better if it weren't so easy to make this error in the first place.  It's
easy to slip up with chmod without knowing it, and when that makes things
break (as when 'chmod * 664' snags a directory by mistake), it can be
pretty tricky to figure out what's gone wrong.  ('ls' works, but nothing
else does).  But accidentally renaming foo.html to foo.doit --- that's
tough.

In fact, suffix-based naming conventions are all over Unix, and many other
widely used operating systems, in part because on many of these systems, a
file's name is one of the few unique attributes the thing has got.  I don't
think it's "inelegant" that the C compiler treats files whose names end in
'.c' different from those whose names end in '.o', and I've never found it
to be bothersome.  Perhaps it's a matter of taste --- but like I said,
arguments over those will never be resolved.

rst



From sanders@BSDI.COM  Thu Dec 30 02:17:42 1993 -0600
Message-Id: <199312300817.CAA16656@austin.BSDI.COM>
Date: Thu, 30 Dec 1993 02:17:42 -0600
From: sanders@BSDI.COM (Tony Sanders)
Subject: Re: CGI and typing files by suffix 

According to John Franks:
> According to Robert S. Thau:
> > n) There should not be any indication within the URL, selector string,
> >    etc., as to whether or not a retrieval will cause a script to be
> >    invoked.
Yes, this is a MUST in my book.

> > The reason I want it is that having put something up as a file, or
> > collection of files, I may want to turn it into a script, without having to
...
> I know you have alreadly expressed a distaste for the redirection
> mechanism in HTTP/1.0, but this situation is exactly what it is
You can use redirection for this but it's a really bad idea (talk about
spaghetti code).  Redirection is nice as the return from a query (esp.
spatial queries via ISMAP).  Permanent redirections are supposed to be
automatically handled (client notifies server that it's URL is out of
date) but doing this right is a lot of work and it looks to be fairly low
on the prio list.

> > Like it or not, most of the existing servers already have such a mechanism
> > --- to tell what type a file is (in order to report the proper MIME type),
> > they discriminate on the basis of the name.  If you put a GIF file up under
> > the name 'foo.au', or even just plain 'foo', then (with the stock NCSA
> > server, and Plexus and CERN as well, I believe), the wrong MIME type will
> > be reported back to the client, and things fall apart.
Of course, the servers do this because it's convenient.
Someday I will fix Plexus so this is done "right" and the typing isn't
wholy suffix dependent.  I will probably end up keeping cache files
in each directory that get updated automatically as needed.  There is
also the non-trivial issue of how to admin such a beast.

> If typing files by suffix were adequate there would be no point in
> using the MIME type at all, the client could just look at the
> suffix. In HTTP/0.9 file types were determined by suffix and there was
> no MIME type.
HTTP/0.9 clearly defined that ONLY plain text and HTML were valid return
types.  NCSA Mosaic violated the spec and used the file suffixes, I'm not
saying this was an unreasonable thing to do, just making it clear that
HTTP never sanctioned this activity.

Basically, typing by suffix is UNACCEPTABLE for the client end (though as
NCSA Mosaic proved it can work ok for some stuff, that isn't the issue)
but it's perfectly fine for the server to use this if it wants.  The key
is that there is nothing requiring the server to do so, it's mearly done
as a matter of convenience on some OS's.

> It is a bad idea to do so, but surely it should be *possible* with any
> HTTP/1.0 server to put up a GIF file with the name foo.au and have it
It is indeed possible and does work.
> work perfectly.  BTW, the reason it is a bad idea is precisely the
> same reason it is a bad idea to have PATH_INFO data look like part of
> the path -- it is misleading and obscure.
I fail to see how:
    http://server/path/cmd;args
Is really any clearer or better than:
    http://server/path/cmd/args

The `;' scheme simply has too many drawbacks (namely you can't front-end
existing directory hierarchies with scripts).

Previously John said in <9312282330.AA05364@hopf.math.nwu.edu>:
> an arbitrary path and an arbitrary name.  You must either have a magic
> directory name like "cgi-bin" in the path above the script or the
> script must have a name ending in a special suffix like ".doit".  On
As others have pointed out, the server is free to use any out-of-band
information it needs/wants to decide what to do.  Encoding this information
in the URL is generally regarded as a bad idea for the general case.

Using the execute bit, where available, is probably the best plan.

--sanders



From cailliau@www1.cern.ch  Thu Dec 30 10:18:27 1993 +0100
Message-Id: <9312300922.AA03091@www1.cern.ch>
Date: Thu, 30 Dec 1993 10:18:27 +0100
From: cailliau@www1.cern.ch (Robert Cailliau)
Subject: WWW Conference URL

WWW94  --  First International Conference on the World-Wide Web

The Conference announcements and proceedings will be in the Web.
The URL is:

    http://www1.cern.ch/WWW94/Welcome.html

The information will be evolving; at this moment it is incomplete.
We intend to gather all contributions into the Web before the Conference.
Mail suggestions, contributions, remarks and questions to:

    www94@www1.cern.ch

And: indicate clearly whether or not you allow us to put your abstract or
contribution into the Web. Not all contributions will be accepted to get
time slots at the conference! Accepted contributions will be put on by
default.

Our best wishes for 1994, and may we meet in Geneva in May!


           Robert Cailliau
        World-Wide Web Project           | phone:  +41 22 767 5005
              C E R N                    | fax:    +41 22 767 8730
European Laboratory for Particle Physics | e-mail: cailliau@www1.cern.ch
         CH - 1211 Geneve 23             | diary:  http://www1.cern.ch/
           (Switzerland)                 |  CERN/Admin/Diaries/Robert.html





From FisherM@is3.indy.tce.com  Thu Dec 30 08:20:00 1993 PST
Message-Id: <2D2302D4@MSMAIL.INDY.TCE.COM>
Date: Thu, 30 Dec 93 08:20:00 PST
From: FisherM@is3.indy.tce.com (Fisher Mark)
Subject: Re: CGI, semicolons, and so on...


From what I see (which is a bit cloudy with only an email Internet 
connection), most WWW servers contain only public data so far.  If the Web 
spreads like we all hope that it will, eventually there will be servers that 
serve some or all data that should be access restricted.  This will probably 
be the case with our servers once we have an IP Internet connection, as we 
plan to use WWW & WAIS for a reference document repository.  The ability to, 
at will, change any script into a file by subtracting a ';' makes me 
nervous.  My suspicion is that there will be more cases where you do not 
want to serve scripts as files than there will be cases of wanting to serve 
scripts as files as the Web grows and gains commercial entities as servers. 
 The opacity or virtualization of the present scheme is nice, as the user of 
the URL does not have to concern her or himself with whether it represents a 
physical file or it is data created on the fly -- he or she just uses it. 
 As someone who lost work time due to the Internet worm, I favor having as 
much security as I can while still being able to share the data I want to 
share.

As far as the overhead for a single stat() call, I think that it is pretty 
small in the scheme of things.  Why even try writing a server in Perl, an 
interpreted language (which I love), if you need to worry about the overhead 
of a single stat() call?  Why even write one in C or C++ rather than 
assembler if a single stat call() can make the difference between a server 
with good response time vs. a server with poor response time?  The reason 
that programming languages have been getting higher and higher level as time 
passes is that human time (designing, writing, debugging, enhancing) gets 
more and more expensive relative to computer time.  If a script is going to 
be served often enough that one stat() call is significant, it should 
probably become its own service (like finger or ftp), with a direct, 
hardwired WWW gateway.
======================================================================
Mark Fisher                            Thomson Consumer Electronics
fisherm@tcemail.indy.tce.com           Indianapolis, IN

"Just as you should not underestimate the bandwidth of a station wagon
traveling 65 mph filled with 8mm tapes, you should not overestimate
the bandwidth of FTP by mail."



From sanders@BSDI.COM  Thu Dec 30 11:30:14 1993 -0600
Message-Id: <199312301730.LAA17181@austin.BSDI.COM>
Date: Thu, 30 Dec 1993 11:30:14 -0600
From: sanders@BSDI.COM (Tony Sanders)
Subject: Re: CGI and typing files by suffix 

> Does Plexus parse the URL by doing stats through the file system to
> find out where the "path/cmd" ends and the "args" begin?  I find this
Plexus has an associative array:
	map /man man.pl &do_man($top, $rest, $query)
So it just looks it up in the table and eval()'s it's contents.  Having
a fixed table of allowed scripts has it's features (security) and drawbacks
(manual updates).  However, I don't add scripts every day so I haven't
found it to be a problem myself.

> > The `;' scheme simply has too many drawbacks (namely you can't front-end
> > existing directory hierarchies with scripts).
> Could you explain this?  What couldn't you do with the ';' scheme that
> you can with the current scheme?
Let's say I currently have the URLs:
	http://server/man/1/ls
	http://server/man/1/cat
	...
Now, let's say I want to change this so that instead of a bunch of files
in the man directory I want to convert `man' to be a script (maybe I want
to generate the html on the fly, maybe I want to WAIS all the data and
provide a search engine as well as a browsing engine).  With the ';' scheme
I would have to change all the URLs in the world that point to my data to
read "http://server/man;html1/ls" (many of which I do not own or even know
about).  This is not acceptable.  This is a real-life situation, I have
done this and I know several other people who have done it (converted
a directory hierarchy to use a search gateway).

The only advantage to ';' is that it's a little easier to parse.  This
isn't a significant enough advancement that it's worth breaking the
script/non-script symmetry.

--sanders



From rst@ai.mit.edu  Thu Dec 30 12:07:57 1993 EST
Message-Id: <9312301707.AA04103@volterra>
Date: Thu, 30 Dec 93 12:07:57 EST
From: rst@ai.mit.edu (Robert S. Thau)
Subject: PATH_INFO on the cheap?

In re the current PATH_INFO discussion, it may be possible to cut the cost
of the current implementations by piggybacking on work which the server (at
least the NCSA server) is already doing anyway.

Here (I think) is the trick.  In order to do access control, the server is
already doing stuff like this (from my previous syscall trace):

  open ("/.htaccess", 0, 0666) = -1 ENOENT (No such file or directory)
  open ("/com/.htaccess", 0, 0666) = -1 ENOENT (No such file or directory)
  open ("/com/doc/.htaccess", 0, 0666) = -1 ENOENT (No such file or directory)
  open ("/com/doc/web-support/.htaccess", 0, 0666) = -1 ENOENT (No such file or directory)
  open ("/com/doc/web-support/cgi-bin/.ht".., 0, 0666) = -1 ENOENT (No such file or directory)

(Hmmm... would a /.htacess ever be particularly useful?  Never mind).

Suppose the pathname it's working on has appended PATH_INFO, say, something
like /usr/webhome/subdirectory/the-script/more/stuff/here.  Then we get a
cascade which looks more or less like this:

  open ("/.htaccess", 0, 0666) = -1 ENOENT
  open ("/usr/.htaccess", 0, 0666) = -1 ENOENT
  open ("/usr/webhome/.htaccess", 0, 0666) = -1 ENOENT
  open ("/usr/webhome/subdirectory/.htaccess", 0, 0666) = -1 ENOENT
  open ("/usr/webhome/subdirectory/the-script/.htaccess", 0, 0666) = -1 ENOTDIR

Note the error codes.  Once the server has seen ENOTDIR, if it ever does
before running out of apparent directories, it can tell it has found the
actual directory containing the script (and in fact, the script itself,
which is not a directory).  The rest of the pathname must be PATH_INFO,
since it corresponds to nothing in the filesystem.  The cost for this case
(PATH_INFO present) is one failed filesystem lookup with no subsequent
access check.

If PATH_INFO is absent, on the other hand --- that is, if the submitted URL
after alias translation refers to an actual file, such as

  /usr/webhome/subdirectory/the-script

then the last apparent directory in the translated pathname is

  /usr/web/home/subdirectory

so the last open call above never happens (why should it?).  The entire
pathname corresponds to something in the filesystem, so PATH_INFO must be
null.  The cost for this more common case (PATH_INFO absent) is zero ---
the server would be doing all those system calls anyway.

Is it inelegant to combine the two directory walks like this?  Perhaps.
I'm certainly not about to change the code to do this in order to gain  
what I regard as a fairly minor efficiency bum --- but then again, I'm
running the server on the machine which has the disks to avoid network
filesystem overhead.  However, I do think it's possible.

One unrelated point, to clear up a misunderstanding.  I have *not*
expressed distaste for the redirection mechanism of HTTP/1.0.  I like it.
I use it.  There are plenty of useful things that you can't do without it.

I have expressed distaste for the specter of server config files that could
ultimately grow to look like:

  Redirect ...
  Redirect ...
  Redirect ...
  Redirect ...
  Redirect ...
  Redirect ...
  Redirect ...
  ...

with one line for every time that I or anybody else here has changed their
mind.  I'm not so much bothered by the overhead this puts on the server,
although that's there, as I am by the unmaintainability of the scheme
itself --- even if the redirection information is distributed, rather than
locked up in a single global config file, it means putting bits of history
and loose ends all over the place for people to trip on, which is a
prospect I find quite unattractive.

rst



From john@math.nwu.edu  Thu Dec 30 10:37:26 1993 -0600 (CST)
Message-Id: <9312301637.AA01034@hopf.math.nwu.edu>
Date: Thu, 30 Dec 1993 10:37:26 -0600 (CST)
From: john@math.nwu.edu (John Franks)
Subject: Re: CGI, semicolons, and so on...

According to Fisher Mark:
> The ability to, 
> at will, change any script into a file by subtracting a ';' makes me 
> nervous.  My suspicion is that there will be more cases where you do not 
> want to serve scripts as files than there will be cases of wanting to serve 
> scripts as files ...

I think there is some confusion here.  The suggestion under discussion
was to have a URL in which a path ending in ';' indicated a *request*
by the client to execute a file and one without the ';' indicated a
*request* to view it as a file.  In my opinion, no sensible server
implementor would design a system where permission to execute a script
implied permission to to view it as a text file or vice versa.
Certainly no one in this discussion made that suggestion.

Any mechanism to determine who has permission to do what must necessarily
be independent of the URL since the client can write any URL it wants.

Other reasons have been pointed out why it is not a good idea to have
the existence of PATH_INFO data (i.e. a ';') imply the file is to be
executed.

John Franks 	Dept of Math. Northwestern University
		john@math.nwu.edu





From john@math.nwu.edu  Thu Dec 30 10:22:01 1993 -0600 (CST)
Message-Id: <9312301622.AA01013@hopf.math.nwu.edu>
Date: Thu, 30 Dec 1993 10:22:01 -0600 (CST)
From: john@math.nwu.edu (John Franks)
Subject: Re: CGI and typing files by suffix

According to Tony Sanders:
> According to John Franks:
> > According to Robert S. Thau:
> > > n) There should not be any indication within the URL, selector string,
> > >    etc., as to whether or not a retrieval will cause a script to be
> > >    invoked.
> Yes, this is a MUST in my book.
> 

OK, I would be happy to allow this to be an implementation dependent
feature.  Some implementations could use "cgi-bin", others ".doit",
others the execute bit and still others could encode this information
in the part of the URL path before the PATH_INFO data since that part
of the URL is opaque even to CGI.

> > It is a bad idea to do so, but surely it should be *possible* with any
> > HTTP/1.0 server to put up a GIF file with the name foo.au and have it
> > work perfectly.

> It is indeed possible and does work.

> >  BTW, the reason it is a bad idea is precisely the
> > same reason it is a bad idea to have PATH_INFO data look like part of
> > the path -- it is misleading and obscure.

> I fail to see how:
>     http://server/path/cmd;args
> Is really any clearer or better than:
>     http://server/path/cmd/args
> 

Does Plexus parse the URL by doing stats through the file system to
find out where the "path/cmd" ends and the "args" begin?  I find this
objectionable.  I don't really care how efficiently one can do stats,
or whether one can patch NCSA httpd to need fewer stats than the
original.  If this is the best way to implement this protocol then
IMHO the protocol is badly designed.


> The `;' scheme simply has too many drawbacks (namely you can't front-end
> existing directory hierarchies with scripts).
> 

Could you explain this?  What couldn't you do with the ';' scheme that
you can with the current scheme?





From robm@ncsa.uiuc.edu  Thu Dec 30 12:02:26 1993 -0600
Message-Id: <9312301802.AA25907@void.ncsa.uiuc.edu>
Date: Thu, 30 Dec 1993 12:02:26 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI suggestion

/*
 * CGI suggestion  by ts (decoux@moulon.inra.fr)
 *    written on Dec 28,  5:12pm.
 *
 * 
 *  URL are :
 *   http://server/cgi-perl/script/extra_path
 *   http://server/cgi-csh/script/extra_path
 * 
 *  I can't have :
 *   http://server/cgi-bin/perl/script/extra_path
 *   http://server/cgi-bin/csh/script/extra_path
 * 
 * 
 */

Why not? You should be able to create a perl subdirectory or a csh
subdirectory in cgi-bin. 

--Rob



From robm@ncsa.uiuc.edu  Thu Dec 30 12:00:48 1993 -0600
Message-Id: <9312301800.AA25865@void.ncsa.uiuc.edu>
Date: Thu, 30 Dec 1993 12:00:48 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI Suggestion

/*
 * CGI Suggestion  by Charles Henrich (henrich@crh.cl.msu.edu)
 *    written on Dec 28, 11:07am.
 *
 * I would like to propose that instead of (or if we must, as well as) allowing
 * the embedding of information in the path (which is really poor!) we should
 * special case the character ';' to mean end of URL for the client.  This would
 * allow folks to use
 * 
 * http://machine/documentpath;info that can be passed to programs.
 * 
 * In the above case the server would return the document /documentpath, but keep
 * the ';' information intact for scripts and programs. Forcing the server to have
 * to stat each directory level is an incredibly waste of resources, and thats
 * doubly so for AFS!
 * 
 * Thoughts?
 */

Actually, I'm going to add a small patch I came up with over the holidays
which will make the average case require one stat, which is fairly
insignificant.

--Rob



From robm@ncsa.uiuc.edu  Thu Dec 30 11:59:37 1993 -0600
Message-Id: <9312301759.AA25849@void.ncsa.uiuc.edu>
Date: Thu, 30 Dec 1993 11:59:37 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI suggestion

/*
 * Re: CGI suggestion  by John Franks (john@math.nwu.edu)
 *    written on Dec 28,  9:46am.
 *
 * > Marc Andreessen writes:
 * > > Who is "I" in this context?  If I == the server, then the server's
 * > > file hierarchy is in fact known.  If I == some user, then it doesn't
 * > > matter one way or the other, does it (since the URL should be
 * > > considered opaque anyway)?  I'm probably missing something...
 * > 
 * 
 * Well the "I" might be a server maintainer who is not fully cognizant
 * of the details of CGI, and would expect something which looks like
 * a path to a file to be one.  Such a maintainer may not, in the best
 * of all possible worlds, really *need* to know what is going on, but
 * that won't prevent mail to the developers saying "File /cgi-bin/foo1/foo2
 * is not in the distribution I got; where is it?"
 * 
 * Also is it really clear that no future caching mechanism will ever
 * need to parse the URL?

I would hope so, since the contents after the third slash are very
server-dependent.

 * >  Actually you can't have a subdirectory under "/cgi-bin". Example :
 * > 
 * >  http://server/cgi-bin/subdir/script/extra_path
 * > 
 * >  With this URL server, actually, call "subdir" and not "subdir/script"

I don't understand where this impression is coming from. /cgi-bin is in no
way special, and you can in fact have multiple subdirectories under a
ScriptAlias directory (I just tried it).

 * This is something that was not clear to me from reading the spec.  I
 * did not realize that the name "cgi-bin" was in any way special. Is,
 * in fact, "cgi-bin" going to be a reserved word in http URL's?  If so
 * then my objection about parsing is not well founded.  This is easy
 * enough to parse -- it will still confuse some people though.  It also
 * seems like a rather artificial restriction.  Am I correct in my
 * understanding that this means that any subdirectory of cgi-bin is
 * inaccessible to a client querying the server?
 * 
 * Could we clarify the CGI spec some more?
 *
 * 1. Is "cgi-bin" a reserved directory name?
 
no

 * 2. Can it be anyplace in the directory hierarchy?
 
yes

 * 3. Can a server have more than one cgi-bin?

yes

 * and most importantly
 * 
 * 4. Is it the case that in any URL containing "cgi-bin" everything
 *    from the second '/' after "cgi-bin" to the end of the URL is always
 *    path info, optionally followed by a ? and a query string?

no

 * If the answers to questions 1-4 are all "yes", then I will withdraw my 
 * suggestions. I still think this is a less than optimal syntax, but it
 * is usable.
 */

--Rob



From robm@ncsa.uiuc.edu  Thu Dec 30 12:06:03 1993 -0600
Message-Id: <9312301806.AA25963@void.ncsa.uiuc.edu>
Date: Thu, 30 Dec 1993 12:06:03 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI Suggestion

/*
 * Re: CGI Suggestion  by John Franks (john@math.nwu.edu)
 *    written on Dec 28, 10:52am.
 *
 * According to Charles Henrich:
 * 
 * > I would like to propose that instead of (or if we must, as well as) allowing
 * > the embedding of information in the path (which is really poor!) we should
 * > special case the character ';' to mean end of URL for the client.  This would
 * > allow folks to use
 * > 
 * > http://machine/documentpath;info that can be passed to programs.
 * 
 * I think this is a much cleaner suggestion than the current scheme

I suppose it's cleaner, but special cases the ; in URLs...


[extra stats]

 * This was what I saw as problmatic also.  But, in fact, that isn't the way
 * that NCSA httpd, at least, works (as Guy Descoux pointed out).  What it
 * does is read some magic names (like "cgi-bin") from a configuration file
 * and assume that the first thing in the path after the magic name is a
 * script and anything else is info.  It is not necessary to stat anything.

No, it doesn't, that's what Charles is talking about. Currently it assumes
nothing about the path and stats each level until it finds something it can
use.

 * This is workable, but less clean than either Charles suggestion or my
 * earlier one (the maintainer has to set up and maintain the magic
 * names, for example).  I also agree with Charles that embedding
 * information in a path is "really poor", primarily because it is
 * potentially confusing.
 */

Well, confusing yes, but it makes for some interesting filters, such as

/cgi-bin/get-annotations/foo/bar/foo.html

which, with PATH_TRANSLATED, allows you to seamlessly get group annotations
for a document.

--Rob



From robm@ncsa.uiuc.edu  Thu Dec 30 12:15:27 1993 -0600
Message-Id: <9312301815.AA26073@void.ncsa.uiuc.edu>
Date: Thu, 30 Dec 1993 12:15:27 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI/1.0 --- what's wrong with the status quo?

/*
 * CGI/1.0 --- what's wrong with the status quo?  by Robert S. Thau (rst@ai.mit.edu)
 *    written on Dec 28, 12:02pm.
 *

[URLs in which you can't distinguish the script from its parameters]

 * My question is, what's wrong with this?  It doesn't confuse me --- I know
 * that 'info' is the script, 'rel' is a parameter, and the rest is info file/
 * node name --- that's the way I chose to set it up.  And as for clients, I
 * would tend to view these alternatives as implementation details which are
 * none of their business.  

I agree completely. I have gotten some rather confused tech support
questions regarding imagemap, so John's point about confusion is valid, but
I think generally people understood when I explained it to them.

 * (Really picky observers may note that these aren't
 * quite the same as the URLs used by the info gateway I'm actually running
 * --- in particular, for back compatibility with an older hack, I'm covering
 * up the 'rel' parameter with a ScriptAlias, but this is a reflection of
 * what's actually going on under my hood).

Hmm, that breaks the modification I was going to make to reduce the number
of stats required. I'll have to rethink it.

 * In fact, I've found the status quo to be in some respects insufficiently
 * flexible.  For instance, it's awkward to have to put Guy Brooker's archie
 * script in a different directory from its coversheet, at potentially far
 * remove.  To deal with this, I've modified my NCSA httpd so that it is
 * capable of running scripts from (some of) the same directories it would
 * ordinarily search for files, under control of a RunScripts allow-option.
 * (The scripts are distinguished from ordinary files by a naming convention
 * which isn't visible to the clients, and PATH_INFO works --- as indicated
 * above, I'm using it.  BTW, I'd be willing to give the changes out as a
 * patch to anyone interested, and willing not to look a gift horse too close
 * in the mouth).

Is this like a ScriptAlias in .htaccess files? If so, I could add such a
capability.

 * With this all in mind, my comments on the two changes which seem to be on
 * the table:
 * 
 * 1) Having a magic character which delimits CGI script parameters ---
 * 
 *    I could live with this, although as I say, I really don't think it's
 *    much of the client's business.  However, it would require modifying
 *    every script out there which takes PATH_INFO --- and every invocation of
 *    one.  (That means every use of imagemap, among many others).

I could live with this as well, but it does in fact break every script out
there. I'm very leery of making Yet Another Incompatible Script Interface,
since we already have two and it's confusing the hell out of people. I don't
know if the potential gains are enough to merit the costs.

 *    BTW, with regard to the specific point that the status quo requires the
 *    daemon to do 'wasted' stats to discover where the script name ends, it's
 *    worth remembering that the daemon may be doing a lot of stats anyway for
 *    other purposes --- the NCSA daemon, for instance, walks the directory
 *    hierarchy repeatedly during access checks, looking for .htaccess files
 *    and symlinks.  In any case, compared with the load of running a Bourne
 *    shell script --- forking and execing a process which is likely to fork
 *    and exec many more --- these stats are pretty trivial.

Unfortunately under AFS stats are expensive, which is Charles's main problem
as I've seen it. However, it is also worth noting that in things like
directory indexing, future versions (i.e. 1.1) will probably stat the files
in a directory to determine their type, which is costly under AFS. 

Of course, as an aside, I'm starting to wonder just what isn't costly under
AFS (yes, we run it here, no I don't run it on my workstation).

 * 2) As an alternative, requiring a fixed string at the name of any URL which
 *    might invoke a script ---
 * 
 *    This would set in stone the notion of separate, parallel directory
 *    hierarchies for scripts and everything else.  As indicated above, I
 *    don't like that notion much at all.
 */

Neither do I.

--Rob



From robm@ncsa.uiuc.edu  Thu Dec 30 12:24:12 1993 -0600
Message-Id: <9312301824.AA26168@void.ncsa.uiuc.edu>
Date: Thu, 30 Dec 1993 12:24:12 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI/1.0 --- what's wrong with the status quo?

/*
 * Re: CGI/1.0 --- what's wrong with the status quo?  by John Franks (john@math.nwu.edu)
 *    written on Dec 28,  2:46pm.
 *
 * Well, you ask what is wrong with the status quo and then tell us about
 * the modifications you have made to your server in order to get around
 * one of the problems which wouldn't exist if either of the suggestions
 * made by Charles Henrich and myself were adopted.  You are absolutely
 * right that there is no reason that the script and coversheet should
 * have to be in different directories.  

The suggestions made by Charles have nothing to do with the particular
problem he's bringing up, what he's done is made it so that the run-time
config files can define scripts in their directories. I don't see how your
suggestion of placing an = in the extra path information helps this unless
you are requiring every script to have extra path information. What Charles
suggested is to have a semicolon before the extra path information, again,
this does not help the particular situation he added code for unless you
require extra path information to scripts! 

What am I missing about your proposal or Charles's that will alleviate this?

 * There is also no reason that
 * directories containing scripts have to be listed in configuration
 * files and processed on server start up.  
 
As a server administrator I would say that I should have at least some
control over what people are running on my server... 
 
 * Or that scripts need to be
 * distinguished from ordinary files by a naming convention which the
 * server presumably decodes.  Adding unnecessary complexity to the
 * server is undesirable.  You have now added more code to your server
 * and you still don't have the functionality (much less the simplicity)
 * that a very minor change in the protocol would give.

Which change is this? I must not understand your proposal. I will add that
the Alias mechanism is already there, and that allowing ScriptAlias from
config files is a realatively minor change.

 * I have to plead guilty to starting this discussion at much too late a
 * date.  The suggestions should have been made several months ago when
 * the CGI standard was still in flux.  One possibility is that this
 * issue could be addressed in CGI/1.1.  I would point out that nothing
 * suggested requires any change in browsers and changes to scripts and
 * servers should be very minimal.  I think that relatively few scripts
 * currently use PATH_INFO.

Well, for every tech support question I still get about the NCSA script
interface, I will testify that even the most minor change, especially the
incompatible ones, is potentially a very major change.

 * I would be interested in hearing from server writers, like Rob McCool, Tony
 * Sanders and the CERN server author.  Also the views of script writers 
 * would be valuable.  Are there examples of widely used scripts that would
 * break?
 */

imagemap would require additional changes.

--Rob



From bobs@sco.com  Thu Dec 30 10:24:16 1993 PST
Message-Id: <9312301024.aa20688@scobob.sco.com>
Date: Thu, 30 Dec 93 10:24:16 PST
From: bobs@sco.com (Bob Stayton)
Subject: server setting the content-type

Is there any way to have the NCSA server set the content
type of a file as text/html if it starts with the <HTML>
tag rather than by its filename extension?

Our site has a mixture of character and graphical terminals, so we
are trying to use both mosaic and lynx.  I've noticed an
inconsistency between the two in reading HTML files from an
NCSA 1.0 server.

- In mosaic, an HTML file named "foo" will display as
formatted text if it contains a <TITLE> tag.

- In lynx, such a file will be interpreted as text and
display the HTML tags.  In order for it to be shown as
formatted text, I had to change my server's srm.conf file to:

DefaultType text/html

so that the delivered document has the proper Content-type
header for HTML.  But that means text files will be
interpreted as HTML also and not display properly.

We have good reasons not to add ".html" to each
HTML document, but we also don't want to add .txt
to every text document.  

I talked with Lou Montulli about the inconsistency
and he suggested that it should be the server that
types a file, not the client.  I seem to agree with
him, hence my question.  It would seem pretty
easy for the server to look at the top of the file for the
<HTML> signature and deliver it with that content-type.

bobs
Bob Stayton                                 425 Encinal Street
Technical Publications                      Santa Cruz, CA  95060
The Santa Cruz Operation, Inc.              (408) 425-7222
                                            bobs@sco.com



From robm@ncsa.uiuc.edu  Thu Dec 30 12:39:01 1993 -0600
Message-Id: <9312301839.AA26373@void.ncsa.uiuc.edu>
Date: Thu, 30 Dec 1993 12:39:01 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI/1.0 --- what's wrong with the status quo?

/*
 * Re: CGI/1.0 --- what's wrong with the status quo?  by Robert S. Thau (rst@ai.mit.edu)
 *    written on Dec 28,  5:32pm.
 *
 * First off --- CGI/1.0 already has a naming convention which some people
 * find at least irksome, the 'nph-' business.   Secondly --- if scripts and
 * ordinary files coexist in the same directories, and the server can't tell
 * them apart by the names, then how *can* it tell them apart?  How is the
 * server to know whether to read the file or to run it?
 *
 * I suppose one could do something with file permissions, but I honestly
 * prefer suffixing the name with '.doit'.  The trouble with using permission
 * bits is that stray 'x' bits do occasionally get set on ordinary files.

I agree about stray x bits, but I don't know about a suffix convention
either. I tend to prefer a config. file directive, since it gives the
administrator a bit more control over what is being executed in his/her
server.

 * With my server the way it is, this doesn't matter.  On the other hand, if
 * the server were using the x bits to tell whether to run the file, and a
 * stray 'x' bit landed on some gateway's conversheet, the server would
 * wind up trying to exec() a file full of HTML, fail, and return a '500
 * Server Error' which *really* confuses the hell out of some poor novice.
 * ("The file is there.  Why can't the server read it?").

Ayup.

 * In short, the naming convention makes it obvious, simply by looking at a
 * file, whether it is a script which the server should run, or an ordinary
 * file which the server should just throw over the transom.  From a *user's*
 * perspective, that's simplicitly --- even if it takes ten more lines of code
 * in the server.  (This is not an exaggeration, BTW --- see below).

A naming convention is just as flexible if you were to use a psuedo mime
type, such as application/x-www-cgi-script, and then map multple suffixes to
it (say, .cgi, .pl, .exe, you get the picture.)

 * As the author of several scripts, I regard
 * your proposed changes as *adding* complexity, by giving me one more
 * inessential detail to keep track of.  Granted, the server code does become
 * perhaps a little simpler, but see below for more on how I see the
 * tradeoff...

I agree here...

 * In any case, the amount of code I have added to the server is *minimal* ---
 * the total number of lines changed or added is well under 200.  If I deleted
 * all of the code related to ScriptAlias (which I no longer actually use), I
 * think the server would actually shrink substantially.

The code used by ScriptAlias is actually just a minor piece of the actual
Alias engine, which, if you removed it, would probably clock in under 100
lines.
 
 * > All I am saying is SIMPLE IS GOOD.  Unnecessary complexity
 * > is bad.
 * 
 * I suppose most people would agree with this in the abstract --- until you
 * get around to the tricky issues of what exactly is "complexity", and what
 * is "necessary", from whose perspective.  In particular, as I've said, you
 * are proposing to *add* complexity from the perspective of the script writer
 * --- in terms of requiring a fixed form for the parameters of their scripts,
 * which is one more inessential detail to keep track of and get right --- in
 * order to keep *your* code simple and clean:

I would agree with that abstract too. Perhaps it would have been better if
Charles had made his suggestion a month ago. At that time, it probably would
have made it into the CGI spec.

But it's too late now. Any changes we make that will break old scripts are
going to have to be scrutinized and their costs and benefits weighed
carefully to avoid a negative impact on the growing base of script authors.

 * The simplicification is in whatever routine in the server identifies the
 * PATH_INFO parameters to a CGI script.  In the distributed NCSA server, this
 * routine is 22 lines of code (get_path_info in http_script.c), two of which
 * are blank.  In my version, it's 62 lines, but I can shrink it to 29 by
 * reverting to the original code's K&R brace style, and stripping out blank
 * lines and comments.  (BTW, I'm counting these 33 lines of braces and
 * whitespace in the change count above.  Also, BTW, the extra nine lines of
 * executable code here are the ones that add the '.doit' and '.nph' suffixes
 * before checking for the existence of the script --- the naming convention
 * mentioned above.  We are not talking about an enormous amount of code to
 * implement *any* of this stuff).

Well, NCSA httpd it's simple, I don't know about the others... At any rate,
most of the time this stuff is never a lot of code, it's just agreeing on
protocols etc....

 * The complication is in every CGI script that takes PATH_INFO.  At my site,
 * that includes 'imagemap' (which may well be the single most used CGI script
 * anyplace), my info gateway, and several scripts which form a community
 * hotlist system which I'm playing around with, along with a few more minor
 * experiments.

I've seen countless others... the documentation for CGI currently ``sucks'',
which has limited its acceptance thus far, but there is still a substantial
script authoring community which we have to keep in mind when considering
protocol changes.

 * > I would be interested in hearing from server writers, like Rob McCool, Tony
 * > Sanders and the CERN server author.  Also the views of script writers 
 * > would be valuable.  
 * 
 * I've never written a whole server, but I have written several nontrivial
 * scripts.  You've got my opinion...
 */

Certainly, I would like to hear from script authors as well since their
input is a lot more important than the server authors to me... the script
authors are the ones who have to use what we put out.

--Rob



From robm@ncsa.uiuc.edu  Thu Dec 30 12:46:29 1993 -0600
Message-Id: <9312301846.AA26584@void.ncsa.uiuc.edu>
Date: Thu, 30 Dec 1993 12:46:29 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: server setting the content-type

/*
 * server setting the content-type  by Bob Stayton (bobs@sco.com)
 *    written on Dec 30, 10:24am.
 *
 * Is there any way to have the NCSA server set the content
 * type of a file as text/html if it starts with the <HTML>
 * tag rather than by its filename extension?

Unfortunately not.

 * Our site has a mixture of character and graphical terminals, so we
 * are trying to use both mosaic and lynx.  I've noticed an
 * inconsistency between the two in reading HTML files from an
 * NCSA 1.0 server.
 * 
 * - In mosaic, an HTML file named "foo" will display as
 * formatted text if it contains a <TITLE> tag.
 * 
 * - In lynx, such a file will be interpreted as text and
 * display the HTML tags.  In order for it to be shown as
 * formatted text, I had to change my server's srm.conf file to:
 * 
 * DefaultType text/html
 * 
 * so that the delivered document has the proper Content-type
 * header for HTML.  But that means text files will be
 * interpreted as HTML also and not display properly.
 * 
 * We have good reasons not to add ".html" to each
 * HTML document, but we also don't want to add .txt
 * to every text document.  
 * 
 * I talked with Lou Montulli about the inconsistency
 * and he suggested that it should be the server that
 * types a file, not the client.  I seem to agree with
 * him, hence my question.  
 
Yes, he is right, it's the server's problem. Unfortunately there isn't too
much that can be done in the current framework to help you... MIME typing is
currently all done either by filename extension or explicit config.
directives (AddType in .htaccess files).

 * It would seem pretty
 * easy for the server to look at the top of the file for the
 * <HTML> signature and deliver it with that content-type.
 */

Um, well, it would be easy, but I don't think it should be done, since
binary files that happen to begin with <HTML> will confuse the server. If
it's a solution that works for you, hacking it in should not be any big
deal.

--Rob



From robm@ncsa.uiuc.edu  Thu Dec 30 12:51:49 1993 -0600
Message-Id: <9312301851.AA26727@void.ncsa.uiuc.edu>
Date: Thu, 30 Dec 1993 12:51:49 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: 

/*
 *   by John Franks (john@math.nwu.edu)
 *    written on Dec 28,  5:30pm.
 *
 * According to Robert S. Thau:
 * >
 * > First off --- CGI/1.0 already has a naming convention which some people
 * > find at least irksome, the 'nph-' business.   
 * 
 * I too find it irksome.  Not horrible, but irksome.

At the time, it was either that or a config file directive. Eventually we
opted for the nph- syntax as the lesser of two evils. If anyone has any
cleaner suggestions I'm listening.

 * > Secondly --- if scripts and
 * > ordinary files coexist in the same directories, and the server can't tell
 * > them apart by the names, then how *can* it tell them apart?  How is the
 * > server to know whether to read the file or to run it?
 * > 
 * 
 * Using Charles Henrich's suggested syntax, for example, URLs like
 * 
 * 	http://host/path/script;
 * 	http://host/path/script;foo
 * 	http://host/path/script;foo?bar
 * 
 * would all be scripts.  I.e. the presence of the ';' indicates it is
 * executable.  An trailing ';' just indicates an empty PATH_INFO.
 * 
 * > 
 * > > Adding unnecessary complexity to the
 * > > server is undesirable.  You have now added more code to your server
 * > > and you still don't have the functionality (much less the simplicity)
 * > > that a very minor change in the protocol would give.
 * > 
 * > I'm not sure what you're getting at.  What functionality don't I have?
 * > Please be specific --- show me something I can't do.  
 * 
 * OK, it is not a big deal, but I do think the current syntax has less
 * functionality and is less flexible than the one described above. If I
 * understand you correctly with your server you can't have a script with
 * an arbitrary path and an arbitrary name.  You must either have a magic
 * directory name like "cgi-bin" in the path above the script or the
 * script must have a name ending in a special suffix like ".doit".  On
 * my server, I have scripts which are both executed and served as text
 * documents.  Which of these is done depends on how the URL references
 * them.  In the syntax described above, for example, the script would be
 * executed if the URL ends with ';' and treated as a document
 * otherwise.  I know you can do the same thing by making a symbolic link
 * to your script with a doit-less name, but this is, as you put it,
 * just "one more inessential detail to keep track of".

Well, requiring a ; in script names isn't that bad, but again, it breaks
everything that's already out there and I'm really hesitant to do that. 


 * Now, could you explain, how the ';' mechanism is more complex than the
 * current syntax?  I find it hard to see how writing a script which
 * outputs
 * 
 * 	http://host/path/script;info
 * 
 * is more complicated than one which outputs
 * 
 * 	http://host/path/script/info
 * 
 * The value of the environmental variable PATH_INFO would be the same
 * with either syntax, so that couldn't make any difference.

Personally, I don't see any added complexity, however, we have to keep the
installed script base in mind. I sure as hell don't want to go into all of
my script-using HTML docs and add a ; to the end of every script HREF.

 * Also could you explain why you find the ';' mechanism less flexible
 * than the current syntax.  I think the example above shows that the ;
 * mechanism is *more* flexible than the current one.  Since it would be
 * trivial to translate the ';' to a '/', I think it is clear that
 * Charles' suggested syntax contains at least as much information as the
 * current syntax and hence is at least as flexible.
 */

Yes, I agree, it is a syntactical change that should have been included a
month ago, since it avoids a lot of stat()'s and apparently some confusion,
but to me it seems that we should keep what we already have.

--Rob



From jonm@ncsa.uiuc.edu  Thu Dec 30 12:58:34 1993 CST
Message-Id: <9312301858.AA26839@void.ncsa.uiuc.edu>
Date: Thu, 30 Dec 93 12:58:34 CST
From: jonm@ncsa.uiuc.edu (Jon E. Mittelhauser)
Subject: Re:  server setting the content-type

>- In mosaic, an HTML file named "foo" will display as
>formatted text if it contains a <TITLE> tag.

This is only true of the X-Windows version (and maybe Mac) and is the result of
a hack that Marc threw in back in HTTP/0.9 days.  In my opinion,
it is a bug and I have told Marc and Eric such.  The windows
version does not try to out-guess the server.  If a HTTP/1.0 server
returns type text/plain, we display it as plain text even if it
contains HTML.  I consider this to be the correct behavior.  The
upshot, of course, is that we repeatedly get bug reports that "this
file works in the X-version but not in the windows version".  The fact
is, the server is telling us that it is plain text so we are displaying
it as such.

>- In lynx, such a file will be interpreted as text and
>display the HTML tags.  In order for it to be shown as
>formatted text, I had to change my server's srm.conf file to:
>
>DefaultType text/html

This is the correct behavior.  The server in (HTTP/1.0) should be
doing all the typing.  This enables a person to put a document up
that shows source HTML via typing it as text/plain.  The X version
of Mosaic will always display it as formatted HTML...

>so that the delivered document has the proper Content-type
>header for HTML.  But that means text files will be
>interpreted as HTML also and not display properly.

>We have good reasons not to add ".html" to each
>HTML document, but we also don't want to add .txt
>to every text document.  

If you have files with identical extensions, you are going to have to
tell the server on a file (or directory) basis what the type is...

-Jon

---
Jon E. Mittelhauser (jonm@ncsa.uiuc.edu)
Research Programmer, NCSA                          (NCSA Mosaic for MS Windows)
More info <a href="http://www.ncsa.uiuc.edu/SDG/People/jonm/jonm.html">here</a>



From robm@ncsa.uiuc.edu  Thu Dec 30 13:10:42 1993 -0600
Message-Id: <9312301910.AA26941@void.ncsa.uiuc.edu>
Date: Thu, 30 Dec 1993 13:10:42 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI, semicolons, and so on...

/*
 * Re: CGI, semicolons, and so on...  by Robert S. Thau (rst@ai.mit.edu)
 *    written on Dec 29,  1:46pm.
 *
 * John Franks says:
 * 
 * > Also could you explain why you find the ';' mechanism less flexible
 * > than the current syntax.  I think the example above shows that the ;
 * > mechanism is *more* flexible than the current one.  Since it would be
 * > trivial to translate the ';' to a '/', I think it is clear that
 * > Charles' suggested syntax contains at least as much information as the
 * > current syntax and hence is at least as flexible.
 * >
 * >	http://host/path/script;
 * >	http://host/path/script;foo
 * >	http://host/path/script;foo?bar
 * >
 * > would all be scripts.  I.e. the presence of the ';' indicates it is
 * > executable.  
 * 
 * You regard this as more flexible because 'GET /path/script;' runs the
 * script, while 'GET /path/script' returns it as a file.  I could actually do
 * pretty much the same thing --- to have 'GET /path/script' run the script,
 * while 'GET /path/script.doit' would return it as a file.  I don't, out of
 * sheer paranoia --- there is actually an extra line of code which I threw in
 * deliberately to *prevent* this from working.  To put it bluntly, if there's
 * a Bourne shell script on my machine which anyone in the world can run, I
 * don't want to let them read it as well without knowing I have done so.
 * Some of them are nasty, and some of the nasty ones know more about the
 * Bourne shell than I do.  But, if that extra line of code offends you, you
 * don't have to write it.

John, correct me if I'm wrong, but I believe you were referring to a method
in which GET /path/script would return a cover page, and GET /path/script;
would execute a script. 

This is fine, except I would REALLY like to see the scripts and documents
transparent. The original goal of the scripts was to make documents on the
fly... I would like to be able to interchange scripts and documents when I
feel like it, for instance, when a script is no longer being offered.

 * The flexibility that concerns me more is my flexibility to decide whether a
 * particular URL is going to run a script at all, or not --- and having made
 * that choice, to change my mind.  Suppose, for instance, that I have a
 * document which is frequently referenced, and I want to add something to it
 * for local eyes only.  One thing I could do, with my current setup, is to
 * turn it into a script, which only prints certain parts of the boilerplate
 * if the connection has come from inside the lab.  

Yes, this goes back to the point being made earlier (I just sent the note a
few minutes ago) about having to change references to scripts. I don't want
to see scripts being referenced explicitly with a ;, I would much rather use
config file directives or suffixes.

 * Now, with your variant of Charles' proposal, this means changing the name
 * of it as well --- I'd have to add that extra semicolon.  Then, I'd have to
 * either track down and change all the references to the old name (a messy
 * chore), or add a Redirect line to srm.conf (which gets ugly when they start
 * to pile up).  And --- to return to an earlier point --- if I wasn't
 * extremely careful about how I wrote the script, then a client who left off
 * the semicolon would get to see the eyes-only matter anyway, and find out a
 * little about my security setup as an added bonus.  ("Oh, so he trusts the
 * nameserver? Hmmmm....")  Because the client can read the script, the whole
 * point of having a script there in the first place has been lost.  This sort
 * of thing is why I *don't* regard the free export of the code of the scripts
 * that I'm running as an "inessential" matter.

I don't know if the point was being able to get the source to a script as
much as it was to get the cover sheet for a script.

 * In short, what I mean by flexibility is the ability to make these kinds of
 * changes --- turning an ordinary file into a script, etc. --- without having
 * to track down all the references and change *those* as well.  Requring
 * special syntax to invoke a script denies me this flexibility; it makes what
 * *ought* to be local changes into global ones.

I agree, the server has domain over what is after the third /, which has
always been reflected in NCSA httpd's design. Whether a document is a script
or a document is the domain of the server alone, and I think we need to keep
the arbitrary nature of script execution.

 * So much for my "flexible".  Now, I'm still confused by your "functional"
 * --- since, as we seem to agree, there is no script which *couldn't* be
 * written to work either way, it seems to me that there is no difference in
 * functionality whatever.  It's just that (aside from the question of
 * changing a "standard" after it was promulgated), one thing is, IMHO, rather
 * easier to keep secure and to administer.
 */

To throw in some of my chips, I would have gladly added Charles's ORIGINAL
proposal (i.e. just replace the first / of the path info with a ;) to CGI
had it been made a month ago, but I feel it's too late now. I don't like the
idea of requiring a ; in every script execution.

--Rob



From robm@ncsa.uiuc.edu  Thu Dec 30 13:21:57 1993 -0600
Message-Id: <9312301921.AA27026@void.ncsa.uiuc.edu>
Date: Thu, 30 Dec 1993 13:21:57 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: your mail

/*
 * Re: your mail  by Robert S. Thau (rst@ai.mit.edu)
 *    written on Dec 29,  1:54pm.
 *
 * First off, with regard to aesthetics, de gustibus non disputandum est.  My
 * personal 'aesthetic' objection to the semicolon syntax is that it keeps me
 * from changing directories to scripts-with-path_info and back without making
 * the change in status visible in the URLs and making me change all the
 * references.  (I don't think this is a totally wild idea --- I've been
 * chewing over turning the 'people' directory on my server into a script
 * which redirects to ~.../public_html areas if they exist for the user in
 * question, and makes up a default home page if they don't).  

I agree. We need to keep the script/document distinction arbitrary.

 * Still, so long as I can turn an ordinary *file* into a script and back
 * without having to find and change everything that cites it (which can be a
 * real pain in the butt) or doing an Alias or Redirect in srm.conf (which
 * could get ugly if they started to add up), this isn't a *major* issue.  If
 * the new syntax is an optional alternative, I have no real objection (though
 * somebody else might --- two ways of specifying PATH_INFO does add a little
 * complication to the server).  I'm frankly more hung up on the notion of
 * incompatible changes to something which has been announced as a standard,
 * over what I see as quite minor efficiency concerns.

But it is a major issue for confusion.... if we're changing the first / of
path info to a ;, but we still support the old method, then what have we
gained? A prudent server would have to do the stats anyway, although it
could search for a ;, which would alleviate the stats in a few cases (but
not all, which to me is a crucial point in determining if this change is
worth pursuing).

 * This efficiency argument is apparently the nub of the dispute --- I just
 * don't find it easy to see how these few extra stat() calls, which needn't
 * occur unless PATH_INFO is present, can possibly amount to a potentially
 * serious problem, in the context of all the other things the server does
 * when processing a request.

They do need to occur regardless of path_info's presence... however, you're
right, looking for .htaccess files in subdirectories is a larger waste of
time.

As an aside, I find it curious that Charles was bringing up efficiency as an
argument for his changes when a month or two ago I was arguing with him
about why he should run his server standalone instead of from inetd.

 * To try to put this in context, I've appended a system-call trace of my
 * (hacked) httpd processing the request 'GET /cgi-bin/fortune'.  The trace
 * was collected from a server running as 'ServerType inetd', so to keep
 * things fair I've deleted all the initialization, opening of the logs, and
 * so forth, and picked up where it actually starts to process the request.
 * For convenience, I've pointed out the PATH_INFO search in the middle of it.
 * It amounts to one stat() --- it would have been five with the stock httpd
 * (Rob goes top down, I go bottom up); 

Interesting... maybe I should go bottom up, it would probably reduce the
average case of the number of stats required.
 
 * Against this background, I
 * find it difficult to see how another stat() or two, or even ten, done only
 * for URLs which happen to invoke a script in the first place, could make
 * enough of a difference to matter.

It's mostly because they're abysmally slow under AFS.

 */

--Rob



From FisherM@is3.indy.tce.com  Thu Dec 30 14:20:00 1993 PST
Message-Id: <2D23548D@MSMAIL.INDY.TCE.COM>
Date: Thu, 30 Dec 93 14:20:00 PST
From: FisherM@is3.indy.tce.com (Fisher Mark)
Subject: Re: CGI, semicolons, and so on...


I'm sorry for any misunderstanding, but I can't easily find any references 
to the ';' being an execution request rather than an execution demand (our 
Internet gateway has been somewhat flaky, though...).  As n ex-system admin, 
I find I like to keep my executables in a set of directories rather than 
spread all over the place.  The transparent virtualization of URL 
directories <-> script outputs under the non-semicolon scheme is attractive 
to me.  I think it really does come down to a matter of taste...
======================================================================
Mark Fisher                            Thomson Consumer Electronics
fisherm@tcemail.indy.tce.com           Indianapolis, IN

"Just as you should not underestimate the bandwidth of a station wagon
traveling 65 mph filled with 8mm tapes, you should not overestimate
the bandwidth of FTP by mail."



From robm@ncsa.uiuc.edu  Thu Dec 30 13:35:39 1993 -0600
Message-Id: <9312301935.AA27158@void.ncsa.uiuc.edu>
Date: Thu, 30 Dec 1993 13:35:39 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI, semicolons, and so on...

/*
 * Re: CGI, semicolons, and so on...  by John Franks (john@math.nwu.edu)
 *    written on Dec 29,  2:24pm.
 *
 * Look, this discussion has wandered far away from the point I wanted to
 * make initially.  I am not unhappy with the functionality or the
 * flexibility of the current PATH_INFO syntax.  I am unhappy with the
 * design of that syntax because it is inelegant, cumbersome to
 * implement, and conducive to misunderstanding by people who are only
 * marginally familiar with the protocol.

I will agree that it is cumbersome to implement... and perhaps that it is
confusing. 

 * Let me mention the syntax used by the Minnesota gopher server for a
 * similar function.  It is fairly similar to URL syntax.  The path part
 * of the URL looks like
 * 
 * 	exec:args:/path/script
 * 
 * I am NOT advocating that this be adopted as part of CGI.  I offer it
 * only as an existence proof that it is not too difficult to design a
 * syntax whose server implementation will have several important
 * properties:
 * 
 * 1) It is simple and clear.  I don't think I even need to explain it;
 *    its meaning should be self evident.  THE FACT THAT THIS PART OF THE
 *    URL IS OPAQUE DOES NOT MEAN IT SHOULD BE OBSCURE.

OBSCURE HOW!?!?!? If I set up or write a script, I damn well know what that
URL means.

 * 2) It is easy and efficient to parse.  It is not necessary to stat any
 *    files or directories in order to parse it. 
 * 
 * 3) It is not necessary to maintain a configuration file which is read
 *    and processed each time a server starts up.  
 * 
 * 4) It uses no magic directory names like "cgi-bin" and no magic 
 *    extensions like ".doit".  You can name files, scripts and directories
 *    whatever you like and mix files and scripts in any directory.

Please. Magic directory names and magic extensions are the domain of the
server; it's up to the server authors to decide how they're going to
distinguish between documents and scripts. I happen to view our decision to
make the distinction between script execution and document retrieval
transparent as a feature, I'm really sorry that you don't view it in that way.

 * I believe that WWW community can do at least as well as the gopher
 * designers.  That's all I wanted to say.  I concede that it is late in
 * the game to be requesting changes.  If it is too late, so be it.
 * Maybe I am just old-fashioned in my belief that programs (and
 * protocols) should try to be simple, clear, concise and if at all
 * possible elegant.

Well, ``simple, clear, concise, and elegant'' are highly subjective terms,
and what you view as simple and clear may be what I view as limiting.

You want to see something like what the gopher people had? Look at NCSA
httpd 1.0a1, from October. We've been growing since then to try and add what
we felt was needed capabilities to the script interface (the path info
stuff). I propogated those changes to the CGI interface because they're very
useful.

 * Robert Thau points out that it is possible to modify the NCSA server
 * so that some of these properties are achieved within the current
 * protocol.  Fine.  But IMHO, if we had had a better protocol to begin
 * with the original implementation would have been better and his
 * modifications would never have been necessary.

Well, I felt that the PATH_INFO modifications were too powerful to be
overlooked, and since NO ONE COMPLAINED AT THE TIME EVEN THOUGH THEY WERE
ASKED TO, then I'm really sorry you don't like the way it turned out, but I
don't see a problem.

 * Interestingly, the gopher syntax does not address the issue raised by
 * Charles Henrich who, quite reasonably, suggests that putting PATH_INFO
 * in the environment should be independent of indicating that a file is
 * executable.  I would agree.

So would I.

 * It seems to me now that there are (at least) three pieces of
 * information which need to be contained in the path part of a URL:
 * 
 * 1) Name and path of the file/script
 * 2) string to be put in PATH_INFO environment variable (if any)
 * 3) Is this file/script to be executed or treated as text

How about query information?

 * I would suggest as an important design criterion that these three
 * pieces of information should be orthogonal, i.e. the value of one
 * should not restrict the possible values of the others.  For example,
 * as Charles Henrich pointed out, my suggestion to make the existence of
 * PATH_INFO data be the indicator that the file should be executed is
 * not a good idea.  Likewise, I would contend that it is not a good idea
 * to have the fact that a file is intended to be executed restrict
 * either its possible name or possible path. It is certainly not
 * technically difficult to have such a design.  The question is, is it
 * too late.
 * 
 */

Now I'm really confused... how do you intend to determine if something is to
be executed if you don't have a config file directive, filename extension,
and have thankfully abandoned the idea of putting a ; at the end???? I
happen to think our design is not THAT BAD as it stands, and I'm really
sorry you don't feel that way.

--Rob
 



From john@math.nwu.edu  Thu Dec 30 13:39:07 1993 -0600 (CST)
Message-Id: <9312301939.AA01392@hopf.math.nwu.edu>
Date: Thu, 30 Dec 1993 13:39:07 -0600 (CST)
From: john@math.nwu.edu (John Franks)
Subject: Re: CGI, semicolons, and so on...

According to Fisher Mark:
> I'm sorry for any misunderstanding, but I can't easily find any references 
> to the ';' being an execution request rather than an execution demand ...

Whenever a client submits a URL to a server it is a request.  The client
cannot "demand" anything from the server.

John





From robm@ncsa.uiuc.edu  Thu Dec 30 13:37:36 1993 -0600
Message-Id: <9312301937.AA27197@void.ncsa.uiuc.edu>
Date: Thu, 30 Dec 1993 13:37:36 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI, semicolons, and so on...

/*
 * Re: CGI, semicolons, and so on...  by Charles Henrich (henrich@crh.cl.msu.edu)
 *    written on Dec 29,  4:51pm.
 *
 * I agree wholeheartedly, my original intent was to make the scheme cleaner and
 * allow for a more efficent implementation.  the stat() call on local unix
 * systems is a waste of resources, and on a AFS system a whole lot of wasted
 * resources.  (We run AFS all over here)
 * 
 * My scheme was simply to have the server ignore everything beyond the first
 * semicolon found in the URL.  That information would then be passed (in any
 * number of ways) to the scripts that get called.  This format works quite well
 * in satisfying the following parameters:

I agree, I think your original proposal was the best yet, I only wish you
had made it a month ago; at the time, I didn't see any problem with what we
were doing.

 * > 3) Is this file/script to be executed or treated as text
 * 
 * The srm.conf file.  Or heaven forbid the execute bit on the file, after all,
 * unix has been using the EXECUTE bit to mean that the file is EXECUTABLE (go
 * figure) for the longest of times..
 * 
 */

Yes, but John has already expressed his distaste for putting magic names in
config files for script execution. 

--Rob



From robm@ncsa.uiuc.edu  Thu Dec 30 13:46:15 1993 -0600
Message-Id: <9312301946.AA27382@void.ncsa.uiuc.edu>
Date: Thu, 30 Dec 1993 13:46:15 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI and typing files by suffix

/*
 * CGI and typing files by suffix  by John Franks (john@math.nwu.edu)
 *    written on Dec 29,  9:15pm.
 *
 * According to Robert S. Thau:
 * > 
 * > n) There should not be any indication within the URL, selector string,
 * >    etc., as to whether or not a retrieval will cause a script to be
 * >    invoked.
 * > 
 * > The reason I want it is that having put something up as a file, or
 * > collection of files, I may want to turn it into a script, without having to
 * > track down all the references to it and change them as well --- which I
 * > would necessarily have to do if the script/file distinction were explicit
 * > in the URL (selector, whatever).  
 * 
 * I know you have alreadly expressed a distaste for the redirection
 * mechanism in HTTP/1.0, but this situation is exactly what it is
 * designed to deal with.  If you find this mechanism cumbersome in the
 * server you use then perhaps that is the part of the server you need to
 * rewrite.

But surely you can see the point that script execution and document
retrieval should be interchangable?

 * If typing files by suffix were adequate there would be no point in
 * using the MIME type at all, the client could just look at the
 * suffix. In HTTP/0.9 file types were determined by suffix and there was
 * no MIME type.  One of the reasons for HTTP/1.0 was to get away from
 * this limitation.  It is reasonable for the default MIME type for a
 * file named foo.gif to be image/gif, but it is not reasonable to
 * require that an image/gif file must have a name with suffix .gif.
 * 
 * It is a bad idea to do so, but surely it should be *possible* with any
 * HTTP/1.0 server to put up a GIF file with the name foo.au and have it
 * work perfectly.  BTW, the reason it is a bad idea is precisely the
 * same reason it is a bad idea to have PATH_INFO data look like part of
 * the path -- it is misleading and obscure.
 */

You can override the default typing conventions under NCSA httpd... you can
make the extensions whatever you want. You can also special case files like
foo.au (for your .gif of Australia) with configuration directives. 

I think you're missing the point that Robert was trying to make... yes, MIME
types are great. I hope we can eventually move away from using filename
extensions to determine type on the server side. When this happens, it will
be even better since it will be transparent to the client. However, until
then, we're stuck with them.

--Rob



From rst@ai.mit.edu  Thu Dec 30 14:56:36 1993 EST
Message-Id: <9312301956.AA04295@volterra>
Date: Thu, 30 Dec 93 14:56:36 EST
From: rst@ai.mit.edu (Robert S. Thau)
Subject: Re: CGI, semicolons, and so on...

> John, correct me if I'm wrong, but I believe you were referring to a method
> in which GET /path/script would return a cover page, and GET /path/script;
> would execute a script. 

Well, at any rate, that's the way I read it...  I'm just following up to
say that coversheets are one reason I like the suffix convention --- I've
got it set up so that if 'foo' and 'foo.doit' are alongside each other, the
file is retrieved as a coversheet in response to parameterless GETs, and
the script is invoked to handle anything else.  This is a particular, if
minor, convenience for ISINDEX documents, in which you can't designate
another URL as the locus of the handler.  (I know, sooner or later forms
support will be universal and ISINDEX stuff can all go away, but in the
meantime it isn't even available on all common platforms yet).

As long as I'm here, I might as well follow up on a few other points.

I'm not so fond of the prefix convention because as an administrative
matter, I find it awkward to have to designate any directory in which a
script might reside.  One of the constraints here is that I'm not the only
person who's putting stuff up on the server, and I don't expect to be the
only script writer here either for very long.  If there's a single file
which designates all the script directories, that's one more way for people
to get in each others' hair.

Also, 'ScriptAlias' designation does prevent scripts and other files from
residing in the same physical directory (unless that directory is
double-mapped, which is itself a little awkward, and does leave the door
open to retrieval of scripts as ordinary files as a somewhat undesirable
default).  I've found that having coversheets and forms handlers in the
same directory does help keep things organized.

Finally, in regards to 'nph' --- here's a somewhat wooly suggestion: Add
another possible keyword to the keys that the server recognizes when
parsing script output, along with "Content-type:" and "Location:" ---
something like 'Verbatim:'.  Then mandate that if the first characters of
the script's output are "Verbatim:\n", the rest of it will be passed to the
client unaltered.  As far as I can tell, this is backward compatible.  How
about it?

rst



From robm@ncsa.uiuc.edu  Thu Dec 30 13:55:22 1993 -0600
Message-Id: <9312301955.AA27539@void.ncsa.uiuc.edu>
Date: Thu, 30 Dec 1993 13:55:22 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI and typing files by suffix

/*
 * Re: CGI and typing files by suffix  by Tony Sanders (sanders@BSDI.COM)
 *    written on Dec 30,  2:17am.
 *
 * Of course, the servers do this because it's convenient.
 * Someday I will fix Plexus so this is done "right" and the typing isn't
 * wholy suffix dependent.  I will probably end up keeping cache files
 * in each directory that get updated automatically as needed.  There is
 * also the non-trivial issue of how to admin such a beast.

Exactly....

 * Basically, typing by suffix is UNACCEPTABLE for the client end (though as
 * NCSA Mosaic proved it can work ok for some stuff, that isn't the issue)
 * but it's perfectly fine for the server to use this if it wants.  The key
 * is that there is nothing requiring the server to do so, it's mearly done
 * as a matter of convenience on some OS's.

Certainly. I'd love to see MacHTTP use the typing information available from
the Mac filesystem to determine MIME type.

 * I fail to see how:
 *     http://server/path/cmd;args
 * Is really any clearer or better than:
 *     http://server/path/cmd/args
 * 
 * The `;' scheme simply has too many drawbacks (namely you can't front-end
 * existing directory hierarchies with scripts).

I would say that the drawback of doing multiple stats may outweigh this
particular benefit, however, I think the status quo is Not That Bad and in
fact is very powerful for a LOT of things.

 * Using the execute bit, where available, is probably the best plan.
 */

I don't know about that... I have a lot of stray x bits on my server... the
tech support when such a plan is adopted would be a nightmare. I don't think
magic names in config files is such a horrible rotten idea, (since the URL
is the domain of the server). I find the idea of making a new content-type
to determine script execution intriguing, since it would mean that if we
ever move away from filename extensions that scripts would be ``just another
object''.

--Rob



From marca@ncsa.uiuc.edu  Thu Dec 30 15:56:45 1993 -0600
Message-Id: <9312302156.AA15485@wintermute.ncsa.uiuc.edu>
Date: Thu, 30 Dec 93 15:56:45 -0600
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Re:  server setting the content-type

Jon E. Mittelhauser writes:
> >- In mosaic, an HTML file named "foo" will display as
> >formatted text if it contains a <TITLE> tag.
> 
> This is only true of the X-Windows version (and maybe Mac) and is
> the result of a hack that Marc threw in back in HTTP/0.9 days.  In
> my opinion, it is a bug and I have told Marc and Eric such.

Yup, I can confirm that -- I've still got the bruises from Jon's
attempts at persuading me that it wasn't a good idea.

> The windows version does not try to out-guess the server.  

Which, in our Brave New HTTP/1.0 World, is how it should be.

Cheers,
Marc

--
Marc Andreessen
Enterprise Integration Technologies
Palo Alto, California
marca@eit.com




From robm@ncsa.uiuc.edu  Thu Dec 30 14:02:32 1993 -0600
Message-Id: <9312302002.AA27667@void.ncsa.uiuc.edu>
Date: Thu, 30 Dec 1993 14:02:32 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI, semicolons, and so on...

/*
 * Re: CGI, semicolons, and so on...  by Fisher Mark (FisherM@is3.indy.tce.com)
 *    written on Dec 30,  8:20am.
 *
 * 
 * The opacity or virtualization of the present scheme is nice, as the user of 
 * the URL does not have to concern her or himself with whether it represents 
 * a physical file or it is data created on the fly -- he or she just uses it.
 
I agree.
 
 * As far as the overhead for a single stat() call, I think that it is pretty 
 * small in the scheme of things.  Why even try writing a server in Perl, an 
 * interpreted language (which I love), if you need to worry about the overhead 
 * of a single stat() call?  Why even write one in C or C++ rather than 
 * assembler if a single stat call() can make the difference between a server 
 * with good response time vs. a server with poor response time?
 */

Well, if it was one stat(), you would be right... however, at times it can
get up to five or six. The overhead for this isn't really significant on a
stock filesystem, but over NFS or AFS (especially AFS) it becomes
significant, and in some cases it becomes large enough to become prohibitive.

--Rob



From robm@ncsa.uiuc.edu  Thu Dec 30 14:06:35 1993 -0600
Message-Id: <9312302006.AA27742@void.ncsa.uiuc.edu>
Date: Thu, 30 Dec 1993 14:06:35 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI and typing files by suffix

/*
 * Re: CGI and typing files by suffix  by Tony Sanders (sanders@BSDI.COM)
 *    written on Dec 30, 11:30am.
 *
 * > Does Plexus parse the URL by doing stats through the file system to
 * > find out where the "path/cmd" ends and the "args" begin?  I find this
 * Plexus has an associative array:
 * 	map /man man.pl &do_man($top, $rest, $query)
 * So it just looks it up in the table and eval()'s it's contents.  Having
 * a fixed table of allowed scripts has it's features (security) and drawbacks
 * (manual updates).  However, I don't add scripts every day so I haven't
 * found it to be a problem myself.

As I'm reading it, this would be equivalent to assuming that ScriptAlias
always pointed to a script... 

 * Let's say I currently have the URLs:
 * 	http://server/man/1/ls
 * 	http://server/man/1/cat
 * 	...
 * Now, let's say I want to change this so that instead of a bunch of files
 * in the man directory I want to convert `man' to be a script (maybe I want
 * to generate the html on the fly, maybe I want to WAIS all the data and
 * provide a search engine as well as a browsing engine).  With the ';' scheme
 * I would have to change all the URLs in the world that point to my data to
 * read "http://server/man;html1/ls" (many of which I do not own or even know
 * about).  

Speaking as one of the people that has to figure out how to reduce the load
on www.ncsa.uiuc.edu, there are often a LOT of links you don't know about.
 
 * This is not acceptable.  This is a real-life situation, I have
 * done this and I know several other people who have done it (converted
 * a directory hierarchy to use a search gateway).
 * 
 * The only advantage to ';' is that it's a little easier to parse.  This
 * isn't a significant enough advancement that it's worth breaking the
 * script/non-script symmetry.
 */

I agree. I also would agree that I could have been a little more sensible in
my implementation of extra path info in NCSA httpd, to make the required
number of stats average 1 instead of 3-4. However, this is something I
feel can be fixed in the current protocol and does not require a new one.

--Rob



From wa@mcc.com  Thu Dec 30 14:23:17 1993 CST
Message-Id: <9312302023.AA04446@coyote.mcc.com>
Date: Thu, 30 Dec 93 14:23:17 CST
From: wa@mcc.com (Wayne Allen)
Subject: ismap functionality...


I recently attempted my first use of the ismap feature to explore it's
possibilities. The very first thing I tried was making a bookmark map,
allowing access to home, help, and search pages, as well as "up" (a
parent document) and "top" (goto top of page). Of couse, these last
two are not possible, as I now know. Using the same map on multiple
pages and parameterizing the URL mappings *or* having relative mappings
is not possible because the mapping is done by the server without
context.

One could have relative mappings (I think) if the client provided the
server with the context URL in the coordinate request, *or* if the
client expanded relative forwarding addresses in its current context,
but X-Mosaic, for example, doesn't seem to do this.

I can see some advantages in having the server do mapping, but I think
URL mapping should also be specifiable in HTML, so the client
can do more sophisticated (not to mention efficient) mapping. For
example, the following:

<A HREF="http://machine/htbin/imagemap/sample">
<img src="sample.gif" ismap>
</A> <P>

might have an alternate representation which could be completely
interpreted by the client without involving (twice!) a (possibly very
busy) server:

<map src="sample.gif" rect="http://somewhere/something.html 0,0 65,15"
		      rect="parent.html 66,0 120,15" 
                      rect="#TOP 180,0 200,15">

I'm sure there has been some discussion of this in the past, and I'm sorry
I missed it. Am I laboring under some misconceptions? Are there good reasons
why the client should not do mapping?

Thanks for any replies...
--
 wa | Wayne Allen, EINet - wa@mcc.com		 	 FAX: (512)338-3897
    | MCC/ISD, 3500 West Balcones Center Dr, Austin, Tx 78759 (512)338-3754








From john@math.nwu.edu  Thu Dec 30 14:27:16 1993 -0600 (CST)
Message-Id: <9312302027.AA01484@hopf.math.nwu.edu>
Date: Thu, 30 Dec 1993 14:27:16 -0600 (CST)
From: john@math.nwu.edu (John Franks)
Subject: Raising the White Flag


UNCLE! UNCLE! I surrender!  I give up.  
(Charles, buddy, you're on your own.)


Hey Rob, welcome back!

Rob McCool says:
> 
> Please. Magic directory names and magic extensions are the domain of the
> server; it's up to the server authors to decide how they're going to
> distinguish between documents and scripts. I happen to view our decision to
> make the distinction between script execution and document retrieval
> transparent as a feature, ...

I agree completely that distinguishing documents from scripts should
be up to the server author.  My main gripe (as I have reitered many
times) is that I feel the protocol is forcing me to use an implementation
(parsing via stat() ) that I don't like when a different protocol
design wouldn't limit my choices this way.  How you implement your
server is none of my business.  I am not that familiar with your server
and I never intended to be critical of your implementation.

Anyway, as I said above, I give up.  I understand and accept the
argument that it is now too late to make changes in the protocol.
As for the other arguments I am not so much persuaded as inundated.

As I understand what Sanders and Thau are saying, the syntax of the
path part of a URL should be be deliberately ambiguous as to whether
the object is a directory file or script and and also ambiguous as to
what part represents a path and what part represents arguments.  This
is done intentionally so the maintainer can change his or her mind
about all these things at a later date.

It would be helpful if the CGI spec explained that this ambiguity is
intentional, what the rationale for it is, and that the designers 
believe that this flexibility is worth the cost of disambiguating 
the URL at the server.  A paragraph explaining this would have saved
me a lot of time.

On the other hand, it has been fun watching Rob blow a whole day
working his way through this discussion :)

John




From robm@ncsa.uiuc.edu  Thu Dec 30 15:13:42 1993 -0600
Message-Id: <9312302113.AA28382@void.ncsa.uiuc.edu>
Date: Thu, 30 Dec 1993 15:13:42 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: PATH_INFO on the cheap?

/*
 * PATH_INFO on the cheap?  by Robert S. Thau (rst@ai.mit.edu)
 *    written on Dec 30, 12:07pm.
 *
 * In re the current PATH_INFO discussion, it may be possible to cut the cost
 * of the current implementations by piggybacking on work which the server (at
 * least the NCSA server) is already doing anyway.
 * 
 * Here (I think) is the trick.  In order to do access control, the server is
 * already doing stuff like this (from my previous syscall trace):
 */

[... combine the two actions of groping for a script and groping for
.htaccess]

Yes, you could do this. Since I've become rather afraid of breaking things,
however, I probably won't change it anytime soon.

--Rob



From sanders@BSDI.COM  Thu Dec 30 15:16:31 1993 -0600
Message-Id: <199312302116.PAA17965@austin.BSDI.COM>
Date: Thu, 30 Dec 1993 15:16:31 -0600
From: sanders@BSDI.COM (Tony Sanders)
Subject: Re: ismap functionality... 

> <map src="sample.gif" rect="http://somewhere/something.html 0,0 65,15"
> 		      rect="parent.html 66,0 120,15" 
>                       rect="#TOP 180,0 200,15">
> 
> I'm sure there has been some discussion of this in the past, and I'm sorry
> I missed it. Am I laboring under some misconceptions? Are there good reasons
> why the client should not do mapping?

Mainly because you forgot to allow for circles, bitmapped objects, arbitrary
polygons, external spatial indexers, etc.  The server can be very flexible
but the client cannot, any finite client side scheme you implement will
not be sufficient.  HTML+ defines polygon support with <FIGA> but it isn't
yet implemented anywhere.

There isn't any reason you can't do your own relative path munging in the
server, it has all the information it needs.

--sanders



From robm@ncsa.uiuc.edu  Thu Dec 30 15:18:12 1993 -0600
Message-Id: <9312302118.AA28436@void.ncsa.uiuc.edu>
Date: Thu, 30 Dec 1993 15:18:12 -0600
From: robm@ncsa.uiuc.edu (Rob McCool)
Subject: Re: CGI, semicolons, and so on...

/*
 * Re: CGI, semicolons, and so on...  by Robert S. Thau (rst@ai.mit.edu)
 *    written on Dec 30,  2:56pm.
 *
 * Finally, in regards to 'nph' --- here's a somewhat wooly suggestion: Add
 * another possible keyword to the keys that the server recognizes when
 * parsing script output, along with "Content-type:" and "Location:" ---
 * something like 'Verbatim:'.  Then mandate that if the first characters of
 * the script's output are "Verbatim:\n", the rest of it will be passed to the
 * client unaltered.  As far as I can tell, this is backward compatible.  How
 * about it?
 * 
 */

Was brought up in the original nph- discussions... in fact the spec had
something like that for a week or two. The problem is, the entire reason for
nph- is to allow the script direct access to the client without *any* server
intervention... in other words, the server has to know that a script is
going to put out its own header before execution... therefore, the question
was either to make a naming convention or have the server authors add
configuration options. The former was eventually chosen.

--Rob



From germuska@casbah.acns.nwu.edu  Thu Dec 30 15:47:01 1993 -0600 (CST)
Message-Id: <9312302147.AA03447@casbah.acns.nwu.edu>
Date: Thu, 30 Dec 1993 15:47:01 -0600 (CST)
From: germuska@casbah.acns.nwu.edu (Joe Germuska)
Subject: Re: ismap functionality... 

Tony Sanders wrote:
> > <map src="sample.gif" rect="http://somewhere/something.html 0,0 65,15"
> > 		      rect="parent.html 66,0 120,15" 
> >                       rect="#TOP 180,0 200,15">
> > 

How about, perhaps, an argument to the "<ISMAP>" tag?  Something like this:
<IMG SRC="map.gif" ISMAP="map.conf"> (or something)

The point being that if the client could read the map configuration, it
could provide much better feedback -- say, hold the option key to see the
outlines of buttons, and highlight the exact "hotspot" before jumping to
the appropriate URL? 

The feedback (or lack of) currently given to users when an ISMAP is clicked
will probably make a lot of people kind of uncomfortable.

So is this idea counter to philosophy, or too hard for client authors to
implement? :-) (my suggestions usually violate philosophies :-)



-- 
joe germuska * j-germuska@nwu.edu * www * res hall net * instruct tech
      academic computing & network services * northwestern univ
A monk told Joshu: "I have just entered the monastery.  Please
teach me."  Joshu asked: "Have you eaten your rice porridge?"  The
monk replied: "I have eaten."  Joshu said: "Then you had better wash
your bowl."  At that moment, the monk was enlightened!



From sanders@BSDI.COM  Thu Dec 30 16:46:14 1993 -0600
Message-Id: <199312302246.QAA18175@austin.BSDI.COM>
Date: Thu, 30 Dec 1993 16:46:14 -0600
From: sanders@BSDI.COM (Tony Sanders)
Subject: Re: ismap functionality... 

> So is this idea counter to philosophy, or too hard for client authors to
> implement? :-) (my suggestions usually violate philosophies :-)

The problem is that client side decoding is inflexible.  You have to define
a spec and stick with it.  Witness <FIGA>, it only supports polygons.  As
soon as someone implements it someone else will want some other feature
and then we will have incompatible versions floating around.  This doesn't
happen with the current scheme.

--sanders



From kevinh  Thu Dec 30 17:07:59 1993 PST
Message-Id: <9312310107.AA05562@eit.COM>
Date: Thu, 30 Dec 93 17:07:59 PST
From: kevinh (Kevin 'Kev' Hughes)
Subject: EIT's server redone!


	The main bulk of EIT's Web site has been redone! The old file
structure is preserved in /usr/local/www.old.
	So everyone knows, here is the new file structure in /usr/local/www:

	/cookbook - this is "The Webmaster's Cookbook" stuff (in progress)
	/demos - old demos and things. If you can't find your old demo,
		look in there first. The /asiceda directory has been
		preserved.
	/graphics - miscellaneous EIT graphics. For those who wish to include
		EIT's logo in your HTML pages, the big logo is "eit.big.gif"
		and the small logo is "eit.small.gif". Enjoy!
	/maps - the EIT office map/road map. In progress.
	/papers - any miscellaneous papers. The top index is papers.html.
	/people - individual html files and gifs. The pictures will be
		redone later; otherwise edit your own html file to your
		heart's content!
	/pr - PR material, such as the overview, fact sheet, recruiting
		materials, and press releases.
	/presentations - presentations folks give. The top index is
		presentations.html.
	/projects - project-related work goes into these subdirectories and
		nowhere else! If you can't find your old information, look
		in there first. The blurb for each project is titled
		<project>.html.
	/software - the old /software directory, untouched. It could use
		some cleaning up.
	/techinfo - technical information; the top index is techinfo.html.
	/web - web resources and things; the top index is web.html.

	eit.home.html - the main page!
	whats.new.html - update as needed.

	Your own html project-related files should be checked for obsolete
links and graphics, and pointers to files within EIT's web structure from
the outside (for instance, Stanford) should be double-checked also.
	Have fun, everyone (and have a Happy New Year),

	-- Kev



From henrich@rs560.cl.msu.edu  Thu Dec 30 21:09:46 1993 -0500 (EST)
Message-Id: <9312310210.AA24616@rs560.cl.msu.edu>
Date: Thu, 30 Dec 1993 21:09:46 -0500 (EST)
From: henrich@rs560.cl.msu.edu (Charles Henrich)
Subject: Re: CGI, semicolons, and so on...

> I agree, I think your original proposal was the best yet, I only wish you
> had made it a month ago; at the time, I didn't see any problem with what we
> were doing.

I was busy preparing for finals at the time!  Comon, you guys are telling me
that you will *never* make any changes to the CGI spec ever again?  Even if by
adding this capability *in addition to* you wont break any scripts out there,
and you will make it more efficent for those who need it, or make it cleaner
for those who like it that way?

> Yes, but John has already expressed his distaste for putting magic names in
> config files for script execution.

I still say we go with the execute bit, 1000 times more flexible and simple
than any other method on the planet.

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                     http://rs560.msu.edu/~henrich/




From ianf@random.se  Fri Dec 31 03:28:30 1993 +0100
Message-Id: <a9494cd7@random.se>
Date: Fri, 31 Dec 93 03:28:30 +0100
From: ianf@random.se (Ian Feldman)
Subject: administrivia: bad aliasing of info.cern.ch

  Forgive me for posting this in the www-talk forum but
  addressing the <listserver@info.cern.ch> leads to the
  enclosed error message. Looks like somebody over @CERN
  aliased _info.cern.ch_ to _www0.cern.ch_ which doesn't
  know of any "listserver" account, so it bounces back.
  Believe me, I mailed <listserver@info.cern.ch> and NOT
  <listserver@www0.cern.ch> as the error header indicates.
  Please reset it back.  Thanks.

__Ian

> Date: Fri, 31 Dec 1993 03:03:27 +0100
> From: MAILER-DAEMON@dxmint.cern.ch (Mail Delivery Subsystem)
> Subject: Returned mail: User unknown

>    ----- Transcript of session follows -----
> While talking to www0.cern.ch:
> >>> RCPT To:<listserver@www0.cern.ch>
> <<< 550 <listserver@www0.cern.ch>... User unknown
> 550 <listserver@info.cern.ch>... User unknown

>    ----- Unsent message follows -----
> To: listserver@www0.cern.ch
> Subject: delete www-talk
> From: ianf@random.se (Ian Feldman)
> Date: Thu, 30 Dec 93 20:47:16 +0100
> Message-Id: <a948eed3@random.se>

> delete www-talk
> add www-announce
> stop




From masinter@parc.xerox.com  Thu Dec 30 23:15:52 1993 PST
Message-Id: <93Dec30.231604pst.2732@golden.parc.xerox.com>
Date: Thu, 30 Dec 1993 23:15:52 PST
From: masinter@parc.xerox.com (Larry Masinter)
Subject: content-type => media-type ?

I've noticed in recent RFCs, it's been explained that `content-type'
as used in MIME is being extended to a broader notion of `media-type'.

MIME can go ahead and use 'content-type', since, in the case of MIME,
it is the type of the content of the message, but for WWW applicatons,
resource-type or some other designation is probably more appropriate.

Just a minor shift in nomenclature. You may now go back to you
regularly scheduled program.




From decoux@moulon.inra.fr  Fri Dec 31 15:53:25 1993 +0100
Message-Id: <9312311453.AA12319@moulon.moulon.inra.fr>
Date: Fri, 31 Dec 93 15:53:25 +0100
From: decoux@moulon.inra.fr (ts)
Subject: CGI suggestion


> /*
>  * CGI suggestion  by ts (decoux@moulon.inra.fr)
>  *    written on Dec 28,  5:12pm.
>  *
>  *  URL are :
>  *   http://server/cgi-perl/script/extra_path
>  *   http://server/cgi-csh/script/extra_path
>  * 
>  *  I can't have :
>  *   http://server/cgi-bin/perl/script/extra_path
>  *   http://server/cgi-bin/csh/script/extra_path
>  * 
>  * 
>  */
> 
> Why not? You should be able to create a perl subdirectory or a csh
> subdirectory in cgi-bin. 
> 

 Actually I don't know exactly the syntax, Example :

 With "srm.conf", like this :

 ____________________________________________________________
ScriptAlias /cgi-bin/ /usr/local/etc/httpd/cgi-bin
ScriptAlias /cgi-bin/perl/ /usr/local/etc/httpd/cgi-bin/perl
 ____________________________________________________________

 URL : http://server/cgi-bin/perl/script/extra_path

 Server call "/cgi-bin/perl" with extra_info "/script/extra_path"
        or   "/cgi-bin/perl/script" with extra_info "/extra_path" ?

 Same question, with "srm.conf" like this :

 ____________________________________________________________
ScriptAlias /cgi-bin/perl/ /usr/local/etc/httpd/cgi-bin/perl
ScriptAlias /cgi-bin/ /usr/local/etc/httpd/cgi-bin
 ____________________________________________________________

Guy Decoux



From henrich@crh.cl.msu.edu  Fri Dec 31 10:59:04 1993 -0500 (EST)
Message-Id: <9312311559.AA05045@crh.cl.msu.edu>
Date: Fri, 31 Dec 1993 10:59:04 -0500 (EST)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: Semicolon's for all

I've come up with another reason (which was my original reason way back, but I
had forgotten about it until I just tried to do something).  With NCSA's
inlined includes, I can server any document and have the inlined include do
something special based on the URL.  For example, the inlined include can peel
off the '?' args and return various bits of information (such as in the
interactive weather browser here).  However, I can only give *one* piece of
information, and I cannot remember information in the URL by using this method
(as I have been doing).  Multiple question marks in a URL are a no-no, and even
with one question mark, the state gets obliterated on a mouse click or isindex
search.  I cant use the path hack for the URL, afterall, im not trying to
execute anything at all, I want to serve up a standard text document, and have
a program in it parse the URL.  I *need* the semicolon syntax to do this.

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                     http://rs560.msu.edu/~henrich/



From ceharris@vt.edu  Fri Dec 31 12:00:09 1993 -0500 (EST)
Message-Id: <199312311700.MAA00419@mal9000.async.vt.edu>
Date: Fri, 31 Dec 1993 12:00:09 -0500 (EST)
From: ceharris@vt.edu (Carl Harris)
Subject: texinfo -> html converter

Is there a texinfo-to-html converter out there?

I'm sure I saw a reference for ____-to-html converters somewhere in the
(seemingly endless) pages of documentation for html, httpd, etc.  Can some-
one please point me in the right direction?

--
Carl Harris
CSUGRAD Administrator (and web neophyte)
ceharris@vt.edu
http://csugrad.cs.vt.edu/aboutus/ceharris.html



From wa@mcc.com  Fri Dec 31 11:08:50 1993 CST
Message-Id: <9312311708.AA05513@coyote.mcc.com>
Date: Fri, 31 Dec 93 11:08:50 CST
From: wa@mcc.com (Wayne Allen)
Subject: ismap functionality... 


   Organization: Berkeley Software Design, Inc.
   Date: Thu, 30 Dec 1993 15:16:31 -0600
   From: Tony Sanders <sanders@bsdi.com>
   Content-Length: 821

   > <map src="sample.gif" rect="http://somewhere/something.html 0,0 65,15"
   > 		      rect="parent.html 66,0 120,15" 
   >                       rect="#TOP 180,0 200,15">
   > 
   > I'm sure there has been some discussion of this in the past, and I'm sorry
   > I missed it. Am I laboring under some misconceptions? Are there good reasons
   > why the client should not do mapping?

   Mainly because you forgot to allow for circles, bitmapped objects, arbitrary
   polygons, external spatial indexers, etc.  The server can be very flexible
   but the client cannot, any finite client side scheme you implement will
   not be sufficient.  HTML+ defines polygon support with <FIGA> but it isn't
   yet implemented anywhere.

I'm sorry, Tony, I should have been more explicit. I use NCSA's
server, and their imagemap program supports rectangles, circles, and
polygons. I should have included all of these objects in my example,
since I think they are sufficient for what I had in mind. Other things
like external spacial indexers, of course, require server-side
mapping support. I'll look at the FIGA spec, and in the mean time, a
better example of what I intended would be:

<A HREF="http://machine/htbin/imagemap/sample">
<img src="sample.gif" ismap
                      rect="http://somewhere/something.html 0,0 65,15"
         	      circ="parent.html 70,35"
                      poly="#TOP 180,0 200,0 200,15 190,15">
</A> <P>

My point was not that the server shouldn't support mapping, but that
some *limited* types of mapping are better done by the client.  For
example, take relative URL's. They are in the spec, and are useful for
maintaining large documents. It seems reaonable that one be able to
map from an image coordinate to a relative url or named anchor. But to
resolve this URL requires browser context, which is properly the
domain of the client rather than the server.

I think it would be easy to support pass-through mapping, so that
coordinates un-resolved by the client get passed to the server as is
done now. In the example above, if the coord is not in one of the
three specified areas, it gets passed to the server as before.  This
would support both relative URL mapping and server-defined
mapping, as well as allowing map interpretations to be controlled to
some degree by the context of which document the map is viewed from.
For example, in one document, a particular coordinate may be mapped by
the server by default, while in another, an "overlayed" mapping
specified in the HTML may take precedent.  Just a wish...

   There isn't any reason you can't do your own relative path munging in the
   server, it has all the information it needs.

The server gets the request "GET /cgi-bin/imagemap/top-line?69,7 HTTP/1.0"
so I'm not sure what it can do to resolve anything.  However, I
think I can hack a fix by passing more arguments to the imagemap
program. Forging ahead...

Cheers,
--
 wa | Wayne Allen, EINet - wa@mcc.com		 	 FAX: (512)338-3897
    | MCC/ISD, 3500 West Balcones Center Dr, Austin, Tx 78759 (512)338-3754





From rst@ai.mit.edu  Fri Dec 31 13:55:43 1993 EST
Message-Id: <9312311855.AA04894@volterra>
Date: Fri, 31 Dec 93 13:55:43 EST
From: rst@ai.mit.edu (Robert S. Thau)
Subject: Re:  Semicolon's for all

I really hate to keep beating this horse, but perhaps one last time...

Charles Henrich writes ...

  I've come up with another reason (which was my original reason way back,
  but I had forgotten about it until I just tried to do something).  With
  NCSA's inlined includes, I can server any document and have the inlined
  include do something special based on the URL.  For example, the inlined
  include can peel off the '?' args and return various bits of information
  (such as in the interactive weather browser here).  However, I can only
  give *one* piece of information, and I cannot remember information in the
  URL by using this method (as I have been doing).  Multiple question marks
  in a URL are a no-no, and even with one question mark, the state gets
  obliterated on a mouse click or isindex search.  I cant use the path hack
  for the URL, afterall, im not trying to execute anything at all,

But you are trying to execute something --- the code that looks at the
information you're passing along. 

  I want
  to serve up a standard text document, and have a program in it parse the
  URL.

A document with server includes is not a standard text document, to my way
of thinking --- standard text documents don't *have* programs in them.
Rather, it's a program in a special-purpose language which is designed to
*produce* standard text documents (as is, say, a TeX input file).  But
that's a rather different thing.

It's worth noting that the use of that language has a certain cost.  The
simplest use of server includes --- say, something like <inc srv "|date">
--- spawns off a Bourne shell, which does at least a couple of file system
operations before spawning off yet another process which finally prints the
date.  A document with several includes incurs this overhead several times
over.  And, at least for those of us who have been spared AFS, spawning a
process costs rather more than a couple of stats.

Much of this overhead could, in principle, be avoided.  If the
server-include code spawned off the "date" process directly, rather than
invoking popen(), which calls up the shell, then the number of process
spawns would be cut in half.  Some of the file system ops would also go
away (all of them in the 'date' example, because 'date' doesn't go near the
filesystem, but that depends on the program being run).  Of course, you
would lose certain convenience features --- path search, argument parsing,
and so forth --- but none of them comes for free, and as I understand your
setup, some of them (path search in particular) aren't necessarily cheap.

I don't begrudge you any of this, if you feel it makes your life easier ---
if there's one thing that ought to be clear by now, it's that I think some
things are worth a price.  I just wish you'd measure the alternatives to
what you're proposing by the same yardstick.

  I *need* the semicolon syntax to do this.

I think I've already pointed out a couple of alternatives.  From the top:

The current PATH_INFO machinery could be extended to retrievals of 'ordinary'
files.  That is, when the server gets a URL which translates to a path like

  /path/to/the/document/here-it-is.html/whatever-you-like

it could retrieve here-it-is.html, saving the "extra" portion of the
pathname for a PATH_INFO argument to any server includes.  As we've been
through several times, this needn't cost anything at all if PATH_INFO is
absent, and the cost even if it's present is at most a few extra stats
above and beyond what the server is doing anyway.

Alternatively, if you want something NOW and you're really hard up, you
could switch to a more powerful scripting language --- something like this:

  #! /usr/local/bin/perl
  do "set-the-weather-variables.pl"; # This code sees PATH_INFO & all CGI vars
  print <<EOF;
  Content-type: text/html

  <title> Weather for $weather_where </title>
  <h1> Weather for $weather_where </h1>

  Here is the available information about weather at $weather_where as of
  $weather_when. <p>

  Maps are available from $weather_sats; see $weather_map_anchors for
  more information.  Also, the local forecast is <a href="$localf">here</a>,
  and the long-range forecast for the region is <a href="$longrangef">here</a>.
  <p>

  In order to use this information ...
  ...
  EOF

Note that the file is basically HTML with $variable inclusions, except for
four lines at the top to invoke Perl code (in a separate file for the
example) which actually sets the $variables.  So, for the most part, it
*looks* like an ordinary text file.  It really isn't, but like I said, I
don't think HTML files with server includes are either.

This is, I'll grant you, not the prettiest thing in the world.  However,
it's not *so* bad, it does get the job done, and it even has a few
advantages.  Being able to throw an 'if' statement into the middle of these
things can grow on you.  Also, it's likely to be at least a little more
efficient --- CGI scripts are spawned directly by the daemon (not through a
shell) and Perl is a powerful enough language that it can do at least
simple jobs with no further process spawning at all.

(If you don't like Perl, you can play the exact same game with any of the
shells, but it may cost you a bit).

In short, I don't see that the semicolon syntax is actually necessary for
what you want to accomplish.  Plausible alternatives are at least as
convenient, and so far as I can tell (when the whole cost of running the
retrieval is factored in) only marginally more expensive.

rst





From henrich@crh.cl.msu.edu  Fri Dec 31 17:15:19 1993 -0500 (EST)
Message-Id: <9312312215.AA05704@crh.cl.msu.edu>
Date: Fri, 31 Dec 1993 17:15:19 -0500 (EST)
From: henrich@crh.cl.msu.edu (Charles Henrich)
Subject: Re: Semicolon's for all

> A document with server includes is not a standard text document, to my way
> of thinking --- standard text documents don't *have* programs in them.
> Rather, it's a program in a special-purpose language which is designed to
> *produce* standard text documents (as is, say, a TeX input file).  But
> that's a rather different thing.

Bullshit.  Its a text document that is parsed by a preprocessor, the
preprocessor can take arguments.  This whole argument is getting rather silly,
Im amazed at the massive pushback at adding something that wont break anything,
even when CGI is still in its infancy.  What happens in a year when folks want
to add something and CGI is well entrenched?

> It's worth noting that the use of that language has a certain cost.  The
> simplest use of server includes --- say, something like <inc srv "|date">
> --- spawns off a Bourne shell, which does at least a couple of file system
> operations before spawning off yet another process which finally prints the
> date.  A document with several includes incurs this overhead several times
> over.  And, at least for those of us who have been spared AFS, spawning a
> process costs rather more than a couple of stats.

Of course, if your running on a RS/6000 with lots of memory (as I am) spawning
and executing are virtually instantaneous as its all out of ram, and nothing
ever hits the disk or network.

> In short, I don't see that the semicolon syntax is actually necessary for
> what you want to accomplish.  Plausible alternatives are at least as
> convenient, and so far as I can tell (when the whole cost of running the
> retrieval is factored in) only marginally more expensive.

It is rediculus that to serve up documents I must spawn a huge scripting
language to emulate a server (which I already have running!).

This morning I absolutely needed the semicolon syntax to accomplish what I want
in any clean manner.  It took exactly 2 additional lines of code to the server.
Im still amazed at the inflexibilty you folks are imposing on something so new,
that hasnt even begun to be used in all possible situations it has been
designed for.  Its okay, I dont mind adding 2 lines of code to every new
release, its too bad that everyone who finds themselves in my position will
also need to do so.

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                     http://rs560.msu.edu/~henrich/



From marca@ncsa.uiuc.edu  Fri Dec 31 18:44:35 1993 -0600
Message-Id: <9401010044.AA19468@wintermute.ncsa.uiuc.edu>
Date: Fri, 31 Dec 93 18:44:35 -0600
From: marca@ncsa.uiuc.edu (Marc Andreessen)
Subject: Re: Semicolon's for all

Charles Henrich writes:
> What happens in a year when folks want to add something and CGI is
> well entrenched?

Then CGI/1.1 is spec'd and stabilized.  

One of the points behind CGI/1.0 was to reach a point of stability wrt
shifting and nontransportable script interfaces; that this stability
has been reached at the "1.0" level is a good thing.

Cheers,
Marc

--
Marc Andreessen
Enterprise Integration Technologies
Palo Alto, California
marca@eit.com




From sanders@BSDI.COM  Fri Dec 31 17:04:10 1993 -0600
Message-Id: <199312312304.RAA20773@austin.BSDI.COM>
Date: Fri, 31 Dec 1993 17:04:10 -0600
From: sanders@BSDI.COM (Tony Sanders)
Subject: Re: Semicolon's for all 

> Im amazed at the massive pushback at adding something that wont break anything,
> even when CGI is still in its infancy.  What happens in a year when folks want
> to add something and CGI is well entrenched?

#1 It *DOES* break things, it breaks things that people will want to do in
   the future, it's a kludge and it's not orthogonal with the rest of the
   system; that's why I'm against it.

#2 You have not presented a single valid case for ';' being part of the
   CGI spec and we have presented several arguments against it.

   Server side includes are *NOT* part of the CGI spec and would require
   seperate consideration.  Perhaps Rob will address this issue.
   This *is* a good point, and something that needs to be addressed but
   it doesn't affect CGI (not directly anyway).

> Of course, if your running on a RS/6000 with lots of memory (as I am) spawning
> and executing are virtually instantaneous as its all out of ram, and nothing
> ever hits the disk or network.
...
> It is rediculus that to serve up documents I must spawn a huge scripting
> language to emulate a server (which I already have running!).
Do I detect a contradiction here? :-)

--sanders



From henrich@rs560.cl.msu.edu  Fri Dec 31 18:18:33 1993 -0500 (EST)
Message-Id: <9312312318.AA24989@rs560.cl.msu.edu>
Date: Fri, 31 Dec 1993 18:18:33 -0500 (EST)
From: henrich@rs560.cl.msu.edu (Charles Henrich)
Subject: Re: Semicolon's for all

> > and executing are virtually instantaneous as its all out of ram, and nothi
ng
>
> > ever hits the disk or network.
> ...
> > It is rediculus that to serve up documents I must spawn a huge scripting
> > language to emulate a server (which I already have running!).

> Do I detect a contradiction here? :-)

Perl is several order's of magnitude larger than anything I spawn, but you
deserve a point. :)

-Crh

    Charles Henrich     Michigan State University     henrich@crh.cl.msu.edu

                     http://rs560.msu.edu/~henrich/



